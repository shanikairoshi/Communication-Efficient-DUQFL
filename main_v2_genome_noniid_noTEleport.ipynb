{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shanikairoshi/Communication-Efficient-DUQFL/blob/main/main_v2_genome_noniid_noTEleport.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bee84f36",
      "metadata": {
        "id": "bee84f36"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bc18ac0f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc18ac0f",
        "outputId": "cc90cb3e-88d8-45b2-bcb2-89b53f9212ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: genomic-benchmarks in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: biopython>=1.79 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (1.85)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (2.32.4)\n",
            "Requirement already satisfied: pip>=20.0.1 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (24.1.2)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (4.67.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (6.0.3)\n",
            "Requirement already satisfied: gdown>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (5.2.0)\n",
            "Requirement already satisfied: yarl in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (1.20.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown>=4.2.0->genomic-benchmarks) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown>=4.2.0->genomic-benchmarks) (3.19.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->genomic-benchmarks) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->genomic-benchmarks) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->genomic-benchmarks) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->genomic-benchmarks) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->genomic-benchmarks) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->genomic-benchmarks) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->genomic-benchmarks) (2025.8.3)\n",
            "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.12/dist-packages (from yarl->genomic-benchmarks) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from yarl->genomic-benchmarks) (0.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.4->genomic-benchmarks) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown>=4.2.0->genomic-benchmarks) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown>=4.2.0->genomic-benchmarks) (4.15.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=4.2.0->genomic-benchmarks) (1.7.1)\n",
            "Requirement already satisfied: qiskit in /usr/local/lib/python3.12/dist-packages (1.4.4)\n",
            "Requirement already satisfied: qiskit_machine_learning in /usr/local/lib/python3.12/dist-packages (0.8.4)\n",
            "Requirement already satisfied: qiskit_algorithms in /usr/local/lib/python3.12/dist-packages (0.4.0)\n",
            "Requirement already satisfied: qiskit-aer in /usr/local/lib/python3.12/dist-packages (0.17.2)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.17.1)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.12/dist-packages (from qiskit) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.12/dist-packages (from qiskit) (1.15.3)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.12/dist-packages (from qiskit) (1.13.3)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.3.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from qiskit) (2.9.0.post0)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from qiskit) (5.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qiskit) (4.15.0)\n",
            "Requirement already satisfied: symengine<0.14,>=0.11 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.13.0)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.12/dist-packages (from qiskit_machine_learning) (1.6.1)\n",
            "Requirement already satisfied: setuptools>=40.1 in /usr/local/lib/python3.12/dist-packages (from qiskit_machine_learning) (75.2.0)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.12/dist-packages (from qiskit-aer) (5.9.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->qiskit_machine_learning) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->qiskit_machine_learning) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# %%capture\n",
        "!pip install genomic-benchmarks\n",
        "!pip install qiskit qiskit_machine_learning qiskit_algorithms qiskit-aer\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2d53c335",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d53c335",
        "outputId": "9f37e077-32ef-4ed5-8410-a5db07b5fbc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5291b3a7",
      "metadata": {
        "id": "5291b3a7"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "PROJ = Path.cwd() / \"tduqfl_Project_AGG\"\n",
        "if str(PROJ) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJ))\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Teleportation/tduqfl_Project_AGG/tDuQFL_Project')\n",
        "# ─── 5. Assemble filenames for each artifact ─────────────────────────────────\n",
        "#drive_root = \"/content/drive/MyDrive/Teleportation/tduqfl_Project_AGG/tDuQFL_Project/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "rWyc1s9R5eyJ"
      },
      "id": "rWyc1s9R5eyJ",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c245a1fd",
      "metadata": {
        "id": "c245a1fd"
      },
      "outputs": [],
      "source": [
        "from common.imports import *\n",
        "#from configs.dataset_genome import *     # swap to other configs as needed\n",
        "from io_utils.naming import stamp_now, flags, build_param_str, make_filenames\n",
        "from data.preprocess_genome import load_and_prepare_dataset\n",
        "from configs.base_config import *\n",
        "from data.splitters import split_dataset_for_epochs\n",
        "from configs.base_config import (\n",
        "    num_clients, num_epochs, samples_per_epoch,\n",
        "    global_seed,client_hparams_csv_file,split_type,dataset_name,use_teleportation,use_noise,num_federated_layers\n",
        ")\n",
        "\n",
        "start_str, date_str = stamp_now()\n",
        "teleport_pl, noise_pl = flags(use_teleportation, use_noise)\n",
        "param_str = build_param_str(num_clients, num_federated_layers, num_deep_unfolding_iterations,\n",
        "                            initial_learning_rate, initial_perturbation)\n",
        "\n",
        "# Modified make_filenames to include split_type\n",
        "best_client_csv_file, global_csv_file, local_csv_file, validation_csv_file = make_filenames(\n",
        "    drive_root, dataset_name, split_type, date_str, teleport_pl, noise_pl, param_str\n",
        ")\n",
        "from io_utils.csv_logger import init_local_csv, init_best_csv, init_validation_csv\n",
        "\n",
        "# Create folders + write headers\n",
        "init_best_csv(best_client_csv_file)\n",
        "\n",
        "local_headers = [\n",
        "    \"Federated Round\", \"Client Number\", \"Iteration\",\n",
        "    \"Objective Function Value\", \"Training Accuracy\", \"Test Accuracy\",\n",
        "    \"Learning Rate\", \"Perturbation\"\n",
        "]\n",
        "init_local_csv(local_csv_file, local_headers)\n",
        "\n",
        "init_validation_csv(validation_csv_file)\n",
        "\n",
        "# Do NOT pre-init global_csv_file here because your save_accuracies_to_csv()\n",
        "# already writes the header each time it runs (in 'w' mode)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "324178e0",
      "metadata": {
        "id": "324178e0"
      },
      "source": [
        "Load and Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d512e2a5",
      "metadata": {
        "id": "d512e2a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "6eabb26f-32bd-49d5-9738-08cc35f4561e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x450 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "\n",
        "np_train_data, np_test_data = load_and_prepare_dataset(word_size, global_seed)\n",
        "\n",
        "# 2) Compute feasible epoch capacity and cap both epochs and rounds\n",
        "N_train = len(np_train_data)\n",
        "train_capacity = N_train // (num_clients * samples_per_epoch)\n",
        "num_epochs_eff = max(1, min(num_epochs, train_capacity))\n",
        "\n",
        "if train_capacity == 0:\n",
        "    raise ValueError(\n",
        "        f\"Not enough training samples ({N_train}) for \"\n",
        "        f\"{num_clients=} × {samples_per_epoch=} per epoch. \"\n",
        "        \"Reduce samples_per_epoch or num_clients, or enable resampling.\"\n",
        "    )\n",
        "\n",
        "num_federated_layers_eff = min(num_federated_layers, num_epochs_eff)\n",
        "\n",
        "# Build clients\n",
        "if split_type.lower() == \"iid\":\n",
        "    from data.splitters import split_dataset_for_epochs\n",
        "    clients = split_dataset_for_epochs(\n",
        "        num_clients=num_clients,\n",
        "        num_epochs=num_epochs_eff,             # or num_epochs\n",
        "        train_data=np_train_data,\n",
        "        test_data=np_test_data,\n",
        "        samples_per_epoch=samples_per_epoch,\n",
        "    )\n",
        "elif split_type.lower() in {\"noniid\", \"non-iid\", \"non_iid\"}:\n",
        "    from data.noniid import make_non_iid_clients\n",
        "    clients = make_non_iid_clients(\n",
        "        train_data=np_train_data,\n",
        "        test_data=np_test_data,\n",
        "        num_clients=num_clients,\n",
        "        num_epochs=num_epochs_eff,             # or num_epochs\n",
        "        samples_per_epoch=samples_per_epoch,\n",
        "        non_iid_ratio=0.8,                     # tune as needed\n",
        "        quantity_variation=0.5,                # tune as needed\n",
        "        seed=global_seed,\n",
        "        plot=True\n",
        "    )\n",
        "else:\n",
        "    raise ValueError(f\"Unknown split_type: {split_type}\")\n",
        "\n",
        "'''\n",
        "clients = split_dataset_for_epochs(\n",
        "    num_clients=num_clients, num_epochs=num_epochs,\n",
        "    train_data=np_train_data, test_data=np_test_data,\n",
        "    samples_per_epoch=samples_per_epoch\n",
        ")\n",
        "'''\n",
        "# validation/tables\n",
        "test_sequences = np.array([d[\"sequence\"] for d in np_test_data])\n",
        "test_labels    = np.array([d[\"label\"]    for d in np_test_data])\n",
        "X_val, y_val   = test_sequences, test_labels\n",
        "\n",
        "# derive num_features once\n",
        "if clients and clients[0].data and clients[0].data[0]:\n",
        "    num_features = clients[0].data[0][0]['sequence'].shape[0]\n",
        "else:\n",
        "    raise RuntimeError(\"Empty client data – check splitting indices.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cf7dd9c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf7dd9c0",
        "outputId": "9a46a98e-0885-4062-8fd6-c049e68aaf69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] num_features = 5\n"
          ]
        }
      ],
      "source": [
        "# Infer num_features from the first available sample in clients\n",
        "def infer_num_features_from_clients(clients):\n",
        "    for c in clients:\n",
        "        for epoch_data in c.data:              # list of samples for that epoch\n",
        "            if not epoch_data:\n",
        "                continue\n",
        "            sample = epoch_data[0]\n",
        "            if \"sequence\" in sample:           # your Genome pipeline\n",
        "                arr = np.asarray(sample[\"sequence\"])\n",
        "                return int(arr.size)\n",
        "            if \"features\" in sample:           # some other pipelines\n",
        "                arr = np.asarray(sample[\"features\"])\n",
        "                return int(arr.size)\n",
        "            if \"image\" in sample:              # e.g., MNIST before flatten\n",
        "                arr = np.asarray(sample[\"image\"]).reshape(-1)\n",
        "                return int(arr.size)\n",
        "            # add any other key you use\n",
        "    raise RuntimeError(\"Could not infer num_features: no samples found.\")\n",
        "\n",
        "num_features = infer_num_features_from_clients(clients)\n",
        "print(f\"[info] num_features = {num_features}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d847bd00",
      "metadata": {
        "id": "d847bd00"
      },
      "source": [
        "run federated loop and plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "bbc26297",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bbc26297",
        "outputId": "ef57ef2c-eebe-4577-fe24-e704d433fd71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 0] Teleportation OFF | Aggregation=best\n",
            "[round 0 | client 0] seed LR=0.1400000000 (prev=0.1400000000), seed PERT=0.1400000000 (prev=0.1400000000), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.500761 step=0.01057 g_raw=+0.003 g_sm=+0.000 acc=1 | LR→0.140280 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#010 loss=0.490114 step=0.04293 g_raw=+0.011 g_sm=+0.006 acc=1 | LR→0.140561 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#015 loss=0.482862 step=0.06813 g_raw=+0.029 g_sm=+0.009 acc=1 | LR→0.140843 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#020 loss=0.478602 step=0.04595 g_raw=+0.017 g_sm=+0.011 acc=1 | LR→0.141125 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#025 loss=0.473317 step=0.02601 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.141408 PERT→0.140001 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1400000000, PERT_used=0.1400000000 → LR_next=0.1414079725, PERT_next=0.1400009396\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1400000000→0.1414079725 PERT 0.1400000000→0.1400009396\n",
            "Training Accuracy: 0.73\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.450407 step=0.09549 g_raw=+0.037 g_sm=+0.020 acc=1 | LR→0.141692 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#035 loss=0.442496 step=0.09972 g_raw=+0.038 g_sm=+0.020 acc=1 | LR→0.141976 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#040 loss=0.435173 step=0.08307 g_raw=+0.032 g_sm=+0.020 acc=1 | LR→0.142261 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#045 loss=0.423909 step=0.007704 g_raw=+0.004 g_sm=+0.021 acc=1 | LR→0.142546 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#050 loss=0.419170 step=0.08436 g_raw=+0.032 g_sm=+0.020 acc=1 | LR→0.142832 PERT→0.140004 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1414079725, PERT_used=0.1400009396 → LR_next=0.1428319123, PERT_next=0.1400036510\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.025 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1414079725→0.1428319123 PERT 0.1400009396→0.1400036510\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.55\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.414577 step=0.02189 g_raw=+0.011 g_sm=+0.019 acc=1 | LR→0.143118 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#060 loss=0.406465 step=0.07818 g_raw=+0.022 g_sm=+0.020 acc=1 | LR→0.143406 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#065 loss=0.384466 step=0.04537 g_raw=+0.012 g_sm=+0.023 acc=1 | LR→0.143693 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#070 loss=0.379922 step=0.09572 g_raw=+0.037 g_sm=+0.021 acc=1 | LR→0.143982 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#075 loss=0.364149 step=0.009097 g_raw=+0.002 g_sm=+0.022 acc=1 | LR→0.144270 PERT→0.140007 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1428319123, PERT_used=0.1400036510 → LR_next=0.1442703995, PERT_next=0.1400065648\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.022 g_sm_mean=+0.021 acc_ratio=1.00 | LR 0.1428319123→0.1442703995 PERT 0.1400036510→0.1400065648\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.359082 step=0.07524 g_raw=+0.026 g_sm=+0.021 acc=1 | LR→0.144560 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#085 loss=0.352329 step=0.05185 g_raw=+0.027 g_sm=+0.021 acc=1 | LR→0.144850 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#090 loss=0.341765 step=0.09546 g_raw=+0.033 g_sm=+0.021 acc=1 | LR→0.145140 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#095 loss=0.336860 step=0.01769 g_raw=+0.003 g_sm=+0.020 acc=1 | LR→0.145432 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#100 loss=0.335672 step=0.03626 g_raw=+0.016 g_sm=+0.017 acc=1 | LR→0.145723 PERT→0.140009 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1442703995, PERT_used=0.1400065648 → LR_next=0.1457232817, PERT_next=0.1400093901\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.020 acc_ratio=1.00 | LR 0.1442703995→0.1457232817 PERT 0.1400065648→0.1400093901\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.333253 step=0.03559 g_raw=+0.012 g_sm=+0.016 acc=1 | LR→0.146016 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#110 loss=0.329185 step=0.008844 g_raw=+0.002 g_sm=+0.016 acc=1 | LR→0.146308 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#115 loss=0.324435 step=0.02079 g_raw=+0.006 g_sm=+0.016 acc=1 | LR→0.146602 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#120 loss=0.318699 step=0.004138 g_raw=-0.001 g_sm=+0.016 acc=1 | LR→0.146896 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#125 loss=0.312092 step=0.01514 g_raw=+0.007 g_sm=+0.016 acc=1 | LR→0.147190 PERT→0.140012 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1457232817, PERT_used=0.1400093901 → LR_next=0.1471902049, PERT_next=0.1400116539\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1457232817→0.1471902049 PERT 0.1400093901→0.1400116539\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "[round 0 | client 0] final LR=0.1471902049, final PERT=0.1400116539  (ΔLR=+0.0071902049, ΔPERT=+0.0000116539)\n",
            "[round 0 | client 1] seed LR=0.1400000000 (prev=0.1400000000), seed PERT=0.1400000000 (prev=0.1400000000), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.481980 step=0.05203 g_raw=+0.026 g_sm=+0.005 acc=1 | LR→0.140280 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#010 loss=0.467958 step=0.1179 g_raw=+0.051 g_sm=+0.010 acc=1 | LR→0.140561 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#015 loss=0.452874 step=0.03776 g_raw=+0.019 g_sm=+0.014 acc=1 | LR→0.140843 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#020 loss=0.450559 step=0.04001 g_raw=+0.020 g_sm=+0.014 acc=1 | LR→0.141126 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#025 loss=0.424224 step=0.1328 g_raw=+0.049 g_sm=+0.019 acc=1 | LR→0.141409 PERT→0.140001 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1400000000, PERT_used=0.1400000000 → LR_next=0.1414085201, PERT_next=0.1400014818\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.025 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1400000000→0.1414085201 PERT 0.1400000000→0.1400014818\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.421130 step=0.0261 g_raw=+0.007 g_sm=+0.017 acc=1 | LR→0.141692 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#035 loss=0.419065 step=0.003269 g_raw=-0.006 g_sm=+0.015 acc=1 | LR→0.141976 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#040 loss=0.412231 step=0.02589 g_raw=+0.012 g_sm=+0.017 acc=1 | LR→0.142261 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#045 loss=0.395762 step=0.0566 g_raw=+0.019 g_sm=+0.020 acc=1 | LR→0.142546 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#050 loss=0.384917 step=0.1232 g_raw=+0.044 g_sm=+0.021 acc=1 | LR→0.142832 PERT→0.140004 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1414085201, PERT_used=0.1400014818 → LR_next=0.1428323098, PERT_next=0.1400040406\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1414085201→0.1428323098 PERT 0.1400014818→0.1400040406\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.378309 step=0.111 g_raw=+0.037 g_sm=+0.021 acc=1 | LR→0.143119 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#060 loss=0.371198 step=0.1048 g_raw=+0.036 g_sm=+0.020 acc=1 | LR→0.143406 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#065 loss=0.370170 step=0.01232 g_raw=+0.004 g_sm=+0.017 acc=1 | LR→0.143694 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#070 loss=0.365390 step=0.03822 g_raw=+0.011 g_sm=+0.017 acc=1 | LR→0.143982 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#075 loss=0.353704 step=0.03523 g_raw=+0.013 g_sm=+0.019 acc=1 | LR→0.144271 PERT→0.140007 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1428323098, PERT_used=0.1400040406 → LR_next=0.1442705143, PERT_next=0.1400066762\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1428323098→0.1442705143 PERT 0.1400040406→0.1400066762\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.348989 step=0.07888 g_raw=+0.025 g_sm=+0.018 acc=1 | LR→0.144560 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#085 loss=0.346538 step=0.04305 g_raw=+0.013 g_sm=+0.016 acc=1 | LR→0.144850 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#090 loss=0.344486 step=0.002554 g_raw=+0.004 g_sm=+0.015 acc=1 | LR→0.145140 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#095 loss=0.338416 step=0.02962 g_raw=+0.007 g_sm=+0.015 acc=1 | LR→0.145431 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#100 loss=0.333743 step=0.0007042 g_raw=+0.003 g_sm=+0.015 acc=1 | LR→0.145723 PERT→0.140009 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1442705143, PERT_used=0.1400066762 → LR_next=0.1457227903, PERT_next=0.1400089180\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1442705143→0.1457227903 PERT 0.1400066762→0.1400089180\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.332307 step=0.01733 g_raw=+0.011 g_sm=+0.013 acc=1 | LR→0.146015 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#110 loss=0.324441 step=0.0613 g_raw=+0.024 g_sm=+0.015 acc=1 | LR→0.146308 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#115 loss=0.321039 step=0.0356 g_raw=+0.006 g_sm=+0.015 acc=1 | LR→0.146601 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#120 loss=0.320195 step=0.02725 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.146895 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#125 loss=0.315482 step=0.08927 g_raw=+0.030 g_sm=+0.014 acc=1 | LR→0.147189 PERT→0.140011 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1457227903, PERT_used=0.1400089180 → LR_next=0.1471893848, PERT_next=0.1400108738\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1457227903→0.1471893848 PERT 0.1400089180→0.1400108738\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.51\n",
            "[round 0 | client 1] final LR=0.1471893848, final PERT=0.1400108738  (ΔLR=+0.0071893848, ΔPERT=+0.0000108738)\n",
            "[round 0 | client 2] seed LR=0.1400000000 (prev=0.1400000000), seed PERT=0.1400000000 (prev=0.1400000000), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.509494 step=0.001969 g_raw=+0.003 g_sm=+0.004 acc=1 | LR→0.140280 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#010 loss=0.499039 step=0.07248 g_raw=+0.030 g_sm=+0.009 acc=1 | LR→0.140561 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#015 loss=0.474859 step=0.1617 g_raw=+0.060 g_sm=+0.016 acc=1 | LR→0.140843 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#020 loss=0.469731 step=0.009582 g_raw=+0.001 g_sm=+0.016 acc=1 | LR→0.141126 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#025 loss=0.437036 step=0.05397 g_raw=+0.016 g_sm=+0.022 acc=1 | LR→0.141409 PERT→0.140002 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1400000000, PERT_used=0.1400000000 → LR_next=0.1414086631, PERT_next=0.1400016234\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.028 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1400000000→0.1414086631 PERT 0.1400000000→0.1400016234\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.57\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.426366 step=0.06445 g_raw=+0.025 g_sm=+0.022 acc=1 | LR→0.141692 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#035 loss=0.409688 step=0.05285 g_raw=+0.020 g_sm=+0.023 acc=1 | LR→0.141977 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#040 loss=0.404189 step=0.1142 g_raw=+0.043 g_sm=+0.022 acc=1 | LR→0.142262 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#045 loss=0.398397 step=0.06975 g_raw=+0.024 g_sm=+0.021 acc=1 | LR→0.142547 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#050 loss=0.392811 step=0.02302 g_raw=+0.006 g_sm=+0.021 acc=1 | LR→0.142833 PERT→0.140005 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1414086631, PERT_used=0.1400016234 → LR_next=0.1428329867, PERT_next=0.1400047040\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.022 acc_ratio=1.00 | LR 0.1414086631→0.1428329867 PERT 0.1400016234→0.1400047040\n",
            "Training Accuracy: 0.77\n",
            "Test Accuracy: 0.42\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.391797 step=0.05606 g_raw=+0.018 g_sm=+0.017 acc=1 | LR→0.143119 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#060 loss=0.369586 step=0.1323 g_raw=+0.051 g_sm=+0.021 acc=1 | LR→0.143407 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#065 loss=0.366207 step=0.07759 g_raw=+0.033 g_sm=+0.019 acc=1 | LR→0.143694 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#070 loss=0.344879 step=0.008334 g_raw=+0.006 g_sm=+0.020 acc=1 | LR→0.143982 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#075 loss=0.328686 step=0.06741 g_raw=+0.022 g_sm=+0.022 acc=1 | LR→0.144271 PERT→0.140007 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1428329867, PERT_used=0.1400047040 → LR_next=0.1442713623, PERT_next=0.1400074991\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.020 acc_ratio=1.00 | LR 0.1428329867→0.1442713623 PERT 0.1400047040→0.1400074991\n",
            "Training Accuracy: 0.77\n",
            "Test Accuracy: 0.46\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.325949 step=0.02942 g_raw=+0.015 g_sm=+0.020 acc=1 | LR→0.144561 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#085 loss=0.316766 step=0.1319 g_raw=+0.040 g_sm=+0.021 acc=1 | LR→0.144851 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#090 loss=0.307193 step=0.05681 g_raw=+0.018 g_sm=+0.021 acc=1 | LR→0.145141 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#095 loss=0.305107 step=0.002806 g_raw=-0.002 g_sm=+0.018 acc=1 | LR→0.145433 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#100 loss=0.304168 step=0.02714 g_raw=+0.013 g_sm=+0.015 acc=1 | LR→0.145724 PERT→0.140010 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1442713623, PERT_used=0.1400074991 → LR_next=0.1457241419, PERT_next=0.1400102166\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1442713623→0.1457241419 PERT 0.1400074991→0.1400102166\n",
            "Training Accuracy: 0.77\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.295236 step=0.128 g_raw=+0.043 g_sm=+0.017 acc=1 | LR→0.146016 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#110 loss=0.289997 step=0.08834 g_raw=+0.026 g_sm=+0.017 acc=1 | LR→0.146309 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#115 loss=0.287977 step=0.02017 g_raw=+0.005 g_sm=+0.015 acc=1 | LR→0.146603 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.284610 step=0.02307 g_raw=+0.010 g_sm=+0.015 acc=1 | LR→0.146896 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#125 loss=0.283832 step=0.003785 g_raw=+0.000 g_sm=+0.013 acc=1 | LR→0.147191 PERT→0.140012 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1457241419, PERT_used=0.1400102166 → LR_next=0.1471909694, PERT_next=0.1400123812\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1457241419→0.1471909694 PERT 0.1400102166→0.1400123812\n",
            "Training Accuracy: 0.77\n",
            "Test Accuracy: 0.50\n",
            "[round 0 | client 2] final LR=0.1471909694, final PERT=0.1400123812  (ΔLR=+0.0071909694, ΔPERT=+0.0000123812)\n",
            "[round 0 | client 3] seed LR=0.1400000000 (prev=0.1400000000), seed PERT=0.1400000000 (prev=0.1400000000), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.545399 step=0.01819 g_raw=+0.006 g_sm=+0.001 acc=1 | LR→0.140280 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#010 loss=0.527020 step=0.07712 g_raw=+0.034 g_sm=+0.009 acc=1 | LR→0.140561 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#015 loss=0.495644 step=0.06126 g_raw=+0.029 g_sm=+0.016 acc=1 | LR→0.140843 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#020 loss=0.452524 step=0.1105 g_raw=+0.042 g_sm=+0.025 acc=1 | LR→0.141126 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#025 loss=0.438985 step=0.1107 g_raw=+0.037 g_sm=+0.025 acc=1 | LR→0.141409 PERT→0.140002 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1400000000, PERT_used=0.1400000000 → LR_next=0.1414089060, PERT_next=0.1400018639\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.032 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1400000000→0.1414089060 PERT 0.1400000000→0.1400018639\n",
            "Training Accuracy: 0.83\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.421662 step=0.1527 g_raw=+0.056 g_sm=+0.026 acc=1 | LR→0.141693 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#035 loss=0.413644 step=0.03239 g_raw=+0.012 g_sm=+0.025 acc=1 | LR→0.141977 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#040 loss=0.411300 step=0.01227 g_raw=+0.007 g_sm=+0.022 acc=1 | LR→0.142262 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#045 loss=0.395101 step=0.1468 g_raw=+0.050 g_sm=+0.024 acc=1 | LR→0.142547 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#050 loss=0.390419 step=0.1063 g_raw=+0.040 g_sm=+0.022 acc=1 | LR→0.142833 PERT→0.140005 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1414089060, PERT_used=0.1400018639 → LR_next=0.1428334706, PERT_next=0.1400051784\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.024 acc_ratio=1.00 | LR 0.1414089060→0.1428334706 PERT 0.1400018639→0.1400051784\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.382983 step=0.06974 g_raw=+0.020 g_sm=+0.022 acc=1 | LR→0.143120 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#060 loss=0.380575 step=0.007154 g_raw=-0.001 g_sm=+0.019 acc=1 | LR→0.143407 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#065 loss=0.374867 step=0.01855 g_raw=+0.008 g_sm=+0.018 acc=1 | LR→0.143695 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#070 loss=0.370681 step=0.03087 g_raw=+0.013 g_sm=+0.017 acc=1 | LR→0.143983 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#075 loss=0.368533 step=0.04336 g_raw=+0.019 g_sm=+0.016 acc=1 | LR→0.144272 PERT→0.140008 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1428334706, PERT_used=0.1400051784 → LR_next=0.1442717100, PERT_next=0.1400078365\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1428334706→0.1442717100 PERT 0.1400051784→0.1400078365\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.366683 step=0.05363 g_raw=+0.019 g_sm=+0.015 acc=1 | LR→0.144561 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#085 loss=0.360442 step=0.08862 g_raw=+0.029 g_sm=+0.016 acc=1 | LR→0.144851 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#090 loss=0.359081 step=0.02693 g_raw=+0.004 g_sm=+0.014 acc=1 | LR→0.145141 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#095 loss=0.354373 step=0.03618 g_raw=+0.015 g_sm=+0.014 acc=1 | LR→0.145432 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#100 loss=0.353350 step=0.01357 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.145724 PERT→0.140010 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1442717100, PERT_used=0.1400078365 → LR_next=0.1457237818, PERT_next=0.1400098706\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1442717100→0.1457237818 PERT 0.1400078365→0.1400098706\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.351260 step=0.04539 g_raw=+0.017 g_sm=+0.013 acc=1 | LR→0.146016 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#110 loss=0.347643 step=0.04597 g_raw=+0.017 g_sm=+0.013 acc=1 | LR→0.146309 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#115 loss=0.346294 step=0.01038 g_raw=-0.001 g_sm=+0.012 acc=1 | LR→0.146602 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#120 loss=0.345281 step=0.03673 g_raw=+0.013 g_sm=+0.011 acc=1 | LR→0.146896 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#125 loss=0.341720 step=0.01313 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.147190 PERT→0.140012 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1457237818, PERT_used=0.1400098706 → LR_next=0.1471901645, PERT_next=0.1400116155\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1457237818→0.1471901645 PERT 0.1400098706→0.1400116155\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.50\n",
            "[round 0 | client 3] final LR=0.1471901645, final PERT=0.1400116155  (ΔLR=+0.0071901645, ΔPERT=+0.0000116155)\n",
            "[round 0 | client 4] seed LR=0.1400000000 (prev=0.1400000000), seed PERT=0.1400000000 (prev=0.1400000000), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.451999 step=0.1001 g_raw=+0.045 g_sm=+0.004 acc=1 | LR→0.140280 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#010 loss=0.434024 step=0.06687 g_raw=+0.030 g_sm=+0.009 acc=1 | LR→0.140561 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#015 loss=0.409494 step=0.01568 g_raw=+0.002 g_sm=+0.014 acc=1 | LR→0.140843 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#020 loss=0.395361 step=0.06123 g_raw=+0.025 g_sm=+0.017 acc=1 | LR→0.141125 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#025 loss=0.378913 step=0.1091 g_raw=+0.040 g_sm=+0.020 acc=1 | LR→0.141409 PERT→0.140002 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1400000000, PERT_used=0.1400000000 → LR_next=0.1414085437, PERT_next=0.1400015052\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.026 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1400000000→0.1414085437 PERT 0.1400000000→0.1400015052\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.373004 step=0.02054 g_raw=+0.005 g_sm=+0.020 acc=1 | LR→0.141692 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#035 loss=0.367376 step=0.003451 g_raw=+0.000 g_sm=+0.019 acc=1 | LR→0.141976 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#040 loss=0.365308 step=0.03381 g_raw=+0.016 g_sm=+0.017 acc=1 | LR→0.142261 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#045 loss=0.356986 step=0.07708 g_raw=+0.031 g_sm=+0.018 acc=1 | LR→0.142546 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#050 loss=0.354575 step=0.02713 g_raw=-0.000 g_sm=+0.016 acc=1 | LR→0.142832 PERT→0.140004 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1414085437, PERT_used=0.1400015052 → LR_next=0.1428323837, PERT_next=0.1400041130\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1414085437→0.1428323837 PERT 0.1400015052→0.1400041130\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.340786 step=0.01753 g_raw=+0.010 g_sm=+0.019 acc=1 | LR→0.143119 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#060 loss=0.334431 step=0.08333 g_raw=+0.030 g_sm=+0.019 acc=1 | LR→0.143406 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#065 loss=0.328276 step=0.09245 g_raw=+0.033 g_sm=+0.019 acc=1 | LR→0.143694 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#070 loss=0.327074 step=0.03697 g_raw=+0.012 g_sm=+0.017 acc=1 | LR→0.143982 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#075 loss=0.323553 step=0.05143 g_raw=+0.017 g_sm=+0.015 acc=1 | LR→0.144270 PERT→0.140007 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1428323837, PERT_used=0.1400041130 → LR_next=0.1442704370, PERT_next=0.1400066012\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1428323837→0.1442704370 PERT 0.1400041130→0.1400066012\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.314695 step=0.04027 g_raw=+0.011 g_sm=+0.016 acc=1 | LR→0.144560 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#085 loss=0.311113 step=0.01548 g_raw=+0.005 g_sm=+0.015 acc=1 | LR→0.144850 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#090 loss=0.309016 step=0.02638 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.145140 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#095 loss=0.305035 step=0.07376 g_raw=+0.024 g_sm=+0.014 acc=1 | LR→0.145431 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#100 loss=0.300507 step=0.03475 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.145723 PERT→0.140009 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1442704370, PERT_used=0.1400066012 → LR_next=0.1457225290, PERT_next=0.1400086669\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1442704370→0.1457225290 PERT 0.1400066012→0.1400086669\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.298490 step=0.05115 g_raw=+0.020 g_sm=+0.013 acc=1 | LR→0.146015 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#110 loss=0.297622 step=0.01337 g_raw=+0.005 g_sm=+0.012 acc=1 | LR→0.146307 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#115 loss=0.296845 step=0.002885 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.146601 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#120 loss=0.293247 step=0.06081 g_raw=+0.020 g_sm=+0.011 acc=1 | LR→0.146894 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#125 loss=0.289683 step=0.08846 g_raw=+0.030 g_sm=+0.011 acc=1 | LR→0.147189 PERT→0.140010 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1457225290, PERT_used=0.1400086669 → LR_next=0.1471887544, PERT_next=0.1400102742\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1457225290→0.1471887544 PERT 0.1400086669→0.1400102742\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "[round 0 | client 4] final LR=0.1471887544, final PERT=0.1400102742  (ΔLR=+0.0071887544, ΔPERT=+0.0000102742)\n",
            "\n",
            "[Round 0] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           3      0.736060      0.504000      0.147190      0.140012\n",
            "           2      0.763675      0.497000      0.147191      0.140012\n",
            "           0      0.785000      0.498000      0.147190      0.140012\n",
            "           1      0.809504      0.506000      0.147189      0.140011\n",
            "           4      0.988466      0.493000      0.147189      0.140010\n",
            "→ [Round 0] action=init_from_best, best_client=3, best_val=0.736060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  10%|█         | 1/10 [19:12<2:52:55, 1152.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   0] acc_g=0.504 (μ=0.500, σ=0.005, FG=0.011) | t=1134.854s, val=0.736 | TEL=FALSE\n",
            "[Round 1] Teleportation OFF | Aggregation=best\n",
            "[round 1 | client 0] seed LR=0.1435951024 (prev=0.1471902049), seed PERT=0.1400058269 (prev=0.1400116539), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.527977 step=0.07879 g_raw=+0.031 g_sm=+0.004 acc=1 | LR→0.143883 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.510686 step=0.1769 g_raw=+0.066 g_sm=+0.010 acc=1 | LR→0.144171 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.492599 step=0.07595 g_raw=+0.024 g_sm=+0.015 acc=1 | LR→0.144460 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.467268 step=0.03375 g_raw=+0.011 g_sm=+0.020 acc=1 | LR→0.144750 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.456619 step=0.09559 g_raw=+0.037 g_sm=+0.021 acc=1 | LR→0.145040 PERT→0.140008 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1435951024, PERT_used=0.1400058269 → LR_next=0.1450400156, PERT_next=0.1400075243\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.028 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1435951024→0.1450400156 PERT 0.1400058269→0.1400075243\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.448075 step=0.01906 g_raw=+0.009 g_sm=+0.021 acc=1 | LR→0.145331 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.440047 step=0.08565 g_raw=+0.030 g_sm=+0.021 acc=1 | LR→0.145623 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.416406 step=0.01034 g_raw=+0.011 g_sm=+0.025 acc=1 | LR→0.145915 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.411359 step=0.01192 g_raw=+0.005 g_sm=+0.022 acc=1 | LR→0.146208 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.406699 step=0.06761 g_raw=+0.025 g_sm=+0.021 acc=1 | LR→0.146501 PERT→0.140011 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1450400156, PERT_used=0.1400075243 → LR_next=0.1465009596, PERT_next=0.1400106472\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.022 g_sm_mean=+0.022 acc_ratio=1.00 | LR 0.1450400156→0.1465009596 PERT 0.1400075243→0.1400106472\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.401724 step=0.007775 g_raw=+0.003 g_sm=+0.020 acc=1 | LR→0.146795 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#060 loss=0.397609 step=0.02542 g_raw=+0.005 g_sm=+0.018 acc=1 | LR→0.147089 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#065 loss=0.388502 step=0.023 g_raw=+0.015 g_sm=+0.020 acc=1 | LR→0.147384 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#070 loss=0.383616 step=0.0717 g_raw=+0.024 g_sm=+0.020 acc=1 | LR→0.147680 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#075 loss=0.373347 step=0.1382 g_raw=+0.047 g_sm=+0.021 acc=1 | LR→0.147976 PERT→0.140013 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1465009596, PERT_used=0.1400106472 → LR_next=0.1479762461, PERT_next=0.1400134170\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.020 acc_ratio=1.00 | LR 0.1465009596→0.1479762461 PERT 0.1400106472→0.1400134170\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.365139 step=0.01834 g_raw=+0.001 g_sm=+0.019 acc=1 | LR→0.148273 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#085 loss=0.359393 step=0.006842 g_raw=+0.001 g_sm=+0.018 acc=1 | LR→0.148571 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#090 loss=0.355786 step=0.03846 g_raw=+0.012 g_sm=+0.017 acc=1 | LR→0.148868 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#095 loss=0.343656 step=0.1205 g_raw=+0.038 g_sm=+0.020 acc=1 | LR→0.149167 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#100 loss=0.338317 step=0.02783 g_raw=+0.006 g_sm=+0.019 acc=1 | LR→0.149466 PERT→0.140016 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1479762461, PERT_used=0.1400134170 → LR_next=0.1494662735, PERT_next=0.1400160787\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1479762461→0.1494662735 PERT 0.1400134170→0.1400160787\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.332434 step=0.08302 g_raw=+0.029 g_sm=+0.018 acc=1 | LR→0.149766 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#110 loss=0.330307 step=0.008771 g_raw=+0.007 g_sm=+0.017 acc=1 | LR→0.150066 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#115 loss=0.326882 step=0.01214 g_raw=+0.008 g_sm=+0.016 acc=1 | LR→0.150367 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#120 loss=0.322690 step=0.06085 g_raw=+0.022 g_sm=+0.016 acc=1 | LR→0.150669 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#125 loss=0.316396 step=0.1323 g_raw=+0.045 g_sm=+0.016 acc=1 | LR→0.150971 PERT→0.140018 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1494662735, PERT_used=0.1400160787 → LR_next=0.1509709093, PERT_next=0.1400183740\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1494662735→0.1509709093 PERT 0.1400160787→0.1400183740\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "[round 1 | client 0] final LR=0.1509709093, final PERT=0.1400183740  (ΔLR=+0.0073758069, ΔPERT=+0.0000125471)\n",
            "[round 1 | client 1] seed LR=0.1435946924 (prev=0.1471893848), seed PERT=0.1400054369 (prev=0.1400108738), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.471499 step=0.1083 g_raw=+0.035 g_sm=+0.007 acc=1 | LR→0.143882 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.462996 step=0.05574 g_raw=+0.022 g_sm=+0.011 acc=1 | LR→0.144171 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.456391 step=0.08535 g_raw=+0.033 g_sm=+0.013 acc=1 | LR→0.144460 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.448199 step=0.04326 g_raw=+0.018 g_sm=+0.015 acc=1 | LR→0.144749 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.434282 step=0.04446 g_raw=+0.012 g_sm=+0.018 acc=1 | LR→0.145039 PERT→0.140007 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1435946924, PERT_used=0.1400054369 → LR_next=0.1450394816, PERT_next=0.1400070186\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.025 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1435946924→0.1450394816 PERT 0.1400054369→0.1400070186\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.421034 step=0.159 g_raw=+0.063 g_sm=+0.019 acc=1 | LR→0.145330 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.415976 step=0.04924 g_raw=+0.018 g_sm=+0.019 acc=1 | LR→0.145622 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.412240 step=0.009392 g_raw=+0.005 g_sm=+0.017 acc=1 | LR→0.145914 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.402254 step=0.01466 g_raw=+0.009 g_sm=+0.018 acc=1 | LR→0.146207 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.387763 step=0.06584 g_raw=+0.025 g_sm=+0.020 acc=1 | LR→0.146500 PERT→0.140010 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1450394816, PERT_used=0.1400070186 → LR_next=0.1464998737, PERT_next=0.1400096191\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1450394816→0.1464998737 PERT 0.1400070186→0.1400096191\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.370522 step=0.08099 g_raw=+0.030 g_sm=+0.023 acc=1 | LR→0.146794 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.355110 step=0.03641 g_raw=+0.015 g_sm=+0.023 acc=1 | LR→0.147088 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.342862 step=0.145 g_raw=+0.044 g_sm=+0.024 acc=1 | LR→0.147384 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#070 loss=0.331962 step=0.0004358 g_raw=+0.000 g_sm=+0.023 acc=1 | LR→0.147679 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#075 loss=0.324467 step=0.0318 g_raw=+0.018 g_sm=+0.022 acc=1 | LR→0.147976 PERT→0.140013 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1464998737, PERT_used=0.1400096191 → LR_next=0.1479756054, PERT_next=0.1400128206\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.024 g_sm_mean=+0.023 acc_ratio=1.00 | LR 0.1464998737→0.1479756054 PERT 0.1400096191→0.1400128206\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.312975 step=0.06924 g_raw=+0.021 g_sm=+0.022 acc=1 | LR→0.148273 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#085 loss=0.304441 step=0.1069 g_raw=+0.032 g_sm=+0.022 acc=1 | LR→0.148570 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#090 loss=0.303813 step=0.0137 g_raw=+0.005 g_sm=+0.019 acc=1 | LR→0.148868 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#095 loss=0.298106 step=0.07742 g_raw=+0.028 g_sm=+0.018 acc=1 | LR→0.149167 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#100 loss=0.295500 step=0.05171 g_raw=+0.015 g_sm=+0.016 acc=1 | LR→0.149466 PERT→0.140016 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1479756054, PERT_used=0.1400128206 → LR_next=0.1494657549, PERT_next=0.1400156027\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.020 acc_ratio=1.00 | LR 0.1479756054→0.1494657549 PERT 0.1400128206→0.1400156027\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.294061 step=0.02329 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.149765 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#110 loss=0.293351 step=0.01049 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.150066 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#115 loss=0.292268 step=0.00339 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.150366 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#120 loss=0.291760 step=0.01852 g_raw=+0.007 g_sm=+0.010 acc=1 | LR→0.150668 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#125 loss=0.291055 step=0.02559 g_raw=+0.012 g_sm=+0.009 acc=1 | LR→0.150970 PERT→0.140017 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1494657549, PERT_used=0.1400156027 → LR_next=0.1509696805, PERT_next=0.1400172441\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.006 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1494657549→0.1509696805 PERT 0.1400156027→0.1400172441\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.51\n",
            "[round 1 | client 1] final LR=0.1509696805, final PERT=0.1400172441  (ΔLR=+0.0073749881, ΔPERT=+0.0000118072)\n",
            "[round 1 | client 2] seed LR=0.1435954847 (prev=0.1471909694), seed PERT=0.1400061906 (prev=0.1400123812), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.463854 step=0.1458 g_raw=+0.057 g_sm=+0.006 acc=1 | LR→0.143883 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.427444 step=0.1089 g_raw=+0.040 g_sm=+0.014 acc=1 | LR→0.144171 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.418961 step=0.04076 g_raw=+0.017 g_sm=+0.016 acc=1 | LR→0.144461 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.401014 step=0.08265 g_raw=+0.029 g_sm=+0.019 acc=1 | LR→0.144750 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.395496 step=0.06277 g_raw=+0.019 g_sm=+0.019 acc=1 | LR→0.145041 PERT→0.140008 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1435954847, PERT_used=0.1400061906 → LR_next=0.1450405851, PERT_next=0.1400080650\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.028 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1435954847→0.1450405851 PERT 0.1400061906→0.1400080650\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.392364 step=0.009233 g_raw=+0.003 g_sm=+0.017 acc=1 | LR→0.145331 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.383620 step=0.07781 g_raw=+0.025 g_sm=+0.017 acc=1 | LR→0.145623 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.380385 step=0.06368 g_raw=+0.020 g_sm=+0.016 acc=1 | LR→0.145915 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#045 loss=0.373907 step=0.03062 g_raw=+0.013 g_sm=+0.016 acc=1 | LR→0.146208 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.364572 step=0.07385 g_raw=+0.024 g_sm=+0.017 acc=1 | LR→0.146501 PERT→0.140010 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1450405851, PERT_used=0.1400080650 → LR_next=0.1465007095, PERT_next=0.1400103990\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1450405851→0.1465007095 PERT 0.1400080650→0.1400103990\n",
            "Training Accuracy: 0.77\n",
            "Test Accuracy: 0.57\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.352995 step=0.1275 g_raw=+0.043 g_sm=+0.019 acc=1 | LR→0.146795 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#060 loss=0.351697 step=0.01108 g_raw=+0.004 g_sm=+0.016 acc=1 | LR→0.147089 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.350162 step=0.01133 g_raw=+0.003 g_sm=+0.014 acc=1 | LR→0.147384 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#070 loss=0.346946 step=0.01619 g_raw=+0.003 g_sm=+0.013 acc=1 | LR→0.147679 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#075 loss=0.343696 step=0.002238 g_raw=-0.002 g_sm=+0.013 acc=1 | LR→0.147975 PERT→0.140013 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1465007095, PERT_used=0.1400103990 → LR_next=0.1479753723, PERT_next=0.1400125812\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1465007095→0.1479753723 PERT 0.1400103990→0.1400125812\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.58\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.342257 step=0.0177 g_raw=+0.005 g_sm=+0.012 acc=1 | LR→0.148272 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#085 loss=0.339269 step=0.01234 g_raw=+0.000 g_sm=+0.011 acc=1 | LR→0.148569 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#090 loss=0.338576 step=0.01359 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.148867 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#095 loss=0.337538 step=0.008265 g_raw=+0.001 g_sm=+0.010 acc=1 | LR→0.149165 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#100 loss=0.337248 step=0.007487 g_raw=+0.002 g_sm=+0.008 acc=1 | LR→0.149464 PERT→0.140014 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1479753723, PERT_used=0.1400125812 → LR_next=0.1494641631, PERT_next=0.1400140927\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1479753723→0.1494641631 PERT 0.1400125812→0.1400140927\n",
            "Training Accuracy: 0.77\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.337104 step=0.007929 g_raw=+0.001 g_sm=+0.006 acc=1 | LR→0.149764 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#110 loss=0.336896 step=0.005302 g_raw=-0.001 g_sm=+0.006 acc=1 | LR→0.150064 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#115 loss=0.335983 step=0.0402 g_raw=+0.008 g_sm=+0.006 acc=1 | LR→0.150364 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#120 loss=0.335175 step=0.02029 g_raw=+0.010 g_sm=+0.006 acc=1 | LR→0.150665 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#125 loss=0.333601 step=0.01607 g_raw=+0.006 g_sm=+0.007 acc=1 | LR→0.150967 PERT→0.140015 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1494641631, PERT_used=0.1400140927 → LR_next=0.1509672502, PERT_next=0.1400149712\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.005 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1494641631→0.1509672502 PERT 0.1400140927→0.1400149712\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.56\n",
            "[round 1 | client 2] final LR=0.1509672502, final PERT=0.1400149712  (ΔLR=+0.0073717654, ΔPERT=+0.0000087807)\n",
            "[round 1 | client 3] seed LR=0.1435950823 (prev=0.1471901645), seed PERT=0.1400058078 (prev=0.1400116155), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.446761 step=0.07338 g_raw=+0.021 g_sm=+0.005 acc=1 | LR→0.143883 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.443218 step=0.0828 g_raw=+0.029 g_sm=+0.007 acc=1 | LR→0.144171 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.435927 step=0.06138 g_raw=+0.024 g_sm=+0.011 acc=1 | LR→0.144460 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.431294 step=0.05181 g_raw=+0.019 g_sm=+0.012 acc=1 | LR→0.144749 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.421779 step=0.005021 g_raw=+0.001 g_sm=+0.014 acc=1 | LR→0.145039 PERT→0.140007 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1435950823, PERT_used=0.1400058078 → LR_next=0.1450394996, PERT_next=0.1400070267\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1435950823→0.1450394996 PERT 0.1400058078→0.1400070267\n",
            "Training Accuracy: 0.73\n",
            "Test Accuracy: 0.44\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.412180 step=0.03275 g_raw=+0.014 g_sm=+0.017 acc=1 | LR→0.145330 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.405733 step=0.02012 g_raw=+0.005 g_sm=+0.016 acc=1 | LR→0.145622 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.402754 step=0.06623 g_raw=+0.027 g_sm=+0.016 acc=1 | LR→0.145914 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.398955 step=0.0196 g_raw=+0.011 g_sm=+0.016 acc=1 | LR→0.146206 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.382783 step=0.1798 g_raw=+0.062 g_sm=+0.019 acc=1 | LR→0.146500 PERT→0.140009 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1450394996, PERT_used=0.1400070267 → LR_next=0.1464995751, PERT_next=0.1400093245\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1450394996→0.1464995751 PERT 0.1400070267→0.1400093245\n",
            "Training Accuracy: 0.77\n",
            "Test Accuracy: 0.47\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.379068 step=0.007065 g_raw=+0.002 g_sm=+0.018 acc=1 | LR→0.146793 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.373993 step=0.05841 g_raw=+0.021 g_sm=+0.017 acc=1 | LR→0.147088 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.368338 step=0.01378 g_raw=+0.004 g_sm=+0.017 acc=1 | LR→0.147383 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#070 loss=0.367510 step=0.04444 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.147678 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#075 loss=0.362329 step=0.04266 g_raw=+0.018 g_sm=+0.015 acc=1 | LR→0.147974 PERT→0.140012 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1464995751, PERT_used=0.1400093245 → LR_next=0.1479743853, PERT_next=0.1400116568\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1464995751→0.1479743853 PERT 0.1400093245→0.1400116568\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.359410 step=0.02335 g_raw=+0.003 g_sm=+0.014 acc=1 | LR→0.148271 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#085 loss=0.354580 step=0.0521 g_raw=+0.022 g_sm=+0.015 acc=1 | LR→0.148568 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#090 loss=0.351270 step=0.04634 g_raw=+0.021 g_sm=+0.015 acc=1 | LR→0.148866 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#095 loss=0.348101 step=0.02618 g_raw=+0.012 g_sm=+0.014 acc=1 | LR→0.149165 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#100 loss=0.346356 step=0.02015 g_raw=+0.005 g_sm=+0.013 acc=1 | LR→0.149464 PERT→0.140014 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1479743853, PERT_used=0.1400116568 → LR_next=0.1494636916, PERT_next=0.1400136605\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1479743853→0.1494636916 PERT 0.1400116568→0.1400136605\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.343515 step=0.01046 g_raw=-0.005 g_sm=+0.012 acc=1 | LR→0.149763 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#110 loss=0.343184 step=0.01982 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.150063 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#115 loss=0.342322 step=0.009628 g_raw=+0.003 g_sm=+0.009 acc=1 | LR→0.150364 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#120 loss=0.340042 step=0.007565 g_raw=+0.003 g_sm=+0.009 acc=1 | LR→0.150666 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#125 loss=0.337154 step=0.06007 g_raw=+0.019 g_sm=+0.010 acc=1 | LR→0.150967 PERT→0.140015 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1494636916, PERT_used=0.1400136605 → LR_next=0.1509674652, PERT_next=0.1400151803\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1494636916→0.1509674652 PERT 0.1400136605→0.1400151803\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "[round 1 | client 3] final LR=0.1509674652, final PERT=0.1400151803  (ΔLR=+0.0073723829, ΔPERT=+0.0000093725)\n",
            "[round 1 | client 4] seed LR=0.1435943772 (prev=0.1471887544), seed PERT=0.1400051371 (prev=0.1400102742), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.503650 step=0.115 g_raw=+0.042 g_sm=+0.004 acc=1 | LR→0.143882 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#010 loss=0.487128 step=0.004227 g_raw=-0.003 g_sm=+0.010 acc=1 | LR→0.144170 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#015 loss=0.481895 step=0.1059 g_raw=+0.036 g_sm=+0.011 acc=1 | LR→0.144459 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.476163 step=0.07913 g_raw=+0.020 g_sm=+0.013 acc=1 | LR→0.144749 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#025 loss=0.465248 step=0.08401 g_raw=+0.025 g_sm=+0.016 acc=1 | LR→0.145039 PERT→0.140006 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1435943772, PERT_used=0.1400051371 → LR_next=0.1450388667, PERT_next=0.1400064325\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1435943772→0.1450388667 PERT 0.1400051371→0.1400064325\n",
            "Training Accuracy: 0.54\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.447813 step=0.1376 g_raw=+0.052 g_sm=+0.020 acc=1 | LR→0.145330 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.441486 step=0.1092 g_raw=+0.040 g_sm=+0.019 acc=1 | LR→0.145621 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#040 loss=0.437924 step=0.05225 g_raw=+0.016 g_sm=+0.018 acc=1 | LR→0.145913 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.433359 step=0.03269 g_raw=+0.012 g_sm=+0.018 acc=1 | LR→0.146206 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.415362 step=0.07875 g_raw=+0.027 g_sm=+0.021 acc=1 | LR→0.146499 PERT→0.140009 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1450388667, PERT_used=0.1400064325 → LR_next=0.1464992278, PERT_next=0.1400090094\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.022 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1450388667→0.1464992278 PERT 0.1400064325→0.1400090094\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.399263 step=0.04486 g_raw=+0.016 g_sm=+0.022 acc=1 | LR→0.146793 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.384640 step=0.1363 g_raw=+0.046 g_sm=+0.024 acc=1 | LR→0.147088 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.380098 step=0.05416 g_raw=+0.020 g_sm=+0.022 acc=1 | LR→0.147383 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#070 loss=0.373053 step=0.009661 g_raw=+0.002 g_sm=+0.021 acc=1 | LR→0.147679 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#075 loss=0.367340 step=0.09253 g_raw=+0.034 g_sm=+0.020 acc=1 | LR→0.147975 PERT→0.140012 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1464992278, PERT_used=0.1400090094 → LR_next=0.1479748334, PERT_next=0.1400120976\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.022 g_sm_mean=+0.022 acc_ratio=1.00 | LR 0.1464992278→0.1479748334 PERT 0.1400090094→0.1400120976\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.338347 step=0.08778 g_raw=+0.031 g_sm=+0.025 acc=1 | LR→0.148272 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#085 loss=0.336994 step=0.02708 g_raw=+0.011 g_sm=+0.022 acc=1 | LR→0.148569 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#090 loss=0.317085 step=0.06866 g_raw=+0.021 g_sm=+0.024 acc=1 | LR→0.148867 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#095 loss=0.302743 step=0.05713 g_raw=+0.017 g_sm=+0.025 acc=1 | LR→0.149166 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#100 loss=0.296082 step=0.03924 g_raw=+0.011 g_sm=+0.024 acc=1 | LR→0.149466 PERT→0.140015 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1479748334, PERT_used=0.1400120976 → LR_next=0.1494655873, PERT_next=0.1400154532\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.026 g_sm_mean=+0.024 acc_ratio=1.00 | LR 0.1479748334→0.1494655873 PERT 0.1400120976→0.1400154532\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.294536 step=0.01177 g_raw=+0.006 g_sm=+0.020 acc=1 | LR→0.149765 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#110 loss=0.289504 step=0.0713 g_raw=+0.024 g_sm=+0.019 acc=1 | LR→0.150066 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#115 loss=0.287905 step=0.03111 g_raw=+0.006 g_sm=+0.016 acc=1 | LR→0.150367 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#120 loss=0.286617 step=0.03631 g_raw=+0.017 g_sm=+0.014 acc=1 | LR→0.150668 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#125 loss=0.282853 step=0.02268 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.150970 PERT→0.140018 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1494655873, PERT_used=0.1400154532 → LR_next=0.1509703705, PERT_next=0.1400178916\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1494655873→0.1509703705 PERT 0.1400154532→0.1400178916\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.49\n",
            "[round 1 | client 4] final LR=0.1509703705, final PERT=0.1400178916  (ΔLR=+0.0073759933, ΔPERT=+0.0000127545)\n",
            "\n",
            "[Round 1] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           4      0.747263      0.494000      0.150970      0.140018\n",
            "           3      0.768526      0.503000      0.150967      0.140015\n",
            "           2      0.807461      0.562000      0.150967      0.140015\n",
            "           0      0.895542      0.493000      0.150971      0.140018\n",
            "           1      0.898737      0.506000      0.150970      0.140017\n",
            "→ [Round 1] best_client=4, best_val=0.747263, prev_global_val=0.736060, improve=-0.011203, action=hold (τ=0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  20%|██        | 2/10 [38:02<2:31:53, 1139.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   1] acc_g=0.507 (μ=0.512, σ=0.026, FG=0.046) | t=1112.163s, val=0.724 | TEL=FALSE\n",
            "[Round 2] Teleportation OFF | Aggregation=best\n",
            "[round 2 | client 0] seed LR=0.1454854546 (prev=0.1509709093), seed PERT=0.1400091870 (prev=0.1400183740), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.451459 step=0.06698 g_raw=+0.020 g_sm=+0.002 acc=1 | LR→0.145777 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#010 loss=0.430190 step=0.07066 g_raw=+0.029 g_sm=+0.009 acc=1 | LR→0.146069 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#015 loss=0.421633 step=0.02837 g_raw=+0.009 g_sm=+0.010 acc=1 | LR→0.146362 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#020 loss=0.393148 step=0.1881 g_raw=+0.066 g_sm=+0.016 acc=1 | LR→0.146655 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#025 loss=0.378141 step=0.03936 g_raw=+0.012 g_sm=+0.018 acc=1 | LR→0.146949 PERT→0.140011 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1454854546, PERT_used=0.1400091870 → LR_next=0.1469490547, PERT_next=0.1400105656\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.024 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1454854546→0.1469490547 PERT 0.1400091870→0.1400105656\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.351780 step=0.02471 g_raw=+0.010 g_sm=+0.022 acc=1 | LR→0.147244 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#035 loss=0.344719 step=0.01811 g_raw=+0.006 g_sm=+0.021 acc=1 | LR→0.147539 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#040 loss=0.335718 step=0.1066 g_raw=+0.033 g_sm=+0.021 acc=1 | LR→0.147835 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#045 loss=0.324547 step=0.07391 g_raw=+0.024 g_sm=+0.022 acc=1 | LR→0.148132 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#050 loss=0.313889 step=0.1032 g_raw=+0.034 g_sm=+0.023 acc=1 | LR→0.148429 PERT→0.140014 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1469490547, PERT_used=0.1400105656 → LR_next=0.1484291459, PERT_next=0.1400136112\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.025 g_sm_mean=+0.022 acc_ratio=1.00 | LR 0.1469490547→0.1484291459 PERT 0.1400105656→0.1400136112\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.308109 step=0.02532 g_raw=+0.008 g_sm=+0.021 acc=1 | LR→0.148727 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#060 loss=0.301660 step=0.004136 g_raw=+0.001 g_sm=+0.019 acc=1 | LR→0.149025 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#065 loss=0.298557 step=0.01888 g_raw=+0.011 g_sm=+0.017 acc=1 | LR→0.149324 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#070 loss=0.293397 step=0.06058 g_raw=+0.015 g_sm=+0.017 acc=1 | LR→0.149624 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#075 loss=0.287492 step=0.06196 g_raw=+0.020 g_sm=+0.017 acc=1 | LR→0.149924 PERT→0.140016 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1484291459, PERT_used=0.1400136112 → LR_next=0.1499237042, PERT_next=0.1400162454\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1484291459→0.1499237042 PERT 0.1400136112→0.1400162454\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.282483 step=0.03146 g_raw=+0.012 g_sm=+0.017 acc=1 | LR→0.150224 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#085 loss=0.277265 step=0.01673 g_raw=+0.001 g_sm=+0.017 acc=1 | LR→0.150526 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#090 loss=0.273866 step=0.06923 g_raw=+0.021 g_sm=+0.016 acc=1 | LR→0.150827 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#095 loss=0.270966 step=0.01019 g_raw=+0.003 g_sm=+0.015 acc=1 | LR→0.151130 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#100 loss=0.268640 step=0.001502 g_raw=-0.001 g_sm=+0.014 acc=1 | LR→0.151433 PERT→0.140018 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1499237042, PERT_used=0.1400162454 → LR_next=0.1514328540, PERT_next=0.1400184567\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1499237042→0.1514328540 PERT 0.1400162454→0.1400184567\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.266483 step=0.05054 g_raw=+0.020 g_sm=+0.013 acc=1 | LR→0.151736 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#110 loss=0.261238 step=0.06522 g_raw=+0.018 g_sm=+0.014 acc=1 | LR→0.152041 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#115 loss=0.260075 step=0.03182 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.152345 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#120 loss=0.259590 step=0.02116 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.152651 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#125 loss=0.258566 step=0.02483 g_raw=+0.012 g_sm=+0.010 acc=1 | LR→0.152957 PERT→0.140020 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1514328540, PERT_used=0.1400184567 → LR_next=0.1529566737, PERT_next=0.1400201907\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1514328540→0.1529566737 PERT 0.1400184567→0.1400201907\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.49\n",
            "[round 2 | client 0] final LR=0.1529566737, final PERT=0.1400201907  (ΔLR=+0.0074712191, ΔPERT=+0.0000110037)\n",
            "[round 2 | client 1] seed LR=0.1454848402 (prev=0.1509696805), seed PERT=0.1400086220 (prev=0.1400172441), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.462875 step=0.000144 g_raw=-0.003 g_sm=-0.000 acc=1 | LR→0.145776 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#010 loss=0.452742 step=0.04988 g_raw=+0.024 g_sm=+0.006 acc=1 | LR→0.146068 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#015 loss=0.441804 step=0.05045 g_raw=+0.019 g_sm=+0.011 acc=1 | LR→0.146361 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#020 loss=0.431603 step=0.1214 g_raw=+0.045 g_sm=+0.013 acc=1 | LR→0.146654 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#025 loss=0.423158 step=0.06384 g_raw=+0.026 g_sm=+0.015 acc=1 | LR→0.146948 PERT→0.140010 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1454848402, PERT_used=0.1400086220 → LR_next=0.1469481245, PERT_next=0.1400097056\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1454848402→0.1469481245 PERT 0.1400086220→0.1400097056\n",
            "Training Accuracy: 0.77\n",
            "Test Accuracy: 0.48\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.416840 step=0.02601 g_raw=+0.007 g_sm=+0.015 acc=1 | LR→0.147243 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#035 loss=0.399035 step=0.1768 g_raw=+0.066 g_sm=+0.019 acc=1 | LR→0.147538 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#040 loss=0.396376 step=0.05603 g_raw=+0.017 g_sm=+0.018 acc=1 | LR→0.147834 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#045 loss=0.395517 step=0.01086 g_raw=+0.004 g_sm=+0.015 acc=1 | LR→0.148130 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#050 loss=0.389399 step=0.06448 g_raw=+0.025 g_sm=+0.015 acc=1 | LR→0.148427 PERT→0.140012 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1469481245, PERT_used=0.1400097056 → LR_next=0.1484273787, PERT_next=0.1400119705\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1469481245→0.1484273787 PERT 0.1400097056→0.1400119705\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.370918 step=0.01772 g_raw=+0.010 g_sm=+0.018 acc=1 | LR→0.148725 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#060 loss=0.352229 step=0.04051 g_raw=+0.014 g_sm=+0.020 acc=1 | LR→0.149023 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#065 loss=0.345931 step=0.01743 g_raw=+0.006 g_sm=+0.020 acc=1 | LR→0.149322 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#070 loss=0.328493 step=0.1826 g_raw=+0.065 g_sm=+0.021 acc=1 | LR→0.149622 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#075 loss=0.323764 step=0.06485 g_raw=+0.020 g_sm=+0.020 acc=1 | LR→0.149922 PERT→0.140015 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1484273787, PERT_used=0.1400119705 → LR_next=0.1499219836, PERT_next=0.1400146649\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.023 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1484273787→0.1499219836 PERT 0.1400119705→0.1400146649\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.318156 step=0.08351 g_raw=+0.025 g_sm=+0.020 acc=1 | LR→0.150223 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#085 loss=0.315718 step=0.05222 g_raw=+0.018 g_sm=+0.017 acc=1 | LR→0.150524 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#090 loss=0.309192 step=0.07506 g_raw=+0.025 g_sm=+0.018 acc=1 | LR→0.150826 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#095 loss=0.304002 step=0.09927 g_raw=+0.032 g_sm=+0.018 acc=1 | LR→0.151128 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#100 loss=0.297241 step=0.1111 g_raw=+0.041 g_sm=+0.017 acc=1 | LR→0.151431 PERT→0.140017 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1499219836, PERT_used=0.1400146649 → LR_next=0.1514314045, PERT_next=0.1400171427\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1499219836→0.1514314045 PERT 0.1400146649→0.1400171427\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.295861 step=0.05252 g_raw=+0.017 g_sm=+0.016 acc=1 | LR→0.151735 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#110 loss=0.294045 step=0.02576 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.152039 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#115 loss=0.290177 step=0.003774 g_raw=-0.000 g_sm=+0.013 acc=1 | LR→0.152344 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#120 loss=0.285346 step=0.007818 g_raw=+0.006 g_sm=+0.014 acc=1 | LR→0.152649 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#125 loss=0.282695 step=0.07931 g_raw=+0.024 g_sm=+0.013 acc=1 | LR→0.152955 PERT→0.140019 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1514314045, PERT_used=0.1400171427 → LR_next=0.1529554839, PERT_next=0.1400191278\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1514314045→0.1529554839 PERT 0.1400171427→0.1400191278\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.51\n",
            "[round 2 | client 1] final LR=0.1529554839, final PERT=0.1400191278  (ΔLR=+0.0074706437, ΔPERT=+0.0000105058)\n",
            "[round 2 | client 2] seed LR=0.1454836251 (prev=0.1509672502), seed PERT=0.1400074856 (prev=0.1400149712), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.483524 step=0.02434 g_raw=+0.008 g_sm=+0.003 acc=1 | LR→0.145775 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.468236 step=0.1238 g_raw=+0.039 g_sm=+0.010 acc=1 | LR→0.146067 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.462703 step=0.03993 g_raw=+0.018 g_sm=+0.012 acc=1 | LR→0.146360 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.449249 step=0.09069 g_raw=+0.032 g_sm=+0.015 acc=1 | LR→0.146653 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.424930 step=0.2018 g_raw=+0.070 g_sm=+0.020 acc=1 | LR→0.146947 PERT→0.140009 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1454836251, PERT_used=0.1400074856 → LR_next=0.1469472418, PERT_next=0.1400088976\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.025 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1454836251→0.1469472418 PERT 0.1400074856→0.1400088976\n",
            "Training Accuracy: 0.73\n",
            "Test Accuracy: 0.42\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.413872 step=0.08072 g_raw=+0.028 g_sm=+0.019 acc=1 | LR→0.147242 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.406936 step=0.04058 g_raw=+0.008 g_sm=+0.019 acc=1 | LR→0.147537 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#040 loss=0.386800 step=0.04478 g_raw=+0.016 g_sm=+0.022 acc=1 | LR→0.147833 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#045 loss=0.363487 step=0.03537 g_raw=+0.009 g_sm=+0.025 acc=1 | LR→0.148130 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#050 loss=0.348384 step=0.02196 g_raw=+0.008 g_sm=+0.025 acc=1 | LR→0.148427 PERT→0.140012 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1469472418, PERT_used=0.1400088976 → LR_next=0.1484273859, PERT_next=0.1400120103\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.026 g_sm_mean=+0.022 acc_ratio=1.00 | LR 0.1469472418→0.1484273859 PERT 0.1400088976→0.1400120103\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.343912 step=0.06124 g_raw=+0.023 g_sm=+0.023 acc=1 | LR→0.148725 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#060 loss=0.339605 step=0.0838 g_raw=+0.031 g_sm=+0.021 acc=1 | LR→0.149024 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#065 loss=0.330374 step=0.04224 g_raw=+0.009 g_sm=+0.021 acc=1 | LR→0.149323 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#070 loss=0.312223 step=0.04163 g_raw=+0.012 g_sm=+0.023 acc=1 | LR→0.149622 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#075 loss=0.305845 step=0.04735 g_raw=+0.014 g_sm=+0.022 acc=1 | LR→0.149922 PERT→0.140015 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1484273859, PERT_used=0.1400120103 → LR_next=0.1499224829, PERT_next=0.1400151641\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.023 acc_ratio=1.00 | LR 0.1484273859→0.1499224829 PERT 0.1400120103→0.1400151641\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.296382 step=0.01691 g_raw=+0.005 g_sm=+0.022 acc=1 | LR→0.150223 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#085 loss=0.294650 step=0.03924 g_raw=+0.011 g_sm=+0.019 acc=1 | LR→0.150525 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#090 loss=0.293467 step=0.01346 g_raw=+0.005 g_sm=+0.016 acc=1 | LR→0.150827 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#095 loss=0.285679 step=0.02342 g_raw=+0.011 g_sm=+0.017 acc=1 | LR→0.151129 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#100 loss=0.279720 step=0.00796 g_raw=+0.003 g_sm=+0.017 acc=1 | LR→0.151432 PERT→0.140018 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1499224829, PERT_used=0.1400151641 → LR_next=0.1514320986, PERT_next=0.1400178175\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1499224829→0.1514320986 PERT 0.1400151641→0.1400178175\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.276393 step=0.0539 g_raw=+0.016 g_sm=+0.016 acc=1 | LR→0.151736 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#110 loss=0.273972 step=0.04111 g_raw=+0.018 g_sm=+0.015 acc=1 | LR→0.152040 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#115 loss=0.271460 step=0.02176 g_raw=+0.008 g_sm=+0.015 acc=1 | LR→0.152345 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#120 loss=0.270257 step=0.0147 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.152650 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#125 loss=0.266937 step=0.004266 g_raw=+0.008 g_sm=+0.013 acc=1 | LR→0.152956 PERT→0.140020 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1514320986, PERT_used=0.1400178175 → LR_next=0.1529562861, PERT_next=0.1400198952\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1514320986→0.1529562861 PERT 0.1400178175→0.1400198952\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.49\n",
            "[round 2 | client 2] final LR=0.1529562861, final PERT=0.1400198952  (ΔLR=+0.0074726611, ΔPERT=+0.0000124096)\n",
            "[round 2 | client 3] seed LR=0.1454837326 (prev=0.1509674652), seed PERT=0.1400075901 (prev=0.1400151803), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.447987 step=0.03176 g_raw=+0.012 g_sm=+0.002 acc=1 | LR→0.145775 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.441891 step=0.0178 g_raw=+0.009 g_sm=+0.006 acc=1 | LR→0.146067 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.438695 step=0.06378 g_raw=+0.020 g_sm=+0.007 acc=1 | LR→0.146360 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.433307 step=0.01931 g_raw=+0.003 g_sm=+0.009 acc=1 | LR→0.146653 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.420380 step=0.08417 g_raw=+0.027 g_sm=+0.013 acc=1 | LR→0.146947 PERT→0.140008 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1454837326, PERT_used=0.1400075901 → LR_next=0.1469468010, PERT_next=0.1400084787\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1454837326→0.1469468010 PERT 0.1400075901→0.1400084787\n",
            "Training Accuracy: 0.90\n",
            "Test Accuracy: 0.73\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.413754 step=0.08647 g_raw=+0.034 g_sm=+0.014 acc=1 | LR→0.147241 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.409240 step=0.001519 g_raw=-0.004 g_sm=+0.014 acc=1 | LR→0.147537 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.404988 step=0.02861 g_raw=+0.006 g_sm=+0.014 acc=1 | LR→0.147832 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#045 loss=0.400127 step=0.07208 g_raw=+0.026 g_sm=+0.015 acc=1 | LR→0.148129 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.397549 step=0.06071 g_raw=+0.018 g_sm=+0.014 acc=1 | LR→0.148426 PERT→0.140010 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1469468010, PERT_used=0.1400084787 → LR_next=0.1484257758, PERT_next=0.1400104925\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1469468010→0.1484257758 PERT 0.1400084787→0.1400104925\n",
            "Training Accuracy: 0.90\n",
            "Test Accuracy: 0.63\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.393285 step=0.05307 g_raw=+0.015 g_sm=+0.014 acc=1 | LR→0.148723 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#060 loss=0.389931 step=0.007256 g_raw=+0.003 g_sm=+0.014 acc=1 | LR→0.149022 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.372020 step=0.0003112 g_raw=+0.000 g_sm=+0.016 acc=1 | LR→0.149320 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#070 loss=0.366447 step=0.03899 g_raw=+0.008 g_sm=+0.016 acc=1 | LR→0.149620 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#075 loss=0.358820 step=0.05261 g_raw=+0.021 g_sm=+0.017 acc=1 | LR→0.149920 PERT→0.140013 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1484257758, PERT_used=0.1400104925 → LR_next=0.1499198144, PERT_next=0.1400126730\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1484257758→0.1499198144 PERT 0.1400104925→0.1400126730\n",
            "Training Accuracy: 0.87\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.349749 step=0.0306 g_raw=+0.004 g_sm=+0.017 acc=1 | LR→0.150220 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#085 loss=0.346879 step=0.0667 g_raw=+0.022 g_sm=+0.016 acc=1 | LR→0.150522 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#090 loss=0.345751 step=1.92e-05 g_raw=+0.003 g_sm=+0.014 acc=1 | LR→0.150823 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#095 loss=0.339310 step=0.08644 g_raw=+0.026 g_sm=+0.015 acc=1 | LR→0.151126 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#100 loss=0.334095 step=0.08684 g_raw=+0.022 g_sm=+0.016 acc=1 | LR→0.151429 PERT→0.140015 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1499198144, PERT_used=0.1400126730 → LR_next=0.1514288265, PERT_next=0.1400147931\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1499198144→0.1514288265 PERT 0.1400126730→0.1400147931\n",
            "Training Accuracy: 0.87\n",
            "Test Accuracy: 0.57\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.328097 step=0.04502 g_raw=+0.017 g_sm=+0.016 acc=1 | LR→0.151732 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#110 loss=0.325836 step=0.04284 g_raw=+0.016 g_sm=+0.015 acc=1 | LR→0.152037 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#115 loss=0.322269 step=0.007608 g_raw=+0.004 g_sm=+0.014 acc=1 | LR→0.152342 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#120 loss=0.321117 step=0.007465 g_raw=+0.005 g_sm=+0.012 acc=1 | LR→0.152647 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#125 loss=0.319606 step=0.04331 g_raw=+0.013 g_sm=+0.011 acc=1 | LR→0.152953 PERT→0.140017 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1514288265, PERT_used=0.1400147931 → LR_next=0.1529528439, PERT_next=0.1400167451\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1514288265→0.1529528439 PERT 0.1400147931→0.1400167451\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.54\n",
            "[round 2 | client 3] final LR=0.1529528439, final PERT=0.1400167451  (ΔLR=+0.0074691113, ΔPERT=+0.0000091550)\n",
            "[round 2 | client 4] seed LR=0.1454851853 (prev=0.1509703705), seed PERT=0.1400089458 (prev=0.1400178916), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.506410 step=0.113 g_raw=+0.044 g_sm=+0.006 acc=1 | LR→0.145777 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#010 loss=0.489927 step=0.06665 g_raw=+0.020 g_sm=+0.012 acc=1 | LR→0.146069 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#015 loss=0.482575 step=0.1236 g_raw=+0.041 g_sm=+0.014 acc=1 | LR→0.146361 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#020 loss=0.460910 step=0.05333 g_raw=+0.018 g_sm=+0.018 acc=1 | LR→0.146655 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#025 loss=0.460452 step=0.02594 g_raw=+0.012 g_sm=+0.015 acc=1 | LR→0.146949 PERT→0.140011 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1454851853, PERT_used=0.1400089458 → LR_next=0.1469490709, PERT_next=0.1400105991\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.023 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1454851853→0.1469490709 PERT 0.1400089458→0.1400105991\n",
            "Training Accuracy: 0.73\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.444864 step=0.08784 g_raw=+0.030 g_sm=+0.019 acc=1 | LR→0.147244 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#035 loss=0.440087 step=0.03178 g_raw=+0.014 g_sm=+0.018 acc=1 | LR→0.147539 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#040 loss=0.427465 step=0.08902 g_raw=+0.028 g_sm=+0.020 acc=1 | LR→0.147835 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#045 loss=0.420083 step=0.02317 g_raw=+0.009 g_sm=+0.019 acc=1 | LR→0.148132 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#050 loss=0.417345 step=0.06726 g_raw=+0.025 g_sm=+0.018 acc=1 | LR→0.148429 PERT→0.140013 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1469490709, PERT_used=0.1400105991 → LR_next=0.1484286946, PERT_next=0.1400132035\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1469490709→0.1484286946 PERT 0.1400105991→0.1400132035\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.413973 step=0.06652 g_raw=+0.022 g_sm=+0.016 acc=1 | LR→0.148726 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#060 loss=0.407358 step=0.006013 g_raw=+0.005 g_sm=+0.017 acc=1 | LR→0.149025 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#065 loss=0.398367 step=0.02708 g_raw=+0.010 g_sm=+0.018 acc=1 | LR→0.149323 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#070 loss=0.390461 step=0.04458 g_raw=+0.008 g_sm=+0.018 acc=1 | LR→0.149623 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#075 loss=0.387668 step=0.06305 g_raw=+0.017 g_sm=+0.016 acc=1 | LR→0.149923 PERT→0.140016 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1484286946, PERT_used=0.1400132035 → LR_next=0.1499229982, PERT_next=0.1400156041\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1484286946→0.1499229982 PERT 0.1400132035→0.1400156041\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.386948 step=0.03079 g_raw=+0.011 g_sm=+0.013 acc=1 | LR→0.150224 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#085 loss=0.386304 step=0.01819 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.150525 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#090 loss=0.379759 step=0.1127 g_raw=+0.042 g_sm=+0.013 acc=1 | LR→0.150826 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#095 loss=0.377389 step=0.0684 g_raw=+0.017 g_sm=+0.012 acc=1 | LR→0.151129 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#100 loss=0.372528 step=0.07422 g_raw=+0.027 g_sm=+0.013 acc=1 | LR→0.151432 PERT→0.140017 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1499229982, PERT_used=0.1400156041 → LR_next=0.1514316703, PERT_next=0.1400173802\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1499229982→0.1514316703 PERT 0.1400156041→0.1400173802\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.360076 step=0.04984 g_raw=+0.017 g_sm=+0.016 acc=1 | LR→0.151735 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#110 loss=0.359202 step=0.008713 g_raw=+0.006 g_sm=+0.014 acc=1 | LR→0.152040 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#115 loss=0.342090 step=0.1014 g_raw=+0.027 g_sm=+0.017 acc=1 | LR→0.152344 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#120 loss=0.334440 step=0.02222 g_raw=+0.013 g_sm=+0.017 acc=1 | LR→0.152650 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#125 loss=0.331968 step=0.01527 g_raw=+0.012 g_sm=+0.016 acc=1 | LR→0.152956 PERT→0.140020 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1514316703, PERT_used=0.1400173802 → LR_next=0.1529560365, PERT_next=0.1400196254\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1514316703→0.1529560365 PERT 0.1400173802→0.1400196254\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.49\n",
            "[round 2 | client 4] final LR=0.1529560365, final PERT=0.1400196254  (ΔLR=+0.0074708512, ΔPERT=+0.0000106796)\n",
            "\n",
            "[Round 2] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           3      0.688270      0.535000      0.152953      0.140017\n",
            "           4      0.705760      0.494000      0.152956      0.140020\n",
            "           1      0.879696      0.506000      0.152955      0.140019\n",
            "           0      0.991518      0.494000      0.152957      0.140020\n",
            "           2      1.139440      0.495000      0.152956      0.140020\n",
            "→ [Round 2] best_client=3, best_val=0.688270, prev_global_val=0.723870, improve=+0.035600, action=adopt+mix τ=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  30%|███       | 3/10 [58:31<2:17:41, 1180.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   2] acc_g=0.599 (μ=0.505, σ=0.016, FG=0.029) | t=1211.134s, val=0.685 | TEL=FALSE\n",
            "[Round 3] Teleportation OFF | Aggregation=best\n",
            "[round 3 | client 0] seed LR=0.1464783369 (prev=0.1529566737), seed PERT=0.1400100953 (prev=0.1400201907), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.531519 step=0.1916 g_raw=+0.069 g_sm=+0.011 acc=1 | LR→0.146772 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#010 loss=0.503695 step=0.05764 g_raw=+0.029 g_sm=+0.016 acc=1 | LR→0.147066 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#015 loss=0.483498 step=0.009722 g_raw=+0.001 g_sm=+0.020 acc=1 | LR→0.147361 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#020 loss=0.473212 step=0.01367 g_raw=+0.008 g_sm=+0.021 acc=1 | LR→0.147657 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#025 loss=0.459670 step=0.07443 g_raw=+0.024 g_sm=+0.023 acc=1 | LR→0.147953 PERT→0.140012 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1464783369, PERT_used=0.1400100953 → LR_next=0.1479528596, PERT_next=0.1400123579\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.033 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1464783369→0.1479528596 PERT 0.1400100953→0.1400123579\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.447379 step=0.05505 g_raw=+0.018 g_sm=+0.023 acc=1 | LR→0.148250 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#035 loss=0.440061 step=0.05969 g_raw=+0.018 g_sm=+0.022 acc=1 | LR→0.148547 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#040 loss=0.425510 step=0.001917 g_raw=+0.001 g_sm=+0.023 acc=1 | LR→0.148845 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#045 loss=0.412499 step=0.01628 g_raw=+0.009 g_sm=+0.024 acc=1 | LR→0.149144 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#050 loss=0.402976 step=0.05398 g_raw=+0.019 g_sm=+0.023 acc=1 | LR→0.149443 PERT→0.140016 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1479528596, PERT_used=0.1400123579 → LR_next=0.1494433010, PERT_next=0.1400156282\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.024 g_sm_mean=+0.023 acc_ratio=1.00 | LR 0.1479528596→0.1494433010 PERT 0.1400123579→0.1400156282\n",
            "Training Accuracy: 0.75\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.391414 step=0.05436 g_raw=+0.018 g_sm=+0.023 acc=1 | LR→0.149743 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#060 loss=0.381352 step=0.1011 g_raw=+0.029 g_sm=+0.023 acc=1 | LR→0.150044 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#065 loss=0.376674 step=0.06636 g_raw=+0.024 g_sm=+0.021 acc=1 | LR→0.150345 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#070 loss=0.373676 step=0.008563 g_raw=+0.004 g_sm=+0.019 acc=1 | LR→0.150646 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#075 loss=0.369074 step=0.06341 g_raw=+0.020 g_sm=+0.018 acc=1 | LR→0.150948 PERT→0.140019 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1494433010, PERT_used=0.1400156282 → LR_next=0.1509484416, PERT_next=0.1400186062\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.021 acc_ratio=1.00 | LR 0.1494433010→0.1509484416 PERT 0.1400156282→0.1400186062\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.47\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.361734 step=0.05681 g_raw=+0.014 g_sm=+0.018 acc=1 | LR→0.151251 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#085 loss=0.361445 step=0.01095 g_raw=+0.007 g_sm=+0.015 acc=1 | LR→0.151555 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#090 loss=0.354974 step=0.1136 g_raw=+0.036 g_sm=+0.016 acc=1 | LR→0.151858 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#095 loss=0.349530 step=0.04506 g_raw=+0.019 g_sm=+0.016 acc=1 | LR→0.152163 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#100 loss=0.345058 step=0.03493 g_raw=+0.013 g_sm=+0.016 acc=1 | LR→0.152468 PERT→0.140021 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1509484416, PERT_used=0.1400186062 → LR_next=0.1524679615, PERT_next=0.1400208680\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1509484416→0.1524679615 PERT 0.1400186062→0.1400208680\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.343642 step=0.02214 g_raw=+0.007 g_sm=+0.014 acc=1 | LR→0.152774 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#110 loss=0.334140 step=0.09623 g_raw=+0.031 g_sm=+0.016 acc=1 | LR→0.153080 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#115 loss=0.330725 step=0.03123 g_raw=+0.003 g_sm=+0.015 acc=1 | LR→0.153387 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#120 loss=0.330175 step=0.01304 g_raw=+0.010 g_sm=+0.014 acc=1 | LR→0.153694 PERT→0.140023 (scale=0.04)\n",
            "[meta] cb#125 loss=0.328857 step=0.05495 g_raw=+0.013 g_sm=+0.012 acc=1 | LR→0.154003 PERT→0.140023 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1524679615, PERT_used=0.1400208680 → LR_next=0.1540025189, PERT_next=0.1400228946\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1524679615→0.1540025189 PERT 0.1400208680→0.1400228946\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "[round 3 | client 0] final LR=0.1540025189, final PERT=0.1400228946  (ΔLR=+0.0075241820, ΔPERT=+0.0000127993)\n",
            "[round 3 | client 1] seed LR=0.1464777420 (prev=0.1529554839), seed PERT=0.1400095639 (prev=0.1400191278), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.467177 step=0.06252 g_raw=+0.032 g_sm=+0.005 acc=1 | LR→0.146771 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#010 loss=0.461120 step=0.01158 g_raw=+0.007 g_sm=+0.008 acc=1 | LR→0.147065 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#015 loss=0.444768 step=0.1441 g_raw=+0.048 g_sm=+0.013 acc=1 | LR→0.147360 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#020 loss=0.431353 step=0.1015 g_raw=+0.033 g_sm=+0.017 acc=1 | LR→0.147655 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#025 loss=0.425862 step=0.01592 g_raw=+0.005 g_sm=+0.017 acc=1 | LR→0.147951 PERT→0.140011 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1464777420, PERT_used=0.1400095639 → LR_next=0.1479514368, PERT_next=0.1400110487\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.023 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1464777420→0.1479514368 PERT 0.1400095639→0.1400110487\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.420630 step=0.07178 g_raw=+0.027 g_sm=+0.017 acc=1 | LR→0.148248 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#035 loss=0.419161 step=0.01814 g_raw=+0.007 g_sm=+0.015 acc=1 | LR→0.148545 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#040 loss=0.414494 step=0.0326 g_raw=+0.008 g_sm=+0.015 acc=1 | LR→0.148843 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#045 loss=0.379744 step=0.1763 g_raw=+0.058 g_sm=+0.021 acc=1 | LR→0.149142 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#050 loss=0.374028 step=0.1055 g_raw=+0.034 g_sm=+0.020 acc=1 | LR→0.149441 PERT→0.140013 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1479514368, PERT_used=0.1400110487 → LR_next=0.1494409693, PERT_next=0.1400134809\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1479514368→0.1494409693 PERT 0.1400110487→0.1400134809\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.367933 step=0.05137 g_raw=+0.015 g_sm=+0.020 acc=1 | LR→0.149741 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#060 loss=0.357717 step=0.0009824 g_raw=-0.000 g_sm=+0.020 acc=1 | LR→0.150041 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#065 loss=0.353802 step=0.02754 g_raw=+0.005 g_sm=+0.018 acc=1 | LR→0.150342 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#070 loss=0.350611 step=0.04786 g_raw=+0.017 g_sm=+0.017 acc=1 | LR→0.150644 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#075 loss=0.344359 step=0.04461 g_raw=+0.010 g_sm=+0.017 acc=1 | LR→0.150946 PERT→0.140016 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1494409693, PERT_used=0.1400134809 → LR_next=0.1509456985, PERT_next=0.1400160990\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1494409693→0.1509456985 PERT 0.1400134809→0.1400160990\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.340541 step=0.03134 g_raw=+0.009 g_sm=+0.016 acc=1 | LR→0.151248 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#085 loss=0.335984 step=0.06389 g_raw=+0.024 g_sm=+0.016 acc=1 | LR→0.151552 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#090 loss=0.331298 step=0.06008 g_raw=+0.019 g_sm=+0.016 acc=1 | LR→0.151856 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#095 loss=0.326738 step=0.007516 g_raw=+0.004 g_sm=+0.016 acc=1 | LR→0.152160 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#100 loss=0.321166 step=0.04769 g_raw=+0.014 g_sm=+0.016 acc=1 | LR→0.152465 PERT→0.140018 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1509456985, PERT_used=0.1400160990 → LR_next=0.1524652024, PERT_next=0.1400183713\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1509456985→0.1524652024 PERT 0.1400160990→0.1400183713\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.315868 step=0.01516 g_raw=+0.007 g_sm=+0.016 acc=1 | LR→0.152771 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#110 loss=0.314310 step=0.01484 g_raw=+0.006 g_sm=+0.014 acc=1 | LR→0.153077 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#115 loss=0.312765 step=0.04764 g_raw=+0.012 g_sm=+0.013 acc=1 | LR→0.153384 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#120 loss=0.311484 step=0.03071 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.153692 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#125 loss=0.309884 step=0.02698 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.154000 PERT→0.140020 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1524652024, PERT_used=0.1400183713 → LR_next=0.1539995971, PERT_next=0.1400202752\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1524652024→0.1539995971 PERT 0.1400183713→0.1400202752\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.51\n",
            "[round 3 | client 1] final LR=0.1539995971, final PERT=0.1400202752  (ΔLR=+0.0075218551, ΔPERT=+0.0000107113)\n",
            "[round 3 | client 2] seed LR=0.1464781431 (prev=0.1529562861), seed PERT=0.1400099476 (prev=0.1400198952), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.511296 step=0.03358 g_raw=+0.015 g_sm=+0.003 acc=1 | LR→0.146771 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#010 loss=0.484788 step=0.09236 g_raw=+0.039 g_sm=+0.012 acc=1 | LR→0.147066 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#015 loss=0.465859 step=0.05472 g_raw=+0.017 g_sm=+0.017 acc=1 | LR→0.147360 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#020 loss=0.449633 step=0.1429 g_raw=+0.054 g_sm=+0.021 acc=1 | LR→0.147656 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#025 loss=0.443021 step=0.03214 g_raw=+0.012 g_sm=+0.020 acc=1 | LR→0.147952 PERT→0.140012 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1464781431, PERT_used=0.1400099476 → LR_next=0.1479522183, PERT_next=0.1400117886\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.029 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1464781431→0.1479522183 PERT 0.1400099476→0.1400117886\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.65\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.437034 step=0.03025 g_raw=+0.008 g_sm=+0.019 acc=1 | LR→0.148249 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#035 loss=0.432233 step=0.1067 g_raw=+0.031 g_sm=+0.018 acc=1 | LR→0.148546 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#040 loss=0.428697 step=0.00346 g_raw=-0.000 g_sm=+0.015 acc=1 | LR→0.148844 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#045 loss=0.425047 step=0.003237 g_raw=+0.003 g_sm=+0.015 acc=1 | LR→0.149143 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#050 loss=0.418669 step=0.009272 g_raw=+0.003 g_sm=+0.016 acc=1 | LR→0.149442 PERT→0.140014 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1479522183, PERT_used=0.1400117886 → LR_next=0.1494417310, PERT_next=0.1400141947\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1479522183→0.1494417310 PERT 0.1400117886→0.1400141947\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.57\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.405642 step=0.08753 g_raw=+0.030 g_sm=+0.018 acc=1 | LR→0.149741 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#060 loss=0.403587 step=0.05743 g_raw=+0.019 g_sm=+0.016 acc=1 | LR→0.150042 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#065 loss=0.393965 step=0.006689 g_raw=+0.001 g_sm=+0.017 acc=1 | LR→0.150343 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#070 loss=0.382448 step=0.008167 g_raw=+0.000 g_sm=+0.018 acc=1 | LR→0.150644 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#075 loss=0.371440 step=0.01791 g_raw=+0.005 g_sm=+0.019 acc=1 | LR→0.150946 PERT→0.140017 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1494417310, PERT_used=0.1400141947 → LR_next=0.1509462903, PERT_next=0.1400166482\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1494417310→0.1509462903 PERT 0.1400141947→0.1400166482\n",
            "Training Accuracy: 0.83\n",
            "Test Accuracy: 0.57\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.361521 step=0.03568 g_raw=+0.012 g_sm=+0.019 acc=1 | LR→0.151249 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#085 loss=0.356686 step=0.005039 g_raw=+0.005 g_sm=+0.018 acc=1 | LR→0.151552 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#090 loss=0.351732 step=0.0362 g_raw=+0.014 g_sm=+0.018 acc=1 | LR→0.151856 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#095 loss=0.349023 step=0.08914 g_raw=+0.025 g_sm=+0.016 acc=1 | LR→0.152161 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#100 loss=0.341692 step=0.07759 g_raw=+0.024 g_sm=+0.018 acc=1 | LR→0.152466 PERT→0.140019 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1509462903, PERT_used=0.1400166482 → LR_next=0.1524660719, PERT_next=0.1400191701\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1509462903→0.1524660719 PERT 0.1400166482→0.1400191701\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.58\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.336811 step=0.05522 g_raw=+0.014 g_sm=+0.017 acc=1 | LR→0.152772 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#110 loss=0.330887 step=0.0486 g_raw=+0.017 g_sm=+0.017 acc=1 | LR→0.153078 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#115 loss=0.325138 step=0.02483 g_raw=+0.009 g_sm=+0.016 acc=1 | LR→0.153385 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#120 loss=0.322960 step=0.009756 g_raw=+0.007 g_sm=+0.015 acc=1 | LR→0.153693 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#125 loss=0.318671 step=0.007125 g_raw=+0.001 g_sm=+0.015 acc=1 | LR→0.154001 PERT→0.140021 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1524660719, PERT_used=0.1400191701 → LR_next=0.1540009295, PERT_next=0.1400214869\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1524660719→0.1540009295 PERT 0.1400191701→0.1400214869\n",
            "Training Accuracy: 0.85\n",
            "Test Accuracy: 0.55\n",
            "[round 3 | client 2] final LR=0.1540009295, final PERT=0.1400214869  (ΔLR=+0.0075227864, ΔPERT=+0.0000115393)\n",
            "[round 3 | client 3] seed LR=0.1464764219 (prev=0.1529528439), seed PERT=0.1400083725 (prev=0.1400167451), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.539882 step=0.0127 g_raw=+0.009 g_sm=+0.004 acc=1 | LR→0.146770 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.523505 step=0.174 g_raw=+0.065 g_sm=+0.009 acc=1 | LR→0.147064 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#015 loss=0.498227 step=0.2182 g_raw=+0.079 g_sm=+0.015 acc=1 | LR→0.147359 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#020 loss=0.492660 step=0.003759 g_raw=+0.005 g_sm=+0.016 acc=1 | LR→0.147654 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#025 loss=0.482639 step=0.147 g_raw=+0.053 g_sm=+0.017 acc=1 | LR→0.147950 PERT→0.140010 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1464764219, PERT_used=0.1400083725 → LR_next=0.1479501006, PERT_next=0.1400098546\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.023 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1464764219→0.1479501006 PERT 0.1400083725→0.1400098546\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.434349 step=0.3107 g_raw=+0.118 g_sm=+0.024 acc=1 | LR→0.148247 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#035 loss=0.403299 step=0.183 g_raw=+0.060 g_sm=+0.028 acc=1 | LR→0.148544 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#040 loss=0.386345 step=0.1574 g_raw=+0.060 g_sm=+0.028 acc=1 | LR→0.148843 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#045 loss=0.376785 step=0.06136 g_raw=+0.021 g_sm=+0.026 acc=1 | LR→0.149141 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#050 loss=0.373439 step=0.04508 g_raw=+0.012 g_sm=+0.023 acc=1 | LR→0.149441 PERT→0.140013 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1479501006, PERT_used=0.1400098546 → LR_next=0.1494407479, PERT_next=0.1400133438\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.030 g_sm_mean=+0.025 acc_ratio=1.00 | LR 0.1479501006→0.1494407479 PERT 0.1400098546→0.1400133438\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.362910 step=0.123 g_raw=+0.030 g_sm=+0.022 acc=1 | LR→0.149741 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#060 loss=0.358117 step=0.03365 g_raw=+0.006 g_sm=+0.020 acc=1 | LR→0.150041 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#065 loss=0.352344 step=0.03147 g_raw=+0.016 g_sm=+0.020 acc=1 | LR→0.150342 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#070 loss=0.346722 step=0.01259 g_raw=+0.007 g_sm=+0.018 acc=1 | LR→0.150644 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#075 loss=0.340981 step=0.08734 g_raw=+0.025 g_sm=+0.018 acc=1 | LR→0.150946 PERT→0.140016 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1494407479, PERT_used=0.1400133438 → LR_next=0.1509457302, PERT_next=0.1400161987\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.020 acc_ratio=1.00 | LR 0.1494407479→0.1509457302 PERT 0.1400133438→0.1400161987\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.335608 step=0.09845 g_raw=+0.030 g_sm=+0.018 acc=1 | LR→0.151248 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#085 loss=0.330907 step=0.004762 g_raw=+0.007 g_sm=+0.016 acc=1 | LR→0.151552 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#090 loss=0.326921 step=0.08556 g_raw=+0.027 g_sm=+0.016 acc=1 | LR→0.151856 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#095 loss=0.325570 step=0.001261 g_raw=+0.001 g_sm=+0.014 acc=1 | LR→0.152160 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#100 loss=0.320479 step=0.0956 g_raw=+0.032 g_sm=+0.014 acc=1 | LR→0.152465 PERT→0.140018 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1509457302, PERT_used=0.1400161987 → LR_next=0.1524651437, PERT_next=0.1400183878\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1509457302→0.1524651437 PERT 0.1400161987→0.1400183878\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.311530 step=0.03484 g_raw=+0.007 g_sm=+0.016 acc=1 | LR→0.152771 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#110 loss=0.310678 step=0.006855 g_raw=+0.007 g_sm=+0.014 acc=1 | LR→0.153077 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#115 loss=0.310016 step=0.004616 g_raw=+0.002 g_sm=+0.012 acc=1 | LR→0.153384 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#120 loss=0.309687 step=0.01116 g_raw=+0.001 g_sm=+0.010 acc=1 | LR→0.153691 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#125 loss=0.306187 step=0.01572 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.153999 PERT→0.140020 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1524651437, PERT_used=0.1400183878 → LR_next=0.1539994000, PERT_next=0.1400201664\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1524651437→0.1539994000 PERT 0.1400183878→0.1400201664\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.51\n",
            "[round 3 | client 3] final LR=0.1539994000, final PERT=0.1400201664  (ΔLR=+0.0075229781, ΔPERT=+0.0000117939)\n",
            "[round 3 | client 4] seed LR=0.1464780183 (prev=0.1529560365), seed PERT=0.1400098127 (prev=0.1400196254), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.501724 step=0.114 g_raw=+0.036 g_sm=+0.011 acc=1 | LR→0.146771 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#010 loss=0.471307 step=0.1468 g_raw=+0.054 g_sm=+0.018 acc=1 | LR→0.147066 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#015 loss=0.390430 step=0.05689 g_raw=+0.025 g_sm=+0.027 acc=1 | LR→0.147361 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#020 loss=0.359764 step=0.199 g_raw=+0.063 g_sm=+0.031 acc=1 | LR→0.147657 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#025 loss=0.339828 step=0.1558 g_raw=+0.059 g_sm=+0.031 acc=1 | LR→0.147953 PERT→0.140013 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1464780183, PERT_used=0.1400098127 → LR_next=0.1479532580, PERT_next=0.1400127569\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.045 g_sm_mean=+0.021 acc_ratio=1.00 | LR 0.1464780183→0.1479532580 PERT 0.1400098127→0.1400127569\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.325570 step=0.1697 g_raw=+0.057 g_sm=+0.030 acc=1 | LR→0.148250 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#035 loss=0.321319 step=0.03282 g_raw=+0.010 g_sm=+0.026 acc=1 | LR→0.148548 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#040 loss=0.309834 step=0.01859 g_raw=+0.006 g_sm=+0.024 acc=1 | LR→0.148846 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#045 loss=0.302146 step=0.05495 g_raw=+0.016 g_sm=+0.023 acc=1 | LR→0.149145 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#050 loss=0.296091 step=0.08527 g_raw=+0.023 g_sm=+0.022 acc=1 | LR→0.149444 PERT→0.140016 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1479532580, PERT_used=0.1400127569 → LR_next=0.1494440511, PERT_next=0.1400163529\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.026 acc_ratio=1.00 | LR 0.1479532580→0.1494440511 PERT 0.1400127569→0.1400163529\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.287223 step=0.02908 g_raw=+0.003 g_sm=+0.021 acc=1 | LR→0.149744 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#060 loss=0.285635 step=0.01668 g_raw=+0.004 g_sm=+0.019 acc=1 | LR→0.150044 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#065 loss=0.283005 step=0.04677 g_raw=+0.016 g_sm=+0.017 acc=1 | LR→0.150345 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#070 loss=0.276622 step=0.04279 g_raw=+0.011 g_sm=+0.016 acc=1 | LR→0.150647 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#075 loss=0.274477 step=0.03513 g_raw=+0.013 g_sm=+0.015 acc=1 | LR→0.150949 PERT→0.140019 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1494440511, PERT_used=0.1400163529 → LR_next=0.1509487365, PERT_next=0.1400189017\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1494440511→0.1509487365 PERT 0.1400163529→0.1400189017\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.268218 step=0.03516 g_raw=+0.011 g_sm=+0.016 acc=1 | LR→0.151251 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#085 loss=0.265831 step=0.03338 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.151555 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#090 loss=0.265265 step=0.002561 g_raw=-0.002 g_sm=+0.012 acc=1 | LR→0.151858 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#095 loss=0.263516 step=0.0004753 g_raw=+0.002 g_sm=+0.012 acc=1 | LR→0.152163 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#100 loss=0.261009 step=0.01845 g_raw=+0.001 g_sm=+0.011 acc=1 | LR→0.152468 PERT→0.140021 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1509487365, PERT_used=0.1400189017 → LR_next=0.1524678384, PERT_next=0.1400207769\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1509487365→0.1524678384 PERT 0.1400189017→0.1400207769\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.260256 step=0.01761 g_raw=+0.004 g_sm=+0.009 acc=1 | LR→0.152773 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#110 loss=0.259338 step=0.03508 g_raw=+0.010 g_sm=+0.009 acc=1 | LR→0.153080 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#115 loss=0.258321 step=0.01933 g_raw=+0.003 g_sm=+0.008 acc=1 | LR→0.153386 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#120 loss=0.255871 step=0.02534 g_raw=+0.013 g_sm=+0.009 acc=1 | LR→0.153694 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#125 loss=0.255531 step=0.01586 g_raw=+0.005 g_sm=+0.007 acc=1 | LR→0.154002 PERT→0.140022 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1524678384, PERT_used=0.1400207769 → LR_next=0.1540015137, PERT_next=0.1400220025\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.006 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1524678384→0.1540015137 PERT 0.1400207769→0.1400220025\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "[round 3 | client 4] final LR=0.1540015137, final PERT=0.1400220025  (ΔLR=+0.0075234954, ΔPERT=+0.0000121898)\n",
            "\n",
            "[Round 3] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           2      0.636916      0.549000      0.154001      0.140021\n",
            "           3      0.733291      0.511000      0.153999      0.140020\n",
            "           4      0.736165      0.494000      0.154002      0.140022\n",
            "           0      0.796592      0.495000      0.154003      0.140023\n",
            "           1      0.846681      0.505000      0.154000      0.140020\n",
            "→ [Round 3] best_client=2, best_val=0.636916, prev_global_val=0.684810, improve=+0.047895, action=adopt+mix τ=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  40%|████      | 4/10 [1:19:37<2:01:23, 1213.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   3] acc_g=0.796 (μ=0.511, σ=0.020, FG=0.039) | t=1248.616s, val=0.626 | TEL=FALSE\n",
            "[Round 4] Teleportation OFF | Aggregation=best\n",
            "[round 4 | client 0] seed LR=0.1470012595 (prev=0.1540025189), seed PERT=0.1400114473 (prev=0.1400228946), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.561803 step=0.09171 g_raw=+0.038 g_sm=+0.004 acc=1 | LR→0.147296 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#010 loss=0.511205 step=0.05724 g_raw=+0.022 g_sm=+0.014 acc=1 | LR→0.147591 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#015 loss=0.486721 step=0.06756 g_raw=+0.021 g_sm=+0.020 acc=1 | LR→0.147887 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#020 loss=0.471379 step=0.03213 g_raw=+0.012 g_sm=+0.022 acc=1 | LR→0.148184 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#025 loss=0.432511 step=0.07685 g_raw=+0.028 g_sm=+0.026 acc=1 | LR→0.148481 PERT→0.140014 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1470012595, PERT_used=0.1400114473 → LR_next=0.1484808922, PERT_next=0.1400135648\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.035 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1470012595→0.1484808922 PERT 0.1400114473→0.1400135648\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.42\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.423882 step=0.03758 g_raw=+0.014 g_sm=+0.026 acc=1 | LR→0.148779 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#035 loss=0.412776 step=0.07441 g_raw=+0.022 g_sm=+0.025 acc=1 | LR→0.149078 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#040 loss=0.391448 step=0.007076 g_raw=+0.006 g_sm=+0.027 acc=1 | LR→0.149377 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#045 loss=0.384334 step=0.002558 g_raw=+0.004 g_sm=+0.024 acc=1 | LR→0.149677 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#050 loss=0.367377 step=0.1098 g_raw=+0.035 g_sm=+0.025 acc=1 | LR→0.149977 PERT→0.140017 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1484808922, PERT_used=0.1400135648 → LR_next=0.1499770116, PERT_next=0.1400171700\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.025 g_sm_mean=+0.026 acc_ratio=1.00 | LR 0.1484808922→0.1499770116 PERT 0.1400135648→0.1400171700\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.340522 step=0.09633 g_raw=+0.032 g_sm=+0.028 acc=1 | LR→0.150278 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#060 loss=0.317157 step=0.06229 g_raw=+0.021 g_sm=+0.028 acc=1 | LR→0.150580 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#065 loss=0.304515 step=0.1361 g_raw=+0.041 g_sm=+0.027 acc=1 | LR→0.150882 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#070 loss=0.297088 step=0.1043 g_raw=+0.035 g_sm=+0.025 acc=1 | LR→0.151185 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#075 loss=0.285989 step=0.06102 g_raw=+0.023 g_sm=+0.025 acc=1 | LR→0.151488 PERT→0.140021 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1499770116, PERT_used=0.1400171700 → LR_next=0.1514884070, PERT_next=0.1400209609\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.027 g_sm_mean=+0.027 acc_ratio=1.00 | LR 0.1499770116→0.1514884070 PERT 0.1400171700→0.1400209609\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.281145 step=0.05452 g_raw=+0.022 g_sm=+0.023 acc=1 | LR→0.151792 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#085 loss=0.275215 step=0.06201 g_raw=+0.021 g_sm=+0.021 acc=1 | LR→0.152097 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#090 loss=0.273392 step=0.07009 g_raw=+0.024 g_sm=+0.018 acc=1 | LR→0.152402 PERT→0.140023 (scale=0.04)\n",
            "[meta] cb#095 loss=0.269056 step=0.06964 g_raw=+0.017 g_sm=+0.017 acc=1 | LR→0.152708 PERT→0.140023 (scale=0.04)\n",
            "[meta] cb#100 loss=0.267616 step=0.01972 g_raw=+0.010 g_sm=+0.016 acc=1 | LR→0.153014 PERT→0.140024 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1514884070, PERT_used=0.1400209609 → LR_next=0.1530139125, PERT_next=0.1400237260\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.020 acc_ratio=1.00 | LR 0.1514884070→0.1530139125 PERT 0.1400209609→0.1400237260\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.266108 step=0.02241 g_raw=+0.009 g_sm=+0.014 acc=1 | LR→0.153321 PERT→0.140024 (scale=0.04)\n",
            "[meta] cb#110 loss=0.263869 step=0.02333 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.153628 PERT→0.140025 (scale=0.04)\n",
            "[meta] cb#115 loss=0.261549 step=0.03553 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.153936 PERT→0.140025 (scale=0.04)\n",
            "[meta] cb#120 loss=0.261180 step=0.004338 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.154245 PERT→0.140025 (scale=0.04)\n",
            "[meta] cb#125 loss=0.258323 step=0.04017 g_raw=+0.010 g_sm=+0.011 acc=1 | LR→0.154554 PERT→0.140025 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1530139125, PERT_used=0.1400237260 → LR_next=0.1545536645, PERT_next=0.1400254806\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1530139125→0.1545536645 PERT 0.1400237260→0.1400254806\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "[round 4 | client 0] final LR=0.1545536645, final PERT=0.1400254806  (ΔLR=+0.0075524050, ΔPERT=+0.0000140333)\n",
            "[round 4 | client 1] seed LR=0.1469997985 (prev=0.1539995971), seed PERT=0.1400101376 (prev=0.1400202752), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.483360 step=0.02241 g_raw=+0.011 g_sm=+0.005 acc=1 | LR→0.147294 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#010 loss=0.468862 step=0.07892 g_raw=+0.029 g_sm=+0.009 acc=1 | LR→0.147589 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#015 loss=0.463040 step=0.01978 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.147885 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#020 loss=0.451938 step=0.1097 g_raw=+0.034 g_sm=+0.015 acc=1 | LR→0.148182 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#025 loss=0.448507 step=0.0522 g_raw=+0.018 g_sm=+0.014 acc=1 | LR→0.148479 PERT→0.140012 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1469997985, PERT_used=0.1400101376 → LR_next=0.1484786210, PERT_next=0.1400115049\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1469997985→0.1484786210 PERT 0.1400101376→0.1400115049\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.442306 step=0.006848 g_raw=+0.002 g_sm=+0.015 acc=1 | LR→0.148776 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#035 loss=0.438159 step=0.06272 g_raw=+0.024 g_sm=+0.015 acc=1 | LR→0.149075 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#040 loss=0.425185 step=0.1232 g_raw=+0.042 g_sm=+0.017 acc=1 | LR→0.149374 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#045 loss=0.418186 step=0.04691 g_raw=+0.019 g_sm=+0.017 acc=1 | LR→0.149673 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#050 loss=0.413127 step=0.09078 g_raw=+0.027 g_sm=+0.018 acc=1 | LR→0.149973 PERT→0.140014 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1484786210, PERT_used=0.1400115049 → LR_next=0.1499732638, PERT_next=0.1400137528\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1484786210→0.1499732638 PERT 0.1400115049→0.1400137528\n",
            "Training Accuracy: 0.83\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.410032 step=0.0332 g_raw=+0.009 g_sm=+0.016 acc=1 | LR→0.150274 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#060 loss=0.407522 step=0.0447 g_raw=+0.012 g_sm=+0.015 acc=1 | LR→0.150575 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#065 loss=0.401605 step=0.04502 g_raw=+0.018 g_sm=+0.016 acc=1 | LR→0.150877 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#070 loss=0.394745 step=0.007273 g_raw=+0.001 g_sm=+0.016 acc=1 | LR→0.151180 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#075 loss=0.389087 step=0.02541 g_raw=+0.008 g_sm=+0.016 acc=1 | LR→0.151483 PERT→0.140016 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1499732638, PERT_used=0.1400137528 → LR_next=0.1514829597, PERT_next=0.1400160077\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1499732638→0.1514829597 PERT 0.1400137528→0.1400160077\n",
            "Training Accuracy: 0.83\n",
            "Test Accuracy: 0.63\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.385614 step=0.06714 g_raw=+0.021 g_sm=+0.015 acc=1 | LR→0.151787 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#085 loss=0.380353 step=0.0402 g_raw=+0.014 g_sm=+0.016 acc=1 | LR→0.152091 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#090 loss=0.374007 step=0.04752 g_raw=+0.024 g_sm=+0.017 acc=1 | LR→0.152396 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#095 loss=0.367122 step=0.009989 g_raw=-0.002 g_sm=+0.016 acc=1 | LR→0.152702 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#100 loss=0.364009 step=0.04288 g_raw=+0.014 g_sm=+0.016 acc=1 | LR→0.153008 PERT→0.140018 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1514829597, PERT_used=0.1400160077 → LR_next=0.1530078355, PERT_next=0.1400182467\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1514829597→0.1530078355 PERT 0.1400160077→0.1400182467\n",
            "Training Accuracy: 0.83\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.362798 step=0.007533 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.153315 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#110 loss=0.356778 step=0.07685 g_raw=+0.024 g_sm=+0.014 acc=1 | LR→0.153622 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#115 loss=0.355906 step=0.005116 g_raw=-0.002 g_sm=+0.012 acc=1 | LR→0.153930 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#120 loss=0.353823 step=0.01058 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.154238 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#125 loss=0.351487 step=0.04692 g_raw=+0.018 g_sm=+0.011 acc=1 | LR→0.154548 PERT→0.140020 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1530078355, PERT_used=0.1400182467 → LR_next=0.1545475858, PERT_next=0.1400200550\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1530078355→0.1545475858 PERT 0.1400182467→0.1400200550\n",
            "Training Accuracy: 0.83\n",
            "Test Accuracy: 0.57\n",
            "[round 4 | client 1] final LR=0.1545475858, final PERT=0.1400200550  (ΔLR=+0.0075477872, ΔPERT=+0.0000099174)\n",
            "[round 4 | client 2] seed LR=0.1470004647 (prev=0.1540009295), seed PERT=0.1400107435 (prev=0.1400214869), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.522215 step=0.004765 g_raw=-0.002 g_sm=+0.002 acc=1 | LR→0.147295 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#010 loss=0.519456 step=0.03305 g_raw=+0.007 g_sm=+0.004 acc=1 | LR→0.147590 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#015 loss=0.510543 step=0.1018 g_raw=+0.039 g_sm=+0.009 acc=1 | LR→0.147885 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#020 loss=0.508517 step=0.06294 g_raw=+0.013 g_sm=+0.009 acc=1 | LR→0.148182 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#025 loss=0.504567 step=0.03919 g_raw=+0.016 g_sm=+0.011 acc=1 | LR→0.148479 PERT→0.140012 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1470004647, PERT_used=0.1400107435 → LR_next=0.1484787416, PERT_next=0.1400115899\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1470004647→0.1484787416 PERT 0.1400107435→0.1400115899\n",
            "Training Accuracy: 0.59\n",
            "Test Accuracy: 0.37\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.502096 step=0.007099 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.148776 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#035 loss=0.497488 step=0.05336 g_raw=+0.019 g_sm=+0.011 acc=1 | LR→0.149074 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#040 loss=0.488666 step=0.0444 g_raw=+0.010 g_sm=+0.014 acc=1 | LR→0.149373 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#045 loss=0.480459 step=0.101 g_raw=+0.037 g_sm=+0.015 acc=1 | LR→0.149673 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#050 loss=0.477734 step=0.02371 g_raw=+0.008 g_sm=+0.015 acc=1 | LR→0.149973 PERT→0.140013 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1484787416, PERT_used=0.1400115899 → LR_next=0.1499729176, PERT_next=0.1400134009\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1484787416→0.1499729176 PERT 0.1400115899→0.1400134009\n",
            "Training Accuracy: 0.71\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.472116 step=0.04066 g_raw=+0.011 g_sm=+0.015 acc=1 | LR→0.150274 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#060 loss=0.458351 step=0.03575 g_raw=+0.011 g_sm=+0.017 acc=1 | LR→0.150575 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#065 loss=0.450200 step=0.03585 g_raw=+0.011 g_sm=+0.019 acc=1 | LR→0.150877 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#070 loss=0.447843 step=0.02035 g_raw=+0.010 g_sm=+0.017 acc=1 | LR→0.151180 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#075 loss=0.435894 step=0.05175 g_raw=+0.018 g_sm=+0.018 acc=1 | LR→0.151483 PERT→0.140016 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1499729176, PERT_used=0.1400134009 → LR_next=0.1514827708, PERT_next=0.1400158044\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1499729176→0.1514827708 PERT 0.1400134009→0.1400158044\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.57\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.425152 step=0.01399 g_raw=+0.008 g_sm=+0.019 acc=1 | LR→0.151787 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#085 loss=0.421452 step=0.04957 g_raw=+0.018 g_sm=+0.018 acc=1 | LR→0.152091 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#090 loss=0.400982 step=0.04104 g_raw=+0.011 g_sm=+0.021 acc=1 | LR→0.152396 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#095 loss=0.396841 step=0.02526 g_raw=+0.010 g_sm=+0.020 acc=1 | LR→0.152702 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#100 loss=0.383194 step=0.1068 g_raw=+0.038 g_sm=+0.022 acc=1 | LR→0.153008 PERT→0.140019 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1514827708, PERT_used=0.1400158044 → LR_next=0.1530082464, PERT_next=0.1400185940\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.023 g_sm_mean=+0.020 acc_ratio=1.00 | LR 0.1514827708→0.1530082464 PERT 0.1400158044→0.1400185940\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.60\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.359888 step=0.1045 g_raw=+0.036 g_sm=+0.024 acc=1 | LR→0.153315 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#110 loss=0.335414 step=0.05591 g_raw=+0.018 g_sm=+0.027 acc=1 | LR→0.153623 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#115 loss=0.331108 step=0.0276 g_raw=+0.014 g_sm=+0.024 acc=1 | LR→0.153931 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#120 loss=0.326794 step=0.0494 g_raw=+0.016 g_sm=+0.021 acc=1 | LR→0.154240 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#125 loss=0.322472 step=0.023 g_raw=+0.004 g_sm=+0.020 acc=1 | LR→0.154550 PERT→0.140022 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1530082464, PERT_used=0.1400185940 → LR_next=0.1545496460, PERT_next=0.1400218930\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.022 g_sm_mean=+0.024 acc_ratio=1.00 | LR 0.1530082464→0.1545496460 PERT 0.1400185940→0.1400218930\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.50\n",
            "[round 4 | client 2] final LR=0.1545496460, final PERT=0.1400218930  (ΔLR=+0.0075491813, ΔPERT=+0.0000111495)\n",
            "[round 4 | client 3] seed LR=0.1469997000 (prev=0.1539994000), seed PERT=0.1400100832 (prev=0.1400201664), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.516714 step=0.115 g_raw=+0.043 g_sm=+0.007 acc=1 | LR→0.147294 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#010 loss=0.497145 step=0.07026 g_raw=+0.026 g_sm=+0.013 acc=1 | LR→0.147589 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#015 loss=0.488579 step=0.1193 g_raw=+0.044 g_sm=+0.015 acc=1 | LR→0.147885 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#020 loss=0.479800 step=0.07304 g_raw=+0.026 g_sm=+0.017 acc=1 | LR→0.148182 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#025 loss=0.471312 step=0.06255 g_raw=+0.026 g_sm=+0.018 acc=1 | LR→0.148479 PERT→0.140012 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1469997000, PERT_used=0.1400100832 → LR_next=0.1484788480, PERT_next=0.1400117584\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.025 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1469997000→0.1484788480 PERT 0.1400100832→0.1400117584\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.462581 step=0.107 g_raw=+0.037 g_sm=+0.019 acc=1 | LR→0.148777 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#035 loss=0.454933 step=0.08107 g_raw=+0.029 g_sm=+0.020 acc=1 | LR→0.149075 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#040 loss=0.436266 step=0.08187 g_raw=+0.036 g_sm=+0.023 acc=1 | LR→0.149374 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#045 loss=0.433368 step=0.006566 g_raw=-0.001 g_sm=+0.020 acc=1 | LR→0.149674 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#050 loss=0.431820 step=0.004873 g_raw=+0.009 g_sm=+0.018 acc=1 | LR→0.149974 PERT→0.140015 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1484788480, PERT_used=0.1400117584 → LR_next=0.1499740989, PERT_next=0.1400145719\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.020 acc_ratio=1.00 | LR 0.1484788480→0.1499740989 PERT 0.1400117584→0.1400145719\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.58\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.427988 step=0.04055 g_raw=+0.020 g_sm=+0.018 acc=1 | LR→0.150275 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#060 loss=0.407927 step=0.138 g_raw=+0.044 g_sm=+0.020 acc=1 | LR→0.150576 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#065 loss=0.405403 step=0.02148 g_raw=+0.009 g_sm=+0.018 acc=1 | LR→0.150878 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#070 loss=0.395911 step=0.03761 g_raw=+0.010 g_sm=+0.018 acc=1 | LR→0.151181 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#075 loss=0.389255 step=0.03823 g_raw=+0.016 g_sm=+0.018 acc=1 | LR→0.151484 PERT→0.140017 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1499740989, PERT_used=0.1400145719 → LR_next=0.1514841765, PERT_next=0.1400171718\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1499740989→0.1514841765 PERT 0.1400145719→0.1400171718\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.55\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.382359 step=0.08769 g_raw=+0.028 g_sm=+0.018 acc=1 | LR→0.151788 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#085 loss=0.377893 step=0.002818 g_raw=+0.000 g_sm=+0.017 acc=1 | LR→0.152092 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#090 loss=0.372847 step=0.09695 g_raw=+0.039 g_sm=+0.017 acc=1 | LR→0.152397 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#095 loss=0.367922 step=0.1015 g_raw=+0.027 g_sm=+0.016 acc=1 | LR→0.152703 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#100 loss=0.358146 step=0.1089 g_raw=+0.039 g_sm=+0.017 acc=1 | LR→0.153009 PERT→0.140020 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1514841765, PERT_used=0.1400171718 → LR_next=0.1530092285, PERT_next=0.1400195609\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1514841765→0.1530092285 PERT 0.1400171718→0.1400195609\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.348168 step=0.1521 g_raw=+0.049 g_sm=+0.018 acc=1 | LR→0.153316 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#110 loss=0.342718 step=0.05994 g_raw=+0.013 g_sm=+0.017 acc=1 | LR→0.153624 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#115 loss=0.337627 step=0.08804 g_raw=+0.025 g_sm=+0.017 acc=1 | LR→0.153932 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#120 loss=0.335275 step=0.03845 g_raw=+0.013 g_sm=+0.015 acc=1 | LR→0.154240 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#125 loss=0.331983 step=0.02623 g_raw=+0.014 g_sm=+0.014 acc=1 | LR→0.154550 PERT→0.140022 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1530092285, PERT_used=0.1400195609 → LR_next=0.1545495319, PERT_next=0.1400218577\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1530092285→0.1545495319 PERT 0.1400195609→0.1400218577\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.53\n",
            "[round 4 | client 3] final LR=0.1545495319, final PERT=0.1400218577  (ΔLR=+0.0075498319, ΔPERT=+0.0000117745)\n",
            "[round 4 | client 4] seed LR=0.1470007568 (prev=0.1540015137), seed PERT=0.1400110013 (prev=0.1400220025), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.460379 step=0.1363 g_raw=+0.058 g_sm=+0.010 acc=1 | LR→0.147295 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#010 loss=0.417770 step=0.0528 g_raw=+0.015 g_sm=+0.016 acc=1 | LR→0.147591 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#015 loss=0.402877 step=0.06809 g_raw=+0.025 g_sm=+0.020 acc=1 | LR→0.147887 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#020 loss=0.396615 step=0.07208 g_raw=+0.027 g_sm=+0.020 acc=1 | LR→0.148183 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#025 loss=0.373513 step=0.02911 g_raw=+0.012 g_sm=+0.024 acc=1 | LR→0.148481 PERT→0.140013 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1470007568, PERT_used=0.1400110013 → LR_next=0.1484805521, PERT_next=0.1400132767\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.034 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1470007568→0.1484805521 PERT 0.1400110013→0.1400132767\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.345629 step=0.1836 g_raw=+0.067 g_sm=+0.027 acc=1 | LR→0.148779 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#035 loss=0.330752 step=0.1562 g_raw=+0.064 g_sm=+0.027 acc=1 | LR→0.149077 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#040 loss=0.327084 step=0.07078 g_raw=+0.017 g_sm=+0.023 acc=1 | LR→0.149376 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#045 loss=0.316270 step=0.05732 g_raw=+0.020 g_sm=+0.022 acc=1 | LR→0.149676 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#050 loss=0.313515 step=0.04962 g_raw=+0.015 g_sm=+0.020 acc=1 | LR→0.149976 PERT→0.140017 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1484805521, PERT_used=0.1400132767 → LR_next=0.1499764001, PERT_next=0.1400166317\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.024 acc_ratio=1.00 | LR 0.1484805521→0.1499764001 PERT 0.1400132767→0.1400166317\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.304722 step=0.04985 g_raw=+0.010 g_sm=+0.020 acc=1 | LR→0.150277 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#060 loss=0.299040 step=0.07644 g_raw=+0.023 g_sm=+0.019 acc=1 | LR→0.150579 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#065 loss=0.296871 step=0.06832 g_raw=+0.023 g_sm=+0.017 acc=1 | LR→0.150881 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#070 loss=0.291319 step=0.1037 g_raw=+0.035 g_sm=+0.017 acc=1 | LR→0.151183 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#075 loss=0.288606 step=0.0774 g_raw=+0.026 g_sm=+0.016 acc=1 | LR→0.151486 PERT→0.140019 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1499764001, PERT_used=0.1400166317 → LR_next=0.1514864395, PERT_next=0.1400191750\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1499764001→0.1514864395 PERT 0.1400166317→0.1400191750\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.286200 step=0.05593 g_raw=+0.020 g_sm=+0.015 acc=1 | LR→0.151790 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#085 loss=0.285501 step=0.04005 g_raw=+0.012 g_sm=+0.013 acc=1 | LR→0.152094 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#090 loss=0.285419 step=0.009401 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.152399 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#095 loss=0.283787 step=0.07193 g_raw=+0.018 g_sm=+0.010 acc=1 | LR→0.152705 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#100 loss=0.281027 step=0.08462 g_raw=+0.026 g_sm=+0.010 acc=1 | LR→0.153011 PERT→0.140021 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1514864395, PERT_used=0.1400191750 → LR_next=0.1530107042, PERT_next=0.1400208227\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1514864395→0.1530107042 PERT 0.1400191750→0.1400208227\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.279381 step=0.02138 g_raw=+0.005 g_sm=+0.009 acc=1 | LR→0.153317 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#110 loss=0.278935 step=0.02471 g_raw=+0.008 g_sm=+0.008 acc=1 | LR→0.153625 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#115 loss=0.275187 step=0.07853 g_raw=+0.027 g_sm=+0.010 acc=1 | LR→0.153932 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#120 loss=0.274764 step=0.0283 g_raw=+0.007 g_sm=+0.008 acc=1 | LR→0.154241 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#125 loss=0.273078 step=0.03871 g_raw=+0.008 g_sm=+0.008 acc=1 | LR→0.154550 PERT→0.140022 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1530107042, PERT_used=0.1400208227 → LR_next=0.1545498330, PERT_next=0.1400220419\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1530107042→0.1545498330 PERT 0.1400208227→0.1400220419\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "[round 4 | client 4] final LR=0.1545498330, final PERT=0.1400220419  (ΔLR=+0.0075490761, ΔPERT=+0.0000110406)\n",
            "\n",
            "[Round 4] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           4      0.657749      0.496000      0.154550      0.140022\n",
            "           1      0.698103      0.574000      0.154548      0.140020\n",
            "           2      0.741291      0.496000      0.154550      0.140022\n",
            "           3      0.790395      0.527000      0.154550      0.140022\n",
            "           0      1.080531      0.495000      0.154554      0.140025\n",
            "→ [Round 4] best_client=4, best_val=0.657749, prev_global_val=0.626381, improve=-0.031368, action=hold (τ=0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  50%|█████     | 5/10 [1:38:47<1:39:14, 1190.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   4] acc_g=0.711 (μ=0.518, σ=0.031, FG=0.060) | t=1133.157s, val=0.623 | TEL=FALSE\n",
            "[Round 5] Teleportation OFF | Aggregation=best\n",
            "[round 5 | client 0] seed LR=0.1472768322 (prev=0.1545536645), seed PERT=0.1400127403 (prev=0.1400254806), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.476458 step=0.004974 g_raw=+0.000 g_sm=+0.004 acc=1 | LR→0.147572 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#010 loss=0.447275 step=0.139 g_raw=+0.055 g_sm=+0.012 acc=1 | LR→0.147867 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#015 loss=0.438030 step=0.05592 g_raw=+0.021 g_sm=+0.013 acc=1 | LR→0.148164 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#020 loss=0.422791 step=0.02767 g_raw=+0.010 g_sm=+0.017 acc=1 | LR→0.148461 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#025 loss=0.410474 step=0.02744 g_raw=+0.009 g_sm=+0.018 acc=1 | LR→0.148759 PERT→0.140014 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1472768322, PERT_used=0.1400127403 → LR_next=0.1487587330, PERT_next=0.1400143818\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.025 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1472768322→0.1487587330 PERT 0.1400127403→0.1400143818\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.402730 step=0.1159 g_raw=+0.040 g_sm=+0.018 acc=1 | LR→0.149057 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#035 loss=0.394603 step=0.1135 g_raw=+0.040 g_sm=+0.019 acc=1 | LR→0.149356 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#040 loss=0.382154 step=0.02881 g_raw=+0.008 g_sm=+0.020 acc=1 | LR→0.149656 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#045 loss=0.379526 step=0.03625 g_raw=+0.014 g_sm=+0.018 acc=1 | LR→0.149956 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#050 loss=0.374208 step=0.01172 g_raw=+0.005 g_sm=+0.017 acc=1 | LR→0.150257 PERT→0.140017 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1487587330, PERT_used=0.1400143818 → LR_next=0.1502565605, PERT_next=0.1400169698\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1487587330→0.1502565605 PERT 0.1400143818→0.1400169698\n",
            "Training Accuracy: 0.85\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.368650 step=0.1243 g_raw=+0.042 g_sm=+0.017 acc=1 | LR→0.150558 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#060 loss=0.360852 step=0.05046 g_raw=+0.019 g_sm=+0.018 acc=1 | LR→0.150860 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#065 loss=0.353609 step=0.02274 g_raw=+0.005 g_sm=+0.018 acc=1 | LR→0.151162 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#070 loss=0.347808 step=0.04141 g_raw=+0.016 g_sm=+0.017 acc=1 | LR→0.151466 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#075 loss=0.345317 step=0.02761 g_raw=+0.010 g_sm=+0.016 acc=1 | LR→0.151769 PERT→0.140019 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1502565605, PERT_used=0.1400169698 → LR_next=0.1517692474, PERT_next=0.1400193532\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1502565605→0.1517692474 PERT 0.1400169698→0.1400193532\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.341680 step=0.0334 g_raw=+0.016 g_sm=+0.015 acc=1 | LR→0.152074 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#085 loss=0.336346 step=0.0004116 g_raw=+0.001 g_sm=+0.015 acc=1 | LR→0.152378 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#090 loss=0.326498 step=0.07304 g_raw=+0.024 g_sm=+0.017 acc=1 | LR→0.152684 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#095 loss=0.321944 step=0.00586 g_raw=+0.005 g_sm=+0.016 acc=1 | LR→0.152990 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#100 loss=0.319154 step=0.08181 g_raw=+0.026 g_sm=+0.015 acc=1 | LR→0.153297 PERT→0.140022 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1517692474, PERT_used=0.1400193532 → LR_next=0.1532970133, PERT_next=0.1400215999\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1517692474→0.1532970133 PERT 0.1400193532→0.1400215999\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.311780 step=0.1046 g_raw=+0.034 g_sm=+0.016 acc=1 | LR→0.153604 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#110 loss=0.304669 step=0.04987 g_raw=+0.015 g_sm=+0.017 acc=1 | LR→0.153912 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#115 loss=0.300578 step=0.05497 g_raw=+0.019 g_sm=+0.017 acc=1 | LR→0.154221 PERT→0.140023 (scale=0.04)\n",
            "[meta] cb#120 loss=0.296276 step=0.06937 g_raw=+0.023 g_sm=+0.017 acc=1 | LR→0.154530 PERT→0.140023 (scale=0.04)\n",
            "[meta] cb#125 loss=0.292370 step=0.05319 g_raw=+0.020 g_sm=+0.016 acc=1 | LR→0.154840 PERT→0.140024 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1532970133, PERT_used=0.1400215999 → LR_next=0.1548402054, PERT_next=0.1400238891\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1532970133→0.1548402054 PERT 0.1400215999→0.1400238891\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.49\n",
            "[round 5 | client 0] final LR=0.1548402054, final PERT=0.1400238891  (ΔLR=+0.0075633732, ΔPERT=+0.0000111488)\n",
            "[round 5 | client 1] seed LR=0.1472737929 (prev=0.1545475858), seed PERT=0.1400100275 (prev=0.1400200550), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.518499 step=0.02281 g_raw=+0.007 g_sm=+0.003 acc=1 | LR→0.147569 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#010 loss=0.492379 step=0.1937 g_raw=+0.075 g_sm=+0.010 acc=1 | LR→0.147864 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#015 loss=0.486044 step=0.09353 g_raw=+0.032 g_sm=+0.012 acc=1 | LR→0.148161 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#020 loss=0.467593 step=0.1022 g_raw=+0.035 g_sm=+0.017 acc=1 | LR→0.148458 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#025 loss=0.458167 step=0.05162 g_raw=+0.019 g_sm=+0.019 acc=1 | LR→0.148755 PERT→0.140011 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1472737929, PERT_used=0.1400100275 → LR_next=0.1487554784, PERT_next=0.1400114951\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.025 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1472737929→0.1487554784 PERT 0.1400100275→0.1400114951\n",
            "Training Accuracy: 0.77\n",
            "Test Accuracy: 0.48\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.450628 step=0.07337 g_raw=+0.027 g_sm=+0.019 acc=1 | LR→0.149054 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#035 loss=0.440321 step=0.1042 g_raw=+0.037 g_sm=+0.021 acc=1 | LR→0.149353 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#040 loss=0.436259 step=0.02987 g_raw=+0.016 g_sm=+0.019 acc=1 | LR→0.149652 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#045 loss=0.429407 step=0.06531 g_raw=+0.023 g_sm=+0.019 acc=1 | LR→0.149953 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#050 loss=0.421984 step=0.001204 g_raw=+0.002 g_sm=+0.019 acc=1 | LR→0.150253 PERT→0.140014 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1487554784, PERT_used=0.1400114951 → LR_next=0.1502534199, PERT_next=0.1400142199\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1487554784→0.1502534199 PERT 0.1400114951→0.1400142199\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.46\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.416747 step=0.06209 g_raw=+0.020 g_sm=+0.019 acc=1 | LR→0.150555 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#060 loss=0.400455 step=0.1088 g_raw=+0.039 g_sm=+0.022 acc=1 | LR→0.150857 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#065 loss=0.395871 step=0.02416 g_raw=+0.005 g_sm=+0.020 acc=1 | LR→0.151159 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#070 loss=0.383491 step=0.03182 g_raw=+0.013 g_sm=+0.020 acc=1 | LR→0.151463 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#075 loss=0.377049 step=0.08372 g_raw=+0.032 g_sm=+0.020 acc=1 | LR→0.151767 PERT→0.140017 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1502534199, PERT_used=0.1400142199 → LR_next=0.1517665569, PERT_next=0.1400170477\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.020 acc_ratio=1.00 | LR 0.1502534199→0.1517665569 PERT 0.1400142199→0.1400170477\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.363870 step=0.06215 g_raw=+0.018 g_sm=+0.021 acc=1 | LR→0.152071 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#085 loss=0.344848 step=0.0384 g_raw=+0.011 g_sm=+0.023 acc=1 | LR→0.152376 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#090 loss=0.332116 step=0.04624 g_raw=+0.016 g_sm=+0.024 acc=1 | LR→0.152682 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#095 loss=0.326724 step=0.01323 g_raw=+0.006 g_sm=+0.022 acc=1 | LR→0.152988 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#100 loss=0.318749 step=0.06811 g_raw=+0.020 g_sm=+0.022 acc=1 | LR→0.153295 PERT→0.140020 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1517665569, PERT_used=0.1400170477 → LR_next=0.1532952924, PERT_next=0.1400202047\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.024 g_sm_mean=+0.023 acc_ratio=1.00 | LR 0.1517665569→0.1532952924 PERT 0.1400170477→0.1400202047\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.315985 step=0.01936 g_raw=+0.009 g_sm=+0.020 acc=1 | LR→0.153603 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#110 loss=0.305487 step=0.03649 g_raw=+0.013 g_sm=+0.020 acc=1 | LR→0.153911 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#115 loss=0.302917 step=0.02956 g_raw=+0.014 g_sm=+0.019 acc=1 | LR→0.154220 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#120 loss=0.293715 step=0.04465 g_raw=+0.018 g_sm=+0.019 acc=1 | LR→0.154529 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#125 loss=0.290388 step=0.05115 g_raw=+0.013 g_sm=+0.018 acc=1 | LR→0.154839 PERT→0.140023 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1532952924, PERT_used=0.1400202047 → LR_next=0.1548389624, PERT_next=0.1400229417\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.020 acc_ratio=1.00 | LR 0.1532952924→0.1548389624 PERT 0.1400202047→0.1400229417\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.51\n",
            "[round 5 | client 1] final LR=0.1548389624, final PERT=0.1400229417  (ΔLR=+0.0075651695, ΔPERT=+0.0000129142)\n",
            "[round 5 | client 2] seed LR=0.1472748230 (prev=0.1545496460), seed PERT=0.1400109465 (prev=0.1400218930), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.461193 step=0.197 g_raw=+0.069 g_sm=+0.010 acc=1 | LR→0.147570 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#010 loss=0.424563 step=0.0356 g_raw=+0.007 g_sm=+0.017 acc=1 | LR→0.147866 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#015 loss=0.394431 step=0.03406 g_raw=+0.010 g_sm=+0.021 acc=1 | LR→0.148162 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#020 loss=0.358350 step=0.04395 g_raw=+0.016 g_sm=+0.026 acc=1 | LR→0.148460 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#025 loss=0.344773 step=0.09386 g_raw=+0.029 g_sm=+0.026 acc=1 | LR→0.148758 PERT→0.140013 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1472748230, PERT_used=0.1400109465 → LR_next=0.1487576239, PERT_next=0.1400134542\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.038 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1472748230→0.1487576239 PERT 0.1400109465→0.1400134542\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.325026 step=0.05623 g_raw=+0.018 g_sm=+0.027 acc=1 | LR→0.149056 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#035 loss=0.318768 step=0.0856 g_raw=+0.029 g_sm=+0.025 acc=1 | LR→0.149355 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#040 loss=0.315249 step=0.06134 g_raw=+0.016 g_sm=+0.023 acc=1 | LR→0.149655 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#045 loss=0.312321 step=0.05237 g_raw=+0.016 g_sm=+0.020 acc=1 | LR→0.149955 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#050 loss=0.311777 step=0.003152 g_raw=-0.001 g_sm=+0.017 acc=1 | LR→0.150256 PERT→0.140017 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1487576239, PERT_used=0.1400134542 → LR_next=0.1502561241, PERT_next=0.1400166795\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.023 acc_ratio=1.00 | LR 0.1487576239→0.1502561241 PERT 0.1400134542→0.1400166795\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.301053 step=0.02061 g_raw=+0.008 g_sm=+0.018 acc=1 | LR→0.150557 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#060 loss=0.293475 step=0.04123 g_raw=+0.011 g_sm=+0.018 acc=1 | LR→0.150859 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#065 loss=0.290869 step=0.02155 g_raw=+0.012 g_sm=+0.017 acc=1 | LR→0.151162 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#070 loss=0.288259 step=0.03746 g_raw=+0.010 g_sm=+0.015 acc=1 | LR→0.151465 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#075 loss=0.283380 step=0.09582 g_raw=+0.027 g_sm=+0.015 acc=1 | LR→0.151769 PERT→0.140019 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1502561241, PERT_used=0.1400166795 → LR_next=0.1517687861, PERT_next=0.1400190440\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1502561241→0.1517687861 PERT 0.1400166795→0.1400190440\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.282411 step=0.009125 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.152073 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#085 loss=0.279709 step=0.01759 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.152378 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#090 loss=0.276160 step=0.05693 g_raw=+0.020 g_sm=+0.012 acc=1 | LR→0.152683 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#095 loss=0.273154 step=0.007574 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.152989 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#100 loss=0.272501 step=0.03887 g_raw=+0.008 g_sm=+0.010 acc=1 | LR→0.153296 PERT→0.140021 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1517687861, PERT_used=0.1400190440 → LR_next=0.1532959695, PERT_next=0.1400207627\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1517687861→0.1532959695 PERT 0.1400190440→0.1400207627\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.272106 step=0.01721 g_raw=+0.012 g_sm=+0.009 acc=1 | LR→0.153603 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#110 loss=0.265643 step=0.07907 g_raw=+0.024 g_sm=+0.011 acc=1 | LR→0.153911 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#115 loss=0.264053 step=0.05131 g_raw=+0.012 g_sm=+0.011 acc=1 | LR→0.154219 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#120 loss=0.260791 step=0.06397 g_raw=+0.018 g_sm=+0.011 acc=1 | LR→0.154529 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#125 loss=0.260440 step=0.02759 g_raw=+0.007 g_sm=+0.009 acc=1 | LR→0.154838 PERT→0.140022 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1532959695, PERT_used=0.1400207627 → LR_next=0.1548381865, PERT_next=0.1400221797\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1532959695→0.1548381865 PERT 0.1400207627→0.1400221797\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "[round 5 | client 2] final LR=0.1548381865, final PERT=0.1400221797  (ΔLR=+0.0075633634, ΔPERT=+0.0000112332)\n",
            "[round 5 | client 3] seed LR=0.1472747660 (prev=0.1545495319), seed PERT=0.1400109289 (prev=0.1400218577), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.535320 step=0.05895 g_raw=+0.024 g_sm=+0.005 acc=1 | LR→0.147570 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#010 loss=0.510182 step=0.1663 g_raw=+0.064 g_sm=+0.013 acc=1 | LR→0.147865 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#015 loss=0.486780 step=0.07982 g_raw=+0.026 g_sm=+0.017 acc=1 | LR→0.148162 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#020 loss=0.475533 step=0.06822 g_raw=+0.023 g_sm=+0.018 acc=1 | LR→0.148459 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#025 loss=0.404682 step=0.3118 g_raw=+0.115 g_sm=+0.028 acc=1 | LR→0.148757 PERT→0.140013 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1472747660, PERT_used=0.1400109289 → LR_next=0.1487569906, PERT_next=0.1400128947\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.035 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1472747660→0.1487569906 PERT 0.1400109289→0.1400128947\n",
            "Training Accuracy: 0.91\n",
            "Test Accuracy: 0.65\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.381148 step=0.1445 g_raw=+0.037 g_sm=+0.030 acc=1 | LR→0.149056 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#035 loss=0.360885 step=0.1147 g_raw=+0.041 g_sm=+0.031 acc=1 | LR→0.149355 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#040 loss=0.314717 step=0.1157 g_raw=+0.036 g_sm=+0.035 acc=1 | LR→0.149655 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#045 loss=0.310764 step=0.067 g_raw=+0.021 g_sm=+0.031 acc=1 | LR→0.149956 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#050 loss=0.302830 step=0.01063 g_raw=+0.005 g_sm=+0.028 acc=1 | LR→0.150257 PERT→0.140017 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1487569906, PERT_used=0.1400128947 → LR_next=0.1502566847, PERT_next=0.1400172385\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.031 g_sm_mean=+0.031 acc_ratio=1.00 | LR 0.1487569906→0.1502566847 PERT 0.1400128947→0.1400172385\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.296592 step=0.02267 g_raw=+0.003 g_sm=+0.025 acc=1 | LR→0.150558 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#060 loss=0.294247 step=0.0379 g_raw=+0.010 g_sm=+0.022 acc=1 | LR→0.150860 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#065 loss=0.284289 step=0.0124 g_raw=+0.008 g_sm=+0.022 acc=1 | LR→0.151163 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#070 loss=0.280102 step=0.0765 g_raw=+0.022 g_sm=+0.020 acc=1 | LR→0.151466 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#075 loss=0.276793 step=0.02322 g_raw=+0.003 g_sm=+0.018 acc=1 | LR→0.151770 PERT→0.140020 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1502566847, PERT_used=0.1400172385 → LR_next=0.1517701314, PERT_next=0.1400203217\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.022 acc_ratio=1.00 | LR 0.1502566847→0.1517701314 PERT 0.1400172385→0.1400203217\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.55\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.272692 step=0.0206 g_raw=+0.010 g_sm=+0.017 acc=1 | LR→0.152075 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#085 loss=0.267570 step=0.006382 g_raw=+0.001 g_sm=+0.016 acc=1 | LR→0.152379 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#090 loss=0.266849 step=0.01162 g_raw=+0.003 g_sm=+0.014 acc=1 | LR→0.152685 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#095 loss=0.265482 step=0.01172 g_raw=-0.001 g_sm=+0.012 acc=1 | LR→0.152991 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#100 loss=0.263978 step=0.02376 g_raw=+0.005 g_sm=+0.012 acc=1 | LR→0.153298 PERT→0.140022 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1517701314, PERT_used=0.1400203217 → LR_next=0.1532977161, PERT_next=0.1400223947\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1517701314→0.1532977161 PERT 0.1400203217→0.1400223947\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.263108 step=0.02834 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.153605 PERT→0.140023 (scale=0.04)\n",
            "[meta] cb#110 loss=0.262225 step=0.009851 g_raw=-0.000 g_sm=+0.010 acc=1 | LR→0.153913 PERT→0.140023 (scale=0.04)\n",
            "[meta] cb#115 loss=0.260649 step=0.01049 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.154221 PERT→0.140023 (scale=0.04)\n",
            "[meta] cb#120 loss=0.259106 step=0.0266 g_raw=+0.004 g_sm=+0.009 acc=1 | LR→0.154530 PERT→0.140024 (scale=0.04)\n",
            "[meta] cb#125 loss=0.258887 step=0.011 g_raw=-0.002 g_sm=+0.008 acc=1 | LR→0.154840 PERT→0.140024 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1532977161, PERT_used=0.1400223947 → LR_next=0.1548398883, PERT_next=0.1400237553\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1532977161→0.1548398883 PERT 0.1400223947→0.1400237553\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.51\n",
            "[round 5 | client 3] final LR=0.1548398883, final PERT=0.1400237553  (ΔLR=+0.0075651224, ΔPERT=+0.0000128265)\n",
            "[round 5 | client 4] seed LR=0.1472749165 (prev=0.1545498330), seed PERT=0.1400110210 (prev=0.1400220419), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.487615 step=0.01955 g_raw=+0.008 g_sm=+0.006 acc=1 | LR→0.147570 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#010 loss=0.477316 step=0.02794 g_raw=+0.010 g_sm=+0.010 acc=1 | LR→0.147866 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#015 loss=0.463757 step=0.1011 g_raw=+0.041 g_sm=+0.014 acc=1 | LR→0.148162 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#020 loss=0.446760 step=0.1044 g_raw=+0.037 g_sm=+0.017 acc=1 | LR→0.148459 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#025 loss=0.433483 step=0.1168 g_raw=+0.044 g_sm=+0.020 acc=1 | LR→0.148757 PERT→0.140013 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1472749165, PERT_used=0.1400110210 → LR_next=0.1487567871, PERT_next=0.1400126522\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.027 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1472749165→0.1487567871 PERT 0.1400110210→0.1400126522\n",
            "Training Accuracy: 0.77\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.412871 step=0.02879 g_raw=+0.008 g_sm=+0.022 acc=1 | LR→0.149055 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#035 loss=0.407809 step=0.04016 g_raw=+0.014 g_sm=+0.020 acc=1 | LR→0.149354 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#040 loss=0.390146 step=0.0648 g_raw=+0.022 g_sm=+0.023 acc=1 | LR→0.149654 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#045 loss=0.373943 step=0.0004188 g_raw=-0.004 g_sm=+0.023 acc=1 | LR→0.149954 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#050 loss=0.363151 step=0.1228 g_raw=+0.040 g_sm=+0.023 acc=1 | LR→0.150255 PERT→0.140016 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1487567871, PERT_used=0.1400126522 → LR_next=0.1502551813, PERT_next=0.1400157866\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.025 g_sm_mean=+0.022 acc_ratio=1.00 | LR 0.1487567871→0.1502551813 PERT 0.1400126522→0.1400157866\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.344797 step=0.03252 g_raw=+0.011 g_sm=+0.024 acc=1 | LR→0.150557 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#060 loss=0.335670 step=0.09341 g_raw=+0.034 g_sm=+0.024 acc=1 | LR→0.150859 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#065 loss=0.331376 step=0.0217 g_raw=+0.002 g_sm=+0.022 acc=1 | LR→0.151162 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#070 loss=0.325249 step=0.01833 g_raw=+0.003 g_sm=+0.020 acc=1 | LR→0.151465 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#075 loss=0.315369 step=0.05439 g_raw=+0.019 g_sm=+0.021 acc=1 | LR→0.151769 PERT→0.140019 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1502551813, PERT_used=0.1400157866 → LR_next=0.1517687161, PERT_next=0.1400189650\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.023 acc_ratio=1.00 | LR 0.1502551813→0.1517687161 PERT 0.1400157866→0.1400189650\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.312225 step=0.07832 g_raw=+0.026 g_sm=+0.019 acc=1 | LR→0.152073 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#085 loss=0.308511 step=0.02764 g_raw=+0.010 g_sm=+0.017 acc=1 | LR→0.152378 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#090 loss=0.306462 step=0.01572 g_raw=+0.006 g_sm=+0.015 acc=1 | LR→0.152684 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#095 loss=0.303131 step=0.04037 g_raw=+0.013 g_sm=+0.015 acc=1 | LR→0.152990 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#100 loss=0.297219 step=0.1143 g_raw=+0.041 g_sm=+0.015 acc=1 | LR→0.153297 PERT→0.140021 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1517687161, PERT_used=0.1400189650 → LR_next=0.1532965513, PERT_next=0.1400212798\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1517687161→0.1532965513 PERT 0.1400189650→0.1400212798\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.294557 step=0.05317 g_raw=+0.017 g_sm=+0.014 acc=1 | LR→0.153604 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#110 loss=0.291480 step=0.03951 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.153912 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#115 loss=0.289512 step=0.06441 g_raw=+0.021 g_sm=+0.013 acc=1 | LR→0.154220 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#120 loss=0.286352 step=0.03718 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.154530 PERT→0.140023 (scale=0.04)\n",
            "[meta] cb#125 loss=0.283293 step=0.03223 g_raw=+0.010 g_sm=+0.012 acc=1 | LR→0.154839 PERT→0.140023 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1532965513, PERT_used=0.1400212798 → LR_next=0.1548392780, PERT_next=0.1400231524\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1532965513→0.1548392780 PERT 0.1400212798→0.1400231524\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.49\n",
            "[round 5 | client 4] final LR=0.1548392780, final PERT=0.1400231524  (ΔLR=+0.0075643615, ΔPERT=+0.0000121314)\n",
            "\n",
            "[Round 5] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           3      0.746912      0.507000      0.154840      0.140024\n",
            "           4      0.749064      0.495000      0.154839      0.140023\n",
            "           1      0.899808      0.505000      0.154839      0.140023\n",
            "           0      0.941407      0.495000      0.154840      0.140024\n",
            "           2      1.005256      0.495000      0.154838      0.140022\n",
            "→ [Round 5] best_client=3, best_val=0.746912, prev_global_val=0.622666, improve=-0.124247, action=hold (τ=0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  60%|██████    | 6/10 [1:53:26<1:12:20, 1085.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   5] acc_g=0.764 (μ=0.499, σ=0.005, FG=0.011) | t=861.052s, val=0.619 | TEL=FALSE\n",
            "[Round 6] Teleportation OFF | Aggregation=best\n",
            "[round 6 | client 0] seed LR=0.1474201027 (prev=0.1548402054), seed PERT=0.1400119445 (prev=0.1400238891), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.486556 step=0.04287 g_raw=+0.016 g_sm=+0.001 acc=1 | LR→0.147715 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#010 loss=0.479719 step=0.03583 g_raw=+0.011 g_sm=+0.006 acc=1 | LR→0.148011 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#015 loss=0.474111 step=0.01451 g_raw=+0.004 g_sm=+0.008 acc=1 | LR→0.148308 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#020 loss=0.467970 step=0.05359 g_raw=+0.022 g_sm=+0.010 acc=1 | LR→0.148605 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#025 loss=0.462513 step=0.06543 g_raw=+0.021 g_sm=+0.012 acc=1 | LR→0.148903 PERT→0.140013 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1474201027, PERT_used=0.1400119445 → LR_next=0.1489026768, PERT_next=0.1400128637\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1474201027→0.1489026768 PERT 0.1400119445→0.1400128637\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.449204 step=0.06262 g_raw=+0.021 g_sm=+0.016 acc=1 | LR→0.149201 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#035 loss=0.440420 step=0.1115 g_raw=+0.035 g_sm=+0.017 acc=1 | LR→0.149500 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#040 loss=0.426623 step=0.00345 g_raw=+0.002 g_sm=+0.019 acc=1 | LR→0.149800 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#045 loss=0.414865 step=0.04109 g_raw=+0.011 g_sm=+0.020 acc=1 | LR→0.150101 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#050 loss=0.402076 step=0.1106 g_raw=+0.040 g_sm=+0.022 acc=1 | LR→0.150402 PERT→0.140015 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1489026768, PERT_used=0.1400128637 → LR_next=0.1504018754, PERT_next=0.1400153789\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.026 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1489026768→0.1504018754 PERT 0.1400128637→0.1400153789\n",
            "Training Accuracy: 0.77\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.389182 step=0.05944 g_raw=+0.022 g_sm=+0.022 acc=1 | LR→0.150704 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#060 loss=0.382937 step=0.04235 g_raw=+0.016 g_sm=+0.021 acc=1 | LR→0.151006 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#065 loss=0.377454 step=0.01969 g_raw=+0.007 g_sm=+0.020 acc=1 | LR→0.151309 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#070 loss=0.372425 step=0.04114 g_raw=+0.013 g_sm=+0.019 acc=1 | LR→0.151612 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#075 loss=0.369186 step=0.01765 g_raw=+0.006 g_sm=+0.018 acc=1 | LR→0.151917 PERT→0.140018 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1504018754, PERT_used=0.1400153789 → LR_next=0.1519165756, PERT_next=0.1400182695\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.021 acc_ratio=1.00 | LR 0.1504018754→0.1519165756 PERT 0.1400153789→0.1400182695\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.362940 step=0.009926 g_raw=+0.006 g_sm=+0.018 acc=1 | LR→0.152221 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#085 loss=0.360926 step=0.03988 g_raw=+0.013 g_sm=+0.016 acc=1 | LR→0.152527 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#090 loss=0.356684 step=0.09315 g_raw=+0.026 g_sm=+0.016 acc=1 | LR→0.152832 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#095 loss=0.354034 step=0.06105 g_raw=+0.021 g_sm=+0.014 acc=1 | LR→0.153139 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#100 loss=0.353632 step=0.0114 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.153446 PERT→0.140020 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1519165756, PERT_used=0.1400182695 → LR_next=0.1534457720, PERT_next=0.1400204681\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1519165756→0.1534457720 PERT 0.1400182695→0.1400204681\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.48\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.352080 step=0.05286 g_raw=+0.012 g_sm=+0.011 acc=1 | LR→0.153753 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#110 loss=0.351462 step=0.03282 g_raw=+0.014 g_sm=+0.010 acc=1 | LR→0.154061 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#115 loss=0.348415 step=0.002704 g_raw=-0.000 g_sm=+0.010 acc=1 | LR→0.154370 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#120 loss=0.346604 step=0.04859 g_raw=+0.015 g_sm=+0.010 acc=1 | LR→0.154680 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#125 loss=0.344139 step=0.06147 g_raw=+0.021 g_sm=+0.010 acc=1 | LR→0.154990 PERT→0.140022 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1534457720, PERT_used=0.1400204681 → LR_next=0.1549895347, PERT_next=0.1400219199\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1534457720→0.1549895347 PERT 0.1400204681→0.1400219199\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.48\n",
            "[round 6 | client 0] final LR=0.1549895347, final PERT=0.1400219199  (ΔLR=+0.0075694320, ΔPERT=+0.0000099754)\n",
            "[round 6 | client 1] seed LR=0.1474194812 (prev=0.1548389624), seed PERT=0.1400114709 (prev=0.1400229417), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.532512 step=0.01797 g_raw=+0.004 g_sm=+0.006 acc=1 | LR→0.147715 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#010 loss=0.504470 step=0.1424 g_raw=+0.048 g_sm=+0.014 acc=1 | LR→0.148011 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#015 loss=0.479627 step=0.04904 g_raw=+0.017 g_sm=+0.018 acc=1 | LR→0.148308 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#020 loss=0.469712 step=0.1025 g_raw=+0.034 g_sm=+0.020 acc=1 | LR→0.148605 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#025 loss=0.453474 step=0.03054 g_raw=+0.011 g_sm=+0.021 acc=1 | LR→0.148903 PERT→0.140013 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1474194812, PERT_used=0.1400114709 → LR_next=0.1489031458, PERT_next=0.1400134213\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.030 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1474194812→0.1489031458 PERT 0.1400114709→0.1400134213\n",
            "Training Accuracy: 0.67\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.436107 step=0.1 g_raw=+0.035 g_sm=+0.023 acc=1 | LR→0.149202 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#035 loss=0.430217 step=0.003942 g_raw=-0.001 g_sm=+0.022 acc=1 | LR→0.149501 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#040 loss=0.405308 step=0.06681 g_raw=+0.022 g_sm=+0.026 acc=1 | LR→0.149801 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#045 loss=0.402454 step=0.06861 g_raw=+0.020 g_sm=+0.022 acc=1 | LR→0.150102 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#050 loss=0.399042 step=0.08273 g_raw=+0.028 g_sm=+0.020 acc=1 | LR→0.150403 PERT→0.140017 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1489031458, PERT_used=0.1400134213 → LR_next=0.1504029977, PERT_next=0.1400165402\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.022 g_sm_mean=+0.022 acc_ratio=1.00 | LR 0.1489031458→0.1504029977 PERT 0.1400134213→0.1400165402\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.387833 step=0.005916 g_raw=+0.004 g_sm=+0.020 acc=1 | LR→0.150705 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#060 loss=0.380200 step=0.03521 g_raw=+0.008 g_sm=+0.020 acc=1 | LR→0.151007 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#065 loss=0.372490 step=0.05074 g_raw=+0.018 g_sm=+0.019 acc=1 | LR→0.151310 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#070 loss=0.369546 step=0.07673 g_raw=+0.024 g_sm=+0.018 acc=1 | LR→0.151613 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#075 loss=0.364797 step=0.02427 g_raw=+0.005 g_sm=+0.017 acc=1 | LR→0.151917 PERT→0.140019 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1504029977, PERT_used=0.1400165402 → LR_next=0.1519174079, PERT_next=0.1400191532\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1504029977→0.1519174079 PERT 0.1400165402→0.1400191532\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.358780 step=0.01663 g_raw=+0.004 g_sm=+0.017 acc=1 | LR→0.152222 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#085 loss=0.357566 step=0.007618 g_raw=+0.001 g_sm=+0.015 acc=1 | LR→0.152527 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#090 loss=0.353418 step=0.009218 g_raw=+0.003 g_sm=+0.014 acc=1 | LR→0.152833 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#095 loss=0.350767 step=0.06413 g_raw=+0.024 g_sm=+0.013 acc=1 | LR→0.153139 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#100 loss=0.348410 step=0.001897 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.153446 PERT→0.140021 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1519174079, PERT_used=0.1400191532 → LR_next=0.1534464653, PERT_next=0.1400212173\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1519174079→0.1534464653 PERT 0.1400191532→0.1400212173\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.347705 step=0.0152 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.153754 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#110 loss=0.340889 step=0.06628 g_raw=+0.021 g_sm=+0.013 acc=1 | LR→0.154062 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#115 loss=0.335869 step=0.06344 g_raw=+0.021 g_sm=+0.014 acc=1 | LR→0.154371 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#120 loss=0.332165 step=0.01959 g_raw=+0.010 g_sm=+0.014 acc=1 | LR→0.154681 PERT→0.140023 (scale=0.04)\n",
            "[meta] cb#125 loss=0.329181 step=0.03146 g_raw=+0.006 g_sm=+0.013 acc=1 | LR→0.154991 PERT→0.140023 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1534464653, PERT_used=0.1400212173 → LR_next=0.1549906085, PERT_next=0.1400230067\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1534464653→0.1549906085 PERT 0.1400212173→0.1400230067\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.51\n",
            "[round 6 | client 1] final LR=0.1549906085, final PERT=0.1400230067  (ΔLR=+0.0075711273, ΔPERT=+0.0000115358)\n",
            "[round 6 | client 2] seed LR=0.1474190932 (prev=0.1548381865), seed PERT=0.1400110898 (prev=0.1400221797), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.466463 step=0.09792 g_raw=+0.033 g_sm=+0.005 acc=1 | LR→0.147714 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#010 loss=0.445170 step=0.1604 g_raw=+0.061 g_sm=+0.011 acc=1 | LR→0.148010 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#015 loss=0.439783 step=0.01953 g_raw=+0.011 g_sm=+0.013 acc=1 | LR→0.148307 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#020 loss=0.433864 step=0.01774 g_raw=+0.006 g_sm=+0.013 acc=1 | LR→0.148604 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#025 loss=0.423327 step=0.07675 g_raw=+0.024 g_sm=+0.016 acc=1 | LR→0.148902 PERT→0.140012 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1474190932, PERT_used=0.1400110898 → LR_next=0.1489021778, PERT_next=0.1400124984\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.022 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1474190932→0.1489021778 PERT 0.1400110898→0.1400124984\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.402890 step=0.04758 g_raw=+0.006 g_sm=+0.019 acc=1 | LR→0.149201 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#035 loss=0.386205 step=0.1016 g_raw=+0.032 g_sm=+0.021 acc=1 | LR→0.149500 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#040 loss=0.372102 step=0.04881 g_raw=+0.015 g_sm=+0.022 acc=1 | LR→0.149800 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#045 loss=0.356137 step=0.03852 g_raw=+0.010 g_sm=+0.023 acc=1 | LR→0.150101 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#050 loss=0.349563 step=0.009918 g_raw=-0.003 g_sm=+0.022 acc=1 | LR→0.150402 PERT→0.140015 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1489021778, PERT_used=0.1400124984 → LR_next=0.1504018278, PERT_next=0.1400154386\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.026 g_sm_mean=+0.021 acc_ratio=1.00 | LR 0.1489021778→0.1504018278 PERT 0.1400124984→0.1400154386\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.345018 step=0.02387 g_raw=+0.007 g_sm=+0.021 acc=1 | LR→0.150704 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#060 loss=0.338854 step=0.05591 g_raw=+0.016 g_sm=+0.020 acc=1 | LR→0.151006 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#065 loss=0.335865 step=0.01646 g_raw=+0.007 g_sm=+0.018 acc=1 | LR→0.151309 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#070 loss=0.329782 step=0.1001 g_raw=+0.036 g_sm=+0.018 acc=1 | LR→0.151612 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#075 loss=0.325808 step=0.00587 g_raw=-0.000 g_sm=+0.017 acc=1 | LR→0.151916 PERT→0.140018 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1504018278, PERT_used=0.1400154386 → LR_next=0.1519162884, PERT_next=0.1400181088\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1504018278→0.1519162884 PERT 0.1400154386→0.1400181088\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.324892 step=0.01911 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.152221 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#085 loss=0.323086 step=0.002784 g_raw=-0.001 g_sm=+0.012 acc=1 | LR→0.152526 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#090 loss=0.320815 step=0.004372 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.152832 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#095 loss=0.319864 step=0.005633 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.153138 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#100 loss=0.316975 step=0.03477 g_raw=+0.016 g_sm=+0.011 acc=1 | LR→0.153445 PERT→0.140020 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1519162884, PERT_used=0.1400181088 → LR_next=0.1534449218, PERT_next=0.1400197963\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1519162884→0.1534449218 PERT 0.1400181088→0.1400197963\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.315781 step=0.02807 g_raw=+0.011 g_sm=+0.010 acc=1 | LR→0.153752 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#110 loss=0.312925 step=0.07248 g_raw=+0.024 g_sm=+0.010 acc=1 | LR→0.154061 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#115 loss=0.310283 step=0.0166 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.154369 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#120 loss=0.304455 step=0.1025 g_raw=+0.031 g_sm=+0.012 acc=1 | LR→0.154679 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#125 loss=0.300718 step=0.03683 g_raw=+0.010 g_sm=+0.012 acc=1 | LR→0.154989 PERT→0.140021 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1534449218, PERT_used=0.1400197963 → LR_next=0.1549887587, PERT_next=0.1400213229\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1534449218→0.1549887587 PERT 0.1400197963→0.1400213229\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.49\n",
            "[round 6 | client 2] final LR=0.1549887587, final PERT=0.1400213229  (ΔLR=+0.0075696655, ΔPERT=+0.0000102331)\n",
            "[round 6 | client 3] seed LR=0.1474199442 (prev=0.1548398883), seed PERT=0.1400118777 (prev=0.1400237553), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.516072 step=0.0283 g_raw=+0.010 g_sm=+0.004 acc=1 | LR→0.147715 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#010 loss=0.502731 step=0.01581 g_raw=+0.006 g_sm=+0.008 acc=1 | LR→0.148011 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#015 loss=0.490036 step=0.05333 g_raw=+0.019 g_sm=+0.012 acc=1 | LR→0.148308 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#020 loss=0.471116 step=0.1664 g_raw=+0.059 g_sm=+0.016 acc=1 | LR→0.148605 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#025 loss=0.461373 step=0.01927 g_raw=+0.009 g_sm=+0.017 acc=1 | LR→0.148903 PERT→0.140013 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1474199442, PERT_used=0.1400118777 → LR_next=0.1489030060, PERT_next=0.1400132568\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.022 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1474199442→0.1489030060 PERT 0.1400118777→0.1400132568\n",
            "Training Accuracy: 0.59\n",
            "Test Accuracy: 0.55\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.458068 step=0.05313 g_raw=+0.020 g_sm=+0.016 acc=1 | LR→0.149202 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#035 loss=0.452217 step=0.05655 g_raw=+0.022 g_sm=+0.017 acc=1 | LR→0.149501 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#040 loss=0.447032 step=0.03497 g_raw=+0.008 g_sm=+0.016 acc=1 | LR→0.149801 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#045 loss=0.443477 step=0.02167 g_raw=+0.002 g_sm=+0.015 acc=1 | LR→0.150101 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#050 loss=0.435307 step=0.08136 g_raw=+0.041 g_sm=+0.018 acc=1 | LR→0.150402 PERT→0.140016 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1489030060, PERT_used=0.1400132568 → LR_next=0.1504019582, PERT_next=0.1400155396\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1489030060→0.1504019582 PERT 0.1400132568→0.1400155396\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.431403 step=0.07448 g_raw=+0.026 g_sm=+0.017 acc=1 | LR→0.150704 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#060 loss=0.429087 step=0.04941 g_raw=+0.021 g_sm=+0.016 acc=1 | LR→0.151006 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#065 loss=0.424870 step=0.05679 g_raw=+0.023 g_sm=+0.017 acc=1 | LR→0.151309 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#070 loss=0.423150 step=0.009417 g_raw=+0.002 g_sm=+0.015 acc=1 | LR→0.151612 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#075 loss=0.419852 step=0.02369 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.151916 PERT→0.140018 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1504019582, PERT_used=0.1400155396 → LR_next=0.1519159418, PERT_next=0.1400177689\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1504019582→0.1519159418 PERT 0.1400155396→0.1400177689\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.55\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.418716 step=0.04444 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.152220 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#085 loss=0.417077 step=0.01605 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.152526 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#090 loss=0.415191 step=0.0104 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.152831 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#095 loss=0.410671 step=0.03448 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.153138 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#100 loss=0.409105 step=0.002621 g_raw=+0.000 g_sm=+0.011 acc=1 | LR→0.153445 PERT→0.140019 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1519159418, PERT_used=0.1400177689 → LR_next=0.1534445286, PERT_next=0.1400194171\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1519159418→0.1534445286 PERT 0.1400177689→0.1400194171\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.57\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.404579 step=0.01394 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.153752 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#110 loss=0.398473 step=0.0986 g_raw=+0.032 g_sm=+0.012 acc=1 | LR→0.154060 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#115 loss=0.391966 step=0.01225 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.154369 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#120 loss=0.384550 step=0.08863 g_raw=+0.031 g_sm=+0.015 acc=1 | LR→0.154679 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#125 loss=0.379001 step=0.08894 g_raw=+0.031 g_sm=+0.015 acc=1 | LR→0.154989 PERT→0.140021 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1534445286, PERT_used=0.1400194171 → LR_next=0.1549886658, PERT_next=0.1400212187\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1534445286→0.1549886658 PERT 0.1400194171→0.1400212187\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.50\n",
            "[round 6 | client 3] final LR=0.1549886658, final PERT=0.1400212187  (ΔLR=+0.0075687217, ΔPERT=+0.0000093410)\n",
            "[round 6 | client 4] seed LR=0.1474196390 (prev=0.1548392780), seed PERT=0.1400115762 (prev=0.1400231524), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.500795 step=0.06823 g_raw=+0.024 g_sm=+0.005 acc=1 | LR→0.147715 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#010 loss=0.493205 step=0.01806 g_raw=+0.007 g_sm=+0.009 acc=1 | LR→0.148011 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#015 loss=0.474492 step=0.03923 g_raw=+0.017 g_sm=+0.014 acc=1 | LR→0.148308 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#020 loss=0.446051 step=0.008552 g_raw=+0.006 g_sm=+0.019 acc=1 | LR→0.148605 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#025 loss=0.423661 step=0.1412 g_raw=+0.053 g_sm=+0.023 acc=1 | LR→0.148903 PERT→0.140013 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1474196390, PERT_used=0.1400115762 → LR_next=0.1489030717, PERT_next=0.1400133070\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.030 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1474196390→0.1489030717 PERT 0.1400115762→0.1400133070\n",
            "Training Accuracy: 0.83\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.417527 step=0.06609 g_raw=+0.020 g_sm=+0.022 acc=1 | LR→0.149202 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#035 loss=0.404131 step=0.08807 g_raw=+0.030 g_sm=+0.024 acc=1 | LR→0.149501 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#040 loss=0.386042 step=0.0982 g_raw=+0.039 g_sm=+0.026 acc=1 | LR→0.149801 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#045 loss=0.377445 step=0.02857 g_raw=+0.010 g_sm=+0.026 acc=1 | LR→0.150102 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#050 loss=0.370460 step=0.02093 g_raw=+0.009 g_sm=+0.024 acc=1 | LR→0.150403 PERT→0.140017 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1489030717, PERT_used=0.1400133070 → LR_next=0.1504032208, PERT_next=0.1400167034\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.025 g_sm_mean=+0.024 acc_ratio=1.00 | LR 0.1489030717→0.1504032208 PERT 0.1400133070→0.1400167034\n",
            "Training Accuracy: 0.83\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.366887 step=0.02396 g_raw=+0.006 g_sm=+0.022 acc=1 | LR→0.150705 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#060 loss=0.343011 step=0.1083 g_raw=+0.037 g_sm=+0.025 acc=1 | LR→0.151007 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#065 loss=0.340812 step=0.02014 g_raw=+0.008 g_sm=+0.021 acc=1 | LR→0.151310 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#070 loss=0.337789 step=0.03791 g_raw=+0.014 g_sm=+0.019 acc=1 | LR→0.151614 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#075 loss=0.324056 step=0.009571 g_raw=+0.002 g_sm=+0.019 acc=1 | LR→0.151918 PERT→0.140020 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1504032208, PERT_used=0.1400167034 → LR_next=0.1519180848, PERT_next=0.1400197325\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.022 acc_ratio=1.00 | LR 0.1504032208→0.1519180848 PERT 0.1400167034→0.1400197325\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.315709 step=0.07509 g_raw=+0.028 g_sm=+0.020 acc=1 | LR→0.152223 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#085 loss=0.310226 step=0.01824 g_raw=+0.008 g_sm=+0.019 acc=1 | LR→0.152528 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#090 loss=0.300824 step=0.00345 g_raw=+0.002 g_sm=+0.019 acc=1 | LR→0.152834 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#095 loss=0.296029 step=0.01136 g_raw=+0.004 g_sm=+0.018 acc=1 | LR→0.153141 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#100 loss=0.292372 step=0.01071 g_raw=+0.005 g_sm=+0.016 acc=1 | LR→0.153448 PERT→0.140022 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1519180848, PERT_used=0.1400197325 → LR_next=0.1534477467, PERT_next=0.1400223421\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1519180848→0.1534477467 PERT 0.1400197325→0.1400223421\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.290291 step=0.001927 g_raw=+0.002 g_sm=+0.015 acc=1 | LR→0.153755 PERT→0.140023 (scale=0.04)\n",
            "[meta] cb#110 loss=0.286039 step=0.00704 g_raw=+0.005 g_sm=+0.014 acc=1 | LR→0.154064 PERT→0.140023 (scale=0.04)\n",
            "[meta] cb#115 loss=0.284728 step=0.02185 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.154373 PERT→0.140024 (scale=0.04)\n",
            "[meta] cb#120 loss=0.280393 step=0.0496 g_raw=+0.014 g_sm=+0.014 acc=1 | LR→0.154682 PERT→0.140024 (scale=0.04)\n",
            "[meta] cb#125 loss=0.279488 step=0.0252 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.154992 PERT→0.140024 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1534477467, PERT_used=0.1400223421 → LR_next=0.1549920965, PERT_next=0.1400243064\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1534477467→0.1549920965 PERT 0.1400223421→0.1400243064\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.49\n",
            "[round 6 | client 4] final LR=0.1549920965, final PERT=0.1400243064  (ΔLR=+0.0075724575, ΔPERT=+0.0000127302)\n",
            "\n",
            "[Round 6] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           3      0.674177      0.504000      0.154989      0.140021\n",
            "           0      0.723395      0.483000      0.154990      0.140022\n",
            "           1      0.755300      0.507000      0.154991      0.140023\n",
            "           2      0.799525      0.495000      0.154989      0.140021\n",
            "           4      0.800525      0.494000      0.154992      0.140024\n",
            "→ [Round 6] best_client=3, best_val=0.674177, prev_global_val=0.618795, improve=-0.055382, action=hold (τ=0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  70%|███████   | 7/10 [2:12:21<55:04, 1101.38s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   6] acc_g=0.771 (μ=0.497, σ=0.008, FG=0.018) | t=1117.789s, val=0.637 | TEL=FALSE\n",
            "[Round 7] Teleportation OFF | Aggregation=best\n",
            "[round 7 | client 0] seed LR=0.1474947673 (prev=0.1549895347), seed PERT=0.1400109600 (prev=0.1400219199), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.507980 step=0.2188 g_raw=+0.084 g_sm=+0.009 acc=1 | LR→0.147790 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#010 loss=0.498846 step=0.03918 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.148086 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#015 loss=0.491176 step=0.03673 g_raw=+0.018 g_sm=+0.014 acc=1 | LR→0.148383 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#020 loss=0.450891 step=0.002079 g_raw=+0.001 g_sm=+0.021 acc=1 | LR→0.148681 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#025 loss=0.418855 step=0.03164 g_raw=+0.009 g_sm=+0.025 acc=1 | LR→0.148979 PERT→0.140013 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1474947673, PERT_used=0.1400109600 → LR_next=0.1489792394, PERT_next=0.1400129571\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.033 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1474947673→0.1489792394 PERT 0.1400109600→0.1400129571\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.415857 step=0.005071 g_raw=+0.000 g_sm=+0.021 acc=1 | LR→0.149278 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#035 loss=0.402461 step=0.04249 g_raw=+0.014 g_sm=+0.022 acc=1 | LR→0.149578 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#040 loss=0.394379 step=0.1066 g_raw=+0.036 g_sm=+0.022 acc=1 | LR→0.149878 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#045 loss=0.377541 step=0.008341 g_raw=+0.004 g_sm=+0.022 acc=1 | LR→0.150179 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#050 loss=0.373557 step=0.03529 g_raw=+0.012 g_sm=+0.020 acc=1 | LR→0.150480 PERT→0.140016 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1489792394, PERT_used=0.1400129571 → LR_next=0.1504798027, PERT_next=0.1400160249\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.022 acc_ratio=1.00 | LR 0.1489792394→0.1504798027 PERT 0.1400129571→0.1400160249\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.358194 step=0.09182 g_raw=+0.031 g_sm=+0.022 acc=1 | LR→0.150782 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#060 loss=0.355861 step=0.02406 g_raw=+0.008 g_sm=+0.019 acc=1 | LR→0.151084 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#065 loss=0.350062 step=0.05641 g_raw=+0.022 g_sm=+0.018 acc=1 | LR→0.151387 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#070 loss=0.346588 step=0.04098 g_raw=+0.020 g_sm=+0.017 acc=1 | LR→0.151691 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#075 loss=0.341665 step=0.04661 g_raw=+0.022 g_sm=+0.017 acc=1 | LR→0.151995 PERT→0.140019 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1504798027, PERT_used=0.1400160249 → LR_next=0.1519950328, PERT_next=0.1400186807\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1504798027→0.1519950328 PERT 0.1400160249→0.1400186807\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.339383 step=0.04263 g_raw=+0.018 g_sm=+0.016 acc=1 | LR→0.152300 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#085 loss=0.331424 step=0.1114 g_raw=+0.035 g_sm=+0.017 acc=1 | LR→0.152605 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#090 loss=0.328011 step=0.0518 g_raw=+0.017 g_sm=+0.016 acc=1 | LR→0.152911 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#095 loss=0.327027 step=0.002535 g_raw=+0.004 g_sm=+0.014 acc=1 | LR→0.153218 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#100 loss=0.322012 step=0.07526 g_raw=+0.020 g_sm=+0.015 acc=1 | LR→0.153525 PERT→0.140021 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1519950328, PERT_used=0.1400186807 → LR_next=0.1535250232, PERT_next=0.1400208831\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1519950328→0.1535250232 PERT 0.1400186807→0.1400208831\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.320824 step=0.0003208 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.153833 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#110 loss=0.317637 step=0.05711 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.154141 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#115 loss=0.314322 step=0.06242 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.154450 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#120 loss=0.313296 step=0.01462 g_raw=+0.005 g_sm=+0.012 acc=1 | LR→0.154760 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#125 loss=0.312858 step=0.0227 g_raw=+0.009 g_sm=+0.010 acc=1 | LR→0.155070 PERT→0.140023 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1535250232, PERT_used=0.1400208831 → LR_next=0.1550699296, PERT_next=0.1400226478\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1535250232→0.1550699296 PERT 0.1400208831→0.1400226478\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.52\n",
            "[round 7 | client 0] final LR=0.1550699296, final PERT=0.1400226478  (ΔLR=+0.0075751622, ΔPERT=+0.0000116878)\n",
            "[round 7 | client 1] seed LR=0.1474953043 (prev=0.1549906085), seed PERT=0.1400115033 (prev=0.1400230067), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.438502 step=0.102 g_raw=+0.032 g_sm=+0.008 acc=1 | LR→0.147791 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#010 loss=0.413327 step=0.08938 g_raw=+0.030 g_sm=+0.013 acc=1 | LR→0.148087 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#015 loss=0.395075 step=0.08701 g_raw=+0.029 g_sm=+0.017 acc=1 | LR→0.148384 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#020 loss=0.388245 step=0.1057 g_raw=+0.033 g_sm=+0.017 acc=1 | LR→0.148681 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#025 loss=0.377136 step=0.009163 g_raw=+0.001 g_sm=+0.018 acc=1 | LR→0.148980 PERT→0.140013 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1474953043, PERT_used=0.1400115033 → LR_next=0.1489796723, PERT_next=0.1400133976\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.027 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1474953043→0.1489796723 PERT 0.1400115033→0.1400133976\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.360227 step=0.1562 g_raw=+0.054 g_sm=+0.020 acc=1 | LR→0.149278 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#035 loss=0.346280 step=0.1051 g_raw=+0.037 g_sm=+0.022 acc=1 | LR→0.149578 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#040 loss=0.339723 step=0.08906 g_raw=+0.026 g_sm=+0.021 acc=1 | LR→0.149878 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#045 loss=0.326817 step=0.01992 g_raw=+0.006 g_sm=+0.022 acc=1 | LR→0.150179 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#050 loss=0.320512 step=0.0549 g_raw=+0.022 g_sm=+0.021 acc=1 | LR→0.150480 PERT→0.140016 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1489796723, PERT_used=0.1400133976 → LR_next=0.1504801181, PERT_next=0.1400163520\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.023 g_sm_mean=+0.021 acc_ratio=1.00 | LR 0.1489796723→0.1504801181 PERT 0.1400133976→0.1400163520\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.313776 step=0.08216 g_raw=+0.029 g_sm=+0.020 acc=1 | LR→0.150782 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#060 loss=0.307625 step=0.06271 g_raw=+0.020 g_sm=+0.020 acc=1 | LR→0.151084 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#065 loss=0.305298 step=0.03803 g_raw=+0.011 g_sm=+0.018 acc=1 | LR→0.151387 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#070 loss=0.295939 step=0.1331 g_raw=+0.042 g_sm=+0.019 acc=1 | LR→0.151691 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#075 loss=0.291764 step=0.06393 g_raw=+0.022 g_sm=+0.018 acc=1 | LR→0.151995 PERT→0.140019 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1504801181, PERT_used=0.1400163520 → LR_next=0.1519953437, PERT_next=0.1400190008\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1504801181→0.1519953437 PERT 0.1400163520→0.1400190008\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.287352 step=0.02347 g_raw=+0.008 g_sm=+0.016 acc=1 | LR→0.152300 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#085 loss=0.285292 step=0.04661 g_raw=+0.018 g_sm=+0.015 acc=1 | LR→0.152606 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#090 loss=0.280224 step=0.02861 g_raw=+0.007 g_sm=+0.015 acc=1 | LR→0.152912 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#095 loss=0.278827 step=0.01304 g_raw=+0.003 g_sm=+0.013 acc=1 | LR→0.153218 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#100 loss=0.276632 step=0.05212 g_raw=+0.019 g_sm=+0.012 acc=1 | LR→0.153525 PERT→0.140021 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1519953437, PERT_used=0.1400190008 → LR_next=0.1535252063, PERT_next=0.1400210838\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1519953437→0.1535252063 PERT 0.1400190008→0.1400210838\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.271661 step=0.07731 g_raw=+0.021 g_sm=+0.013 acc=1 | LR→0.153833 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#110 loss=0.268524 step=0.04928 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.154141 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#115 loss=0.267237 step=0.02156 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.154450 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#120 loss=0.265537 step=0.007221 g_raw=-0.001 g_sm=+0.010 acc=1 | LR→0.154760 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#125 loss=0.264543 step=0.02164 g_raw=+0.005 g_sm=+0.009 acc=1 | LR→0.155070 PERT→0.140023 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1535252063, PERT_used=0.1400210838 → LR_next=0.1550698958, PERT_next=0.1400226510\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1535252063→0.1550698958 PERT 0.1400210838→0.1400226510\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.51\n",
            "[round 7 | client 1] final LR=0.1550698958, final PERT=0.1400226510  (ΔLR=+0.0075745916, ΔPERT=+0.0000111477)\n",
            "[round 7 | client 2] seed LR=0.1474943794 (prev=0.1549887587), seed PERT=0.1400106615 (prev=0.1400213229), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.437343 step=0.1088 g_raw=+0.035 g_sm=+0.007 acc=1 | LR→0.147790 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#010 loss=0.412222 step=0.03309 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.148086 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#015 loss=0.408819 step=0.06874 g_raw=+0.021 g_sm=+0.013 acc=1 | LR→0.148383 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#020 loss=0.392148 step=0.0004235 g_raw=-0.002 g_sm=+0.015 acc=1 | LR→0.148680 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#025 loss=0.367283 step=0.1324 g_raw=+0.044 g_sm=+0.020 acc=1 | LR→0.148978 PERT→0.140012 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1474943794, PERT_used=0.1400106615 → LR_next=0.1489784830, PERT_next=0.1400123160\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.027 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1474943794→0.1489784830 PERT 0.1400106615→0.1400123160\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.359929 step=0.02409 g_raw=+0.012 g_sm=+0.019 acc=1 | LR→0.149277 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#035 loss=0.345309 step=0.01021 g_raw=+0.009 g_sm=+0.021 acc=1 | LR→0.149577 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#040 loss=0.338042 step=0.05784 g_raw=+0.015 g_sm=+0.021 acc=1 | LR→0.149877 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#045 loss=0.337152 step=0.02585 g_raw=+0.007 g_sm=+0.018 acc=1 | LR→0.150177 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#050 loss=0.321535 step=0.04351 g_raw=+0.017 g_sm=+0.020 acc=1 | LR→0.150479 PERT→0.140015 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1489784830, PERT_used=0.1400123160 → LR_next=0.1504787057, PERT_next=0.1400150740\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.020 acc_ratio=1.00 | LR 0.1489784830→0.1504787057 PERT 0.1400123160→0.1400150740\n",
            "Training Accuracy: 0.81\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.316253 step=0.08227 g_raw=+0.025 g_sm=+0.019 acc=1 | LR→0.150781 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#060 loss=0.313375 step=0.05647 g_raw=+0.022 g_sm=+0.018 acc=1 | LR→0.151083 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#065 loss=0.308854 step=0.02271 g_raw=+0.006 g_sm=+0.017 acc=1 | LR→0.151386 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#070 loss=0.306994 step=0.006215 g_raw=+0.003 g_sm=+0.015 acc=1 | LR→0.151690 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#075 loss=0.303972 step=0.02726 g_raw=+0.003 g_sm=+0.014 acc=1 | LR→0.151994 PERT→0.140017 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1504787057, PERT_used=0.1400150740 → LR_next=0.1519936549, PERT_next=0.1400174811\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1504787057→0.1519936549 PERT 0.1400150740→0.1400174811\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.302592 step=0.04467 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.152298 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#085 loss=0.301940 step=0.007582 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.152604 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#090 loss=0.300892 step=0.04042 g_raw=+0.014 g_sm=+0.011 acc=1 | LR→0.152909 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#095 loss=0.299534 step=0.02774 g_raw=+0.006 g_sm=+0.010 acc=1 | LR→0.153216 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#100 loss=0.298024 step=0.03236 g_raw=+0.005 g_sm=+0.009 acc=1 | LR→0.153523 PERT→0.140019 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1519936549, PERT_used=0.1400174811 → LR_next=0.1535229593, PERT_next=0.1400190706\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1519936549→0.1535229593 PERT 0.1400174811→0.1400190706\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.297243 step=0.02453 g_raw=+0.011 g_sm=+0.009 acc=1 | LR→0.153831 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#110 loss=0.297172 step=0.00649 g_raw=+0.003 g_sm=+0.007 acc=1 | LR→0.154139 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#115 loss=0.296583 step=0.02258 g_raw=+0.009 g_sm=+0.007 acc=1 | LR→0.154448 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#120 loss=0.295873 step=0.02927 g_raw=+0.008 g_sm=+0.006 acc=1 | LR→0.154757 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#125 loss=0.295362 step=0.02228 g_raw=+0.006 g_sm=+0.006 acc=1 | LR→0.155067 PERT→0.140020 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1535229593, PERT_used=0.1400190706 → LR_next=0.1550670206, PERT_next=0.1400200909\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.005 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1535229593→0.1550670206 PERT 0.1400190706→0.1400200909\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.49\n",
            "[round 7 | client 2] final LR=0.1550670206, final PERT=0.1400200909  (ΔLR=+0.0075726413, ΔPERT=+0.0000094294)\n",
            "[round 7 | client 3] seed LR=0.1474943329 (prev=0.1549886658), seed PERT=0.1400106093 (prev=0.1400212187), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.486638 step=0.08977 g_raw=+0.029 g_sm=+0.003 acc=1 | LR→0.147790 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#010 loss=0.445041 step=0.02593 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.148086 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#015 loss=0.441493 step=0.05421 g_raw=+0.024 g_sm=+0.014 acc=1 | LR→0.148383 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#020 loss=0.428517 step=0.166 g_raw=+0.060 g_sm=+0.016 acc=1 | LR→0.148680 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#025 loss=0.418943 step=0.03605 g_raw=+0.013 g_sm=+0.017 acc=1 | LR→0.148978 PERT→0.140012 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1474943329, PERT_used=0.1400106093 → LR_next=0.1489783659, PERT_next=0.1400121979\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.025 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1474943329→0.1489783659 PERT 0.1400106093→0.1400121979\n",
            "Training Accuracy: 0.94\n",
            "Test Accuracy: 0.63\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.415580 step=0.06981 g_raw=+0.024 g_sm=+0.017 acc=1 | LR→0.149277 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#035 loss=0.403732 step=0.1317 g_raw=+0.043 g_sm=+0.019 acc=1 | LR→0.149576 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#040 loss=0.386783 step=0.1345 g_raw=+0.044 g_sm=+0.022 acc=1 | LR→0.149877 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#045 loss=0.382900 step=0.02065 g_raw=+0.012 g_sm=+0.020 acc=1 | LR→0.150177 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#050 loss=0.375126 step=0.09238 g_raw=+0.039 g_sm=+0.020 acc=1 | LR→0.150478 PERT→0.140015 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1489783659, PERT_used=0.1400121979 → LR_next=0.1504784523, PERT_next=0.1400148301\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1489783659→0.1504784523 PERT 0.1400121979→0.1400148301\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.363924 step=0.1403 g_raw=+0.052 g_sm=+0.020 acc=1 | LR→0.150780 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#060 loss=0.357183 step=0.07303 g_raw=+0.023 g_sm=+0.020 acc=1 | LR→0.151083 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#065 loss=0.353084 step=0.04492 g_raw=+0.018 g_sm=+0.019 acc=1 | LR→0.151386 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#070 loss=0.351103 step=0.02171 g_raw=+0.009 g_sm=+0.017 acc=1 | LR→0.151689 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#075 loss=0.341886 step=0.04929 g_raw=+0.017 g_sm=+0.017 acc=1 | LR→0.151994 PERT→0.140017 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1504784523, PERT_used=0.1400148301 → LR_next=0.1519936159, PERT_next=0.1400174371\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1504784523→0.1519936159 PERT 0.1400148301→0.1400174371\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.335999 step=0.02946 g_raw=+0.010 g_sm=+0.017 acc=1 | LR→0.152298 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#085 loss=0.329737 step=0.03026 g_raw=+0.014 g_sm=+0.018 acc=1 | LR→0.152604 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#090 loss=0.328724 step=0.02011 g_raw=+0.004 g_sm=+0.015 acc=1 | LR→0.152910 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#095 loss=0.326916 step=0.03091 g_raw=+0.009 g_sm=+0.014 acc=1 | LR→0.153216 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#100 loss=0.325116 step=0.04328 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.153524 PERT→0.140020 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1519936159, PERT_used=0.1400174371 → LR_next=0.1535236090, PERT_next=0.1400196551\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1519936159→0.1535236090 PERT 0.1400174371→0.1400196551\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.323185 step=0.0639 g_raw=+0.018 g_sm=+0.013 acc=1 | LR→0.153831 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#110 loss=0.321086 step=0.01068 g_raw=+0.005 g_sm=+0.012 acc=1 | LR→0.154140 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#115 loss=0.318159 step=0.08635 g_raw=+0.028 g_sm=+0.012 acc=1 | LR→0.154449 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#120 loss=0.316097 step=0.03371 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.154758 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#125 loss=0.314387 step=0.008566 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.155068 PERT→0.140021 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1535236090, PERT_used=0.1400196551 → LR_next=0.1550683947, PERT_next=0.1400213236\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1535236090→0.1550683947 PERT 0.1400196551→0.1400213236\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.51\n",
            "[round 7 | client 3] final LR=0.1550683947, final PERT=0.1400213236  (ΔLR=+0.0075740618, ΔPERT=+0.0000107142)\n",
            "[round 7 | client 4] seed LR=0.1474960482 (prev=0.1549920965), seed PERT=0.1400121532 (prev=0.1400243064), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.476732 step=0.03266 g_raw=+0.009 g_sm=+0.005 acc=1 | LR→0.147791 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#010 loss=0.467711 step=0.1099 g_raw=+0.042 g_sm=+0.009 acc=1 | LR→0.148087 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#015 loss=0.466474 step=0.04964 g_raw=+0.015 g_sm=+0.008 acc=1 | LR→0.148384 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#020 loss=0.463384 step=0.01215 g_raw=+0.005 g_sm=+0.009 acc=1 | LR→0.148682 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#025 loss=0.458926 step=0.06703 g_raw=+0.025 g_sm=+0.010 acc=1 | LR→0.148979 PERT→0.140013 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1474960482, PERT_used=0.1400121532 → LR_next=0.1489794696, PERT_next=0.1400131507\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1474960482→0.1489794696 PERT 0.1400121532→0.1400131507\n",
            "Training Accuracy: 0.71\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.449828 step=0.03873 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.149278 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#035 loss=0.446319 step=0.002668 g_raw=+0.005 g_sm=+0.013 acc=1 | LR→0.149577 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#040 loss=0.435852 step=0.0368 g_raw=+0.017 g_sm=+0.016 acc=1 | LR→0.149877 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#045 loss=0.429004 step=0.0968 g_raw=+0.033 g_sm=+0.017 acc=1 | LR→0.150178 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#050 loss=0.425549 step=0.03162 g_raw=+0.014 g_sm=+0.016 acc=1 | LR→0.150479 PERT→0.140015 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1489794696, PERT_used=0.1400131507 → LR_next=0.1504789627, PERT_next=0.1400152206\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1489794696→0.1504789627 PERT 0.1400131507→0.1400152206\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.418765 step=0.03218 g_raw=+0.013 g_sm=+0.017 acc=1 | LR→0.150781 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#060 loss=0.416038 step=0.03967 g_raw=+0.011 g_sm=+0.016 acc=1 | LR→0.151083 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#065 loss=0.409703 step=0.07893 g_raw=+0.028 g_sm=+0.016 acc=1 | LR→0.151386 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#070 loss=0.403571 step=0.01309 g_raw=+0.009 g_sm=+0.016 acc=1 | LR→0.151690 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#075 loss=0.395167 step=0.111 g_raw=+0.040 g_sm=+0.017 acc=1 | LR→0.151994 PERT→0.140017 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1504789627, PERT_used=0.1400152206 → LR_next=0.1519937674, PERT_next=0.1400174923\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1504789627→0.1519937674 PERT 0.1400152206→0.1400174923\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.47\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.392625 step=0.08238 g_raw=+0.028 g_sm=+0.015 acc=1 | LR→0.152299 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#085 loss=0.386936 step=0.04542 g_raw=+0.014 g_sm=+0.015 acc=1 | LR→0.152604 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#090 loss=0.376849 step=0.03373 g_raw=+0.014 g_sm=+0.015 acc=1 | LR→0.152910 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#095 loss=0.373973 step=0.05009 g_raw=+0.024 g_sm=+0.015 acc=1 | LR→0.153216 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#100 loss=0.372158 step=0.0463 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.153524 PERT→0.140020 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1519937674, PERT_used=0.1400174923 → LR_next=0.1535235786, PERT_next=0.1400195429\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1519937674→0.1535235786 PERT 0.1400174923→0.1400195429\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.45\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.368209 step=0.01433 g_raw=+0.003 g_sm=+0.013 acc=1 | LR→0.153831 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#110 loss=0.358080 step=0.0681 g_raw=+0.024 g_sm=+0.015 acc=1 | LR→0.154140 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#115 loss=0.353906 step=0.0003604 g_raw=+0.003 g_sm=+0.015 acc=1 | LR→0.154449 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#120 loss=0.350794 step=0.04205 g_raw=+0.016 g_sm=+0.014 acc=1 | LR→0.154758 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#125 loss=0.348235 step=0.05377 g_raw=+0.018 g_sm=+0.014 acc=1 | LR→0.155069 PERT→0.140022 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1535235786, PERT_used=0.1400195429 → LR_next=0.1550687446, PERT_next=0.1400215550\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1535235786→0.1550687446 PERT 0.1400195429→0.1400215550\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.49\n",
            "[round 7 | client 4] final LR=0.1550687446, final PERT=0.1400215550  (ΔLR=+0.0075726963, ΔPERT=+0.0000094019)\n",
            "\n",
            "[Round 7] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           0      0.637496      0.516000      0.155070      0.140023\n",
            "           3      0.655880      0.508000      0.155068      0.140021\n",
            "           4      0.736446      0.495000      0.155069      0.140022\n",
            "           2      0.876553      0.494000      0.155067      0.140020\n",
            "           1      0.910041      0.506000      0.155070      0.140023\n",
            "→ [Round 7] best_client=0, best_val=0.637496, prev_global_val=0.637368, improve=-0.000128, action=hold (τ=0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  80%|████████  | 8/10 [2:29:02<35:38, 1069.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   7] acc_g=0.762 (μ=0.504, σ=0.008, FG=0.018) | t=982.874s, val=0.633 | TEL=FALSE\n",
            "[Round 8] Teleportation OFF | Aggregation=best\n",
            "[round 8 | client 0] seed LR=0.1475349648 (prev=0.1550699296), seed PERT=0.1400113239 (prev=0.1400226478), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.447152 step=0.1222 g_raw=+0.047 g_sm=+0.008 acc=1 | LR→0.147830 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#010 loss=0.430158 step=0.012 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.148127 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#015 loss=0.379134 step=0.04707 g_raw=+0.015 g_sm=+0.021 acc=1 | LR→0.148424 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#020 loss=0.370411 step=0.02089 g_raw=+0.010 g_sm=+0.021 acc=1 | LR→0.148722 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#025 loss=0.356987 step=0.01925 g_raw=+0.001 g_sm=+0.021 acc=1 | LR→0.149020 PERT→0.140013 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1475349648, PERT_used=0.1400113239 → LR_next=0.1490199391, PERT_next=0.1400134128\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.031 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1475349648→0.1490199391 PERT 0.1400113239→0.1400134128\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.340619 step=0.08691 g_raw=+0.026 g_sm=+0.023 acc=1 | LR→0.149319 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#035 loss=0.319155 step=0.1751 g_raw=+0.060 g_sm=+0.025 acc=1 | LR→0.149619 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#040 loss=0.309951 step=0.01925 g_raw=+0.006 g_sm=+0.023 acc=1 | LR→0.149919 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#045 loss=0.292415 step=0.008223 g_raw=+0.003 g_sm=+0.024 acc=1 | LR→0.150220 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#050 loss=0.283509 step=0.02601 g_raw=+0.003 g_sm=+0.023 acc=1 | LR→0.150521 PERT→0.140017 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1490199391, PERT_used=0.1400134128 → LR_next=0.1505211707, PERT_next=0.1400167209\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.025 g_sm_mean=+0.024 acc_ratio=1.00 | LR 0.1490199391→0.1505211707 PERT 0.1400134128→0.1400167209\n",
            "Training Accuracy: 0.83\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.276228 step=0.01627 g_raw=+0.006 g_sm=+0.021 acc=1 | LR→0.150823 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#060 loss=0.273716 step=0.04899 g_raw=+0.012 g_sm=+0.019 acc=1 | LR→0.151126 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#065 loss=0.263248 step=0.06826 g_raw=+0.016 g_sm=+0.019 acc=1 | LR→0.151429 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#070 loss=0.260713 step=0.02712 g_raw=+0.011 g_sm=+0.018 acc=1 | LR→0.151733 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#075 loss=0.258342 step=0.007967 g_raw=+0.002 g_sm=+0.016 acc=1 | LR→0.152037 PERT→0.140019 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1505211707, PERT_used=0.1400167209 → LR_next=0.1520368786, PERT_next=0.1400194331\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1505211707→0.1520368786 PERT 0.1400167209→0.1400194331\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.253933 step=0.03082 g_raw=+0.010 g_sm=+0.016 acc=1 | LR→0.152342 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#085 loss=0.251156 step=0.02441 g_raw=+0.010 g_sm=+0.015 acc=1 | LR→0.152647 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#090 loss=0.250532 step=0.04053 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.152953 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#095 loss=0.249651 step=0.01381 g_raw=-0.001 g_sm=+0.011 acc=1 | LR→0.153260 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#100 loss=0.249476 step=0.01617 g_raw=+0.006 g_sm=+0.009 acc=1 | LR→0.153567 PERT→0.140021 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1520368786, PERT_used=0.1400194331 → LR_next=0.1535669183, PERT_next=0.1400212965\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1520368786→0.1535669183 PERT 0.1400194331→0.1400212965\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.249377 step=0.01371 g_raw=-0.003 g_sm=+0.007 acc=1 | LR→0.153875 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#110 loss=0.248566 step=0.02177 g_raw=+0.010 g_sm=+0.007 acc=1 | LR→0.154183 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#115 loss=0.248042 step=0.03368 g_raw=+0.009 g_sm=+0.006 acc=1 | LR→0.154492 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#120 loss=0.247463 step=0.003697 g_raw=+0.006 g_sm=+0.006 acc=1 | LR→0.154801 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#125 loss=0.247465 step=0.0081 g_raw=-0.001 g_sm=+0.005 acc=1 | LR→0.155111 PERT→0.140022 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1535669183, PERT_used=0.1400212965 → LR_next=0.1551113332, PERT_next=0.1400222369\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.003 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1535669183→0.1551113332 PERT 0.1400212965→0.1400222369\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "[round 8 | client 0] final LR=0.1551113332, final PERT=0.1400222369  (ΔLR=+0.0075763684, ΔPERT=+0.0000109130)\n",
            "[round 8 | client 1] seed LR=0.1475349479 (prev=0.1550698958), seed PERT=0.1400113255 (prev=0.1400226510), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.517036 step=0.06342 g_raw=+0.025 g_sm=+0.004 acc=1 | LR→0.147830 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#010 loss=0.491141 step=0.02135 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.148127 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#015 loss=0.482782 step=0.03371 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.148424 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#020 loss=0.472406 step=0.06356 g_raw=+0.025 g_sm=+0.016 acc=1 | LR→0.148721 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#025 loss=0.462821 step=0.1292 g_raw=+0.046 g_sm=+0.017 acc=1 | LR→0.149019 PERT→0.140013 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1475349479, PERT_used=0.1400113255 → LR_next=0.1490194000, PERT_next=0.1400129238\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.025 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1475349479→0.1490194000 PERT 0.1400113255→0.1400129238\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.62\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.455109 step=0.07774 g_raw=+0.034 g_sm=+0.018 acc=1 | LR→0.149318 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#035 loss=0.452923 step=0.05293 g_raw=+0.022 g_sm=+0.017 acc=1 | LR→0.149618 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#040 loss=0.431284 step=0.03885 g_raw=+0.006 g_sm=+0.020 acc=1 | LR→0.149918 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#045 loss=0.422989 step=0.06669 g_raw=+0.026 g_sm=+0.019 acc=1 | LR→0.150219 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#050 loss=0.419721 step=0.03143 g_raw=+0.012 g_sm=+0.017 acc=1 | LR→0.150520 PERT→0.140016 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1490194000, PERT_used=0.1400129238 → LR_next=0.1505198773, PERT_next=0.1400155354\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1490194000→0.1505198773 PERT 0.1400129238→0.1400155354\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.44\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.406696 step=0.07301 g_raw=+0.028 g_sm=+0.019 acc=1 | LR→0.150822 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#060 loss=0.400592 step=0.0209 g_raw=+0.005 g_sm=+0.019 acc=1 | LR→0.151124 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#065 loss=0.383037 step=0.08598 g_raw=+0.023 g_sm=+0.021 acc=1 | LR→0.151428 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#070 loss=0.379388 step=0.03249 g_raw=+0.013 g_sm=+0.020 acc=1 | LR→0.151731 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#075 loss=0.374921 step=0.01211 g_raw=+0.002 g_sm=+0.018 acc=1 | LR→0.152036 PERT→0.140018 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1505198773, PERT_used=0.1400155354 → LR_next=0.1520356248, PERT_next=0.1400182960\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.020 acc_ratio=1.00 | LR 0.1505198773→0.1520356248 PERT 0.1400155354→0.1400182960\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.368071 step=0.03868 g_raw=+0.013 g_sm=+0.018 acc=1 | LR→0.152341 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#085 loss=0.363853 step=0.02343 g_raw=+0.004 g_sm=+0.017 acc=1 | LR→0.152646 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#090 loss=0.357838 step=0.06687 g_raw=+0.024 g_sm=+0.018 acc=1 | LR→0.152952 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#095 loss=0.354015 step=0.008314 g_raw=-0.001 g_sm=+0.016 acc=1 | LR→0.153259 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#100 loss=0.348875 step=0.04907 g_raw=+0.018 g_sm=+0.016 acc=1 | LR→0.153566 PERT→0.140021 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1520356248, PERT_used=0.1400182960 → LR_next=0.1535662637, PERT_next=0.1400207173\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1520356248→0.1535662637 PERT 0.1400182960→0.1400207173\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.346637 step=0.0234 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.153874 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#110 loss=0.336973 step=0.004936 g_raw=+0.005 g_sm=+0.016 acc=1 | LR→0.154183 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#115 loss=0.333324 step=0.0553 g_raw=+0.019 g_sm=+0.015 acc=1 | LR→0.154492 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#120 loss=0.331410 step=0.02797 g_raw=+0.009 g_sm=+0.014 acc=1 | LR→0.154802 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#125 loss=0.325651 step=0.03568 g_raw=+0.010 g_sm=+0.015 acc=1 | LR→0.155112 PERT→0.140023 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1535662637, PERT_used=0.1400207173 → LR_next=0.1551119348, PERT_next=0.1400227976\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1535662637→0.1551119348 PERT 0.1400207173→0.1400227976\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.53\n",
            "[round 8 | client 1] final LR=0.1551119348, final PERT=0.1400227976  (ΔLR=+0.0075769869, ΔPERT=+0.0000114721)\n",
            "[round 8 | client 2] seed LR=0.1475335103 (prev=0.1550670206), seed PERT=0.1400100454 (prev=0.1400200909), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.471671 step=0.08044 g_raw=+0.031 g_sm=+0.005 acc=1 | LR→0.147829 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#010 loss=0.455829 step=0.06046 g_raw=+0.018 g_sm=+0.010 acc=1 | LR→0.148125 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#015 loss=0.394999 step=0.2252 g_raw=+0.076 g_sm=+0.021 acc=1 | LR→0.148422 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#020 loss=0.355513 step=0.01143 g_raw=+0.003 g_sm=+0.026 acc=1 | LR→0.148720 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#025 loss=0.353866 step=0.03064 g_raw=+0.010 g_sm=+0.022 acc=1 | LR→0.149019 PERT→0.140012 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1475335103, PERT_used=0.1400100454 → LR_next=0.1490185472, PERT_next=0.1400122069\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.032 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1475335103→0.1490185472 PERT 0.1400100454→0.1400122069\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.340626 step=0.09442 g_raw=+0.029 g_sm=+0.022 acc=1 | LR→0.149318 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#035 loss=0.334610 step=0.0826 g_raw=+0.026 g_sm=+0.021 acc=1 | LR→0.149617 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#040 loss=0.323115 step=0.01048 g_raw=+0.010 g_sm=+0.022 acc=1 | LR→0.149917 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#045 loss=0.318740 step=0.00331 g_raw=+0.004 g_sm=+0.020 acc=1 | LR→0.150218 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#050 loss=0.310914 step=0.03246 g_raw=+0.012 g_sm=+0.020 acc=1 | LR→0.150519 PERT→0.140015 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1490185472, PERT_used=0.1400122069 → LR_next=0.1505194044, PERT_next=0.1400151798\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.021 acc_ratio=1.00 | LR 0.1490185472→0.1505194044 PERT 0.1400122069→0.1400151798\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.309024 step=0.0423 g_raw=+0.019 g_sm=+0.017 acc=1 | LR→0.150821 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#060 loss=0.306001 step=0.02229 g_raw=+0.006 g_sm=+0.016 acc=1 | LR→0.151124 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#065 loss=0.303494 step=0.02391 g_raw=+0.003 g_sm=+0.015 acc=1 | LR→0.151427 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#070 loss=0.301475 step=0.0157 g_raw=+0.010 g_sm=+0.014 acc=1 | LR→0.151730 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#075 loss=0.299833 step=0.001668 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.152034 PERT→0.140017 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1505194044, PERT_used=0.1400151798 → LR_next=0.1520344852, PERT_next=0.1400173308\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1505194044→0.1520344852 PERT 0.1400151798→0.1400173308\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.296005 step=0.04462 g_raw=+0.015 g_sm=+0.012 acc=1 | LR→0.152339 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#085 loss=0.288145 step=0.05704 g_raw=+0.020 g_sm=+0.014 acc=1 | LR→0.152645 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#090 loss=0.285725 step=0.03815 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.152951 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#095 loss=0.284680 step=0.01768 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.153257 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#100 loss=0.283123 step=0.03295 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.153564 PERT→0.140019 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1520344852, PERT_used=0.1400173308 → LR_next=0.1535643813, PERT_next=0.1400190852\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1520344852→0.1535643813 PERT 0.1400173308→0.1400190852\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.281999 step=0.01601 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.153872 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#110 loss=0.277800 step=0.06681 g_raw=+0.021 g_sm=+0.011 acc=1 | LR→0.154181 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#115 loss=0.276937 step=0.02628 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.154490 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#120 loss=0.276086 step=0.01131 g_raw=+0.004 g_sm=+0.009 acc=1 | LR→0.154799 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#125 loss=0.275532 step=0.007997 g_raw=+0.002 g_sm=+0.008 acc=1 | LR→0.155109 PERT→0.140020 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1535643813, PERT_used=0.1400190852 → LR_next=0.1551092703, PERT_next=0.1400204766\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1535643813→0.1551092703 PERT 0.1400190852→0.1400204766\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "[round 8 | client 2] final LR=0.1551092703, final PERT=0.1400204766  (ΔLR=+0.0075757600, ΔPERT=+0.0000104311)\n",
            "[round 8 | client 3] seed LR=0.1475341973 (prev=0.1550683947), seed PERT=0.1400106618 (prev=0.1400213236), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.404997 step=0.06162 g_raw=+0.021 g_sm=+0.003 acc=1 | LR→0.147830 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#010 loss=0.395942 step=0.08365 g_raw=+0.033 g_sm=+0.008 acc=1 | LR→0.148126 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#015 loss=0.384097 step=0.1555 g_raw=+0.047 g_sm=+0.011 acc=1 | LR→0.148423 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#020 loss=0.377680 step=0.08684 g_raw=+0.030 g_sm=+0.013 acc=1 | LR→0.148720 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#025 loss=0.374532 step=0.03421 g_raw=+0.011 g_sm=+0.013 acc=1 | LR→0.149018 PERT→0.140012 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1475341973, PERT_used=0.1400106618 → LR_next=0.1490181903, PERT_next=0.1400118359\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1475341973→0.1490181903 PERT 0.1400106618→0.1400118359\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.352702 step=0.02233 g_raw=+0.011 g_sm=+0.017 acc=1 | LR→0.149317 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#035 loss=0.337188 step=0.1063 g_raw=+0.033 g_sm=+0.020 acc=1 | LR→0.149617 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#040 loss=0.328646 step=0.01084 g_raw=+0.006 g_sm=+0.019 acc=1 | LR→0.149917 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#045 loss=0.321990 step=0.0936 g_raw=+0.028 g_sm=+0.019 acc=1 | LR→0.150217 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#050 loss=0.304784 step=0.1274 g_raw=+0.045 g_sm=+0.021 acc=1 | LR→0.150519 PERT→0.140014 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1490181903, PERT_used=0.1400118359 → LR_next=0.1505186994, PERT_next=0.1400144883\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.025 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1490181903→0.1505186994 PERT 0.1400118359→0.1400144883\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.295629 step=0.04786 g_raw=+0.011 g_sm=+0.021 acc=1 | LR→0.150821 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#060 loss=0.290303 step=0.08707 g_raw=+0.032 g_sm=+0.020 acc=1 | LR→0.151123 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#065 loss=0.287455 step=0.04602 g_raw=+0.013 g_sm=+0.017 acc=1 | LR→0.151426 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#070 loss=0.286231 step=0.02574 g_raw=+0.006 g_sm=+0.015 acc=1 | LR→0.151730 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#075 loss=0.284438 step=0.01836 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.152034 PERT→0.140017 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1505186994, PERT_used=0.1400144883 → LR_next=0.1520341566, PERT_next=0.1400169925\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1505186994→0.1520341566 PERT 0.1400144883→0.1400169925\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.282605 step=0.05431 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.152339 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#085 loss=0.281516 step=0.0469 g_raw=+0.017 g_sm=+0.011 acc=1 | LR→0.152644 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#090 loss=0.280613 step=0.00747 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.152950 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#095 loss=0.279332 step=0.006084 g_raw=+0.000 g_sm=+0.008 acc=1 | LR→0.153257 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#100 loss=0.275908 step=0.01853 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.153564 PERT→0.140018 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1520341566, PERT_used=0.1400169925 → LR_next=0.1535637439, PERT_next=0.1400184683\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1520341566→0.1535637439 PERT 0.1400169925→0.1400184683\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.275812 step=0.02709 g_raw=-0.000 g_sm=+0.007 acc=1 | LR→0.153871 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#110 loss=0.274801 step=0.01293 g_raw=+0.002 g_sm=+0.007 acc=1 | LR→0.154180 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#115 loss=0.274083 step=0.04093 g_raw=+0.011 g_sm=+0.007 acc=1 | LR→0.154489 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#120 loss=0.273492 step=0.02338 g_raw=+0.005 g_sm=+0.006 acc=1 | LR→0.154798 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#125 loss=0.272509 step=0.02409 g_raw=+0.007 g_sm=+0.006 acc=1 | LR→0.155108 PERT→0.140019 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1535637439, PERT_used=0.1400184683 → LR_next=0.1551081382, PERT_next=0.1400194189\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.004 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1535637439→0.1551081382 PERT 0.1400184683→0.1400194189\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.51\n",
            "[round 8 | client 3] final LR=0.1551081382, final PERT=0.1400194189  (ΔLR=+0.0075739409, ΔPERT=+0.0000087571)\n",
            "[round 8 | client 4] seed LR=0.1475343723 (prev=0.1550687446), seed PERT=0.1400107775 (prev=0.1400215550), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.489771 step=0.03331 g_raw=+0.013 g_sm=+0.005 acc=1 | LR→0.147830 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#010 loss=0.470893 step=0.01477 g_raw=+0.006 g_sm=+0.010 acc=1 | LR→0.148126 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#015 loss=0.456496 step=0.1355 g_raw=+0.054 g_sm=+0.014 acc=1 | LR→0.148423 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#020 loss=0.426203 step=0.006272 g_raw=+0.005 g_sm=+0.019 acc=1 | LR→0.148721 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#025 loss=0.400333 step=0.1559 g_raw=+0.046 g_sm=+0.024 acc=1 | LR→0.149019 PERT→0.140013 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1475343723, PERT_used=0.1400107775 → LR_next=0.1490190212, PERT_next=0.1400125663\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.031 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1475343723→0.1490190212 PERT 0.1400107775→0.1400125663\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.374003 step=0.03269 g_raw=+0.008 g_sm=+0.027 acc=1 | LR→0.149318 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#035 loss=0.358871 step=0.01799 g_raw=+0.004 g_sm=+0.026 acc=1 | LR→0.149618 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#040 loss=0.355510 step=0.02609 g_raw=+0.007 g_sm=+0.023 acc=1 | LR→0.149918 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#045 loss=0.352858 step=0.07713 g_raw=+0.027 g_sm=+0.020 acc=1 | LR→0.150219 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#050 loss=0.345335 step=0.0638 g_raw=+0.020 g_sm=+0.020 acc=1 | LR→0.150520 PERT→0.140016 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1490190212, PERT_used=0.1400125663 → LR_next=0.1505202503, PERT_next=0.1400158807\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.024 acc_ratio=1.00 | LR 0.1490190212→0.1505202503 PERT 0.1400125663→0.1400158807\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.341070 step=0.01665 g_raw=+0.001 g_sm=+0.019 acc=1 | LR→0.150822 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#060 loss=0.337314 step=0.07022 g_raw=+0.029 g_sm=+0.018 acc=1 | LR→0.151125 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#065 loss=0.331882 step=0.02903 g_raw=+0.010 g_sm=+0.018 acc=1 | LR→0.151428 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#070 loss=0.319848 step=0.001288 g_raw=-0.002 g_sm=+0.019 acc=1 | LR→0.151732 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#075 loss=0.314240 step=0.06315 g_raw=+0.023 g_sm=+0.019 acc=1 | LR→0.152036 PERT→0.140019 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1505202503, PERT_used=0.1400158807 → LR_next=0.1520358602, PERT_next=0.1400185112\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1505202503→0.1520358602 PERT 0.1400158807→0.1400185112\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.306279 step=0.0485 g_raw=+0.021 g_sm=+0.019 acc=1 | LR→0.152341 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#085 loss=0.303915 step=0.02243 g_raw=+0.010 g_sm=+0.017 acc=1 | LR→0.152646 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#090 loss=0.299626 step=0.06838 g_raw=+0.017 g_sm=+0.017 acc=1 | LR→0.152952 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#095 loss=0.298530 step=0.05297 g_raw=+0.012 g_sm=+0.014 acc=1 | LR→0.153259 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#100 loss=0.296829 step=0.01859 g_raw=+0.003 g_sm=+0.013 acc=1 | LR→0.153566 PERT→0.140021 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1520358602, PERT_used=0.1400185112 → LR_next=0.1535663996, PERT_next=0.1400208395\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1520358602→0.1535663996 PERT 0.1400185112→0.1400208395\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.289374 step=0.0544 g_raw=+0.014 g_sm=+0.013 acc=1 | LR→0.153874 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#110 loss=0.288881 step=0.001545 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.154183 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#115 loss=0.284420 step=0.118 g_raw=+0.032 g_sm=+0.011 acc=1 | LR→0.154492 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#120 loss=0.280627 step=0.06614 g_raw=+0.020 g_sm=+0.012 acc=1 | LR→0.154801 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#125 loss=0.278953 step=0.05802 g_raw=+0.018 g_sm=+0.011 acc=1 | LR→0.155112 PERT→0.140023 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1535663996, PERT_used=0.1400208395 → LR_next=0.1551116257, PERT_next=0.1400225168\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1535663996→0.1551116257 PERT 0.1400208395→0.1400225168\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "[round 8 | client 4] final LR=0.1551116257, final PERT=0.1400225168  (ΔLR=+0.0075772534, ΔPERT=+0.0000117393)\n",
            "\n",
            "[Round 8] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           1      0.749949      0.525000      0.155112      0.140023\n",
            "           3      0.812348      0.506000      0.155108      0.140019\n",
            "           2      0.872576      0.495000      0.155109      0.140020\n",
            "           4      0.924521      0.495000      0.155112      0.140023\n",
            "           0      0.996476      0.494000      0.155111      0.140022\n",
            "→ [Round 8] best_client=1, best_val=0.749949, prev_global_val=0.633160, improve=-0.116789, action=hold (τ=0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  90%|█████████ | 9/10 [2:46:42<17:46, 1066.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   8] acc_g=0.771 (μ=0.503, σ=0.012, FG=0.023) | t=1042.184s, val=0.632 | TEL=FALSE\n",
            "[Round 9] Teleportation OFF | Aggregation=best\n",
            "[round 9 | client 0] seed LR=0.1475556666 (prev=0.1551113332), seed PERT=0.1400111184 (prev=0.1400222369), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.428741 step=0.09928 g_raw=+0.035 g_sm=+0.004 acc=1 | LR→0.147851 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#010 loss=0.424198 step=0.05026 g_raw=+0.022 g_sm=+0.006 acc=1 | LR→0.148147 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#015 loss=0.383941 step=0.1555 g_raw=+0.051 g_sm=+0.016 acc=1 | LR→0.148444 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#020 loss=0.362020 step=0.1641 g_raw=+0.067 g_sm=+0.020 acc=1 | LR→0.148742 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#025 loss=0.332747 step=0.08799 g_raw=+0.029 g_sm=+0.025 acc=1 | LR→0.149040 PERT→0.140013 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1475556666, PERT_used=0.1400111184 → LR_next=0.1490403548, PERT_next=0.1400127428\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.030 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1475556666→0.1490403548 PERT 0.1400111184→0.1400127428\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.326510 step=0.08103 g_raw=+0.020 g_sm=+0.023 acc=1 | LR→0.149339 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#035 loss=0.320336 step=0.08532 g_raw=+0.021 g_sm=+0.022 acc=1 | LR→0.149639 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#040 loss=0.314823 step=0.06051 g_raw=+0.020 g_sm=+0.020 acc=1 | LR→0.149939 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#045 loss=0.311680 step=0.04998 g_raw=+0.013 g_sm=+0.018 acc=1 | LR→0.150240 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#050 loss=0.308161 step=0.03661 g_raw=+0.008 g_sm=+0.017 acc=1 | LR→0.150541 PERT→0.140016 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1490403548, PERT_used=0.1400127428 → LR_next=0.1505413346, PERT_next=0.1400156254\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.021 acc_ratio=1.00 | LR 0.1490403548→0.1505413346 PERT 0.1400127428→0.1400156254\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.304175 step=0.01818 g_raw=+0.003 g_sm=+0.016 acc=1 | LR→0.150843 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#060 loss=0.299482 step=0.04238 g_raw=+0.013 g_sm=+0.016 acc=1 | LR→0.151146 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#065 loss=0.299027 step=0.01063 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.151449 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#070 loss=0.291992 step=0.1099 g_raw=+0.031 g_sm=+0.014 acc=1 | LR→0.151752 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#075 loss=0.291496 step=0.0242 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.152056 PERT→0.140018 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1505413346, PERT_used=0.1400156254 → LR_next=0.1520564791, PERT_next=0.1400176318\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1505413346→0.1520564791 PERT 0.1400156254→0.1400176318\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.287646 step=0.01574 g_raw=+0.008 g_sm=+0.013 acc=1 | LR→0.152361 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#085 loss=0.285451 step=0.009228 g_raw=-0.001 g_sm=+0.012 acc=1 | LR→0.152667 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#090 loss=0.283038 step=0.03933 g_raw=+0.016 g_sm=+0.011 acc=1 | LR→0.152973 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#095 loss=0.282581 step=0.0107 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.153279 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#100 loss=0.282150 step=0.03462 g_raw=+0.012 g_sm=+0.008 acc=1 | LR→0.153586 PERT→0.140019 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1520564791, PERT_used=0.1400176318 → LR_next=0.1535863540, PERT_next=0.1400191652\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1520564791→0.1535863540 PERT 0.1400176318→0.1400191652\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.280975 step=0.0231 g_raw=+0.004 g_sm=+0.008 acc=1 | LR→0.153894 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#110 loss=0.278964 step=0.0452 g_raw=+0.013 g_sm=+0.009 acc=1 | LR→0.154202 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#115 loss=0.277342 step=0.0007513 g_raw=-0.003 g_sm=+0.008 acc=1 | LR→0.154511 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#120 loss=0.276787 step=0.004692 g_raw=+0.000 g_sm=+0.007 acc=1 | LR→0.154821 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#125 loss=0.276390 step=0.01266 g_raw=+0.003 g_sm=+0.007 acc=1 | LR→0.155131 PERT→0.140020 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1535863540, PERT_used=0.1400191652 → LR_next=0.1551311443, PERT_next=0.1400202679\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1535863540→0.1551311443 PERT 0.1400191652→0.1400202679\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "[round 9 | client 0] final LR=0.1551311443, final PERT=0.1400202679  (ΔLR=+0.0075754777, ΔPERT=+0.0000091495)\n",
            "[round 9 | client 1] seed LR=0.1475559674 (prev=0.1551119348), seed PERT=0.1400113988 (prev=0.1400227976), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.593570 step=0.03318 g_raw=+0.014 g_sm=+0.005 acc=1 | LR→0.147851 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#010 loss=0.576113 step=0.1381 g_raw=+0.049 g_sm=+0.011 acc=1 | LR→0.148148 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#015 loss=0.568191 step=0.003607 g_raw=+0.004 g_sm=+0.013 acc=1 | LR→0.148445 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#020 loss=0.544591 step=0.06946 g_raw=+0.028 g_sm=+0.019 acc=1 | LR→0.148742 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#025 loss=0.528596 step=0.1498 g_raw=+0.062 g_sm=+0.022 acc=1 | LR→0.149041 PERT→0.140013 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1475559674, PERT_used=0.1400113988 → LR_next=0.1490407690, PERT_next=0.1400131268\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.029 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1475559674→0.1490407690 PERT 0.1400113988→0.1400131268\n",
            "Training Accuracy: 0.29\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.520860 step=0.1186 g_raw=+0.044 g_sm=+0.022 acc=1 | LR→0.149340 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#035 loss=0.509402 step=0.1241 g_raw=+0.045 g_sm=+0.023 acc=1 | LR→0.149639 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#040 loss=0.475858 step=0.02983 g_raw=+0.012 g_sm=+0.028 acc=1 | LR→0.149940 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#045 loss=0.463938 step=0.109 g_raw=+0.032 g_sm=+0.027 acc=1 | LR→0.150241 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#050 loss=0.461671 step=0.04654 g_raw=+0.018 g_sm=+0.024 acc=1 | LR→0.150542 PERT→0.140017 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1490407690, PERT_used=0.1400131268 → LR_next=0.1505422976, PERT_next=0.1400165160\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.025 g_sm_mean=+0.024 acc_ratio=1.00 | LR 0.1490407690→0.1505422976 PERT 0.1400131268→0.1400165160\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.445436 step=0.04297 g_raw=+0.019 g_sm=+0.024 acc=1 | LR→0.150844 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#060 loss=0.433211 step=0.103 g_raw=+0.035 g_sm=+0.025 acc=1 | LR→0.151147 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#065 loss=0.428820 step=0.01377 g_raw=+0.005 g_sm=+0.022 acc=1 | LR→0.151450 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#070 loss=0.419694 step=0.1225 g_raw=+0.046 g_sm=+0.022 acc=1 | LR→0.151754 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#075 loss=0.401894 step=0.01092 g_raw=+0.000 g_sm=+0.024 acc=1 | LR→0.152059 PERT→0.140020 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1505422976, PERT_used=0.1400165160 → LR_next=0.1520587858, PERT_next=0.1400197509\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.023 g_sm_mean=+0.023 acc_ratio=1.00 | LR 0.1505422976→0.1520587858 PERT 0.1400165160→0.1400197509\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.383815 step=0.07465 g_raw=+0.025 g_sm=+0.024 acc=1 | LR→0.152364 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#085 loss=0.373018 step=0.09389 g_raw=+0.032 g_sm=+0.024 acc=1 | LR→0.152670 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#090 loss=0.366998 step=0.0619 g_raw=+0.019 g_sm=+0.023 acc=1 | LR→0.152976 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#095 loss=0.358318 step=0.04363 g_raw=+0.012 g_sm=+0.022 acc=1 | LR→0.153283 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#100 loss=0.351267 step=0.1069 g_raw=+0.033 g_sm=+0.021 acc=1 | LR→0.153591 PERT→0.140023 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1520587858, PERT_used=0.1400197509 → LR_next=0.1535905421, PERT_next=0.1400229783\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.023 acc_ratio=1.00 | LR 0.1520587858→0.1535905421 PERT 0.1400197509→0.1400229783\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.330413 step=0.1757 g_raw=+0.048 g_sm=+0.023 acc=1 | LR→0.153899 PERT→0.140024 (scale=0.04)\n",
            "[meta] cb#110 loss=0.320235 step=0.05704 g_raw=+0.019 g_sm=+0.023 acc=1 | LR→0.154208 PERT→0.140024 (scale=0.04)\n",
            "[meta] cb#115 loss=0.318450 step=0.004081 g_raw=+0.003 g_sm=+0.019 acc=1 | LR→0.154517 PERT→0.140025 (scale=0.04)\n",
            "[meta] cb#120 loss=0.317148 step=0.06596 g_raw=+0.014 g_sm=+0.016 acc=1 | LR→0.154827 PERT→0.140025 (scale=0.04)\n",
            "[meta] cb#125 loss=0.315546 step=0.004872 g_raw=-0.001 g_sm=+0.014 acc=1 | LR→0.155137 PERT→0.140026 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1535905421, PERT_used=0.1400229783 → LR_next=0.1551372059, PERT_next=0.1400257341\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.020 acc_ratio=1.00 | LR 0.1535905421→0.1551372059 PERT 0.1400229783→0.1400257341\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.55\n",
            "[round 9 | client 1] final LR=0.1551372059, final PERT=0.1400257341  (ΔLR=+0.0075812385, ΔPERT=+0.0000143353)\n",
            "[round 9 | client 2] seed LR=0.1475546352 (prev=0.1551092703), seed PERT=0.1400102383 (prev=0.1400204766), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.405872 step=0.154 g_raw=+0.060 g_sm=+0.016 acc=1 | LR→0.147850 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#010 loss=0.389823 step=0.08629 g_raw=+0.026 g_sm=+0.018 acc=1 | LR→0.148147 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#015 loss=0.356738 step=0.1809 g_raw=+0.057 g_sm=+0.025 acc=1 | LR→0.148444 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#020 loss=0.351928 step=0.07291 g_raw=+0.029 g_sm=+0.023 acc=1 | LR→0.148742 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#025 loss=0.329099 step=0.174 g_raw=+0.055 g_sm=+0.026 acc=1 | LR→0.149040 PERT→0.140013 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1475546352, PERT_used=0.1400102383 → LR_next=0.1490404324, PERT_next=0.1400129143\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.039 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1475546352→0.1490404324 PERT 0.1400102383→0.1400129143\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.317788 step=0.03697 g_raw=+0.012 g_sm=+0.025 acc=1 | LR→0.149340 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#035 loss=0.315557 step=0.008015 g_raw=+0.003 g_sm=+0.021 acc=1 | LR→0.149639 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#040 loss=0.308272 step=0.03794 g_raw=+0.011 g_sm=+0.021 acc=1 | LR→0.149940 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#045 loss=0.305832 step=0.05047 g_raw=+0.014 g_sm=+0.019 acc=1 | LR→0.150240 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#050 loss=0.302652 step=0.02524 g_raw=+0.003 g_sm=+0.017 acc=1 | LR→0.150542 PERT→0.140016 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1490404324, PERT_used=0.1400129143 → LR_next=0.1505415864, PERT_next=0.1400159582\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.022 acc_ratio=1.00 | LR 0.1490404324→0.1505415864 PERT 0.1400129143→0.1400159582\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.302183 step=0.002538 g_raw=+0.004 g_sm=+0.014 acc=1 | LR→0.150843 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#060 loss=0.301700 step=0.009825 g_raw=-0.003 g_sm=+0.012 acc=1 | LR→0.151146 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#065 loss=0.300631 step=0.02746 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.151449 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#070 loss=0.299067 step=0.03055 g_raw=+0.010 g_sm=+0.011 acc=1 | LR→0.151752 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#075 loss=0.298236 step=0.01592 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.152056 PERT→0.140018 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1505415864, PERT_used=0.1400159582 → LR_next=0.1520563789, PERT_next=0.1400176381\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.006 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1505415864→0.1520563789 PERT 0.1400159582→0.1400176381\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.297768 step=0.00966 g_raw=+0.005 g_sm=+0.009 acc=1 | LR→0.152361 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#085 loss=0.297161 step=0.0003671 g_raw=-0.001 g_sm=+0.008 acc=1 | LR→0.152666 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#090 loss=0.296901 step=0.0002159 g_raw=-0.001 g_sm=+0.007 acc=1 | LR→0.152972 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#095 loss=0.296813 step=0.01252 g_raw=+0.003 g_sm=+0.005 acc=1 | LR→0.153279 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#100 loss=0.296265 step=0.007722 g_raw=+0.002 g_sm=+0.005 acc=1 | LR→0.153586 PERT→0.140019 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1520563789, PERT_used=0.1400176381 → LR_next=0.1535856572, PERT_next=0.1400186284\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.004 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1520563789→0.1535856572 PERT 0.1400176381→0.1400186284\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.294958 step=0.03965 g_raw=+0.007 g_sm=+0.005 acc=1 | LR→0.153893 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#110 loss=0.294200 step=0.01466 g_raw=+0.003 g_sm=+0.005 acc=1 | LR→0.154202 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#115 loss=0.293742 step=0.02606 g_raw=+0.011 g_sm=+0.005 acc=1 | LR→0.154510 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#120 loss=0.293421 step=0.01776 g_raw=+0.007 g_sm=+0.005 acc=1 | LR→0.154820 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#125 loss=0.293143 step=0.02074 g_raw=+0.005 g_sm=+0.005 acc=1 | LR→0.155130 PERT→0.140019 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1535856572, PERT_used=0.1400186284 → LR_next=0.1551300144, PERT_next=0.1400193466\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.005 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1535856572→0.1551300144 PERT 0.1400186284→0.1400193466\n",
            "Training Accuracy: 0.79\n",
            "Test Accuracy: 0.49\n",
            "[round 9 | client 2] final LR=0.1551300144, final PERT=0.1400193466  (ΔLR=+0.0075753792, ΔPERT=+0.0000091083)\n",
            "[round 9 | client 3] seed LR=0.1475540691 (prev=0.1551081382), seed PERT=0.1400097095 (prev=0.1400194189), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.489947 step=0.03725 g_raw=+0.016 g_sm=+0.005 acc=1 | LR→0.147850 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#010 loss=0.484902 step=0.1098 g_raw=+0.039 g_sm=+0.007 acc=1 | LR→0.148146 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#015 loss=0.480156 step=0.06412 g_raw=+0.029 g_sm=+0.009 acc=1 | LR→0.148443 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#020 loss=0.477894 step=0.03589 g_raw=+0.012 g_sm=+0.009 acc=1 | LR→0.148740 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#025 loss=0.475644 step=0.04994 g_raw=+0.011 g_sm=+0.009 acc=1 | LR→0.149038 PERT→0.140011 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1475540691, PERT_used=0.1400097095 → LR_next=0.1490380398, PERT_next=0.1400106748\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1475540691→0.1490380398 PERT 0.1400097095→0.1400106748\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.60\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.468805 step=0.1012 g_raw=+0.039 g_sm=+0.011 acc=1 | LR→0.149337 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#035 loss=0.466057 step=0.03339 g_raw=+0.013 g_sm=+0.011 acc=1 | LR→0.149636 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#040 loss=0.462372 step=0.02409 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.149936 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#045 loss=0.456097 step=0.1183 g_raw=+0.042 g_sm=+0.013 acc=1 | LR→0.150236 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#050 loss=0.452335 step=0.07364 g_raw=+0.025 g_sm=+0.013 acc=1 | LR→0.150538 PERT→0.140012 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1490380398, PERT_used=0.1400106748 → LR_next=0.1505376493, PERT_next=0.1400123047\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1490380398→0.1505376493 PERT 0.1400106748→0.1400123047\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.58\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.448495 step=0.03012 g_raw=+0.008 g_sm=+0.013 acc=1 | LR→0.150839 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#060 loss=0.440785 step=0.05521 g_raw=+0.017 g_sm=+0.015 acc=1 | LR→0.151142 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#065 loss=0.430521 step=0.04671 g_raw=+0.023 g_sm=+0.017 acc=1 | LR→0.151445 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#070 loss=0.428693 step=0.02008 g_raw=+0.005 g_sm=+0.016 acc=1 | LR→0.151749 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#075 loss=0.422838 step=0.06696 g_raw=+0.024 g_sm=+0.017 acc=1 | LR→0.152053 PERT→0.140014 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1505376493, PERT_used=0.1400123047 → LR_next=0.1520528954, PERT_next=0.1400144388\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1505376493→0.1520528954 PERT 0.1400123047→0.1400144388\n",
            "Training Accuracy: 0.89\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.421739 step=0.03083 g_raw=+0.009 g_sm=+0.015 acc=1 | LR→0.152358 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#085 loss=0.413568 step=0.1263 g_raw=+0.049 g_sm=+0.016 acc=1 | LR→0.152663 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#090 loss=0.409247 step=0.06019 g_raw=+0.020 g_sm=+0.015 acc=1 | LR→0.152969 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#095 loss=0.404584 step=0.008723 g_raw=+0.003 g_sm=+0.015 acc=1 | LR→0.153276 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#100 loss=0.396097 step=0.02298 g_raw=+0.007 g_sm=+0.016 acc=1 | LR→0.153583 PERT→0.140017 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1520528954, PERT_used=0.1400144388 → LR_next=0.1535833985, PERT_next=0.1400165776\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1520528954→0.1535833985 PERT 0.1400144388→0.1400165776\n",
            "Training Accuracy: 0.94\n",
            "Test Accuracy: 0.76\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.387777 step=0.03129 g_raw=+0.012 g_sm=+0.018 acc=1 | LR→0.153891 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#110 loss=0.375804 step=0.03899 g_raw=+0.012 g_sm=+0.019 acc=1 | LR→0.154200 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#115 loss=0.367088 step=0.08123 g_raw=+0.030 g_sm=+0.020 acc=1 | LR→0.154509 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#120 loss=0.360950 step=0.08702 g_raw=+0.025 g_sm=+0.019 acc=1 | LR→0.154819 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#125 loss=0.356061 step=0.01221 g_raw=+0.002 g_sm=+0.018 acc=1 | LR→0.155130 PERT→0.140019 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1535833985, PERT_used=0.1400165776 → LR_next=0.1551298683, PERT_next=0.1400192231\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1535833985→0.1551298683 PERT 0.1400165776→0.1400192231\n",
            "Training Accuracy: 0.94\n",
            "Test Accuracy: 0.73\n",
            "[round 9 | client 3] final LR=0.1551298683, final PERT=0.1400192231  (ΔLR=+0.0075757992, ΔPERT=+0.0000095136)\n",
            "[round 9 | client 4] seed LR=0.1475558128 (prev=0.1551116257), seed PERT=0.1400112584 (prev=0.1400225168), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.444081 step=0.1085 g_raw=+0.037 g_sm=+0.003 acc=1 | LR→0.147851 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#010 loss=0.411733 step=0.1588 g_raw=+0.059 g_sm=+0.012 acc=1 | LR→0.148147 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#015 loss=0.391634 step=0.03665 g_raw=+0.009 g_sm=+0.016 acc=1 | LR→0.148445 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#020 loss=0.363000 step=0.09926 g_raw=+0.032 g_sm=+0.021 acc=1 | LR→0.148742 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#025 loss=0.355272 step=0.02049 g_raw=+0.008 g_sm=+0.021 acc=1 | LR→0.149041 PERT→0.140013 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1475558128, PERT_used=0.1400112584 → LR_next=0.1490407322, PERT_next=0.1400130985\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.029 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1475558128→0.1490407322 PERT 0.1400112584→0.1400130985\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.352105 step=0.009583 g_raw=+0.002 g_sm=+0.018 acc=1 | LR→0.149340 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#035 loss=0.338351 step=0.04438 g_raw=+0.013 g_sm=+0.019 acc=1 | LR→0.149639 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#040 loss=0.334573 step=0.04313 g_raw=+0.016 g_sm=+0.018 acc=1 | LR→0.149939 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#045 loss=0.329678 step=0.0872 g_raw=+0.023 g_sm=+0.018 acc=1 | LR→0.150240 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#050 loss=0.325684 step=0.01423 g_raw=+0.002 g_sm=+0.017 acc=1 | LR→0.150541 PERT→0.140016 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1490407322, PERT_used=0.1400130985 → LR_next=0.1505413644, PERT_next=0.1400156544\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1490407322→0.1505413644 PERT 0.1400130985→0.1400156544\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.322579 step=0.03079 g_raw=+0.012 g_sm=+0.016 acc=1 | LR→0.150843 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#060 loss=0.320928 step=0.01334 g_raw=+0.003 g_sm=+0.014 acc=1 | LR→0.151146 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#065 loss=0.316733 step=0.01984 g_raw=+0.007 g_sm=+0.014 acc=1 | LR→0.151449 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#070 loss=0.315250 step=0.0005668 g_raw=+0.005 g_sm=+0.013 acc=1 | LR→0.151752 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#075 loss=0.311587 step=0.02537 g_raw=+0.005 g_sm=+0.013 acc=1 | LR→0.152056 PERT→0.140018 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1505413644, PERT_used=0.1400156544 → LR_next=0.1520564708, PERT_next=0.1400176254\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1505413644→0.1520564708 PERT 0.1400156544→0.1400176254\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.306690 step=0.009581 g_raw=+0.003 g_sm=+0.013 acc=1 | LR→0.152361 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#085 loss=0.306218 step=0.01406 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.152667 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#090 loss=0.303274 step=0.009872 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.152973 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#095 loss=0.302636 step=0.00824 g_raw=+0.006 g_sm=+0.010 acc=1 | LR→0.153279 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#100 loss=0.298731 step=0.01649 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.153586 PERT→0.140019 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1520564708, PERT_used=0.1400176254 → LR_next=0.1535864402, PERT_next=0.1400192450\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1520564708→0.1535864402 PERT 0.1400176254→0.1400192450\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.295669 step=0.05743 g_raw=+0.020 g_sm=+0.011 acc=1 | LR→0.153894 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#110 loss=0.294133 step=0.007213 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.154203 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#115 loss=0.292583 step=0.00811 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.154512 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#120 loss=0.291371 step=0.02617 g_raw=+0.003 g_sm=+0.009 acc=1 | LR→0.154821 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#125 loss=0.291205 step=0.01499 g_raw=+0.006 g_sm=+0.008 acc=1 | LR→0.155132 PERT→0.140021 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1535864402, PERT_used=0.1400192450 → LR_next=0.1551315319, PERT_next=0.1400206190\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1535864402→0.1551315319 PERT 0.1400192450→0.1400206190\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.50\n",
            "[round 9 | client 4] final LR=0.1551315319, final PERT=0.1400206190  (ΔLR=+0.0075757190, ΔPERT=+0.0000093606)\n",
            "\n",
            "[Round 9] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           3      0.578230      0.726000      0.155130      0.140019\n",
            "           1      0.803374      0.548000      0.155137      0.140026\n",
            "           2      0.836965      0.494000      0.155130      0.140019\n",
            "           4      0.907561      0.496000      0.155132      0.140021\n",
            "           0      0.981608      0.495000      0.155131      0.140020\n",
            "→ [Round 9] best_client=3, best_val=0.578230, prev_global_val=0.631847, improve=+0.053616, action=adopt+mix τ=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 10/10 [3:01:16<00:00, 1087.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   9] acc_g=0.688 (μ=0.552, σ=0.089, FG=0.160) | t=856.301s, val=0.604 | TEL=FALSE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 650x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 650x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 650x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from training.loop import run_federated_training\n",
        "from configs.base_config import use_teleportation as CFG_TEL, noise_preset, shots_used,aggregation,client_hparams_csv_file\n",
        "from training.metrics import metrics_init, metrics_log_round, metrics_finalize, compute_auc,metrics_summarize\n",
        "from viz.plots import plot_accuracy_curve, plot_val_loss, plot_time_per_round, plot_fidelity_vs_delta_acc, plot_beta_hist, plot_client_fairness_last_round\n",
        "# Initialize metrics store once\n",
        "metrics_store = metrics_init(\n",
        "    log_path=os.path.join(drive_root, \"teleport_metrics_Perturb_shrink.csv\")\n",
        ")\n",
        "\n",
        "#new\n",
        "from ml import optimizers as mlopt\n",
        "from configs.base_config import drive_root\n",
        "import os\n",
        "\n",
        "mlopt.meta_trace_enable(\n",
        "    path=os.path.join(drive_root, \"meta_trace.csv\"),  # or None to skip CSV\n",
        "    every=5                                           # print every 5 callbacks\n",
        ")\n",
        "\n",
        "###########\n",
        "global_acc, clients_train, clients_test, round_times, val_losses, info_last = run_federated_training(\n",
        "    clients=clients,\n",
        "    num_federated_layers=num_federated_layers,\n",
        "    num_deep_unfolding_iterations=num_deep_unfolding_iterations,\n",
        "    initial_learning_rate=initial_learning_rate,\n",
        "    initial_perturbation=initial_perturbation,\n",
        "    num_features=num_features,\n",
        "    best_client_csv_file=best_client_csv_file,\n",
        "    global_csv_file=global_csv_file,\n",
        "    local_csv_file=local_csv_file,\n",
        "    validation_csv_file=validation_csv_file,\n",
        "    test_sequences=test_sequences,\n",
        "    test_labels=test_labels,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    use_teleportation=CFG_TEL,          # ← important\n",
        "    noise_preset=noise_preset,\n",
        "    shots_used=shots_used,\n",
        "    metrics=metrics_store,   # <-- pass it in\n",
        "    aggregation=aggregation,\n",
        "    client_hparams_csv_file=client_hparams_csv_file,   # <-- NEW# <--- switch here\n",
        ")\n",
        "\n",
        "rows_np = metrics_finalize(metrics_store)   # if you need the in-memory array\n",
        "#summary = metrics_summarize(metrics_store)  # prints a concise summary, returns a dict\n",
        "\n",
        "# quick visuals\n",
        "rounds = list(range(len(global_acc)))\n",
        "plot_accuracy_curve(rounds, global_acc, label=\"Global accuracy (DT-DUQFL)\")\n",
        "plot_val_loss(rounds, val_losses, label=\"Central validation loss\")\n",
        "plot_time_per_round(rounds, round_times)\n",
        "\n",
        "if info_last is not None:\n",
        "    # this uses \"last\" round's info; in your logger you kept per-round arrays; adapt if needed\n",
        "    pass\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}