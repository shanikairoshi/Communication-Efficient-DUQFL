# Communication-Efficient-DUQFL
This is the official implementation for Communication-Efficient Deep Unfolded Quantum Federated Learning. This repository includes all the setup details, experimental results, and the code structure necessary to reproduce the purpose.

Deep-unfolding federated learning with learnable SPSA hyper-params (learning rate & perturbation), optional quantum teleportation perturbation, and pluggable aggregation strategies.

âœ¨ Highlights

Deep-Unfolding SPSA: LR & perturbation are adapted during each local fit via a momentum-smoothed controller.

Trust-Region Caps: Safety bounds for LR/PERT to avoid divergence.

Federated Rounds with client carry-over of learned hyper-params.

Aggregation plugins: Best-Client (val-gated & smoothed) or FedAvg.

Metrics logging: global/client accuracies, validation loss, (optional) teleportation stats.

# tDuQFL â€” Teleportation-aware Deep-Unfolded QFL (SPSA)

![python](https://img.shields.io/badge/python-3.10%2B-blue)
![qiskit](https://img.shields.io/badge/qiskit-yes-5A3FD9)
![status](https://img.shields.io/badge/status-research--prototype-green)

Federated learning with a learnable SPSA optimizer and deep-unfolding hyper-step adaptation. Optional quantum â€œteleportationâ€ perturbation of global weights for robustness.

---

## ğŸ“ Repository Structure

```text
tDuQFL_Project/
â”œâ”€ README.md
â”œâ”€ requirements.txt
â”œâ”€ .gitignore

â”œâ”€ configs/
â”‚  â”œâ”€ base_config.py                 # global knobs (rounds, clients, LR/PERT, seeds, etc.)
â”‚  â””â”€ mnist_config.py                # (optional) dataset-specific overrides

â”œâ”€ common/
â”‚  â””â”€ imports.py                     # centralized imports / globals

â”œâ”€ data/
â”‚  â”œâ”€ preprocess_genome.py           # build Genome dataset tensors
â”‚  â”œâ”€ preprocess_mnist.py            # (optional) MNIST preprocessor
â”‚  â”œâ”€ splitters/
â”‚  â”‚  â”œâ”€ iid.py                      # IID client/epoch splitter
â”‚  â”‚  â””â”€ noniid.py                   # Non-IID splitter (quantity + label skew)
â”‚  â””â”€ __init__.py

â”œâ”€ fl/
â”‚  â”œâ”€ client.py                      # Client wrapper (train/test shards, current model)
â”‚  â””â”€ aggregation/
â”‚     â”œâ”€ __init__.py
â”‚     â”œâ”€ best_client.py              # pick best clientâ€™s weights (argmax/lowest val)
â”‚     â””â”€ fedavg.py                   # standard FedAvg (weighted mean by samples)

â”œâ”€ ml/
â”‚  â”œâ”€ models.py                      # QNN model init/wiring to optimizer
â”‚  â”œâ”€ optimizers.py                  # Learnable SPSA + deep-unfolding controller
â”‚  â””â”€ __init__.py

â”œâ”€ training/
â”‚  â”œâ”€ loop.py                        # federated rounds + deep unfolding per client
â”‚  â”œâ”€ callbacks.py                   # SPSA callback trackers (LR/PERT/objective)
â”‚  â”œâ”€ metrics.py                     # round metrics logger + summary helpers
â”‚  â””â”€ __init__.py

â”œâ”€ tele/
â”‚  â”œâ”€ teleport.py                    # (optional) parameter teleportation
â”‚  â”œâ”€ noise.py                       # (optional) noise backends
â”‚  â””â”€ __init__.py

â”œâ”€ io_utils/
â”‚  â”œâ”€ csv_logger.py                  # local/global CSV logging helpers
â”‚  â””â”€ __init__.py

â”œâ”€ scripts/
â”‚  â”œâ”€ run_genome_iid.py              # launch Genome + IID split
â”‚  â”œâ”€ run_genome_noniid.py           # launch Genome + Non-IID split
â”‚  â”œâ”€ run_mnist_iid.py               # (optional) launch MNIST + IID split
â”‚  â””â”€ make_readme_assets.py          # generate README figures from CSVs (or synthesize)

â”œâ”€ docs/
â”‚  â””â”€ images/                        # figures used in README (auto-generated)

â”œâ”€ results/                          # generated at runtime
â”‚  â”œâ”€ best_client.csv
â”‚  â”œâ”€ global_accuracies.csv
â”‚  â”œâ”€ local_training.csv
â”‚  â””â”€ validation.csv

â””â”€ artifacts/                        # saved weights / checkpoints
   â””â”€ models/

