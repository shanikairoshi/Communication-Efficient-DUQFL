{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shanikairoshi/Communication-Efficient-DUQFL/blob/main/main_v2_1.3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bee84f36",
      "metadata": {
        "id": "bee84f36"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bc18ac0f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc18ac0f",
        "outputId": "980a9918-9d6e-4af2-add7-76e4eb1c1bb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting genomic-benchmarks\n",
            "  Downloading genomic_benchmarks-1.0.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting biopython>=1.79 (from genomic-benchmarks)\n",
            "  Downloading biopython-1.85-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (2.32.4)\n",
            "Requirement already satisfied: pip>=20.0.1 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (24.1.2)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (4.67.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (6.0.3)\n",
            "Requirement already satisfied: gdown>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (5.2.0)\n",
            "Requirement already satisfied: yarl in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (1.20.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown>=4.2.0->genomic-benchmarks) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown>=4.2.0->genomic-benchmarks) (3.19.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->genomic-benchmarks) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->genomic-benchmarks) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->genomic-benchmarks) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->genomic-benchmarks) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->genomic-benchmarks) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->genomic-benchmarks) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->genomic-benchmarks) (2025.8.3)\n",
            "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.12/dist-packages (from yarl->genomic-benchmarks) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from yarl->genomic-benchmarks) (0.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.4->genomic-benchmarks) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown>=4.2.0->genomic-benchmarks) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown>=4.2.0->genomic-benchmarks) (4.15.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=4.2.0->genomic-benchmarks) (1.7.1)\n",
            "Downloading biopython-1.85-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: genomic-benchmarks\n",
            "  Building wheel for genomic-benchmarks (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for genomic-benchmarks: filename=genomic_benchmarks-1.0.0-py3-none-any.whl size=22550 sha256=cc2c5974f49d748a9e2855c82e713529ba1ce2b623f5ac5ff5078d756c45215e\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/3a/9a/0f21797a390f81beeeb52e9ccc71e6d5e262786ecd01e046bf\n",
            "Successfully built genomic-benchmarks\n",
            "Installing collected packages: biopython, genomic-benchmarks\n",
            "Successfully installed biopython-1.85 genomic-benchmarks-1.0.0\n",
            "Collecting qiskit\n",
            "  Downloading qiskit-2.2.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (12 kB)\n",
            "Collecting qiskit_machine_learning\n",
            "  Downloading qiskit_machine_learning-0.8.4-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting qiskit_algorithms\n",
            "  Downloading qiskit_algorithms-0.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting qiskit-aer\n",
            "  Downloading qiskit_aer-0.17.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
            "Collecting rustworkx>=0.15.0 (from qiskit)\n",
            "  Downloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.12/dist-packages (from qiskit) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.12/dist-packages (from qiskit) (1.16.2)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.3.8)\n",
            "Collecting stevedore>=3.0.0 (from qiskit)\n",
            "  Downloading stevedore-5.5.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qiskit) (4.15.0)\n",
            "Collecting qiskit\n",
            "  Downloading qiskit-1.4.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting scipy>=1.5 (from qiskit)\n",
            "  Downloading scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.12/dist-packages (from qiskit_machine_learning) (1.6.1)\n",
            "Requirement already satisfied: setuptools>=40.1 in /usr/local/lib/python3.12/dist-packages (from qiskit_machine_learning) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.12/dist-packages (from qiskit) (1.13.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from qiskit) (2.9.0.post0)\n",
            "Collecting symengine<0.14,>=0.11 (from qiskit)\n",
            "  Downloading symengine-0.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.12/dist-packages (from qiskit-aer) (5.9.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->qiskit_machine_learning) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->qiskit_machine_learning) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
            "Downloading qiskit_machine_learning-0.8.4-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit-1.4.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit_algorithms-0.4.0-py3-none-any.whl (327 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.8/327.8 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit_aer-0.17.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading symengine-0.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: symengine, stevedore, scipy, rustworkx, qiskit, qiskit_machine_learning, qiskit_algorithms, qiskit-aer\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.2\n",
            "    Uninstalling scipy-1.16.2:\n",
            "      Successfully uninstalled scipy-1.16.2\n",
            "Successfully installed qiskit-1.4.4 qiskit-aer-0.17.2 qiskit_algorithms-0.4.0 qiskit_machine_learning-0.8.4 rustworkx-0.17.1 scipy-1.15.3 stevedore-5.5.0 symengine-0.13.0\n"
          ]
        }
      ],
      "source": [
        "# %%capture\n",
        "!pip install genomic-benchmarks\n",
        "!pip install qiskit qiskit_machine_learning qiskit_algorithms qiskit-aer\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2d53c335",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d53c335",
        "outputId": "c0b5c477-8ca0-4b5c-cac3-b05fb5979307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5291b3a7",
      "metadata": {
        "id": "5291b3a7"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "PROJ = Path.cwd() / \"tduqfl_Project_AGG\"\n",
        "if str(PROJ) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJ))\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Teleportation/tduqfl_Project_AGG/tDuQFL_Project')\n",
        "# ─── 5. Assemble filenames for each artifact ─────────────────────────────────\n",
        "#drive_root = \"/content/drive/MyDrive/Teleportation/tduqfl_Project_AGG/tDuQFL_Project/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c245a1fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c245a1fd",
        "outputId": "f8cef83c-a36f-477e-d0e0-45ac36f9ec59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/genomic_benchmarks/utils/datasets.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Python: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "Qiskit: 1.4.4\n",
            "qiskit_aer available?: True\n"
          ]
        }
      ],
      "source": [
        "from common.imports import *\n",
        "from configs.dataset_genome_iid import *     # swap to other configs as needed\n",
        "from io_utils.naming import stamp_now, flags, build_param_str, make_filenames\n",
        "\n",
        "start_str, date_str = stamp_now()\n",
        "teleport_pl, noise_pl = flags(use_teleportation, use_noise)\n",
        "param_str = build_param_str(num_clients, num_federated_layers, num_deep_unfolding_iterations,\n",
        "                            initial_learning_rate, initial_perturbation)\n",
        "\n",
        "best_client_csv_file, global_csv_file, local_csv_file, validation_csv_file = make_filenames(\n",
        "    drive_root, dataset_name, split_type, date_str, teleport_pl, noise_pl, param_str\n",
        ")\n",
        "from io_utils.csv_logger import init_local_csv, init_best_csv, init_validation_csv\n",
        "\n",
        "# Create folders + write headers\n",
        "init_best_csv(best_client_csv_file)\n",
        "\n",
        "local_headers = [\n",
        "    \"Federated Round\", \"Client Number\", \"Iteration\",\n",
        "    \"Objective Function Value\", \"Training Accuracy\", \"Test Accuracy\",\n",
        "    \"Learning Rate\", \"Perturbation\"\n",
        "]\n",
        "init_local_csv(local_csv_file, local_headers)\n",
        "\n",
        "init_validation_csv(validation_csv_file)\n",
        "\n",
        "# Do NOT pre-init global_csv_file here because your save_accuracies_to_csv()\n",
        "# already writes the header each time it runs (in 'w' mode)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "324178e0",
      "metadata": {
        "id": "324178e0"
      },
      "source": [
        "Load and Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d512e2a5",
      "metadata": {
        "id": "d512e2a5"
      },
      "outputs": [],
      "source": [
        "from data.preprocess_genome import load_and_prepare_dataset\n",
        "from data.splitters import split_dataset_for_epochs\n",
        "from configs.base_config import (\n",
        "    num_clients, num_epochs, samples_per_epoch, split_type,\n",
        "    global_seed\n",
        ")\n",
        "\n",
        "np_train_data, np_test_data = load_and_prepare_dataset(word_size, global_seed)\n",
        "\n",
        "# 2) Compute feasible epoch capacity and cap both epochs and rounds\n",
        "N_train = len(np_train_data)\n",
        "train_capacity = N_train // (num_clients * samples_per_epoch)\n",
        "num_epochs_eff = max(1, min(num_epochs, train_capacity))\n",
        "\n",
        "if train_capacity == 0:\n",
        "    raise ValueError(\n",
        "        f\"Not enough training samples ({N_train}) for \"\n",
        "        f\"{num_clients=} × {samples_per_epoch=} per epoch. \"\n",
        "        \"Reduce samples_per_epoch or num_clients, or enable resampling.\"\n",
        "    )\n",
        "\n",
        "num_federated_layers_eff = min(num_federated_layers, num_epochs_eff)\n",
        "\n",
        "# Build clients\n",
        "if split_type.lower() == \"iid\":\n",
        "    from data.splitters import split_dataset_for_epochs\n",
        "    clients = split_dataset_for_epochs(\n",
        "        num_clients=num_clients,\n",
        "        num_epochs=num_epochs_eff,             # or num_epochs\n",
        "        train_data=np_train_data,\n",
        "        test_data=np_test_data,\n",
        "        samples_per_epoch=samples_per_epoch,\n",
        "    )\n",
        "elif split_type.lower() in {\"noniid\", \"non-iid\", \"non_iid\"}:\n",
        "    from data.noniid import make_non_iid_clients\n",
        "    clients = make_non_iid_clients(\n",
        "        train_data=np_train_data,\n",
        "        test_data=np_test_data,\n",
        "        num_clients=num_clients,\n",
        "        num_epochs=num_epochs_eff,             # or num_epochs\n",
        "        samples_per_epoch=samples_per_epoch,\n",
        "        non_iid_ratio=0.8,                     # tune as needed\n",
        "        quantity_variation=0.5,                # tune as needed\n",
        "        seed=global_seed,\n",
        "        plot=True\n",
        "    )\n",
        "else:\n",
        "    raise ValueError(f\"Unknown split_type: {split_type}\")\n",
        "\n",
        "'''\n",
        "clients = split_dataset_for_epochs(\n",
        "    num_clients=num_clients, num_epochs=num_epochs,\n",
        "    train_data=np_train_data, test_data=np_test_data,\n",
        "    samples_per_epoch=samples_per_epoch\n",
        ")\n",
        "'''\n",
        "# validation/tables\n",
        "test_sequences = np.array([d[\"sequence\"] for d in np_test_data])\n",
        "test_labels    = np.array([d[\"label\"]    for d in np_test_data])\n",
        "X_val, y_val   = test_sequences, test_labels\n",
        "\n",
        "# derive num_features once\n",
        "if clients and clients[0].data and clients[0].data[0]:\n",
        "    num_features = clients[0].data[0][0]['sequence'].shape[0]\n",
        "else:\n",
        "    raise RuntimeError(\"Empty client data – check splitting indices.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cf7dd9c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf7dd9c0",
        "outputId": "527711b1-d631-4cd4-90cf-7770a71b395f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] num_features = 5\n"
          ]
        }
      ],
      "source": [
        "# Infer num_features from the first available sample in clients\n",
        "def infer_num_features_from_clients(clients):\n",
        "    for c in clients:\n",
        "        for epoch_data in c.data:              # list of samples for that epoch\n",
        "            if not epoch_data:\n",
        "                continue\n",
        "            sample = epoch_data[0]\n",
        "            if \"sequence\" in sample:           # your Genome pipeline\n",
        "                arr = np.asarray(sample[\"sequence\"])\n",
        "                return int(arr.size)\n",
        "            if \"features\" in sample:           # some other pipelines\n",
        "                arr = np.asarray(sample[\"features\"])\n",
        "                return int(arr.size)\n",
        "            if \"image\" in sample:              # e.g., MNIST before flatten\n",
        "                arr = np.asarray(sample[\"image\"]).reshape(-1)\n",
        "                return int(arr.size)\n",
        "            # add any other key you use\n",
        "    raise RuntimeError(\"Could not infer num_features: no samples found.\")\n",
        "\n",
        "num_features = infer_num_features_from_clients(clients)\n",
        "print(f\"[info] num_features = {num_features}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d847bd00",
      "metadata": {
        "id": "d847bd00"
      },
      "source": [
        "run federated loop and plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bbc26297",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bbc26297",
        "outputId": "15456c98-1be7-49a0-a4f1-1e5e59a7a1a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:   0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 0] Teleportation OFF | Aggregation=best\n",
            "[round 0 | client 0] seed LR=0.1400000000 (prev=0.1400000000), seed PERT=0.1400000000 (prev=0.1400000000), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.487030 step=0.02795 g_raw=+0.013 g_sm=+0.002 acc=1 | LR→0.140280 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#010 loss=0.481864 step=0.04636 g_raw=+0.018 g_sm=+0.006 acc=1 | LR→0.140561 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#015 loss=0.478418 step=0.03597 g_raw=+0.013 g_sm=+0.008 acc=1 | LR→0.140843 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#020 loss=0.473077 step=0.01103 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.141125 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#025 loss=0.469252 step=0.005033 g_raw=+0.001 g_sm=+0.011 acc=1 | LR→0.141408 PERT→0.140001 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1400000000, PERT_used=0.1400000000 → LR_next=0.1414079494, PERT_next=0.1400009168\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1400000000→0.1414079494 PERT 0.1400000000→0.1400009168\n",
            "Training Accuracy: 0.56\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.467190 step=0.04497 g_raw=+0.018 g_sm=+0.011 acc=1 | LR→0.141691 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#035 loss=0.464540 step=0.02197 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.141975 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#040 loss=0.460422 step=0.01666 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.142260 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#045 loss=0.459838 step=0.01789 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.142545 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#050 loss=0.458621 step=0.01695 g_raw=+0.006 g_sm=+0.010 acc=1 | LR→0.142831 PERT→0.140002 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1414079494, PERT_used=0.1400009168 → LR_next=0.1428306973, PERT_next=0.1400024600\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1414079494→0.1428306973 PERT 0.1400009168→0.1400024600\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.456930 step=0.03653 g_raw=+0.015 g_sm=+0.010 acc=1 | LR→0.143117 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#060 loss=0.452770 step=0.005279 g_raw=-0.001 g_sm=+0.011 acc=1 | LR→0.143404 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#065 loss=0.449391 step=0.0007084 g_raw=+0.003 g_sm=+0.012 acc=1 | LR→0.143691 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#070 loss=0.448107 step=0.006268 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.143979 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#075 loss=0.445581 step=0.01867 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.144268 PERT→0.140004 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1428306973, PERT_used=0.1400024600 → LR_next=0.1442677578, PERT_next=0.1400040012\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1428306973→0.1442677578 PERT 0.1400024600→0.1400040012\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.73\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.443876 step=0.03074 g_raw=+0.011 g_sm=+0.011 acc=1 | LR→0.144557 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#085 loss=0.440591 step=0.02565 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.144847 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#090 loss=0.440113 step=0.02117 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.145137 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#095 loss=0.436714 step=0.05899 g_raw=+0.019 g_sm=+0.011 acc=1 | LR→0.145428 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#100 loss=0.432069 step=0.01231 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.145719 PERT→0.140006 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1442677578, PERT_used=0.1400040012 → LR_next=0.1457193098, PERT_next=0.1400055739\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1442677578→0.1457193098 PERT 0.1400040012→0.1400055739\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.431513 step=0.001084 g_raw=-0.001 g_sm=+0.011 acc=1 | LR→0.146011 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#110 loss=0.430147 step=0.006539 g_raw=+0.006 g_sm=+0.010 acc=1 | LR→0.146304 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#115 loss=0.428265 step=0.03612 g_raw=+0.015 g_sm=+0.011 acc=1 | LR→0.146597 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#120 loss=0.426479 step=0.05266 g_raw=+0.019 g_sm=+0.011 acc=1 | LR→0.146891 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#125 loss=0.423412 step=0.05364 g_raw=+0.020 g_sm=+0.011 acc=1 | LR→0.147185 PERT→0.140007 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1457193098, PERT_used=0.1400055739 → LR_next=0.1471853538, PERT_next=0.1400070394\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1457193098→0.1471853538 PERT 0.1400055739→0.1400070394\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.73\n",
            "[round 0 | client 0] final LR=0.1471853538, final PERT=0.1400070394  (ΔLR=+0.0071853538, ΔPERT=+0.0000070394)\n",
            "[round 0 | client 1] seed LR=0.1400000000 (prev=0.1400000000), seed PERT=0.1400000000 (prev=0.1400000000), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.479296 step=0.003366 g_raw=+0.002 g_sm=+0.004 acc=1 | LR→0.140280 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#010 loss=0.474306 step=0.0795 g_raw=+0.034 g_sm=+0.007 acc=1 | LR→0.140561 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#015 loss=0.467296 step=0.04746 g_raw=+0.019 g_sm=+0.009 acc=1 | LR→0.140843 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#020 loss=0.463507 step=0.044 g_raw=+0.016 g_sm=+0.011 acc=1 | LR→0.141125 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#025 loss=0.461784 step=0.04687 g_raw=+0.019 g_sm=+0.011 acc=1 | LR→0.141408 PERT→0.140001 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1400000000, PERT_used=0.1400000000 → LR_next=0.1414080579, PERT_next=0.1400010242\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1400000000→0.1414080579 PERT 0.1400000000→0.1400010242\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.55\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.456466 step=0.08608 g_raw=+0.035 g_sm=+0.012 acc=1 | LR→0.141691 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#035 loss=0.448022 step=0.08104 g_raw=+0.035 g_sm=+0.014 acc=1 | LR→0.141975 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#040 loss=0.440149 step=0.05842 g_raw=+0.023 g_sm=+0.016 acc=1 | LR→0.142260 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#045 loss=0.437041 step=0.007226 g_raw=+0.004 g_sm=+0.015 acc=1 | LR→0.142545 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#050 loss=0.430028 step=0.06322 g_raw=+0.021 g_sm=+0.016 acc=1 | LR→0.142831 PERT→0.140003 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1414080579, PERT_used=0.1400010242 → LR_next=0.1428312093, PERT_next=0.1400029619\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1414080579→0.1428312093 PERT 0.1400010242→0.1400029619\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.429790 step=0.01263 g_raw=+0.004 g_sm=+0.013 acc=1 | LR→0.143118 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#060 loss=0.425579 step=0.05231 g_raw=+0.021 g_sm=+0.014 acc=1 | LR→0.143404 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#065 loss=0.423227 step=0.007462 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.143692 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#070 loss=0.419728 step=0.05953 g_raw=+0.020 g_sm=+0.013 acc=1 | LR→0.143980 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#075 loss=0.418421 step=0.02492 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.144269 PERT→0.140005 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1428312093, PERT_used=0.1400029619 → LR_next=0.1442686408, PERT_next=0.1400048580\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1428312093→0.1442686408 PERT 0.1400029619→0.1400048580\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.78\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.415122 step=0.01949 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.144558 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#085 loss=0.413651 step=0.02894 g_raw=+0.014 g_sm=+0.012 acc=1 | LR→0.144848 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#090 loss=0.406076 step=0.06871 g_raw=+0.028 g_sm=+0.014 acc=1 | LR→0.145138 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#095 loss=0.403894 step=0.02168 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.145429 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#100 loss=0.402256 step=0.02361 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.145720 PERT→0.140007 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1442686408, PERT_used=0.1400048580 → LR_next=0.1457203893, PERT_next=0.1400066111\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1442686408→0.1457203893 PERT 0.1400048580→0.1400066111\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.77\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.399582 step=0.05823 g_raw=+0.021 g_sm=+0.012 acc=1 | LR→0.146012 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#110 loss=0.398801 step=0.03351 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.146305 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#115 loss=0.396698 step=0.02331 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.146598 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#120 loss=0.394653 step=0.002904 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.146892 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#125 loss=0.391618 step=0.01203 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.147187 PERT→0.140008 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1457203893, PERT_used=0.1400066111 → LR_next=0.1471865515, PERT_next=0.1400081787\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1457203893→0.1471865515 PERT 0.1400066111→0.1400081787\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.72\n",
            "[round 0 | client 1] final LR=0.1471865515, final PERT=0.1400081787  (ΔLR=+0.0071865515, ΔPERT=+0.0000081787)\n",
            "[round 0 | client 2] seed LR=0.1400000000 (prev=0.1400000000), seed PERT=0.1400000000 (prev=0.1400000000), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.494118 step=0.05375 g_raw=+0.018 g_sm=+0.001 acc=1 | LR→0.140280 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#010 loss=0.492479 step=0.03553 g_raw=+0.017 g_sm=+0.003 acc=1 | LR→0.140561 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#015 loss=0.490758 step=0.00693 g_raw=+0.007 g_sm=+0.005 acc=1 | LR→0.140843 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#020 loss=0.487772 step=0.009973 g_raw=+0.006 g_sm=+0.007 acc=1 | LR→0.141125 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#025 loss=0.483495 step=0.07127 g_raw=+0.032 g_sm=+0.009 acc=1 | LR→0.141408 PERT→0.140001 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1400000000, PERT_used=0.1400000000 → LR_next=0.1414076237, PERT_next=0.1400005943\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.004 acc_ratio=1.00 | LR 0.1400000000→0.1414076237 PERT 0.1400000000→0.1400005943\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.62\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.482137 step=0.001403 g_raw=+0.000 g_sm=+0.009 acc=1 | LR→0.141691 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#035 loss=0.479611 step=0.05935 g_raw=+0.026 g_sm=+0.009 acc=1 | LR→0.141975 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#040 loss=0.477122 step=0.03673 g_raw=+0.014 g_sm=+0.010 acc=1 | LR→0.142259 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#045 loss=0.470052 step=0.02933 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.142545 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#050 loss=0.468463 step=0.001629 g_raw=-0.001 g_sm=+0.011 acc=1 | LR→0.142830 PERT→0.140002 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1414076237, PERT_used=0.1400005943 → LR_next=0.1428302164, PERT_next=0.1400019886\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1414076237→0.1428302164 PERT 0.1400005943→0.1400019886\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.465835 step=0.03366 g_raw=+0.013 g_sm=+0.011 acc=1 | LR→0.143116 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#060 loss=0.462726 step=0.01856 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.143403 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#065 loss=0.458912 step=0.0211 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.143691 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#070 loss=0.457817 step=0.01172 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.143979 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#075 loss=0.454436 step=0.03382 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.144267 PERT→0.140004 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1428302164, PERT_used=0.1400019886 → LR_next=0.1442673631, PERT_next=0.1400036182\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1428302164→0.1442673631 PERT 0.1400019886→0.1400036182\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.73\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.446907 step=0.01269 g_raw=+0.004 g_sm=+0.014 acc=1 | LR→0.144557 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#085 loss=0.441542 step=0.07046 g_raw=+0.027 g_sm=+0.015 acc=1 | LR→0.144846 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#090 loss=0.438368 step=0.02702 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.145137 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#095 loss=0.435982 step=0.009474 g_raw=+0.006 g_sm=+0.014 acc=1 | LR→0.145428 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#100 loss=0.431401 step=0.0867 g_raw=+0.034 g_sm=+0.015 acc=1 | LR→0.145719 PERT→0.140006 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1442673631, PERT_used=0.1400036182 → LR_next=0.1457193073, PERT_next=0.1400055715\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1442673631→0.1457193073 PERT 0.1400036182→0.1400055715\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.73\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.428370 step=0.01832 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.146011 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#110 loss=0.427736 step=0.01882 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.146304 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#115 loss=0.425342 step=0.01266 g_raw=+0.005 g_sm=+0.012 acc=1 | LR→0.146597 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#120 loss=0.422678 step=0.01227 g_raw=+0.005 g_sm=+0.012 acc=1 | LR→0.146891 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#125 loss=0.421566 step=0.02852 g_raw=+0.011 g_sm=+0.011 acc=1 | LR→0.147186 PERT→0.140007 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1457193073, PERT_used=0.1400055715 → LR_next=0.1471856938, PERT_next=0.1400073628\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1457193073→0.1471856938 PERT 0.1400055715→0.1400073628\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.69\n",
            "[round 0 | client 2] final LR=0.1471856938, final PERT=0.1400073628  (ΔLR=+0.0071856938, ΔPERT=+0.0000073628)\n",
            "[round 0 | client 3] seed LR=0.1400000000 (prev=0.1400000000), seed PERT=0.1400000000 (prev=0.1400000000), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.515261 step=0.01891 g_raw=+0.006 g_sm=+0.001 acc=1 | LR→0.140280 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#010 loss=0.510067 step=0.02351 g_raw=+0.009 g_sm=+0.005 acc=1 | LR→0.140561 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#015 loss=0.504531 step=0.02409 g_raw=+0.011 g_sm=+0.008 acc=1 | LR→0.140843 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#020 loss=0.498826 step=0.09724 g_raw=+0.039 g_sm=+0.010 acc=1 | LR→0.141125 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#025 loss=0.497006 step=0.001582 g_raw=+0.001 g_sm=+0.010 acc=1 | LR→0.141408 PERT→0.140001 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1400000000, PERT_used=0.1400000000 → LR_next=0.1414079131, PERT_next=0.1400008809\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1400000000→0.1414079131 PERT 0.1400000000→0.1400008809\n",
            "Training Accuracy: 0.50\n",
            "Test Accuracy: 0.47\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.494471 step=0.01898 g_raw=+0.007 g_sm=+0.010 acc=1 | LR→0.141691 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#035 loss=0.491933 step=0.05197 g_raw=+0.020 g_sm=+0.011 acc=1 | LR→0.141975 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#040 loss=0.485806 step=0.02235 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.142260 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#045 loss=0.480556 step=0.03897 g_raw=+0.017 g_sm=+0.014 acc=1 | LR→0.142545 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#050 loss=0.478965 step=0.01452 g_raw=+0.003 g_sm=+0.012 acc=1 | LR→0.142831 PERT→0.140003 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1414079131, PERT_used=0.1400008809 → LR_next=0.1428307503, PERT_next=0.1400025120\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1414079131→0.1428307503 PERT 0.1400008809→0.1400025120\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.477724 step=0.05757 g_raw=+0.019 g_sm=+0.011 acc=1 | LR→0.143117 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#060 loss=0.475353 step=0.0186 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.143404 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#065 loss=0.468935 step=0.1259 g_raw=+0.044 g_sm=+0.012 acc=1 | LR→0.143691 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#070 loss=0.467609 step=0.0137 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.143979 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#075 loss=0.460975 step=0.0316 g_raw=+0.014 g_sm=+0.013 acc=1 | LR→0.144268 PERT→0.140004 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1428307503, PERT_used=0.1400025120 → LR_next=0.1442678471, PERT_next=0.1400040879\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1428307503→0.1442678471 PERT 0.1400025120→0.1400040879\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.456436 step=0.09388 g_raw=+0.038 g_sm=+0.014 acc=1 | LR→0.144557 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#085 loss=0.450027 step=0.05813 g_raw=+0.024 g_sm=+0.015 acc=1 | LR→0.144847 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#090 loss=0.447601 step=0.001999 g_raw=-0.000 g_sm=+0.014 acc=1 | LR→0.145137 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#095 loss=0.446504 step=0.02807 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.145428 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#100 loss=0.440449 step=0.02855 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.145720 PERT→0.140006 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1442678471, PERT_used=0.1400040879 → LR_next=0.1457197230, PERT_next=0.1400059709\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1442678471→0.1457197230 PERT 0.1400040879→0.1400059709\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.438031 step=0.04952 g_raw=+0.018 g_sm=+0.014 acc=1 | LR→0.146012 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#110 loss=0.436570 step=0.02754 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.146305 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#115 loss=0.435426 step=0.02818 g_raw=+0.010 g_sm=+0.012 acc=1 | LR→0.146598 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#120 loss=0.428730 step=0.06787 g_raw=+0.022 g_sm=+0.013 acc=1 | LR→0.146892 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#125 loss=0.426268 step=0.07424 g_raw=+0.027 g_sm=+0.013 acc=1 | LR→0.147186 PERT→0.140008 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1457197230, PERT_used=0.1400059709 → LR_next=0.1471861073, PERT_next=0.1400077561\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1457197230→0.1471861073 PERT 0.1400059709→0.1400077561\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.71\n",
            "[round 0 | client 3] final LR=0.1471861073, final PERT=0.1400077561  (ΔLR=+0.0071861073, ΔPERT=+0.0000077561)\n",
            "[round 0 | client 4] seed LR=0.1400000000 (prev=0.1400000000), seed PERT=0.1400000000 (prev=0.1400000000), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.472791 step=0.01419 g_raw=+0.003 g_sm=+0.005 acc=1 | LR→0.140280 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#010 loss=0.461994 step=0.03814 g_raw=+0.016 g_sm=+0.009 acc=1 | LR→0.140561 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#015 loss=0.452633 step=0.007566 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.140843 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#020 loss=0.451450 step=0.02605 g_raw=+0.007 g_sm=+0.010 acc=1 | LR→0.141125 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#025 loss=0.449591 step=0.0003801 g_raw=-0.003 g_sm=+0.010 acc=1 | LR→0.141408 PERT→0.140001 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1400000000, PERT_used=0.1400000000 → LR_next=0.1414082615, PERT_next=0.1400012258\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1400000000→0.1414082615 PERT 0.1400000000→0.1400012258\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.442579 step=0.06943 g_raw=+0.025 g_sm=+0.012 acc=1 | LR→0.141692 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#035 loss=0.439077 step=0.002755 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.141976 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#040 loss=0.435768 step=0.003096 g_raw=+0.003 g_sm=+0.012 acc=1 | LR→0.142260 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#045 loss=0.433914 step=0.0006093 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.142545 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#050 loss=0.432680 step=0.01903 g_raw=+0.010 g_sm=+0.011 acc=1 | LR→0.142831 PERT→0.140003 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1414082615, PERT_used=0.1400012258 → LR_next=0.1428311488, PERT_next=0.1400029026\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1414082615→0.1428311488 PERT 0.1400012258→0.1400029026\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.48\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.428449 step=0.002762 g_raw=+0.003 g_sm=+0.012 acc=1 | LR→0.143117 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#060 loss=0.423421 step=0.08553 g_raw=+0.029 g_sm=+0.012 acc=1 | LR→0.143404 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#065 loss=0.421316 step=0.03368 g_raw=+0.015 g_sm=+0.012 acc=1 | LR→0.143692 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#070 loss=0.414994 step=0.08573 g_raw=+0.032 g_sm=+0.014 acc=1 | LR→0.143980 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#075 loss=0.413146 step=0.008414 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.144268 PERT→0.140005 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1428311488, PERT_used=0.1400029026 → LR_next=0.1442683837, PERT_next=0.1400046086\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1428311488→0.1442683837 PERT 0.1400029026→0.1400046086\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.412212 step=0.006055 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.144558 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#085 loss=0.409201 step=0.06061 g_raw=+0.022 g_sm=+0.011 acc=1 | LR→0.144847 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#090 loss=0.407015 step=0.01619 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.145138 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#095 loss=0.405501 step=0.006148 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.145428 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#100 loss=0.404854 step=0.01549 g_raw=+0.007 g_sm=+0.010 acc=1 | LR→0.145720 PERT→0.140006 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1442683837, PERT_used=0.1400046086 → LR_next=0.1457199142, PERT_next=0.1400061546\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1442683837→0.1457199142 PERT 0.1400046086→0.1400061546\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.403415 step=0.04821 g_raw=+0.022 g_sm=+0.009 acc=1 | LR→0.146012 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#110 loss=0.402016 step=0.03436 g_raw=+0.016 g_sm=+0.010 acc=1 | LR→0.146305 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#115 loss=0.401405 step=0.0125 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.146598 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#120 loss=0.400492 step=0.01835 g_raw=+0.006 g_sm=+0.009 acc=1 | LR→0.146891 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#125 loss=0.397308 step=0.005202 g_raw=+0.001 g_sm=+0.009 acc=1 | LR→0.147186 PERT→0.140007 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1457199142, PERT_used=0.1400061546 → LR_next=0.1471857825, PERT_next=0.1400074472\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1457199142→0.1471857825 PERT 0.1400061546→0.1400074472\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.52\n",
            "[round 0 | client 4] final LR=0.1471857825, final PERT=0.1400074472  (ΔLR=+0.0071857825, ΔPERT=+0.0000074472)\n",
            "\n",
            "[Round 0] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           1      0.550452      0.725000      0.147187      0.140008\n",
            "           2      0.561531      0.695000      0.147186      0.140007\n",
            "           0      0.573654      0.735000      0.147185      0.140007\n",
            "           4      0.608121      0.520000      0.147186      0.140007\n",
            "           3      0.619406      0.710000      0.147186      0.140008\n",
            "→ [Round 0] action=init_from_best, best_client=1, best_val=0.550452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:   2%|▏         | 1/50 [14:57<12:12:57, 897.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   0] acc_g=0.747 (μ=0.677, σ=0.080, FG=0.141) | t=881.512s, val=0.550 | TEL=FALSE\n",
            "[Round 1] Teleportation OFF | Aggregation=best\n",
            "[round 1 | client 0] seed LR=0.1471853538 (prev=0.1471853538), seed PERT=0.1400070394 (prev=0.1400070394), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.456573 step=0.071 g_raw=+0.023 g_sm=+0.003 acc=1 | LR→0.147480 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.452095 step=0.02911 g_raw=+0.008 g_sm=+0.006 acc=1 | LR→0.147775 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.450152 step=0.03699 g_raw=+0.013 g_sm=+0.007 acc=1 | LR→0.148072 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.448639 step=0.007459 g_raw=+0.005 g_sm=+0.008 acc=1 | LR→0.148368 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.445461 step=0.005189 g_raw=+0.005 g_sm=+0.008 acc=1 | LR→0.148665 PERT→0.140008 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1471853538, PERT_used=0.1400070394 → LR_next=0.1486654505, PERT_next=0.1400078486\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1471853538→0.1486654505 PERT 0.1400070394→0.1400078486\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.443128 step=0.03004 g_raw=+0.007 g_sm=+0.009 acc=1 | LR→0.148963 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.441731 step=0.008146 g_raw=+0.004 g_sm=+0.008 acc=1 | LR→0.149262 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.440112 step=0.03452 g_raw=+0.010 g_sm=+0.008 acc=1 | LR→0.149561 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.438123 step=0.03877 g_raw=+0.012 g_sm=+0.009 acc=1 | LR→0.149861 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.436885 step=0.01475 g_raw=+0.004 g_sm=+0.009 acc=1 | LR→0.150161 PERT→0.140009 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1486654505, PERT_used=0.1400078486 → LR_next=0.1501608635, PERT_next=0.1400090611\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1486654505→0.1501608635 PERT 0.1400078486→0.1400090611\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.435327 step=0.0526 g_raw=+0.018 g_sm=+0.009 acc=1 | LR→0.150462 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.433222 step=0.05581 g_raw=+0.017 g_sm=+0.009 acc=1 | LR→0.150763 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.430229 step=0.01535 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.151065 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.428961 step=0.03788 g_raw=+0.013 g_sm=+0.010 acc=1 | LR→0.151368 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.426433 step=0.01386 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.151671 PERT→0.140010 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1501608635, PERT_used=0.1400090611 → LR_next=0.1516714560, PERT_next=0.1400104003\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1501608635→0.1516714560 PERT 0.1400090611→0.1400104003\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.426135 step=0.004261 g_raw=+0.003 g_sm=+0.009 acc=1 | LR→0.151975 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.423548 step=0.001621 g_raw=-0.002 g_sm=+0.009 acc=1 | LR→0.152280 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.421771 step=0.003387 g_raw=-0.000 g_sm=+0.009 acc=1 | LR→0.152585 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.419944 step=0.02018 g_raw=+0.008 g_sm=+0.009 acc=1 | LR→0.152891 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.418958 step=0.01067 g_raw=+0.002 g_sm=+0.008 acc=1 | LR→0.153197 PERT→0.140012 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1516714560, PERT_used=0.1400104003 → LR_next=0.1531971742, PERT_next=0.1400116750\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1516714560→0.1531971742 PERT 0.1400104003→0.1400116750\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.417646 step=0.004953 g_raw=-0.002 g_sm=+0.008 acc=1 | LR→0.153504 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.416888 step=0.01704 g_raw=+0.002 g_sm=+0.008 acc=1 | LR→0.153812 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.415327 step=0.0422 g_raw=+0.015 g_sm=+0.008 acc=1 | LR→0.154120 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.413830 step=0.003489 g_raw=+0.002 g_sm=+0.008 acc=1 | LR→0.154429 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.411905 step=0.03243 g_raw=+0.010 g_sm=+0.009 acc=1 | LR→0.154738 PERT→0.140013 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1531971742, PERT_used=0.1400116750 → LR_next=0.1547380765, PERT_next=0.1400128016\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1531971742→0.1547380765 PERT 0.1400116750→0.1400128016\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.57\n",
            "[round 1 | client 0] final LR=0.1547380765, final PERT=0.1400128016  (ΔLR=+0.0075527227, ΔPERT=+0.0000057622)\n",
            "[round 1 | client 1] seed LR=0.1471865515 (prev=0.1471865515), seed PERT=0.1400081787 (prev=0.1400081787), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.492697 step=0.02769 g_raw=+0.010 g_sm=+0.002 acc=1 | LR→0.147481 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.488229 step=0.06208 g_raw=+0.023 g_sm=+0.005 acc=1 | LR→0.147777 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.486772 step=0.006606 g_raw=+0.004 g_sm=+0.006 acc=1 | LR→0.148073 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.484563 step=0.01471 g_raw=+0.004 g_sm=+0.007 acc=1 | LR→0.148369 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#025 loss=0.482023 step=0.0448 g_raw=+0.014 g_sm=+0.008 acc=1 | LR→0.148667 PERT→0.140009 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1471865515, PERT_used=0.1400081787 → LR_next=0.1486665500, PERT_next=0.1400088841\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1471865515→0.1486665500 PERT 0.1400081787→0.1400088841\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.65\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.479071 step=0.003891 g_raw=-0.000 g_sm=+0.009 acc=1 | LR→0.148964 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.478492 step=0.001639 g_raw=+0.000 g_sm=+0.008 acc=1 | LR→0.149263 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.475971 step=0.02164 g_raw=+0.008 g_sm=+0.009 acc=1 | LR→0.149562 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#045 loss=0.471704 step=0.07207 g_raw=+0.027 g_sm=+0.010 acc=1 | LR→0.149862 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.467161 step=0.03031 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.150162 PERT→0.140010 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1486665500, PERT_used=0.1400088841 → LR_next=0.1501620861, PERT_next=0.1400102011\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1486665500→0.1501620861 PERT 0.1400088841→0.1400102011\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.464664 step=0.04752 g_raw=+0.018 g_sm=+0.012 acc=1 | LR→0.150463 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#060 loss=0.463100 step=0.01608 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.150765 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.462618 step=0.01079 g_raw=-0.000 g_sm=+0.010 acc=1 | LR→0.151067 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#070 loss=0.461787 step=0.0148 g_raw=+0.004 g_sm=+0.009 acc=1 | LR→0.151370 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#075 loss=0.460814 step=0.02485 g_raw=+0.012 g_sm=+0.009 acc=1 | LR→0.151673 PERT→0.140012 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1501620861, PERT_used=0.1400102011 → LR_next=0.1516728372, PERT_next=0.1400116753\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1501620861→0.1516728372 PERT 0.1400102011→0.1400116753\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.76\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.460745 step=0.004207 g_raw=+0.001 g_sm=+0.007 acc=1 | LR→0.151977 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#085 loss=0.460472 step=0.003603 g_raw=+0.001 g_sm=+0.006 acc=1 | LR→0.152281 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#090 loss=0.459550 step=0.03107 g_raw=+0.010 g_sm=+0.006 acc=1 | LR→0.152586 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.458309 step=0.003528 g_raw=+0.004 g_sm=+0.007 acc=1 | LR→0.152892 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.457507 step=0.02681 g_raw=+0.010 g_sm=+0.007 acc=1 | LR→0.153198 PERT→0.140013 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1516728372, PERT_used=0.1400116753 → LR_next=0.1531982193, PERT_next=0.1400126301\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.005 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1516728372→0.1531982193 PERT 0.1400116753→0.1400126301\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.79\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.456683 step=0.0367 g_raw=+0.012 g_sm=+0.007 acc=1 | LR→0.153505 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#110 loss=0.456322 step=0.001665 g_raw=-0.000 g_sm=+0.006 acc=1 | LR→0.153813 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.455360 step=0.000572 g_raw=-0.000 g_sm=+0.006 acc=1 | LR→0.154121 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.454677 step=0.03446 g_raw=+0.011 g_sm=+0.006 acc=1 | LR→0.154430 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.453179 step=0.01336 g_raw=+0.005 g_sm=+0.007 acc=1 | LR→0.154739 PERT→0.140014 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1531982193, PERT_used=0.1400126301 → LR_next=0.1547388836, PERT_next=0.1400135319\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1531982193→0.1547388836 PERT 0.1400126301→0.1400135319\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.79\n",
            "[round 1 | client 1] final LR=0.1547388836, final PERT=0.1400135319  (ΔLR=+0.0075523321, ΔPERT=+0.0000053533)\n",
            "[round 1 | client 2] seed LR=0.1471856938 (prev=0.1471856938), seed PERT=0.1400073628 (prev=0.1400073628), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.490142 step=0.02037 g_raw=+0.011 g_sm=+0.003 acc=1 | LR→0.147480 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.487148 step=0.06332 g_raw=+0.021 g_sm=+0.005 acc=1 | LR→0.147776 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.481370 step=0.04716 g_raw=+0.020 g_sm=+0.007 acc=1 | LR→0.148072 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.477518 step=0.06927 g_raw=+0.030 g_sm=+0.009 acc=1 | LR→0.148369 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.467619 step=0.0488 g_raw=+0.020 g_sm=+0.012 acc=1 | LR→0.148666 PERT→0.140008 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1471856938, PERT_used=0.1400073628 → LR_next=0.1486658785, PERT_next=0.1400082517\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1471856938→0.1486658785 PERT 0.1400073628→0.1400082517\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.466553 step=0.03934 g_raw=+0.010 g_sm=+0.011 acc=1 | LR→0.148964 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.440889 step=0.02779 g_raw=+0.010 g_sm=+0.017 acc=1 | LR→0.149263 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.436358 step=0.07034 g_raw=+0.023 g_sm=+0.017 acc=1 | LR→0.149562 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.431866 step=0.02259 g_raw=+0.006 g_sm=+0.016 acc=1 | LR→0.149862 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.422054 step=0.01739 g_raw=+0.003 g_sm=+0.016 acc=1 | LR→0.150162 PERT→0.140010 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1486658785, PERT_used=0.1400082517 → LR_next=0.1501623255, PERT_next=0.1400104243\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1486658785→0.1501623255 PERT 0.1400082517→0.1400104243\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.407655 step=0.1374 g_raw=+0.047 g_sm=+0.019 acc=1 | LR→0.150463 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#060 loss=0.403740 step=0.0002361 g_raw=+0.000 g_sm=+0.018 acc=1 | LR→0.150765 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.400588 step=0.02424 g_raw=+0.009 g_sm=+0.017 acc=1 | LR→0.151068 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#070 loss=0.397202 step=0.08606 g_raw=+0.032 g_sm=+0.016 acc=1 | LR→0.151371 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#075 loss=0.392953 step=0.01336 g_raw=+0.004 g_sm=+0.015 acc=1 | LR→0.151674 PERT→0.140013 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1501623255, PERT_used=0.1400104243 → LR_next=0.1516740646, PERT_next=0.1400128083\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1501623255→0.1516740646 PERT 0.1400104243→0.1400128083\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.58\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.389895 step=0.05038 g_raw=+0.022 g_sm=+0.015 acc=1 | LR→0.151978 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#085 loss=0.388961 step=0.03081 g_raw=+0.012 g_sm=+0.013 acc=1 | LR→0.152283 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#090 loss=0.386418 step=0.0198 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.152588 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#095 loss=0.383133 step=0.02538 g_raw=+0.013 g_sm=+0.012 acc=1 | LR→0.152894 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#100 loss=0.382621 step=0.03066 g_raw=+0.013 g_sm=+0.011 acc=1 | LR→0.153200 PERT→0.140015 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1516740646, PERT_used=0.1400128083 → LR_next=0.1532003588, PERT_next=0.1400145855\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1516740646→0.1532003588 PERT 0.1400128083→0.1400145855\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.381946 step=0.01557 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.153507 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#110 loss=0.380512 step=0.04378 g_raw=+0.011 g_sm=+0.009 acc=1 | LR→0.153815 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#115 loss=0.379108 step=0.007579 g_raw=-0.000 g_sm=+0.009 acc=1 | LR→0.154123 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#120 loss=0.378222 step=0.02878 g_raw=+0.010 g_sm=+0.009 acc=1 | LR→0.154432 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#125 loss=0.377087 step=0.04677 g_raw=+0.014 g_sm=+0.008 acc=1 | LR→0.154741 PERT→0.140016 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1532003588, PERT_used=0.1400145855 → LR_next=0.1547414646, PERT_next=0.1400158673\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1532003588→0.1547414646 PERT 0.1400145855→0.1400158673\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.60\n",
            "[round 1 | client 2] final LR=0.1547414646, final PERT=0.1400158673  (ΔLR=+0.0075557708, ΔPERT=+0.0000085044)\n",
            "[round 1 | client 3] seed LR=0.1471861073 (prev=0.1471861073), seed PERT=0.1400077561 (prev=0.1400077561), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.497490 step=0.07377 g_raw=+0.026 g_sm=+0.004 acc=1 | LR→0.147481 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.496516 step=0.02749 g_raw=+0.002 g_sm=+0.005 acc=1 | LR→0.147776 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.484871 step=0.09934 g_raw=+0.036 g_sm=+0.010 acc=1 | LR→0.148072 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.460018 step=0.1223 g_raw=+0.046 g_sm=+0.017 acc=1 | LR→0.148369 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#025 loss=0.453803 step=0.07634 g_raw=+0.029 g_sm=+0.017 acc=1 | LR→0.148667 PERT→0.140009 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1471861073, PERT_used=0.1400077561 → LR_next=0.1486666556, PERT_next=0.1400089835\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.022 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1471861073→0.1486666556 PERT 0.1400077561→0.1400089835\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.60\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.443260 step=0.02389 g_raw=+0.010 g_sm=+0.018 acc=1 | LR→0.148965 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#035 loss=0.434000 step=0.06351 g_raw=+0.023 g_sm=+0.020 acc=1 | LR→0.149264 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#040 loss=0.429558 step=0.008043 g_raw=+0.005 g_sm=+0.019 acc=1 | LR→0.149563 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#045 loss=0.426116 step=0.0478 g_raw=+0.018 g_sm=+0.018 acc=1 | LR→0.149863 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#050 loss=0.418058 step=0.1024 g_raw=+0.037 g_sm=+0.019 acc=1 | LR→0.150164 PERT→0.140012 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1486666556, PERT_used=0.1400089835 → LR_next=0.1501636094, PERT_next=0.1400116213\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1486666556→0.1501636094 PERT 0.1400089835→0.1400116213\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.416302 step=0.04602 g_raw=+0.017 g_sm=+0.017 acc=1 | LR→0.150465 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#060 loss=0.411392 step=0.0285 g_raw=+0.010 g_sm=+0.016 acc=1 | LR→0.150767 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#065 loss=0.404950 step=0.02106 g_raw=+0.006 g_sm=+0.016 acc=1 | LR→0.151069 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#070 loss=0.404539 step=0.001672 g_raw=-0.002 g_sm=+0.013 acc=1 | LR→0.151372 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#075 loss=0.397968 step=0.0595 g_raw=+0.022 g_sm=+0.014 acc=1 | LR→0.151675 PERT→0.140014 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1501636094, PERT_used=0.1400116213 → LR_next=0.1516751856, PERT_next=0.1400138432\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1501636094→0.1516751856 PERT 0.1400116213→0.1400138432\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.396732 step=0.02845 g_raw=+0.011 g_sm=+0.013 acc=1 | LR→0.151979 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#085 loss=0.395045 step=0.003713 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.152284 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#090 loss=0.393301 step=0.0251 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.152589 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#095 loss=0.390912 step=0.02833 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.152895 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#100 loss=0.389677 step=0.0477 g_raw=+0.019 g_sm=+0.010 acc=1 | LR→0.153201 PERT→0.140015 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1516751856, PERT_used=0.1400138432 → LR_next=0.1532013302, PERT_next=0.1400154733\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1516751856→0.1532013302 PERT 0.1400138432→0.1400154733\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.79\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.388474 step=0.00346 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.153508 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#110 loss=0.386500 step=0.02452 g_raw=+0.007 g_sm=+0.009 acc=1 | LR→0.153816 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#115 loss=0.385162 step=0.00223 g_raw=+0.009 g_sm=+0.009 acc=1 | LR→0.154124 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#120 loss=0.383205 step=0.07006 g_raw=+0.023 g_sm=+0.009 acc=1 | LR→0.154433 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#125 loss=0.382811 step=0.02309 g_raw=+0.005 g_sm=+0.008 acc=1 | LR→0.154742 PERT→0.140017 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1532013302, PERT_used=0.1400154733 → LR_next=0.1547424832, PERT_next=0.1400167890\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1532013302→0.1547424832 PERT 0.1400154733→0.1400167890\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.77\n",
            "[round 1 | client 3] final LR=0.1547424832, final PERT=0.1400167890  (ΔLR=+0.0075563760, ΔPERT=+0.0000090329)\n",
            "[round 1 | client 4] seed LR=0.1471857825 (prev=0.1471857825), seed PERT=0.1400074472 (prev=0.1400074472), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.480925 step=0.02226 g_raw=+0.007 g_sm=+0.003 acc=1 | LR→0.147481 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.474935 step=0.03549 g_raw=+0.012 g_sm=+0.005 acc=1 | LR→0.147776 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.470454 step=0.01614 g_raw=+0.005 g_sm=+0.007 acc=1 | LR→0.148072 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.461963 step=0.03528 g_raw=+0.012 g_sm=+0.010 acc=1 | LR→0.148369 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.459092 step=0.005154 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.148666 PERT→0.140008 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1471857825, PERT_used=0.1400074472 → LR_next=0.1486660395, PERT_next=0.1400084034\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1471857825→0.1486660395 PERT 0.1400074472→0.1400084034\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.73\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.454851 step=0.07019 g_raw=+0.027 g_sm=+0.012 acc=1 | LR→0.148964 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.435264 step=0.02408 g_raw=+0.007 g_sm=+0.016 acc=1 | LR→0.149263 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.422932 step=0.045 g_raw=+0.017 g_sm=+0.017 acc=1 | LR→0.149562 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#045 loss=0.419062 step=0.02465 g_raw=+0.009 g_sm=+0.016 acc=1 | LR→0.149862 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.402349 step=0.05152 g_raw=+0.013 g_sm=+0.019 acc=1 | LR→0.150162 PERT→0.140011 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1486660395, PERT_used=0.1400084034 → LR_next=0.1501624939, PERT_next=0.1400105813\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.022 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1486660395→0.1501624939 PERT 0.1400084034→0.1400105813\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.80\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.399165 step=0.04067 g_raw=+0.017 g_sm=+0.017 acc=1 | LR→0.150464 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#060 loss=0.394607 step=0.05001 g_raw=+0.018 g_sm=+0.016 acc=1 | LR→0.150765 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#065 loss=0.393076 step=0.0348 g_raw=+0.013 g_sm=+0.015 acc=1 | LR→0.151068 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#070 loss=0.391701 step=0.02678 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.151371 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#075 loss=0.387783 step=0.05422 g_raw=+0.015 g_sm=+0.014 acc=1 | LR→0.151674 PERT→0.140013 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1501624939, PERT_used=0.1400105813 → LR_next=0.1516740032, PERT_next=0.1400127516\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1501624939→0.1516740032 PERT 0.1400105813→0.1400127516\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.81\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.384533 step=0.0415 g_raw=+0.015 g_sm=+0.014 acc=1 | LR→0.151978 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#085 loss=0.382618 step=3.67e-05 g_raw=-0.000 g_sm=+0.013 acc=1 | LR→0.152283 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#090 loss=0.378892 step=0.02867 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.152588 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#095 loss=0.376738 step=0.04514 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.152894 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#100 loss=0.368249 step=0.05503 g_raw=+0.019 g_sm=+0.014 acc=1 | LR→0.153200 PERT→0.140015 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1516740032, PERT_used=0.1400127516 → LR_next=0.1532003302, PERT_next=0.1400145593\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1516740032→0.1532003302 PERT 0.1400127516→0.1400145593\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.80\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.366037 step=0.004199 g_raw=-0.002 g_sm=+0.012 acc=1 | LR→0.153507 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#110 loss=0.362736 step=0.006368 g_raw=+0.002 g_sm=+0.012 acc=1 | LR→0.153815 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#115 loss=0.361570 step=0.008443 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.154123 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#120 loss=0.360751 step=0.003316 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.154432 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#125 loss=0.358683 step=0.02111 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.154742 PERT→0.140016 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1532003302, PERT_used=0.1400145593 → LR_next=0.1547418139, PERT_next=0.1400161833\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1532003302→0.1547418139 PERT 0.1400145593→0.1400161833\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.78\n",
            "[round 1 | client 4] final LR=0.1547418139, final PERT=0.1400161833  (ΔLR=+0.0075560313, ΔPERT=+0.0000087361)\n",
            "\n",
            "[Round 1] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           4      0.533990      0.775000      0.154742      0.140016\n",
            "           3      0.556091      0.765000      0.154742      0.140017\n",
            "           2      0.566593      0.605000      0.154741      0.140016\n",
            "           1      0.591420      0.790000      0.154739      0.140014\n",
            "           0      0.712901      0.570000      0.154738      0.140013\n",
            "→ [Round 1] best_client=4, best_val=0.533990, prev_global_val=0.550452, improve=+0.016462, action=adopt+mix τ=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:   4%|▍         | 2/50 [29:58<11:59:45, 899.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   1] acc_g=0.744 (μ=0.701, σ=0.094, FG=0.200) | t=885.154s, val=0.613 | TEL=FALSE\n",
            "[Round 2] Teleportation OFF | Aggregation=best\n",
            "[round 2 | client 0] seed LR=0.1547380765 (prev=0.1547380765), seed PERT=0.1400128016 (prev=0.1400128016), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.492569 step=0.03857 g_raw=+0.013 g_sm=+0.004 acc=1 | LR→0.155048 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#010 loss=0.478301 step=0.05684 g_raw=+0.026 g_sm=+0.009 acc=1 | LR→0.155359 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#015 loss=0.468771 step=0.01208 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.155670 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#020 loss=0.464761 step=0.03652 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.155982 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#025 loss=0.458134 step=0.03145 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.156295 PERT→0.140014 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1547380765, PERT_used=0.1400128016 → LR_next=0.1562946108, PERT_next=0.1400140475\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1547380765→0.1562946108 PERT 0.1400128016→0.1400140475\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.453855 step=0.01477 g_raw=+0.003 g_sm=+0.013 acc=1 | LR→0.156608 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#035 loss=0.446303 step=0.06417 g_raw=+0.024 g_sm=+0.015 acc=1 | LR→0.156922 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#040 loss=0.436718 step=0.1592 g_raw=+0.054 g_sm=+0.016 acc=1 | LR→0.157237 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#045 loss=0.428861 step=0.002439 g_raw=+0.004 g_sm=+0.017 acc=1 | LR→0.157552 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#050 loss=0.420891 step=0.00556 g_raw=-0.001 g_sm=+0.017 acc=1 | LR→0.157868 PERT→0.140016 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1562946108, PERT_used=0.1400140475 → LR_next=0.1578677878, PERT_next=0.1400161673\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1562946108→0.1578677878 PERT 0.1400140475→0.1400161673\n",
            "Training Accuracy: 0.92\n",
            "Test Accuracy: 0.91\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.417179 step=0.05585 g_raw=+0.019 g_sm=+0.017 acc=1 | LR→0.158184 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#060 loss=0.413952 step=0.00265 g_raw=-0.003 g_sm=+0.016 acc=1 | LR→0.158502 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#065 loss=0.411701 step=0.02891 g_raw=+0.009 g_sm=+0.014 acc=1 | LR→0.158819 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#070 loss=0.409420 step=0.06216 g_raw=+0.022 g_sm=+0.013 acc=1 | LR→0.159138 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#075 loss=0.402691 step=0.1082 g_raw=+0.036 g_sm=+0.014 acc=1 | LR→0.159457 PERT→0.140018 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1578677878, PERT_used=0.1400161673 → LR_next=0.1594567456, PERT_next=0.1400182397\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1578677878→0.1594567456 PERT 0.1400161673→0.1400182397\n",
            "Training Accuracy: 0.94\n",
            "Test Accuracy: 0.91\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.400804 step=0.02365 g_raw=+0.008 g_sm=+0.013 acc=1 | LR→0.159776 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#085 loss=0.397674 step=0.03271 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.160097 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#090 loss=0.397540 step=0.005979 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.160418 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#095 loss=0.394253 step=0.01381 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.160739 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#100 loss=0.390722 step=0.004014 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.161061 PERT→0.140020 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1594567456, PERT_used=0.1400182397 → LR_next=0.1610612708, PERT_next=0.1400199421\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1594567456→0.1610612708 PERT 0.1400182397→0.1400199421\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.86\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.389743 step=0.003296 g_raw=-0.002 g_sm=+0.010 acc=1 | LR→0.161384 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#110 loss=0.386738 step=0.01734 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.161707 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#115 loss=0.384334 step=0.06479 g_raw=+0.025 g_sm=+0.010 acc=1 | LR→0.162032 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#120 loss=0.382371 step=0.03878 g_raw=+0.012 g_sm=+0.010 acc=1 | LR→0.162356 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#125 loss=0.379644 step=0.02927 g_raw=+0.009 g_sm=+0.010 acc=1 | LR→0.162682 PERT→0.140021 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1610612708, PERT_used=0.1400199421 → LR_next=0.1626816061, PERT_next=0.1400213560\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1610612708→0.1626816061 PERT 0.1400199421→0.1400213560\n",
            "Training Accuracy: 0.94\n",
            "Test Accuracy: 0.92\n",
            "[round 2 | client 0] final LR=0.1626816061, final PERT=0.1400213560  (ΔLR=+0.0079435296, ΔPERT=+0.0000085544)\n",
            "[round 2 | client 1] seed LR=0.1547388836 (prev=0.1547388836), seed PERT=0.1400135319 (prev=0.1400135319), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.512123 step=0.05383 g_raw=+0.020 g_sm=+0.007 acc=1 | LR→0.155049 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#010 loss=0.500956 step=0.05616 g_raw=+0.020 g_sm=+0.011 acc=1 | LR→0.155360 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#015 loss=0.492340 step=0.06875 g_raw=+0.025 g_sm=+0.014 acc=1 | LR→0.155671 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#020 loss=0.484441 step=0.08983 g_raw=+0.034 g_sm=+0.016 acc=1 | LR→0.155983 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#025 loss=0.480709 step=0.06153 g_raw=+0.022 g_sm=+0.016 acc=1 | LR→0.156296 PERT→0.140015 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1547388836, PERT_used=0.1400135319 → LR_next=0.1562958379, PERT_next=0.1400151468\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.024 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1547388836→0.1562958379 PERT 0.1400135319→0.1400151468\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.469684 step=0.08599 g_raw=+0.028 g_sm=+0.018 acc=1 | LR→0.156609 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#035 loss=0.465968 step=0.07863 g_raw=+0.027 g_sm=+0.017 acc=1 | LR→0.156923 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#040 loss=0.456566 step=0.0004266 g_raw=-0.000 g_sm=+0.018 acc=1 | LR→0.157238 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#045 loss=0.446536 step=0.05457 g_raw=+0.024 g_sm=+0.019 acc=1 | LR→0.157553 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#050 loss=0.437067 step=0.02538 g_raw=+0.009 g_sm=+0.020 acc=1 | LR→0.157870 PERT→0.140018 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1562958379, PERT_used=0.1400151468 → LR_next=0.1578695587, PERT_next=0.1400177380\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.022 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1562958379→0.1578695587 PERT 0.1400151468→0.1400177380\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.430796 step=0.07647 g_raw=+0.023 g_sm=+0.020 acc=1 | LR→0.158186 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#060 loss=0.418322 step=0.09628 g_raw=+0.035 g_sm=+0.022 acc=1 | LR→0.158504 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#065 loss=0.397382 step=0.005859 g_raw=+0.004 g_sm=+0.024 acc=1 | LR→0.158822 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#070 loss=0.392821 step=0.1063 g_raw=+0.031 g_sm=+0.022 acc=1 | LR→0.159140 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#075 loss=0.390074 step=0.01264 g_raw=+0.004 g_sm=+0.019 acc=1 | LR→0.159460 PERT→0.140021 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1578695587, PERT_used=0.1400177380 → LR_next=0.1594595675, PERT_next=0.1400207177\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.021 acc_ratio=1.00 | LR 0.1578695587→0.1594595675 PERT 0.1400177380→0.1400207177\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.63\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.386233 step=0.06964 g_raw=+0.022 g_sm=+0.018 acc=1 | LR→0.159779 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#085 loss=0.385463 step=0.01574 g_raw=+0.002 g_sm=+0.015 acc=1 | LR→0.160100 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#090 loss=0.371997 step=0.06375 g_raw=+0.021 g_sm=+0.018 acc=1 | LR→0.160421 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#095 loss=0.370829 step=0.01496 g_raw=+0.005 g_sm=+0.015 acc=1 | LR→0.160743 PERT→0.140023 (scale=0.04)\n",
            "[meta] cb#100 loss=0.367589 step=0.04023 g_raw=+0.013 g_sm=+0.015 acc=1 | LR→0.161065 PERT→0.140023 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1594595675, PERT_used=0.1400207177 → LR_next=0.1610648080, PERT_next=0.1400230173\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1594595675→0.1610648080 PERT 0.1400207177→0.1400230173\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.364265 step=0.08724 g_raw=+0.026 g_sm=+0.014 acc=1 | LR→0.161388 PERT→0.140023 (scale=0.04)\n",
            "[meta] cb#110 loss=0.360437 step=0.05448 g_raw=+0.016 g_sm=+0.014 acc=1 | LR→0.161711 PERT→0.140024 (scale=0.04)\n",
            "[meta] cb#115 loss=0.355000 step=0.08314 g_raw=+0.025 g_sm=+0.014 acc=1 | LR→0.162035 PERT→0.140024 (scale=0.04)\n",
            "[meta] cb#120 loss=0.353212 step=0.03673 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.162360 PERT→0.140025 (scale=0.04)\n",
            "[meta] cb#125 loss=0.351793 step=0.02009 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.162686 PERT→0.140025 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1610648080, PERT_used=0.1400230173 → LR_next=0.1626856989, PERT_next=0.1400248787\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1610648080→0.1626856989 PERT 0.1400230173→0.1400248787\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.64\n",
            "[round 2 | client 1] final LR=0.1626856989, final PERT=0.1400248787  (ΔLR=+0.0079468152, ΔPERT=+0.0000113467)\n",
            "[round 2 | client 2] seed LR=0.1547414646 (prev=0.1547414646), seed PERT=0.1400158673 (prev=0.1400158673), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.465887 step=0.02303 g_raw=+0.010 g_sm=+0.003 acc=1 | LR→0.155051 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#010 loss=0.464689 step=0.03387 g_raw=+0.012 g_sm=+0.004 acc=1 | LR→0.155362 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#015 loss=0.462442 step=0.0212 g_raw=+0.005 g_sm=+0.006 acc=1 | LR→0.155673 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#020 loss=0.458547 step=0.0675 g_raw=+0.025 g_sm=+0.008 acc=1 | LR→0.155985 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#025 loss=0.454919 step=0.06679 g_raw=+0.020 g_sm=+0.009 acc=1 | LR→0.156297 PERT→0.140017 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1547414646, PERT_used=0.1400158673 → LR_next=0.1562974291, PERT_next=0.1400165723\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1547414646→0.1562974291 PERT 0.1400158673→0.1400165723\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.76\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.452519 step=0.03475 g_raw=+0.008 g_sm=+0.009 acc=1 | LR→0.156611 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#035 loss=0.449399 step=0.02355 g_raw=+0.009 g_sm=+0.010 acc=1 | LR→0.156924 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#040 loss=0.444970 step=0.07975 g_raw=+0.026 g_sm=+0.012 acc=1 | LR→0.157239 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#045 loss=0.442092 step=0.04252 g_raw=+0.017 g_sm=+0.012 acc=1 | LR→0.157554 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#050 loss=0.439597 step=0.04612 g_raw=+0.015 g_sm=+0.012 acc=1 | LR→0.157870 PERT→0.140018 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1562974291, PERT_used=0.1400165723 → LR_next=0.1578699766, PERT_next=0.1400181086\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1562974291→0.1578699766 PERT 0.1400165723→0.1400181086\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.74\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.438508 step=0.02175 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.158186 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#060 loss=0.436552 step=0.02079 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.158503 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#065 loss=0.431876 step=0.09453 g_raw=+0.035 g_sm=+0.012 acc=1 | LR→0.158821 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#070 loss=0.426590 step=0.00317 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.159140 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#075 loss=0.425267 step=0.03177 g_raw=+0.013 g_sm=+0.012 acc=1 | LR→0.159458 PERT→0.140020 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1578699766, PERT_used=0.1400181086 → LR_next=0.1594584975, PERT_next=0.1400197781\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1578699766→0.1594584975 PERT 0.1400181086→0.1400197781\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.79\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.420518 step=0.03507 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.159778 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#085 loss=0.419338 step=0.004746 g_raw=-0.002 g_sm=+0.011 acc=1 | LR→0.160098 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#090 loss=0.416890 step=0.02636 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.160419 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#095 loss=0.414943 step=0.02508 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.160741 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#100 loss=0.413731 step=0.02092 g_raw=+0.009 g_sm=+0.010 acc=1 | LR→0.161063 PERT→0.140021 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1594584975, PERT_used=0.1400197781 → LR_next=0.1610629197, PERT_next=0.1400213757\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1594584975→0.1610629197 PERT 0.1400197781→0.1400213757\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.80\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.411373 step=0.07303 g_raw=+0.022 g_sm=+0.010 acc=1 | LR→0.161386 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#110 loss=0.410149 step=0.01472 g_raw=+0.007 g_sm=+0.010 acc=1 | LR→0.161709 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#115 loss=0.409497 step=0.01424 g_raw=+0.005 g_sm=+0.009 acc=1 | LR→0.162033 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#120 loss=0.407347 step=0.01985 g_raw=+0.008 g_sm=+0.009 acc=1 | LR→0.162358 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#125 loss=0.406200 step=0.009084 g_raw=+0.006 g_sm=+0.009 acc=1 | LR→0.162683 PERT→0.140023 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1610629197, PERT_used=0.1400213757 → LR_next=0.1626831347, PERT_next=0.1400226716\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1610629197→0.1626831347 PERT 0.1400213757→0.1400226716\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.77\n",
            "[round 2 | client 2] final LR=0.1626831347, final PERT=0.1400226716  (ΔLR=+0.0079416701, ΔPERT=+0.0000068044)\n",
            "[round 2 | client 3] seed LR=0.1547424832 (prev=0.1547424832), seed PERT=0.1400167890 (prev=0.1400167890), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.488359 step=0.03185 g_raw=+0.011 g_sm=+0.004 acc=1 | LR→0.155052 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#010 loss=0.473639 step=0.01823 g_raw=+0.006 g_sm=+0.008 acc=1 | LR→0.155363 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#015 loss=0.465326 step=0.06868 g_raw=+0.025 g_sm=+0.011 acc=1 | LR→0.155674 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#020 loss=0.462017 step=0.03635 g_raw=+0.010 g_sm=+0.012 acc=1 | LR→0.155986 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#025 loss=0.457749 step=0.02649 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.156299 PERT→0.140018 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1547424832, PERT_used=0.1400167890 → LR_next=0.1562989698, PERT_next=0.1400179524\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1547424832→0.1562989698 PERT 0.1400167890→0.1400179524\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.447169 step=0.05984 g_raw=+0.021 g_sm=+0.016 acc=1 | LR→0.156612 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#035 loss=0.437415 step=0.0018 g_raw=-0.002 g_sm=+0.016 acc=1 | LR→0.156926 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#040 loss=0.431940 step=0.02747 g_raw=+0.009 g_sm=+0.016 acc=1 | LR→0.157241 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#045 loss=0.426002 step=0.03643 g_raw=+0.013 g_sm=+0.016 acc=1 | LR→0.157556 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#050 loss=0.422133 step=0.003111 g_raw=-0.000 g_sm=+0.015 acc=1 | LR→0.157872 PERT→0.140020 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1562989698, PERT_used=0.1400179524 → LR_next=0.1578723078, PERT_next=0.1400201762\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1562989698→0.1578723078 PERT 0.1400179524→0.1400201762\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.79\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.420925 step=0.02459 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.158189 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#060 loss=0.417371 step=0.07011 g_raw=+0.023 g_sm=+0.013 acc=1 | LR→0.158506 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#065 loss=0.414027 step=0.03879 g_raw=+0.014 g_sm=+0.013 acc=1 | LR→0.158824 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#070 loss=0.412507 step=0.02333 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.159142 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#075 loss=0.409586 step=0.08262 g_raw=+0.025 g_sm=+0.012 acc=1 | LR→0.159461 PERT→0.140022 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1578723078, PERT_used=0.1400201762 → LR_next=0.1594610430, PERT_next=0.1400220133\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1578723078→0.1594610430 PERT 0.1400201762→0.1400220133\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.77\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.405498 step=0.05619 g_raw=+0.014 g_sm=+0.012 acc=1 | LR→0.159781 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#085 loss=0.400812 step=0.08356 g_raw=+0.027 g_sm=+0.013 acc=1 | LR→0.160101 PERT→0.140023 (scale=0.04)\n",
            "[meta] cb#090 loss=0.397411 step=0.01584 g_raw=+0.004 g_sm=+0.013 acc=1 | LR→0.160422 PERT→0.140023 (scale=0.04)\n",
            "[meta] cb#095 loss=0.395396 step=0.01667 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.160743 PERT→0.140023 (scale=0.04)\n",
            "[meta] cb#100 loss=0.391673 step=0.06349 g_raw=+0.018 g_sm=+0.012 acc=1 | LR→0.161066 PERT→0.140024 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1594610430, PERT_used=0.1400220133 → LR_next=0.1610656429, PERT_next=0.1400237431\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1594610430→0.1610656429 PERT 0.1400220133→0.1400237431\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.74\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.386571 step=0.004825 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.161389 PERT→0.140024 (scale=0.04)\n",
            "[meta] cb#110 loss=0.384327 step=0.05745 g_raw=+0.019 g_sm=+0.012 acc=1 | LR→0.161712 PERT→0.140024 (scale=0.04)\n",
            "[meta] cb#115 loss=0.379896 step=0.05798 g_raw=+0.018 g_sm=+0.013 acc=1 | LR→0.162036 PERT→0.140025 (scale=0.04)\n",
            "[meta] cb#120 loss=0.378010 step=0.03465 g_raw=+0.015 g_sm=+0.012 acc=1 | LR→0.162361 PERT→0.140025 (scale=0.04)\n",
            "[meta] cb#125 loss=0.375918 step=0.05018 g_raw=+0.015 g_sm=+0.012 acc=1 | LR→0.162686 PERT→0.140025 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1610656429, PERT_used=0.1400237431 → LR_next=0.1626863864, PERT_next=0.1400254705\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1610656429→0.1626863864 PERT 0.1400237431→0.1400254705\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.74\n",
            "[round 2 | client 3] final LR=0.1626863864, final PERT=0.1400254705  (ΔLR=+0.0079439032, ΔPERT=+0.0000086815)\n",
            "[round 2 | client 4] seed LR=0.1547418139 (prev=0.1547418139), seed PERT=0.1400161833 (prev=0.1400161833), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.522697 step=0.01901 g_raw=+0.008 g_sm=+0.002 acc=1 | LR→0.155052 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#010 loss=0.517705 step=0.03761 g_raw=+0.014 g_sm=+0.005 acc=1 | LR→0.155362 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#015 loss=0.516099 step=0.01227 g_raw=+0.002 g_sm=+0.006 acc=1 | LR→0.155673 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#020 loss=0.513350 step=0.03511 g_raw=+0.011 g_sm=+0.008 acc=1 | LR→0.155985 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#025 loss=0.511430 step=0.04186 g_raw=+0.014 g_sm=+0.008 acc=1 | LR→0.156298 PERT→0.140017 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1547418139, PERT_used=0.1400161833 → LR_next=0.1562978090, PERT_next=0.1400169126\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1547418139→0.1562978090 PERT 0.1400161833→0.1400169126\n",
            "Training Accuracy: 0.36\n",
            "Test Accuracy: 0.33\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.503754 step=0.1296 g_raw=+0.046 g_sm=+0.010 acc=1 | LR→0.156611 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#035 loss=0.503261 step=0.01091 g_raw=+0.008 g_sm=+0.009 acc=1 | LR→0.156925 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#040 loss=0.500869 step=0.03637 g_raw=+0.013 g_sm=+0.010 acc=1 | LR→0.157239 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#045 loss=0.500200 step=0.01279 g_raw=+0.006 g_sm=+0.009 acc=1 | LR→0.157554 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#050 loss=0.497258 step=0.02374 g_raw=+0.008 g_sm=+0.010 acc=1 | LR→0.157870 PERT→0.140018 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1562978090, PERT_used=0.1400169126 → LR_next=0.1578701072, PERT_next=0.1400182244\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1562978090→0.1578701072 PERT 0.1400169126→0.1400182244\n",
            "Training Accuracy: 0.54\n",
            "Test Accuracy: 0.46\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.495850 step=0.03435 g_raw=+0.011 g_sm=+0.010 acc=1 | LR→0.158186 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#060 loss=0.492221 step=0.00775 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.158503 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#065 loss=0.487646 step=0.02126 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.158821 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#070 loss=0.483838 step=0.01794 g_raw=+0.010 g_sm=+0.012 acc=1 | LR→0.159140 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#075 loss=0.482033 step=0.01491 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.159459 PERT→0.140020 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1578701072, PERT_used=0.1400182244 → LR_next=0.1594585013, PERT_next=0.1400197814\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1578701072→0.1594585013 PERT 0.1400182244→0.1400197814\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.479585 step=0.01808 g_raw=+0.005 g_sm=+0.012 acc=1 | LR→0.159778 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#085 loss=0.477381 step=0.03406 g_raw=+0.014 g_sm=+0.011 acc=1 | LR→0.160098 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#090 loss=0.475101 step=0.0222 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.160419 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#095 loss=0.473896 step=0.003374 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.160741 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#100 loss=0.472389 step=0.04654 g_raw=+0.016 g_sm=+0.011 acc=1 | LR→0.161063 PERT→0.140021 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1594585013, PERT_used=0.1400197814 → LR_next=0.1610629041, PERT_next=0.1400213621\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1594585013→0.1610629041 PERT 0.1400197814→0.1400213621\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.74\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.470538 step=0.000194 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.161386 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#110 loss=0.468749 step=0.06524 g_raw=+0.023 g_sm=+0.010 acc=1 | LR→0.161709 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#115 loss=0.466646 step=0.01125 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.162033 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#120 loss=0.464581 step=0.03577 g_raw=+0.010 g_sm=+0.010 acc=1 | LR→0.162358 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#125 loss=0.462736 step=0.044 g_raw=+0.013 g_sm=+0.010 acc=1 | LR→0.162683 PERT→0.140023 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1610629041, PERT_used=0.1400213621 → LR_next=0.1626832259, PERT_next=0.1400227502\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1610629041→0.1626832259 PERT 0.1400213621→0.1400227502\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.76\n",
            "[round 2 | client 4] final LR=0.1626832259, final PERT=0.1400227502  (ΔLR=+0.0079414120, ΔPERT=+0.0000065669)\n",
            "\n",
            "[Round 2] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           0      0.498200      0.920000      0.162682      0.140021\n",
            "           2      0.532537      0.765000      0.162683      0.140023\n",
            "           3      0.558085      0.740000      0.162686      0.140025\n",
            "           1      0.558614      0.640000      0.162686      0.140025\n",
            "           4      0.633103      0.755000      0.162683      0.140023\n",
            "→ [Round 2] best_client=0, best_val=0.498200, prev_global_val=0.613417, improve=+0.115217, action=adopt+mix τ=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:   6%|▌         | 3/50 [45:10<11:49:09, 905.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   2] acc_g=0.871 (μ=0.764, σ=0.090, FG=0.178) | t=891.703s, val=0.559 | TEL=FALSE\n",
            "[Round 3] Teleportation OFF | Aggregation=best\n",
            "[round 3 | client 0] seed LR=0.1626816061 (prev=0.1626816061), seed PERT=0.1400213560 (prev=0.1400213560), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.485124 step=0.01861 g_raw=+0.012 g_sm=+0.005 acc=1 | LR→0.163007 PERT→0.140021 (scale=0.04)\n",
            "[meta] cb#010 loss=0.475321 step=0.05899 g_raw=+0.016 g_sm=+0.009 acc=1 | LR→0.163334 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#015 loss=0.468018 step=0.1044 g_raw=+0.031 g_sm=+0.011 acc=1 | LR→0.163661 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#020 loss=0.462223 step=0.08114 g_raw=+0.024 g_sm=+0.013 acc=1 | LR→0.163989 PERT→0.140022 (scale=0.04)\n",
            "[meta] cb#025 loss=0.456299 step=0.05596 g_raw=+0.016 g_sm=+0.015 acc=1 | LR→0.164318 PERT→0.140023 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1626816061, PERT_used=0.1400213560 → LR_next=0.1643181040, PERT_next=0.1400226518\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1626816061→0.1643181040 PERT 0.1400213560→0.1400226518\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.448459 step=0.02722 g_raw=+0.008 g_sm=+0.016 acc=1 | LR→0.164648 PERT→0.140023 (scale=0.04)\n",
            "[meta] cb#035 loss=0.445815 step=0.01986 g_raw=+0.006 g_sm=+0.015 acc=1 | LR→0.164978 PERT→0.140024 (scale=0.04)\n",
            "[meta] cb#040 loss=0.430201 step=0.1254 g_raw=+0.044 g_sm=+0.017 acc=1 | LR→0.165309 PERT→0.140024 (scale=0.04)\n",
            "[meta] cb#045 loss=0.427550 step=0.009715 g_raw=+0.004 g_sm=+0.016 acc=1 | LR→0.165640 PERT→0.140024 (scale=0.04)\n",
            "[meta] cb#050 loss=0.421436 step=0.05042 g_raw=+0.015 g_sm=+0.017 acc=1 | LR→0.165972 PERT→0.140025 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1643181040, PERT_used=0.1400226518 → LR_next=0.1659721788, PERT_next=0.1400248878\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1643181040→0.1659721788 PERT 0.1400226518→0.1400248878\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.414599 step=0.06913 g_raw=+0.019 g_sm=+0.017 acc=1 | LR→0.166305 PERT→0.140025 (scale=0.04)\n",
            "[meta] cb#060 loss=0.413083 step=0.02075 g_raw=+0.007 g_sm=+0.015 acc=1 | LR→0.166639 PERT→0.140026 (scale=0.04)\n",
            "[meta] cb#065 loss=0.410900 step=0.02877 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.166973 PERT→0.140026 (scale=0.04)\n",
            "[meta] cb#070 loss=0.407538 step=0.03758 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.167307 PERT→0.140027 (scale=0.04)\n",
            "[meta] cb#075 loss=0.405409 step=0.001543 g_raw=+0.000 g_sm=+0.012 acc=1 | LR→0.167643 PERT→0.140027 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1659721788, PERT_used=0.1400248878 → LR_next=0.1676427582, PERT_next=0.1400270021\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1659721788→0.1676427582 PERT 0.1400248878→0.1400270021\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.403391 step=0.0002128 g_raw=+0.003 g_sm=+0.012 acc=1 | LR→0.167979 PERT→0.140027 (scale=0.04)\n",
            "[meta] cb#085 loss=0.402169 step=0.004297 g_raw=-0.000 g_sm=+0.011 acc=1 | LR→0.168315 PERT→0.140028 (scale=0.04)\n",
            "[meta] cb#090 loss=0.393565 step=0.05353 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.168653 PERT→0.140028 (scale=0.04)\n",
            "[meta] cb#095 loss=0.388581 step=0.0268 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.168991 PERT→0.140028 (scale=0.04)\n",
            "[meta] cb#100 loss=0.380171 step=0.1019 g_raw=+0.031 g_sm=+0.015 acc=1 | LR→0.169330 PERT→0.140029 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1676427582, PERT_used=0.1400270021 → LR_next=0.1693297199, PERT_next=0.1400287585\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1676427582→0.1693297199 PERT 0.1400270021→0.1400287585\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.377704 step=0.01424 g_raw=+0.006 g_sm=+0.014 acc=1 | LR→0.169669 PERT→0.140029 (scale=0.04)\n",
            "[meta] cb#110 loss=0.375920 step=0.0232 g_raw=+0.012 g_sm=+0.013 acc=1 | LR→0.170009 PERT→0.140030 (scale=0.04)\n",
            "[meta] cb#115 loss=0.372104 step=0.02751 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.170350 PERT→0.140030 (scale=0.04)\n",
            "[meta] cb#120 loss=0.369473 step=0.04029 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.170692 PERT→0.140030 (scale=0.04)\n",
            "[meta] cb#125 loss=0.367042 step=0.03345 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.171034 PERT→0.140031 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1693297199, PERT_used=0.1400287585 → LR_next=0.1710337723, PERT_next=0.1400306092\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1693297199→0.1710337723 PERT 0.1400287585→0.1400306092\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.65\n",
            "[round 3 | client 0] final LR=0.1710337723, final PERT=0.1400306092  (ΔLR=+0.0083521662, ΔPERT=+0.0000092532)\n",
            "[round 3 | client 1] seed LR=0.1626856989 (prev=0.1626856989), seed PERT=0.1400248787 (prev=0.1400248787), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.488579 step=0.09696 g_raw=+0.036 g_sm=+0.003 acc=1 | LR→0.163011 PERT→0.140025 (scale=0.04)\n",
            "[meta] cb#010 loss=0.487053 step=0.03189 g_raw=+0.015 g_sm=+0.005 acc=1 | LR→0.163338 PERT→0.140025 (scale=0.04)\n",
            "[meta] cb#015 loss=0.485708 step=0.03767 g_raw=+0.011 g_sm=+0.006 acc=1 | LR→0.163665 PERT→0.140025 (scale=0.04)\n",
            "[meta] cb#020 loss=0.483037 step=0.02189 g_raw=+0.009 g_sm=+0.007 acc=1 | LR→0.163993 PERT→0.140025 (scale=0.04)\n",
            "[meta] cb#025 loss=0.475816 step=0.01139 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.164322 PERT→0.140026 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1626856989, PERT_used=0.1400248787 → LR_next=0.1643216155, PERT_next=0.1400256440\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1626856989→0.1643216155 PERT 0.1400248787→0.1400256440\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.474526 step=0.007346 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.164651 PERT→0.140026 (scale=0.04)\n",
            "[meta] cb#035 loss=0.468443 step=0.01492 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.164981 PERT→0.140026 (scale=0.04)\n",
            "[meta] cb#040 loss=0.465229 step=0.001098 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.165312 PERT→0.140027 (scale=0.04)\n",
            "[meta] cb#045 loss=0.463679 step=0.04076 g_raw=+0.012 g_sm=+0.010 acc=1 | LR→0.165643 PERT→0.140027 (scale=0.04)\n",
            "[meta] cb#050 loss=0.462228 step=0.0195 g_raw=+0.006 g_sm=+0.010 acc=1 | LR→0.165975 PERT→0.140027 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1643216155, PERT_used=0.1400256440 → LR_next=0.1659748027, PERT_next=0.1400271015\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1643216155→0.1659748027 PERT 0.1400256440→0.1400271015\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.460531 step=0.03782 g_raw=+0.013 g_sm=+0.010 acc=1 | LR→0.166307 PERT→0.140027 (scale=0.04)\n",
            "[meta] cb#060 loss=0.458725 step=0.01399 g_raw=+0.005 g_sm=+0.009 acc=1 | LR→0.166641 PERT→0.140028 (scale=0.04)\n",
            "[meta] cb#065 loss=0.457863 step=0.003981 g_raw=+0.003 g_sm=+0.009 acc=1 | LR→0.166975 PERT→0.140028 (scale=0.04)\n",
            "[meta] cb#070 loss=0.456502 step=0.02271 g_raw=+0.011 g_sm=+0.009 acc=1 | LR→0.167309 PERT→0.140028 (scale=0.04)\n",
            "[meta] cb#075 loss=0.455171 step=0.01968 g_raw=+0.007 g_sm=+0.008 acc=1 | LR→0.167644 PERT→0.140028 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1659748027, PERT_used=0.1400271015 → LR_next=0.1676444034, PERT_next=0.1400283763\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1659748027→0.1676444034 PERT 0.1400271015→0.1400283763\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.57\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.452393 step=0.07114 g_raw=+0.019 g_sm=+0.009 acc=1 | LR→0.167980 PERT→0.140029 (scale=0.04)\n",
            "[meta] cb#085 loss=0.451340 step=0.04608 g_raw=+0.015 g_sm=+0.009 acc=1 | LR→0.168317 PERT→0.140029 (scale=0.04)\n",
            "[meta] cb#090 loss=0.449933 step=0.01872 g_raw=+0.008 g_sm=+0.009 acc=1 | LR→0.168654 PERT→0.140029 (scale=0.04)\n",
            "[meta] cb#095 loss=0.449039 step=0.03229 g_raw=+0.007 g_sm=+0.008 acc=1 | LR→0.168992 PERT→0.140029 (scale=0.04)\n",
            "[meta] cb#100 loss=0.445112 step=0.0448 g_raw=+0.020 g_sm=+0.010 acc=1 | LR→0.169331 PERT→0.140030 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1676444034, PERT_used=0.1400283763 → LR_next=0.1693307577, PERT_next=0.1400296168\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1676444034→0.1693307577 PERT 0.1400283763→0.1400296168\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.48\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.442907 step=0.02531 g_raw=+0.010 g_sm=+0.010 acc=1 | LR→0.169670 PERT→0.140030 (scale=0.04)\n",
            "[meta] cb#110 loss=0.442280 step=0.002363 g_raw=+0.001 g_sm=+0.009 acc=1 | LR→0.170010 PERT→0.140030 (scale=0.04)\n",
            "[meta] cb#115 loss=0.440878 step=0.02431 g_raw=+0.006 g_sm=+0.008 acc=1 | LR→0.170351 PERT→0.140030 (scale=0.04)\n",
            "[meta] cb#120 loss=0.436730 step=0.02346 g_raw=+0.003 g_sm=+0.009 acc=1 | LR→0.170692 PERT→0.140031 (scale=0.04)\n",
            "[meta] cb#125 loss=0.436211 step=0.03522 g_raw=+0.012 g_sm=+0.008 acc=1 | LR→0.171034 PERT→0.140031 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1693307577, PERT_used=0.1400296168 → LR_next=0.1710340947, PERT_next=0.1400308731\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1693307577→0.1710340947 PERT 0.1400296168→0.1400308731\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.48\n",
            "[round 3 | client 1] final LR=0.1710340947, final PERT=0.1400308731  (ΔLR=+0.0083483958, ΔPERT=+0.0000059945)\n",
            "[round 3 | client 2] seed LR=0.1626831347 (prev=0.1626831347), seed PERT=0.1400226716 (prev=0.1400226716), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.466094 step=0.02922 g_raw=+0.009 g_sm=+0.002 acc=1 | LR→0.163009 PERT→0.140023 (scale=0.04)\n",
            "[meta] cb#010 loss=0.460476 step=0.1105 g_raw=+0.036 g_sm=+0.005 acc=1 | LR→0.163335 PERT→0.140023 (scale=0.04)\n",
            "[meta] cb#015 loss=0.452842 step=0.05866 g_raw=+0.018 g_sm=+0.008 acc=1 | LR→0.163663 PERT→0.140023 (scale=0.04)\n",
            "[meta] cb#020 loss=0.450614 step=0.04672 g_raw=+0.017 g_sm=+0.009 acc=1 | LR→0.163991 PERT→0.140023 (scale=0.04)\n",
            "[meta] cb#025 loss=0.443937 step=0.02823 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.164319 PERT→0.140024 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1626831347, PERT_used=0.1400226716 → LR_next=0.1643191386, PERT_next=0.1400235334\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1626831347→0.1643191386 PERT 0.1400226716→0.1400235334\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.435705 step=0.05909 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.164649 PERT→0.140024 (scale=0.04)\n",
            "[meta] cb#035 loss=0.432853 step=0.006171 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.164979 PERT→0.140024 (scale=0.04)\n",
            "[meta] cb#040 loss=0.431264 step=0.01075 g_raw=+0.003 g_sm=+0.012 acc=1 | LR→0.165309 PERT→0.140025 (scale=0.04)\n",
            "[meta] cb#045 loss=0.428796 step=0.01207 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.165641 PERT→0.140025 (scale=0.04)\n",
            "[meta] cb#050 loss=0.426926 step=0.0345 g_raw=+0.010 g_sm=+0.011 acc=1 | LR→0.165973 PERT→0.140025 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1643191386, PERT_used=0.1400235334 → LR_next=0.1659725422, PERT_next=0.1400251943\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1643191386→0.1659725422 PERT 0.1400235334→0.1400251943\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.423963 step=0.0312 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.166305 PERT→0.140025 (scale=0.04)\n",
            "[meta] cb#060 loss=0.420736 step=0.01469 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.166639 PERT→0.140026 (scale=0.04)\n",
            "[meta] cb#065 loss=0.416661 step=0.05339 g_raw=+0.016 g_sm=+0.012 acc=1 | LR→0.166973 PERT→0.140026 (scale=0.04)\n",
            "[meta] cb#070 loss=0.413864 step=0.001208 g_raw=-0.002 g_sm=+0.011 acc=1 | LR→0.167307 PERT→0.140026 (scale=0.04)\n",
            "[meta] cb#075 loss=0.410432 step=0.01699 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.167643 PERT→0.140027 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1659725422, PERT_used=0.1400251943 → LR_next=0.1676425024, PERT_next=0.1400267884\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1659725422→0.1676425024 PERT 0.1400251943→0.1400267884\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.73\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.407556 step=0.02113 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.167978 PERT→0.140027 (scale=0.04)\n",
            "[meta] cb#085 loss=0.405117 step=0.03635 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.168315 PERT→0.140027 (scale=0.04)\n",
            "[meta] cb#090 loss=0.403256 step=0.03908 g_raw=+0.014 g_sm=+0.011 acc=1 | LR→0.168652 PERT→0.140028 (scale=0.04)\n",
            "[meta] cb#095 loss=0.402840 step=0.003077 g_raw=+0.000 g_sm=+0.009 acc=1 | LR→0.168990 PERT→0.140028 (scale=0.04)\n",
            "[meta] cb#100 loss=0.401208 step=0.02075 g_raw=+0.006 g_sm=+0.009 acc=1 | LR→0.169329 PERT→0.140028 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1676425024, PERT_used=0.1400267884 → LR_next=0.1693290948, PERT_next=0.1400282416\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1676425024→0.1693290948 PERT 0.1400267884→0.1400282416\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.75\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.401048 step=0.017 g_raw=+0.006 g_sm=+0.008 acc=1 | LR→0.169668 PERT→0.140028 (scale=0.04)\n",
            "[meta] cb#110 loss=0.400605 step=0.01449 g_raw=+0.005 g_sm=+0.007 acc=1 | LR→0.170008 PERT→0.140029 (scale=0.04)\n",
            "[meta] cb#115 loss=0.398623 step=0.01368 g_raw=+0.004 g_sm=+0.008 acc=1 | LR→0.170349 PERT→0.140029 (scale=0.04)\n",
            "[meta] cb#120 loss=0.397934 step=0.003548 g_raw=+0.003 g_sm=+0.007 acc=1 | LR→0.170690 PERT→0.140029 (scale=0.04)\n",
            "[meta] cb#125 loss=0.397404 step=0.008605 g_raw=+0.004 g_sm=+0.007 acc=1 | LR→0.171032 PERT→0.140029 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1693290948, PERT_used=0.1400282416 → LR_next=0.1710321522, PERT_next=0.1400292828\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.006 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1693290948→0.1710321522 PERT 0.1400282416→0.1400292828\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.74\n",
            "[round 3 | client 2] final LR=0.1710321522, final PERT=0.1400292828  (ΔLR=+0.0083490175, ΔPERT=+0.0000066111)\n",
            "[round 3 | client 3] seed LR=0.1626863864 (prev=0.1626863864), seed PERT=0.1400254705 (prev=0.1400254705), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.521039 step=0.023 g_raw=+0.008 g_sm=+0.004 acc=1 | LR→0.163012 PERT→0.140026 (scale=0.04)\n",
            "[meta] cb#010 loss=0.515890 step=0.05071 g_raw=+0.017 g_sm=+0.007 acc=1 | LR→0.163339 PERT→0.140026 (scale=0.04)\n",
            "[meta] cb#015 loss=0.510773 step=0.1086 g_raw=+0.037 g_sm=+0.008 acc=1 | LR→0.163666 PERT→0.140026 (scale=0.04)\n",
            "[meta] cb#020 loss=0.509402 step=0.03192 g_raw=+0.011 g_sm=+0.009 acc=1 | LR→0.163994 PERT→0.140026 (scale=0.04)\n",
            "[meta] cb#025 loss=0.503577 step=0.102 g_raw=+0.033 g_sm=+0.011 acc=1 | LR→0.164322 PERT→0.140026 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1626863864, PERT_used=0.1400254705 → LR_next=0.1643224778, PERT_next=0.1400263789\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1626863864→0.1643224778 PERT 0.1400254705→0.1400263789\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.45\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.495234 step=0.08238 g_raw=+0.031 g_sm=+0.013 acc=1 | LR→0.164652 PERT→0.140027 (scale=0.04)\n",
            "[meta] cb#035 loss=0.481475 step=0.1552 g_raw=+0.051 g_sm=+0.016 acc=1 | LR→0.164982 PERT→0.140027 (scale=0.04)\n",
            "[meta] cb#040 loss=0.474383 step=0.0794 g_raw=+0.027 g_sm=+0.017 acc=1 | LR→0.165313 PERT→0.140028 (scale=0.04)\n",
            "[meta] cb#045 loss=0.466110 step=0.0372 g_raw=+0.014 g_sm=+0.018 acc=1 | LR→0.165644 PERT→0.140028 (scale=0.04)\n",
            "[meta] cb#050 loss=0.462608 step=0.08915 g_raw=+0.031 g_sm=+0.017 acc=1 | LR→0.165977 PERT→0.140029 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1643224778, PERT_used=0.1400263789 → LR_next=0.1659765544, PERT_next=0.1400285793\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1643224778→0.1659765544 PERT 0.1400263789→0.1400285793\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.459952 step=0.0337 g_raw=+0.009 g_sm=+0.016 acc=1 | LR→0.166309 PERT→0.140029 (scale=0.04)\n",
            "[meta] cb#060 loss=0.458521 step=0.02557 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.166643 PERT→0.140029 (scale=0.04)\n",
            "[meta] cb#065 loss=0.447589 step=0.02675 g_raw=+0.008 g_sm=+0.015 acc=1 | LR→0.166977 PERT→0.140030 (scale=0.04)\n",
            "[meta] cb#070 loss=0.446624 step=0.04463 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.167312 PERT→0.140030 (scale=0.04)\n",
            "[meta] cb#075 loss=0.444376 step=0.03804 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.167647 PERT→0.140031 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1659765544, PERT_used=0.1400285793 → LR_next=0.1676470971, PERT_next=0.1400306263\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1659765544→0.1676470971 PERT 0.1400285793→0.1400306263\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.440229 step=0.01061 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.167983 PERT→0.140031 (scale=0.04)\n",
            "[meta] cb#085 loss=0.434874 step=0.01135 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.168320 PERT→0.140031 (scale=0.04)\n",
            "[meta] cb#090 loss=0.433040 step=0.05435 g_raw=+0.016 g_sm=+0.012 acc=1 | LR→0.168657 PERT→0.140032 (scale=0.04)\n",
            "[meta] cb#095 loss=0.431054 step=0.02727 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.168995 PERT→0.140032 (scale=0.04)\n",
            "[meta] cb#100 loss=0.427141 step=0.06903 g_raw=+0.024 g_sm=+0.012 acc=1 | LR→0.169334 PERT→0.140032 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1676470971, PERT_used=0.1400306263 → LR_next=0.1693340052, PERT_next=0.1400323023\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1676470971→0.1693340052 PERT 0.1400306263→0.1400323023\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.424076 step=0.0004736 g_raw=+0.000 g_sm=+0.012 acc=1 | LR→0.169673 PERT→0.140033 (scale=0.04)\n",
            "[meta] cb#110 loss=0.423321 step=0.03276 g_raw=+0.009 g_sm=+0.010 acc=1 | LR→0.170013 PERT→0.140033 (scale=0.04)\n",
            "[meta] cb#115 loss=0.422538 step=0.01045 g_raw=+0.005 g_sm=+0.009 acc=1 | LR→0.170354 PERT→0.140033 (scale=0.04)\n",
            "[meta] cb#120 loss=0.421171 step=0.0458 g_raw=+0.015 g_sm=+0.009 acc=1 | LR→0.170696 PERT→0.140033 (scale=0.04)\n",
            "[meta] cb#125 loss=0.419745 step=0.01438 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.171038 PERT→0.140034 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1693340052, PERT_used=0.1400323023 → LR_next=0.1710375800, PERT_next=0.1400337267\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1693340052→0.1710375800 PERT 0.1400323023→0.1400337267\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.49\n",
            "[round 3 | client 3] final LR=0.1710375800, final PERT=0.1400337267  (ΔLR=+0.0083511935, ΔPERT=+0.0000082562)\n",
            "[round 3 | client 4] seed LR=0.1626832259 (prev=0.1626832259), seed PERT=0.1400227502 (prev=0.1400227502), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.508345 step=0.01287 g_raw=+0.003 g_sm=+0.004 acc=1 | LR→0.163009 PERT→0.140023 (scale=0.04)\n",
            "[meta] cb#010 loss=0.502810 step=0.03879 g_raw=+0.021 g_sm=+0.007 acc=1 | LR→0.163336 PERT→0.140023 (scale=0.04)\n",
            "[meta] cb#015 loss=0.500581 step=0.009938 g_raw=+0.001 g_sm=+0.008 acc=1 | LR→0.163663 PERT→0.140023 (scale=0.04)\n",
            "[meta] cb#020 loss=0.489943 step=0.01289 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.163991 PERT→0.140023 (scale=0.04)\n",
            "[meta] cb#025 loss=0.483829 step=0.08045 g_raw=+0.026 g_sm=+0.012 acc=1 | LR→0.164319 PERT→0.140024 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1626832259, PERT_used=0.1400227502 → LR_next=0.1643194093, PERT_next=0.1400237640\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1626832259→0.1643194093 PERT 0.1400227502→0.1400237640\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.475592 step=0.09785 g_raw=+0.034 g_sm=+0.014 acc=1 | LR→0.164649 PERT→0.140024 (scale=0.04)\n",
            "[meta] cb#035 loss=0.471798 step=0.05544 g_raw=+0.016 g_sm=+0.014 acc=1 | LR→0.164979 PERT→0.140024 (scale=0.04)\n",
            "[meta] cb#040 loss=0.462855 step=0.02362 g_raw=+0.009 g_sm=+0.016 acc=1 | LR→0.165310 PERT→0.140025 (scale=0.04)\n",
            "[meta] cb#045 loss=0.453730 step=0.0769 g_raw=+0.025 g_sm=+0.017 acc=1 | LR→0.165641 PERT→0.140025 (scale=0.04)\n",
            "[meta] cb#050 loss=0.450884 step=0.04423 g_raw=+0.015 g_sm=+0.016 acc=1 | LR→0.165973 PERT→0.140026 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1643194093, PERT_used=0.1400237640 → LR_next=0.1659732982, PERT_next=0.1400258322\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1643194093→0.1659732982 PERT 0.1400237640→0.1400258322\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.447646 step=0.0776 g_raw=+0.023 g_sm=+0.015 acc=1 | LR→0.166306 PERT→0.140026 (scale=0.04)\n",
            "[meta] cb#060 loss=0.419665 step=0.1581 g_raw=+0.056 g_sm=+0.021 acc=1 | LR→0.166640 PERT→0.140027 (scale=0.04)\n",
            "[meta] cb#065 loss=0.417977 step=0.0205 g_raw=+0.004 g_sm=+0.018 acc=1 | LR→0.166974 PERT→0.140027 (scale=0.04)\n",
            "[meta] cb#070 loss=0.414016 step=0.02765 g_raw=+0.008 g_sm=+0.017 acc=1 | LR→0.167309 PERT→0.140028 (scale=0.04)\n",
            "[meta] cb#075 loss=0.407385 step=0.02455 g_raw=+0.010 g_sm=+0.017 acc=1 | LR→0.167644 PERT→0.140028 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1659732982, PERT_used=0.1400258322 → LR_next=0.1676443523, PERT_next=0.1400283336\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1659732982→0.1676443523 PERT 0.1400258322→0.1400283336\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.62\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.398369 step=0.008858 g_raw=+0.006 g_sm=+0.017 acc=1 | LR→0.167981 PERT→0.140029 (scale=0.04)\n",
            "[meta] cb#085 loss=0.394150 step=0.02691 g_raw=+0.012 g_sm=+0.016 acc=1 | LR→0.168317 PERT→0.140029 (scale=0.04)\n",
            "[meta] cb#090 loss=0.387889 step=0.0657 g_raw=+0.024 g_sm=+0.017 acc=1 | LR→0.168655 PERT→0.140030 (scale=0.04)\n",
            "[meta] cb#095 loss=0.386815 step=0.02479 g_raw=+0.010 g_sm=+0.014 acc=1 | LR→0.168993 PERT→0.140030 (scale=0.04)\n",
            "[meta] cb#100 loss=0.383467 step=0.006114 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.169332 PERT→0.140031 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1676443523, PERT_used=0.1400283336 → LR_next=0.1693319096, PERT_next=0.1400305693\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1676443523→0.1693319096 PERT 0.1400283336→0.1400305693\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.378665 step=0.02915 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.169671 PERT→0.140031 (scale=0.04)\n",
            "[meta] cb#110 loss=0.376544 step=0.0299 g_raw=+0.014 g_sm=+0.013 acc=1 | LR→0.170012 PERT→0.140031 (scale=0.04)\n",
            "[meta] cb#115 loss=0.375120 step=0.05271 g_raw=+0.019 g_sm=+0.012 acc=1 | LR→0.170352 PERT→0.140032 (scale=0.04)\n",
            "[meta] cb#120 loss=0.371811 step=0.08275 g_raw=+0.027 g_sm=+0.012 acc=1 | LR→0.170694 PERT→0.140032 (scale=0.04)\n",
            "[meta] cb#125 loss=0.371057 step=0.000671 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.171036 PERT→0.140032 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1693319096, PERT_used=0.1400305693 → LR_next=0.1710358564, PERT_next=0.1400323156\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1693319096→0.1710358564 PERT 0.1400305693→0.1400323156\n",
            "Training Accuracy: 0.92\n",
            "Test Accuracy: 0.79\n",
            "[round 3 | client 4] final LR=0.1710358564, final PERT=0.1400323156  (ΔLR=+0.0083526305, ΔPERT=+0.0000095654)\n",
            "\n",
            "[Round 3] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           2      0.521546      0.740000      0.171032      0.140029\n",
            "           4      0.559145      0.785000      0.171036      0.140032\n",
            "           0      0.595142      0.650000      0.171034      0.140031\n",
            "           3      0.695552      0.490000      0.171038      0.140034\n",
            "           1      0.731721      0.485000      0.171034      0.140031\n",
            "→ [Round 3] best_client=2, best_val=0.521546, prev_global_val=0.558575, improve=+0.037028, action=adopt+mix τ=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:   8%|▊         | 4/50 [1:00:14<11:33:38, 904.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   3] acc_g=0.769 (μ=0.630, σ=0.124, FG=0.280) | t=886.444s, val=0.556 | TEL=FALSE\n",
            "[Round 4] Teleportation OFF | Aggregation=best\n",
            "[round 4 | client 0] seed LR=0.1710337723 (prev=0.1710337723), seed PERT=0.1400306092 (prev=0.1400306092), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.522115 step=0.07528 g_raw=+0.022 g_sm=+0.003 acc=1 | LR→0.171376 PERT→0.140031 (scale=0.04)\n",
            "[meta] cb#010 loss=0.502218 step=0.1024 g_raw=+0.038 g_sm=+0.011 acc=1 | LR→0.171720 PERT→0.140031 (scale=0.04)\n",
            "[meta] cb#015 loss=0.490897 step=0.02022 g_raw=+0.006 g_sm=+0.014 acc=1 | LR→0.172064 PERT→0.140031 (scale=0.04)\n",
            "[meta] cb#020 loss=0.485260 step=0.1006 g_raw=+0.032 g_sm=+0.015 acc=1 | LR→0.172409 PERT→0.140032 (scale=0.04)\n",
            "[meta] cb#025 loss=0.471743 step=0.0574 g_raw=+0.016 g_sm=+0.017 acc=1 | LR→0.172755 PERT→0.140032 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1710337723, PERT_used=0.1400306092 → LR_next=0.1727545123, PERT_next=0.1400320861\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.024 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1710337723→0.1727545123 PERT 0.1400306092→0.1400320861\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.461848 step=0.05995 g_raw=+0.017 g_sm=+0.018 acc=1 | LR→0.173101 PERT→0.140033 (scale=0.04)\n",
            "[meta] cb#035 loss=0.454940 step=0.02392 g_raw=+0.008 g_sm=+0.018 acc=1 | LR→0.173448 PERT→0.140033 (scale=0.04)\n",
            "[meta] cb#040 loss=0.445841 step=0.0326 g_raw=+0.011 g_sm=+0.018 acc=1 | LR→0.173796 PERT→0.140034 (scale=0.04)\n",
            "[meta] cb#045 loss=0.442994 step=0.06783 g_raw=+0.019 g_sm=+0.017 acc=1 | LR→0.174145 PERT→0.140034 (scale=0.04)\n",
            "[meta] cb#050 loss=0.439690 step=1.386e-05 g_raw=-0.001 g_sm=+0.016 acc=1 | LR→0.174494 PERT→0.140035 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1727545123, PERT_used=0.1400320861 → LR_next=0.1744938187, PERT_next=0.1400345696\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1727545123→0.1744938187 PERT 0.1400320861→0.1400345696\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.57\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.429232 step=0.05808 g_raw=+0.015 g_sm=+0.017 acc=1 | LR→0.174844 PERT→0.140035 (scale=0.04)\n",
            "[meta] cb#060 loss=0.425359 step=0.003693 g_raw=-0.000 g_sm=+0.016 acc=1 | LR→0.175194 PERT→0.140036 (scale=0.04)\n",
            "[meta] cb#065 loss=0.420423 step=0.1047 g_raw=+0.027 g_sm=+0.015 acc=1 | LR→0.175546 PERT→0.140036 (scale=0.04)\n",
            "[meta] cb#070 loss=0.414910 step=0.008469 g_raw=+0.000 g_sm=+0.015 acc=1 | LR→0.175898 PERT→0.140036 (scale=0.04)\n",
            "[meta] cb#075 loss=0.409783 step=0.04285 g_raw=+0.012 g_sm=+0.016 acc=1 | LR→0.176250 PERT→0.140037 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1744938187, PERT_used=0.1400345696 → LR_next=0.1762503193, PERT_next=0.1400368011\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1744938187→0.1762503193 PERT 0.1400345696→0.1400368011\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.402764 step=0.02906 g_raw=+0.010 g_sm=+0.016 acc=1 | LR→0.176604 PERT→0.140037 (scale=0.04)\n",
            "[meta] cb#085 loss=0.399807 step=0.02973 g_raw=+0.011 g_sm=+0.015 acc=1 | LR→0.176958 PERT→0.140038 (scale=0.04)\n",
            "[meta] cb#090 loss=0.396398 step=0.02432 g_raw=+0.009 g_sm=+0.015 acc=1 | LR→0.177313 PERT→0.140038 (scale=0.04)\n",
            "[meta] cb#095 loss=0.394660 step=0.04197 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.177668 PERT→0.140038 (scale=0.04)\n",
            "[meta] cb#100 loss=0.390727 step=0.0437 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.178024 PERT→0.140039 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1762503193, PERT_used=0.1400368011 → LR_next=0.1780242623, PERT_next=0.1400388447\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1762503193→0.1780242623 PERT 0.1400368011→0.1400388447\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.58\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.387450 step=0.01139 g_raw=+0.006 g_sm=+0.013 acc=1 | LR→0.178381 PERT→0.140039 (scale=0.04)\n",
            "[meta] cb#110 loss=0.385893 step=0.02087 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.178739 PERT→0.140040 (scale=0.04)\n",
            "[meta] cb#115 loss=0.383570 step=0.05122 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.179097 PERT→0.140040 (scale=0.04)\n",
            "[meta] cb#120 loss=0.380653 step=0.001785 g_raw=-0.001 g_sm=+0.011 acc=1 | LR→0.179456 PERT→0.140040 (scale=0.04)\n",
            "[meta] cb#125 loss=0.378011 step=0.02929 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.179816 PERT→0.140041 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1780242623, PERT_used=0.1400388447 → LR_next=0.1798156080, PERT_next=0.1400405364\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1780242623→0.1798156080 PERT 0.1400388447→0.1400405364\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.56\n",
            "[round 4 | client 0] final LR=0.1798156080, final PERT=0.1400405364  (ΔLR=+0.0087818357, ΔPERT=+0.0000099272)\n",
            "[round 4 | client 1] seed LR=0.1710340947 (prev=0.1710340947), seed PERT=0.1400308731 (prev=0.1400308731), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.491192 step=0.02681 g_raw=+0.004 g_sm=+0.002 acc=1 | LR→0.171377 PERT→0.140031 (scale=0.04)\n",
            "[meta] cb#010 loss=0.489833 step=0.007107 g_raw=+0.002 g_sm=+0.004 acc=1 | LR→0.171720 PERT→0.140031 (scale=0.04)\n",
            "[meta] cb#015 loss=0.486041 step=0.006256 g_raw=+0.000 g_sm=+0.006 acc=1 | LR→0.172064 PERT→0.140031 (scale=0.04)\n",
            "[meta] cb#020 loss=0.481434 step=0.03475 g_raw=+0.013 g_sm=+0.007 acc=1 | LR→0.172408 PERT→0.140031 (scale=0.04)\n",
            "[meta] cb#025 loss=0.479905 step=0.02418 g_raw=+0.009 g_sm=+0.008 acc=1 | LR→0.172754 PERT→0.140032 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1710340947, PERT_used=0.1400308731 → LR_next=0.1727538512, PERT_next=0.1400315502\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1710340947→0.1727538512 PERT 0.1400308731→0.1400315502\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.478566 step=0.01831 g_raw=+0.008 g_sm=+0.008 acc=1 | LR→0.173100 PERT→0.140032 (scale=0.04)\n",
            "[meta] cb#035 loss=0.475644 step=0.06824 g_raw=+0.021 g_sm=+0.009 acc=1 | LR→0.173447 PERT→0.140032 (scale=0.04)\n",
            "[meta] cb#040 loss=0.474549 step=0.003323 g_raw=+0.002 g_sm=+0.008 acc=1 | LR→0.173794 PERT→0.140032 (scale=0.04)\n",
            "[meta] cb#045 loss=0.470131 step=0.05494 g_raw=+0.020 g_sm=+0.009 acc=1 | LR→0.174143 PERT→0.140032 (scale=0.04)\n",
            "[meta] cb#050 loss=0.464878 step=0.01781 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.174492 PERT→0.140033 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1727538512, PERT_used=0.1400315502 → LR_next=0.1744915525, PERT_next=0.1400327510\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1727538512→0.1744915525 PERT 0.1400315502→0.1400327510\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.77\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.462523 step=0.05317 g_raw=+0.021 g_sm=+0.011 acc=1 | LR→0.174841 PERT→0.140033 (scale=0.04)\n",
            "[meta] cb#060 loss=0.460039 step=0.02613 g_raw=+0.012 g_sm=+0.011 acc=1 | LR→0.175192 PERT→0.140033 (scale=0.04)\n",
            "[meta] cb#065 loss=0.454998 step=0.03081 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.175543 PERT→0.140034 (scale=0.04)\n",
            "[meta] cb#070 loss=0.451274 step=0.04841 g_raw=+0.016 g_sm=+0.012 acc=1 | LR→0.175895 PERT→0.140034 (scale=0.04)\n",
            "[meta] cb#075 loss=0.449282 step=0.07005 g_raw=+0.021 g_sm=+0.011 acc=1 | LR→0.176247 PERT→0.140034 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1744915525, PERT_used=0.1400327510 → LR_next=0.1762472209, PERT_next=0.1400343393\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1744915525→0.1762472209 PERT 0.1400327510→0.1400343393\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.82\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.439906 step=0.1318 g_raw=+0.040 g_sm=+0.014 acc=1 | LR→0.176600 PERT→0.140035 (scale=0.04)\n",
            "[meta] cb#085 loss=0.437995 step=0.01696 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.176955 PERT→0.140035 (scale=0.04)\n",
            "[meta] cb#090 loss=0.434582 step=0.007754 g_raw=+0.003 g_sm=+0.012 acc=1 | LR→0.177309 PERT→0.140035 (scale=0.04)\n",
            "[meta] cb#095 loss=0.432858 step=0.01898 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.177665 PERT→0.140036 (scale=0.04)\n",
            "[meta] cb#100 loss=0.429387 step=0.1014 g_raw=+0.030 g_sm=+0.011 acc=1 | LR→0.178021 PERT→0.140036 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1762472209, PERT_used=0.1400343393 → LR_next=0.1780206183, PERT_next=0.1400359782\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1762472209→0.1780206183 PERT 0.1400343393→0.1400359782\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.83\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.426738 step=0.0126 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.178377 PERT→0.140036 (scale=0.04)\n",
            "[meta] cb#110 loss=0.424515 step=0.001023 g_raw=-0.000 g_sm=+0.010 acc=1 | LR→0.178735 PERT→0.140037 (scale=0.04)\n",
            "[meta] cb#115 loss=0.423194 step=0.04267 g_raw=+0.015 g_sm=+0.010 acc=1 | LR→0.179093 PERT→0.140037 (scale=0.04)\n",
            "[meta] cb#120 loss=0.420137 step=0.01894 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.179452 PERT→0.140037 (scale=0.04)\n",
            "[meta] cb#125 loss=0.419855 step=0.01467 g_raw=+0.004 g_sm=+0.009 acc=1 | LR→0.179812 PERT→0.140037 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1780206183, PERT_used=0.1400359782 → LR_next=0.1798115827, PERT_next=0.1400374014\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1780206183→0.1798115827 PERT 0.1400359782→0.1400374014\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.84\n",
            "[round 4 | client 1] final LR=0.1798115827, final PERT=0.1400374014  (ΔLR=+0.0087774880, ΔPERT=+0.0000065282)\n",
            "[round 4 | client 2] seed LR=0.1710321522 (prev=0.1710321522), seed PERT=0.1400292828 (prev=0.1400292828), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.443615 step=0.166 g_raw=+0.053 g_sm=+0.004 acc=1 | LR→0.171375 PERT→0.140029 (scale=0.04)\n",
            "[meta] cb#010 loss=0.430867 step=0.1047 g_raw=+0.029 g_sm=+0.009 acc=1 | LR→0.171718 PERT→0.140030 (scale=0.04)\n",
            "[meta] cb#015 loss=0.408477 step=0.1827 g_raw=+0.056 g_sm=+0.014 acc=1 | LR→0.172062 PERT→0.140030 (scale=0.04)\n",
            "[meta] cb#020 loss=0.395524 step=0.05296 g_raw=+0.012 g_sm=+0.016 acc=1 | LR→0.172407 PERT→0.140030 (scale=0.04)\n",
            "[meta] cb#025 loss=0.389568 step=0.0372 g_raw=+0.007 g_sm=+0.016 acc=1 | LR→0.172753 PERT→0.140031 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1710321522, PERT_used=0.1400292828 → LR_next=0.1727528469, PERT_next=0.1400307361\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.022 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1710321522→0.1727528469 PERT 0.1400292828→0.1400307361\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.60\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.376008 step=0.06678 g_raw=+0.020 g_sm=+0.018 acc=1 | LR→0.173099 PERT→0.140031 (scale=0.04)\n",
            "[meta] cb#035 loss=0.366922 step=0.06876 g_raw=+0.018 g_sm=+0.018 acc=1 | LR→0.173446 PERT→0.140032 (scale=0.04)\n",
            "[meta] cb#040 loss=0.352874 step=0.08502 g_raw=+0.027 g_sm=+0.020 acc=1 | LR→0.173794 PERT→0.140032 (scale=0.04)\n",
            "[meta] cb#045 loss=0.351679 step=0.0137 g_raw=+0.005 g_sm=+0.017 acc=1 | LR→0.174143 PERT→0.140033 (scale=0.04)\n",
            "[meta] cb#050 loss=0.348670 step=0.06847 g_raw=+0.017 g_sm=+0.016 acc=1 | LR→0.174492 PERT→0.140033 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1727528469, PERT_used=0.1400307361 → LR_next=0.1744921167, PERT_next=0.1400332038\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1727528469→0.1744921167 PERT 0.1400307361→0.1400332038\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.345398 step=0.06895 g_raw=+0.019 g_sm=+0.015 acc=1 | LR→0.174842 PERT→0.140034 (scale=0.04)\n",
            "[meta] cb#060 loss=0.343463 step=0.003249 g_raw=+0.004 g_sm=+0.013 acc=1 | LR→0.175192 PERT→0.140034 (scale=0.04)\n",
            "[meta] cb#065 loss=0.342776 step=0.006166 g_raw=-0.000 g_sm=+0.011 acc=1 | LR→0.175544 PERT→0.140034 (scale=0.04)\n",
            "[meta] cb#070 loss=0.340156 step=0.00604 g_raw=-0.001 g_sm=+0.010 acc=1 | LR→0.175895 PERT→0.140035 (scale=0.04)\n",
            "[meta] cb#075 loss=0.335944 step=0.03176 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.176248 PERT→0.140035 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1744921167, PERT_used=0.1400332038 → LR_next=0.1762480116, PERT_next=0.1400349676\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1744921167→0.1762480116 PERT 0.1400332038→0.1400349676\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.334719 step=0.005335 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.176601 PERT→0.140035 (scale=0.04)\n",
            "[meta] cb#085 loss=0.331784 step=0.03329 g_raw=+0.009 g_sm=+0.010 acc=1 | LR→0.176955 PERT→0.140036 (scale=0.04)\n",
            "[meta] cb#090 loss=0.331297 step=0.01267 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.177310 PERT→0.140036 (scale=0.04)\n",
            "[meta] cb#095 loss=0.330791 step=0.0188 g_raw=+0.004 g_sm=+0.008 acc=1 | LR→0.177665 PERT→0.140036 (scale=0.04)\n",
            "[meta] cb#100 loss=0.330601 step=0.03038 g_raw=+0.004 g_sm=+0.007 acc=1 | LR→0.178021 PERT→0.140036 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1762480116, PERT_used=0.1400349676 → LR_next=0.1780209674, PERT_next=0.1400362528\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.006 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1762480116→0.1780209674 PERT 0.1400349676→0.1400362528\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.58\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.329383 step=0.05898 g_raw=+0.013 g_sm=+0.006 acc=1 | LR→0.178378 PERT→0.140036 (scale=0.04)\n",
            "[meta] cb#110 loss=0.327834 step=0.007758 g_raw=+0.004 g_sm=+0.006 acc=1 | LR→0.178735 PERT→0.140037 (scale=0.04)\n",
            "[meta] cb#115 loss=0.327205 step=0.007715 g_raw=-0.001 g_sm=+0.006 acc=1 | LR→0.179093 PERT→0.140037 (scale=0.04)\n",
            "[meta] cb#120 loss=0.326853 step=0.02481 g_raw=+0.007 g_sm=+0.006 acc=1 | LR→0.179452 PERT→0.140037 (scale=0.04)\n",
            "[meta] cb#125 loss=0.326363 step=0.005973 g_raw=+0.001 g_sm=+0.005 acc=1 | LR→0.179811 PERT→0.140037 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1780209674, PERT_used=0.1400362528 → LR_next=0.1798112092, PERT_next=0.1400371106\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.005 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1780209674→0.1798112092 PERT 0.1400362528→0.1400371106\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.58\n",
            "[round 4 | client 2] final LR=0.1798112092, final PERT=0.1400371106  (ΔLR=+0.0087790570, ΔPERT=+0.0000078278)\n",
            "[round 4 | client 3] seed LR=0.1710375800 (prev=0.1710375800), seed PERT=0.1400337267 (prev=0.1400337267), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.501261 step=0.05441 g_raw=+0.019 g_sm=+0.004 acc=1 | LR→0.171380 PERT→0.140034 (scale=0.04)\n",
            "[meta] cb#010 loss=0.500089 step=0.03227 g_raw=+0.006 g_sm=+0.005 acc=1 | LR→0.171723 PERT→0.140034 (scale=0.04)\n",
            "[meta] cb#015 loss=0.485877 step=0.1011 g_raw=+0.030 g_sm=+0.010 acc=1 | LR→0.172067 PERT→0.140034 (scale=0.04)\n",
            "[meta] cb#020 loss=0.478388 step=0.06024 g_raw=+0.017 g_sm=+0.012 acc=1 | LR→0.172412 PERT→0.140034 (scale=0.04)\n",
            "[meta] cb#025 loss=0.460384 step=0.1578 g_raw=+0.051 g_sm=+0.016 acc=1 | LR→0.172758 PERT→0.140035 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1710375800, PERT_used=0.1400337267 → LR_next=0.1727579057, PERT_next=0.1400348367\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1710375800→0.1727579057 PERT 0.1400337267→0.1400348367\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.62\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.451029 step=0.00828 g_raw=-0.000 g_sm=+0.017 acc=1 | LR→0.173104 PERT→0.140035 (scale=0.04)\n",
            "[meta] cb#035 loss=0.440937 step=0.04296 g_raw=+0.012 g_sm=+0.017 acc=1 | LR→0.173452 PERT→0.140036 (scale=0.04)\n",
            "[meta] cb#040 loss=0.437963 step=0.06541 g_raw=+0.019 g_sm=+0.016 acc=1 | LR→0.173799 PERT→0.140036 (scale=0.04)\n",
            "[meta] cb#045 loss=0.422526 step=0.03556 g_raw=+0.005 g_sm=+0.018 acc=1 | LR→0.174148 PERT→0.140037 (scale=0.04)\n",
            "[meta] cb#050 loss=0.418575 step=0.0144 g_raw=-0.000 g_sm=+0.017 acc=1 | LR→0.174497 PERT→0.140037 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1727579057, PERT_used=0.1400348367 → LR_next=0.1744971697, PERT_next=0.1400372588\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1727579057→0.1744971697 PERT 0.1400348367→0.1400372588\n",
            "Training Accuracy: 0.92\n",
            "Test Accuracy: 0.79\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.415001 step=0.03696 g_raw=+0.011 g_sm=+0.016 acc=1 | LR→0.174847 PERT→0.140038 (scale=0.04)\n",
            "[meta] cb#060 loss=0.409026 step=0.04496 g_raw=+0.013 g_sm=+0.015 acc=1 | LR→0.175198 PERT→0.140038 (scale=0.04)\n",
            "[meta] cb#065 loss=0.406254 step=0.04979 g_raw=+0.014 g_sm=+0.014 acc=1 | LR→0.175549 PERT→0.140039 (scale=0.04)\n",
            "[meta] cb#070 loss=0.396902 step=0.079 g_raw=+0.021 g_sm=+0.016 acc=1 | LR→0.175901 PERT→0.140039 (scale=0.04)\n",
            "[meta] cb#075 loss=0.391667 step=0.08066 g_raw=+0.026 g_sm=+0.016 acc=1 | LR→0.176254 PERT→0.140039 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1744971697, PERT_used=0.1400372588 → LR_next=0.1762536306, PERT_next=0.1400394321\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1744971697→0.1762536306 PERT 0.1400372588→0.1400394321\n",
            "Training Accuracy: 0.94\n",
            "Test Accuracy: 0.81\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.385643 step=0.09092 g_raw=+0.022 g_sm=+0.016 acc=1 | LR→0.176607 PERT→0.140040 (scale=0.04)\n",
            "[meta] cb#085 loss=0.376329 step=0.05756 g_raw=+0.018 g_sm=+0.017 acc=1 | LR→0.176961 PERT→0.140040 (scale=0.04)\n",
            "[meta] cb#090 loss=0.369291 step=0.02405 g_raw=+0.012 g_sm=+0.016 acc=1 | LR→0.177316 PERT→0.140041 (scale=0.04)\n",
            "[meta] cb#095 loss=0.363206 step=0.01776 g_raw=+0.001 g_sm=+0.015 acc=1 | LR→0.177672 PERT→0.140041 (scale=0.04)\n",
            "[meta] cb#100 loss=0.356643 step=0.03651 g_raw=+0.005 g_sm=+0.015 acc=1 | LR→0.178028 PERT→0.140042 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1762536306, PERT_used=0.1400394321 → LR_next=0.1780278294, PERT_next=0.1400416507\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1762536306→0.1780278294 PERT 0.1400394321→0.1400416507\n",
            "Training Accuracy: 0.92\n",
            "Test Accuracy: 0.81\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.355506 step=0.04123 g_raw=+0.012 g_sm=+0.013 acc=1 | LR→0.178385 PERT→0.140042 (scale=0.04)\n",
            "[meta] cb#110 loss=0.350125 step=0.03327 g_raw=+0.005 g_sm=+0.014 acc=1 | LR→0.178742 PERT→0.140042 (scale=0.04)\n",
            "[meta] cb#115 loss=0.348364 step=0.06627 g_raw=+0.022 g_sm=+0.012 acc=1 | LR→0.179101 PERT→0.140043 (scale=0.04)\n",
            "[meta] cb#120 loss=0.347052 step=0.002763 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.179460 PERT→0.140043 (scale=0.04)\n",
            "[meta] cb#125 loss=0.342476 step=0.07211 g_raw=+0.019 g_sm=+0.011 acc=1 | LR→0.179819 PERT→0.140043 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1780278294, PERT_used=0.1400416507 → LR_next=0.1798192730, PERT_next=0.1400433906\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1780278294→0.1798192730 PERT 0.1400416507→0.1400433906\n",
            "Training Accuracy: 0.94\n",
            "Test Accuracy: 0.81\n",
            "[round 4 | client 3] final LR=0.1798192730, final PERT=0.1400433906  (ΔLR=+0.0087816930, ΔPERT=+0.0000096640)\n",
            "[round 4 | client 4] seed LR=0.1710358564 (prev=0.1710358564), seed PERT=0.1400323156 (prev=0.1400323156), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.483578 step=0.02589 g_raw=+0.006 g_sm=+0.002 acc=1 | LR→0.171378 PERT→0.140032 (scale=0.04)\n",
            "[meta] cb#010 loss=0.470748 step=0.1485 g_raw=+0.053 g_sm=+0.007 acc=1 | LR→0.171722 PERT→0.140032 (scale=0.04)\n",
            "[meta] cb#015 loss=0.466120 step=0.02282 g_raw=+0.006 g_sm=+0.009 acc=1 | LR→0.172066 PERT→0.140033 (scale=0.04)\n",
            "[meta] cb#020 loss=0.455683 step=0.007655 g_raw=-0.000 g_sm=+0.011 acc=1 | LR→0.172411 PERT→0.140033 (scale=0.04)\n",
            "[meta] cb#025 loss=0.455426 step=0.008121 g_raw=+0.006 g_sm=+0.009 acc=1 | LR→0.172756 PERT→0.140033 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1710358564, PERT_used=0.1400323156 → LR_next=0.1727560274, PERT_next=0.1400333142\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1710358564→0.1727560274 PERT 0.1400323156→0.1400333142\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.449140 step=0.1096 g_raw=+0.034 g_sm=+0.010 acc=1 | LR→0.173102 PERT→0.140034 (scale=0.04)\n",
            "[meta] cb#035 loss=0.446924 step=0.07198 g_raw=+0.025 g_sm=+0.010 acc=1 | LR→0.173449 PERT→0.140034 (scale=0.04)\n",
            "[meta] cb#040 loss=0.446090 step=0.002632 g_raw=-0.000 g_sm=+0.009 acc=1 | LR→0.173797 PERT→0.140034 (scale=0.04)\n",
            "[meta] cb#045 loss=0.440468 step=0.08504 g_raw=+0.027 g_sm=+0.010 acc=1 | LR→0.174145 PERT→0.140034 (scale=0.04)\n",
            "[meta] cb#050 loss=0.430434 step=0.0621 g_raw=+0.018 g_sm=+0.013 acc=1 | LR→0.174494 PERT→0.140035 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1727560274, PERT_used=0.1400333142 → LR_next=0.1744939985, PERT_next=0.1400347139\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1727560274→0.1744939985 PERT 0.1400333142→0.1400347139\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.77\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.426435 step=0.0002987 g_raw=-0.002 g_sm=+0.012 acc=1 | LR→0.174844 PERT→0.140035 (scale=0.04)\n",
            "[meta] cb#060 loss=0.422530 step=0.06025 g_raw=+0.019 g_sm=+0.013 acc=1 | LR→0.175194 PERT→0.140035 (scale=0.04)\n",
            "[meta] cb#065 loss=0.417885 step=0.03485 g_raw=+0.012 g_sm=+0.013 acc=1 | LR→0.175545 PERT→0.140036 (scale=0.04)\n",
            "[meta] cb#070 loss=0.412730 step=0.1144 g_raw=+0.035 g_sm=+0.013 acc=1 | LR→0.175897 PERT→0.140036 (scale=0.04)\n",
            "[meta] cb#075 loss=0.410584 step=0.05498 g_raw=+0.016 g_sm=+0.012 acc=1 | LR→0.176250 PERT→0.140036 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1744939985, PERT_used=0.1400347139 → LR_next=0.1762499056, PERT_next=0.1400364724\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1744939985→0.1762499056 PERT 0.1400347139→0.1400364724\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.77\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.407185 step=0.01063 g_raw=+0.003 g_sm=+0.012 acc=1 | LR→0.176603 PERT→0.140037 (scale=0.04)\n",
            "[meta] cb#085 loss=0.404085 step=0.0002772 g_raw=+0.000 g_sm=+0.011 acc=1 | LR→0.176957 PERT→0.140037 (scale=0.04)\n",
            "[meta] cb#090 loss=0.402617 step=0.001519 g_raw=-0.002 g_sm=+0.010 acc=1 | LR→0.177312 PERT→0.140037 (scale=0.04)\n",
            "[meta] cb#095 loss=0.400047 step=0.03376 g_raw=+0.011 g_sm=+0.010 acc=1 | LR→0.177667 PERT→0.140038 (scale=0.04)\n",
            "[meta] cb#100 loss=0.398255 step=0.03522 g_raw=+0.009 g_sm=+0.010 acc=1 | LR→0.178023 PERT→0.140038 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1762499056, PERT_used=0.1400364724 → LR_next=0.1780231575, PERT_next=0.1400379756\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1762499056→0.1780231575 PERT 0.1400364724→0.1400379756\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.81\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.394892 step=0.08397 g_raw=+0.023 g_sm=+0.010 acc=1 | LR→0.178380 PERT→0.140038 (scale=0.04)\n",
            "[meta] cb#110 loss=0.393209 step=0.03018 g_raw=+0.007 g_sm=+0.010 acc=1 | LR→0.178737 PERT→0.140039 (scale=0.04)\n",
            "[meta] cb#115 loss=0.389317 step=0.08586 g_raw=+0.024 g_sm=+0.010 acc=1 | LR→0.179096 PERT→0.140039 (scale=0.04)\n",
            "[meta] cb#120 loss=0.389112 step=0.009591 g_raw=+0.003 g_sm=+0.009 acc=1 | LR→0.179454 PERT→0.140039 (scale=0.04)\n",
            "[meta] cb#125 loss=0.387105 step=0.04995 g_raw=+0.016 g_sm=+0.009 acc=1 | LR→0.179814 PERT→0.140039 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1780231575, PERT_used=0.1400379756 → LR_next=0.1798140551, PERT_next=0.1400393269\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1780231575→0.1798140551 PERT 0.1400379756→0.1400393269\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.83\n",
            "[round 4 | client 4] final LR=0.1798140551, final PERT=0.1400393269  (ΔLR=+0.0087781986, ΔPERT=+0.0000070114)\n",
            "\n",
            "[Round 4] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           4      0.528274      0.835000      0.179814      0.140039\n",
            "           2      0.559697      0.580000      0.179811      0.140037\n",
            "           1      0.567294      0.845000      0.179812      0.140037\n",
            "           3      0.571542      0.810000      0.179819      0.140043\n",
            "           0      0.616130      0.565000      0.179816      0.140041\n",
            "→ [Round 4] best_client=4, best_val=0.528274, prev_global_val=0.556019, improve=+0.027745, action=adopt+mix τ=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  10%|█         | 5/50 [1:15:24<11:20:00, 906.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   4] acc_g=0.854 (μ=0.727, σ=0.127, FG=0.270) | t=893.517s, val=0.538 | TEL=FALSE\n",
            "[Round 5] Teleportation OFF | Aggregation=best\n",
            "[round 5 | client 0] seed LR=0.1798156080 (prev=0.1798156080), seed PERT=0.1400405364 (prev=0.1400405364), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.471583 step=0.1193 g_raw=+0.034 g_sm=+0.004 acc=1 | LR→0.180176 PERT→0.140041 (scale=0.04)\n",
            "[meta] cb#010 loss=0.465291 step=0.009308 g_raw=+0.003 g_sm=+0.007 acc=1 | LR→0.180537 PERT→0.140041 (scale=0.04)\n",
            "[meta] cb#015 loss=0.460934 step=0.02928 g_raw=+0.007 g_sm=+0.009 acc=1 | LR→0.180898 PERT→0.140041 (scale=0.04)\n",
            "[meta] cb#020 loss=0.455030 step=0.06036 g_raw=+0.014 g_sm=+0.011 acc=1 | LR→0.181261 PERT→0.140041 (scale=0.04)\n",
            "[meta] cb#025 loss=0.448639 step=0.002453 g_raw=-0.001 g_sm=+0.012 acc=1 | LR→0.181624 PERT→0.140042 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1798156080, PERT_used=0.1400405364 → LR_next=0.1816241781, PERT_next=0.1400416106\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1798156080→0.1816241781 PERT 0.1400405364→0.1400416106\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.65\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.440833 step=0.08555 g_raw=+0.027 g_sm=+0.013 acc=1 | LR→0.181988 PERT→0.140042 (scale=0.04)\n",
            "[meta] cb#035 loss=0.434778 step=0.03831 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.182353 PERT→0.140042 (scale=0.04)\n",
            "[meta] cb#040 loss=0.431370 step=0.06426 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.182719 PERT→0.140043 (scale=0.04)\n",
            "[meta] cb#045 loss=0.414894 step=0.09225 g_raw=+0.027 g_sm=+0.016 acc=1 | LR→0.183085 PERT→0.140043 (scale=0.04)\n",
            "[meta] cb#050 loss=0.406750 step=0.08461 g_raw=+0.025 g_sm=+0.017 acc=1 | LR→0.183452 PERT→0.140044 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1816241781, PERT_used=0.1400416106 → LR_next=0.1834520782, PERT_next=0.1400435547\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1816241781→0.1834520782 PERT 0.1400416106→0.1400435547\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.404638 step=0.003051 g_raw=-0.002 g_sm=+0.015 acc=1 | LR→0.183820 PERT→0.140044 (scale=0.04)\n",
            "[meta] cb#060 loss=0.401346 step=0.03165 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.184188 PERT→0.140044 (scale=0.04)\n",
            "[meta] cb#065 loss=0.397693 step=0.04005 g_raw=+0.012 g_sm=+0.014 acc=1 | LR→0.184558 PERT→0.140045 (scale=0.04)\n",
            "[meta] cb#070 loss=0.392387 step=0.0838 g_raw=+0.023 g_sm=+0.015 acc=1 | LR→0.184928 PERT→0.140045 (scale=0.04)\n",
            "[meta] cb#075 loss=0.390149 step=0.03662 g_raw=+0.008 g_sm=+0.013 acc=1 | LR→0.185298 PERT→0.140046 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1834520782, PERT_used=0.1400435547 → LR_next=0.1852984882, PERT_next=0.1400455847\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1834520782→0.1852984882 PERT 0.1400435547→0.1400455847\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.73\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.386230 step=0.04022 g_raw=+0.012 g_sm=+0.013 acc=1 | LR→0.185670 PERT→0.140046 (scale=0.04)\n",
            "[meta] cb#085 loss=0.383290 step=0.01499 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.186042 PERT→0.140046 (scale=0.04)\n",
            "[meta] cb#090 loss=0.381264 step=0.04292 g_raw=+0.012 g_sm=+0.011 acc=1 | LR→0.186415 PERT→0.140047 (scale=0.04)\n",
            "[meta] cb#095 loss=0.379316 step=0.05056 g_raw=+0.014 g_sm=+0.011 acc=1 | LR→0.186789 PERT→0.140047 (scale=0.04)\n",
            "[meta] cb#100 loss=0.379017 step=0.02648 g_raw=+0.009 g_sm=+0.009 acc=1 | LR→0.187163 PERT→0.140047 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1852984882, PERT_used=0.1400455847 → LR_next=0.1871628926, PERT_next=0.1400471737\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1852984882→0.1871628926 PERT 0.1400455847→0.1400471737\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.75\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.376238 step=0.06136 g_raw=+0.017 g_sm=+0.009 acc=1 | LR→0.187538 PERT→0.140047 (scale=0.04)\n",
            "[meta] cb#110 loss=0.373289 step=0.03454 g_raw=+0.012 g_sm=+0.010 acc=1 | LR→0.187914 PERT→0.140048 (scale=0.04)\n",
            "[meta] cb#115 loss=0.370481 step=0.02974 g_raw=+0.006 g_sm=+0.010 acc=1 | LR→0.188290 PERT→0.140048 (scale=0.04)\n",
            "[meta] cb#120 loss=0.370325 step=0.0025 g_raw=+0.001 g_sm=+0.008 acc=1 | LR→0.188668 PERT→0.140048 (scale=0.04)\n",
            "[meta] cb#125 loss=0.368787 step=0.05266 g_raw=+0.014 g_sm=+0.009 acc=1 | LR→0.189046 PERT→0.140048 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1871628926, PERT_used=0.1400471737 → LR_next=0.1890456903, PERT_next=0.1400484919\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1871628926→0.1890456903 PERT 0.1400471737→0.1400484919\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.81\n",
            "[round 5 | client 0] final LR=0.1890456903, final PERT=0.1400484919  (ΔLR=+0.0092300822, ΔPERT=+0.0000079555)\n",
            "[round 5 | client 1] seed LR=0.1798115827 (prev=0.1798115827), seed PERT=0.1400374014 (prev=0.1400374014), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.444805 step=0.1374 g_raw=+0.040 g_sm=+0.003 acc=1 | LR→0.180172 PERT→0.140037 (scale=0.04)\n",
            "[meta] cb#010 loss=0.438585 step=0.08542 g_raw=+0.029 g_sm=+0.007 acc=1 | LR→0.180532 PERT→0.140038 (scale=0.04)\n",
            "[meta] cb#015 loss=0.433505 step=0.06696 g_raw=+0.020 g_sm=+0.008 acc=1 | LR→0.180894 PERT→0.140038 (scale=0.04)\n",
            "[meta] cb#020 loss=0.424307 step=0.01141 g_raw=+0.001 g_sm=+0.010 acc=1 | LR→0.181257 PERT→0.140038 (scale=0.04)\n",
            "[meta] cb#025 loss=0.414983 step=0.1196 g_raw=+0.036 g_sm=+0.013 acc=1 | LR→0.181620 PERT→0.140038 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1798115827, PERT_used=0.1400374014 → LR_next=0.1816200146, PERT_next=0.1400384003\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1798115827→0.1816200146 PERT 0.1400374014→0.1400384003\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.78\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.404984 step=0.03868 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.181984 PERT→0.140039 (scale=0.04)\n",
            "[meta] cb#035 loss=0.401114 step=0.04877 g_raw=+0.010 g_sm=+0.014 acc=1 | LR→0.182349 PERT→0.140039 (scale=0.04)\n",
            "[meta] cb#040 loss=0.395900 step=0.00624 g_raw=-0.001 g_sm=+0.013 acc=1 | LR→0.182715 PERT→0.140040 (scale=0.04)\n",
            "[meta] cb#045 loss=0.389740 step=0.0305 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.183081 PERT→0.140040 (scale=0.04)\n",
            "[meta] cb#050 loss=0.387482 step=0.02489 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.183448 PERT→0.140040 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1816200146, PERT_used=0.1400384003 → LR_next=0.1834478087, PERT_next=0.1400402955\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1816200146→0.1834478087 PERT 0.1400384003→0.1400402955\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.81\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.385940 step=0.06482 g_raw=+0.016 g_sm=+0.011 acc=1 | LR→0.183815 PERT→0.140041 (scale=0.04)\n",
            "[meta] cb#060 loss=0.383792 step=0.05145 g_raw=+0.018 g_sm=+0.011 acc=1 | LR→0.184184 PERT→0.140041 (scale=0.04)\n",
            "[meta] cb#065 loss=0.376505 step=0.1056 g_raw=+0.032 g_sm=+0.013 acc=1 | LR→0.184553 PERT→0.140041 (scale=0.04)\n",
            "[meta] cb#070 loss=0.370590 step=0.02561 g_raw=+0.008 g_sm=+0.013 acc=1 | LR→0.184923 PERT→0.140042 (scale=0.04)\n",
            "[meta] cb#075 loss=0.368543 step=0.005196 g_raw=-0.002 g_sm=+0.012 acc=1 | LR→0.185294 PERT→0.140042 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1834478087, PERT_used=0.1400402955 → LR_next=0.1852937148, PERT_next=0.1400419770\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1834478087→0.1852937148 PERT 0.1400402955→0.1400419770\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.81\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.364893 step=0.02478 g_raw=+0.010 g_sm=+0.012 acc=1 | LR→0.185665 PERT→0.140042 (scale=0.04)\n",
            "[meta] cb#085 loss=0.363745 step=0.008234 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.186037 PERT→0.140043 (scale=0.04)\n",
            "[meta] cb#090 loss=0.358818 step=0.004561 g_raw=-0.003 g_sm=+0.012 acc=1 | LR→0.186410 PERT→0.140043 (scale=0.04)\n",
            "[meta] cb#095 loss=0.356431 step=0.06192 g_raw=+0.017 g_sm=+0.011 acc=1 | LR→0.186784 PERT→0.140043 (scale=0.04)\n",
            "[meta] cb#100 loss=0.354238 step=0.01728 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.187158 PERT→0.140044 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1852937148, PERT_used=0.1400419770 → LR_next=0.1871581306, PERT_next=0.1400436105\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1852937148→0.1871581306 PERT 0.1400419770→0.1400436105\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.79\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.351010 step=0.07122 g_raw=+0.019 g_sm=+0.011 acc=1 | LR→0.187533 PERT→0.140044 (scale=0.04)\n",
            "[meta] cb#110 loss=0.349701 step=0.06586 g_raw=+0.018 g_sm=+0.010 acc=1 | LR→0.187909 PERT→0.140044 (scale=0.04)\n",
            "[meta] cb#115 loss=0.349043 step=0.00712 g_raw=+0.001 g_sm=+0.009 acc=1 | LR→0.188286 PERT→0.140044 (scale=0.04)\n",
            "[meta] cb#120 loss=0.347494 step=0.003302 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.188663 PERT→0.140045 (scale=0.04)\n",
            "[meta] cb#125 loss=0.344436 step=0.08841 g_raw=+0.021 g_sm=+0.009 acc=1 | LR→0.189041 PERT→0.140045 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1871581306, PERT_used=0.1400436105 → LR_next=0.1890409010, PERT_next=0.1400449439\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1871581306→0.1890409010 PERT 0.1400436105→0.1400449439\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.80\n",
            "[round 5 | client 1] final LR=0.1890409010, final PERT=0.1400449439  (ΔLR=+0.0092293183, ΔPERT=+0.0000075425)\n",
            "[round 5 | client 2] seed LR=0.1798112092 (prev=0.1798112092), seed PERT=0.1400371106 (prev=0.1400371106), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.501592 step=0.01177 g_raw=+0.004 g_sm=+0.001 acc=1 | LR→0.180171 PERT→0.140037 (scale=0.04)\n",
            "[meta] cb#010 loss=0.499094 step=0.02841 g_raw=+0.005 g_sm=+0.003 acc=1 | LR→0.180532 PERT→0.140037 (scale=0.04)\n",
            "[meta] cb#015 loss=0.493832 step=0.08653 g_raw=+0.025 g_sm=+0.005 acc=1 | LR→0.180894 PERT→0.140037 (scale=0.04)\n",
            "[meta] cb#020 loss=0.490792 step=0.02912 g_raw=+0.008 g_sm=+0.006 acc=1 | LR→0.181256 PERT→0.140037 (scale=0.04)\n",
            "[meta] cb#025 loss=0.489824 step=0.04037 g_raw=+0.013 g_sm=+0.006 acc=1 | LR→0.181619 PERT→0.140038 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1798112092, PERT_used=0.1400371106 → LR_next=0.1816190279, PERT_next=0.1400376395\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.004 acc_ratio=1.00 | LR 0.1798112092→0.1816190279 PERT 0.1400371106→0.1400376395\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.488998 step=0.003972 g_raw=+0.002 g_sm=+0.006 acc=1 | LR→0.181983 PERT→0.140038 (scale=0.04)\n",
            "[meta] cb#035 loss=0.487384 step=0.03788 g_raw=+0.013 g_sm=+0.007 acc=1 | LR→0.182347 PERT→0.140038 (scale=0.04)\n",
            "[meta] cb#040 loss=0.485479 step=0.009416 g_raw=+0.006 g_sm=+0.008 acc=1 | LR→0.182713 PERT→0.140038 (scale=0.04)\n",
            "[meta] cb#045 loss=0.484058 step=0.01007 g_raw=+0.000 g_sm=+0.007 acc=1 | LR→0.183079 PERT→0.140038 (scale=0.04)\n",
            "[meta] cb#050 loss=0.482902 step=0.0153 g_raw=-0.000 g_sm=+0.007 acc=1 | LR→0.183446 PERT→0.140039 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1816190279, PERT_used=0.1400376395 → LR_next=0.1834456066, PERT_next=0.1400386144\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1816190279→0.1834456066 PERT 0.1400376395→0.1400386144\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.57\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.480526 step=0.03027 g_raw=+0.010 g_sm=+0.008 acc=1 | LR→0.183813 PERT→0.140039 (scale=0.04)\n",
            "[meta] cb#060 loss=0.478001 step=0.004617 g_raw=+0.003 g_sm=+0.008 acc=1 | LR→0.184181 PERT→0.140039 (scale=0.04)\n",
            "[meta] cb#065 loss=0.471980 step=0.01184 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.184551 PERT→0.140039 (scale=0.04)\n",
            "[meta] cb#070 loss=0.468780 step=0.04608 g_raw=+0.016 g_sm=+0.011 acc=1 | LR→0.184920 PERT→0.140040 (scale=0.04)\n",
            "[meta] cb#075 loss=0.466717 step=0.04065 g_raw=+0.015 g_sm=+0.011 acc=1 | LR→0.185291 PERT→0.140040 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1834456066, PERT_used=0.1400386144 → LR_next=0.1852910043, PERT_next=0.1400399285\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1834456066→0.1852910043 PERT 0.1400386144→0.1400399285\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.464885 step=0.009831 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.185662 PERT→0.140040 (scale=0.04)\n",
            "[meta] cb#085 loss=0.464147 step=0.01706 g_raw=+0.003 g_sm=+0.009 acc=1 | LR→0.186034 PERT→0.140040 (scale=0.04)\n",
            "[meta] cb#090 loss=0.463777 step=0.02108 g_raw=+0.008 g_sm=+0.008 acc=1 | LR→0.186407 PERT→0.140041 (scale=0.04)\n",
            "[meta] cb#095 loss=0.462657 step=0.02932 g_raw=+0.009 g_sm=+0.008 acc=1 | LR→0.186781 PERT→0.140041 (scale=0.04)\n",
            "[meta] cb#100 loss=0.460734 step=0.01668 g_raw=+0.004 g_sm=+0.008 acc=1 | LR→0.187155 PERT→0.140041 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1852910043, PERT_used=0.1400399285 → LR_next=0.1871548366, PERT_next=0.1400411457\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1852910043→0.1871548366 PERT 0.1400399285→0.1400411457\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.459303 step=0.04507 g_raw=+0.018 g_sm=+0.008 acc=1 | LR→0.187530 PERT→0.140041 (scale=0.04)\n",
            "[meta] cb#110 loss=0.456391 step=0.05539 g_raw=+0.020 g_sm=+0.009 acc=1 | LR→0.187906 PERT→0.140042 (scale=0.04)\n",
            "[meta] cb#115 loss=0.455160 step=0.004333 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.188282 PERT→0.140042 (scale=0.04)\n",
            "[meta] cb#120 loss=0.453451 step=0.02269 g_raw=+0.007 g_sm=+0.009 acc=1 | LR→0.188659 PERT→0.140042 (scale=0.04)\n",
            "[meta] cb#125 loss=0.452339 step=0.02448 g_raw=+0.005 g_sm=+0.009 acc=1 | LR→0.189037 PERT→0.140042 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1871548366, PERT_used=0.1400411457 → LR_next=0.1890374369, PERT_next=0.1400423776\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1871548366→0.1890374369 PERT 0.1400411457→0.1400423776\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.68\n",
            "[round 5 | client 2] final LR=0.1890374369, final PERT=0.1400423776  (ΔLR=+0.0092262276, ΔPERT=+0.0000052671)\n",
            "[round 5 | client 3] seed LR=0.1798192730 (prev=0.1798192730), seed PERT=0.1400433906 (prev=0.1400433906), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.481283 step=0.02437 g_raw=+0.007 g_sm=+0.002 acc=1 | LR→0.180179 PERT→0.140043 (scale=0.04)\n",
            "[meta] cb#010 loss=0.476577 step=0.024 g_raw=+0.007 g_sm=+0.005 acc=1 | LR→0.180540 PERT→0.140044 (scale=0.04)\n",
            "[meta] cb#015 loss=0.469586 step=0.03901 g_raw=+0.010 g_sm=+0.008 acc=1 | LR→0.180902 PERT→0.140044 (scale=0.04)\n",
            "[meta] cb#020 loss=0.466036 step=0.01558 g_raw=+0.004 g_sm=+0.009 acc=1 | LR→0.181264 PERT→0.140044 (scale=0.04)\n",
            "[meta] cb#025 loss=0.456938 step=0.06348 g_raw=+0.025 g_sm=+0.011 acc=1 | LR→0.181628 PERT→0.140044 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1798192730, PERT_used=0.1400433906 → LR_next=0.1816276174, PERT_next=0.1400442624\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1798192730→0.1816276174 PERT 0.1400433906→0.1400442624\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.451176 step=0.0005237 g_raw=-0.002 g_sm=+0.012 acc=1 | LR→0.181992 PERT→0.140045 (scale=0.04)\n",
            "[meta] cb#035 loss=0.426801 step=0.1723 g_raw=+0.047 g_sm=+0.017 acc=1 | LR→0.182357 PERT→0.140045 (scale=0.04)\n",
            "[meta] cb#040 loss=0.424842 step=0.02199 g_raw=+0.005 g_sm=+0.015 acc=1 | LR→0.182722 PERT→0.140045 (scale=0.04)\n",
            "[meta] cb#045 loss=0.421003 step=0.06974 g_raw=+0.019 g_sm=+0.014 acc=1 | LR→0.183089 PERT→0.140046 (scale=0.04)\n",
            "[meta] cb#050 loss=0.418100 step=0.03424 g_raw=+0.009 g_sm=+0.014 acc=1 | LR→0.183456 PERT→0.140046 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1816276174, PERT_used=0.1400442624 → LR_next=0.1834556284, PERT_next=0.1400462648\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1816276174→0.1834556284 PERT 0.1400442624→0.1400462648\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.413667 step=0.01567 g_raw=+0.001 g_sm=+0.014 acc=1 | LR→0.183823 PERT→0.140047 (scale=0.04)\n",
            "[meta] cb#060 loss=0.411924 step=0.009432 g_raw=+0.003 g_sm=+0.013 acc=1 | LR→0.184192 PERT→0.140047 (scale=0.04)\n",
            "[meta] cb#065 loss=0.409743 step=0.02766 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.184561 PERT→0.140047 (scale=0.04)\n",
            "[meta] cb#070 loss=0.405689 step=0.03199 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.184931 PERT→0.140048 (scale=0.04)\n",
            "[meta] cb#075 loss=0.403510 step=0.01703 g_raw=+0.003 g_sm=+0.012 acc=1 | LR→0.185302 PERT→0.140048 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1834556284, PERT_used=0.1400462648 → LR_next=0.1853017778, PERT_next=0.1400480710\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1834556284→0.1853017778 PERT 0.1400462648→0.1400480710\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.400425 step=0.002439 g_raw=+0.001 g_sm=+0.011 acc=1 | LR→0.185673 PERT→0.140048 (scale=0.04)\n",
            "[meta] cb#085 loss=0.396445 step=0.04055 g_raw=+0.013 g_sm=+0.012 acc=1 | LR→0.186045 PERT→0.140049 (scale=0.04)\n",
            "[meta] cb#090 loss=0.395065 step=0.0544 g_raw=+0.016 g_sm=+0.011 acc=1 | LR→0.186418 PERT→0.140049 (scale=0.04)\n",
            "[meta] cb#095 loss=0.391095 step=0.04257 g_raw=+0.015 g_sm=+0.011 acc=1 | LR→0.186792 PERT→0.140049 (scale=0.04)\n",
            "[meta] cb#100 loss=0.388669 step=0.02252 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.187166 PERT→0.140050 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1853017778, PERT_used=0.1400480710 → LR_next=0.1871661895, PERT_next=0.1400496407\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1853017778→0.1871661895 PERT 0.1400480710→0.1400496407\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.386977 step=0.04125 g_raw=+0.011 g_sm=+0.010 acc=1 | LR→0.187541 PERT→0.140050 (scale=0.04)\n",
            "[meta] cb#110 loss=0.385168 step=0.05767 g_raw=+0.016 g_sm=+0.010 acc=1 | LR→0.187917 PERT→0.140050 (scale=0.04)\n",
            "[meta] cb#115 loss=0.384389 step=0.04327 g_raw=+0.012 g_sm=+0.009 acc=1 | LR→0.188294 PERT→0.140050 (scale=0.04)\n",
            "[meta] cb#120 loss=0.380243 step=0.08324 g_raw=+0.023 g_sm=+0.010 acc=1 | LR→0.188671 PERT→0.140051 (scale=0.04)\n",
            "[meta] cb#125 loss=0.379077 step=0.009403 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.189049 PERT→0.140051 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1871661895, PERT_used=0.1400496407 → LR_next=0.1890491235, PERT_next=0.1400510353\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1871661895→0.1890491235 PERT 0.1400496407→0.1400510353\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.71\n",
            "[round 5 | client 3] final LR=0.1890491235, final PERT=0.1400510353  (ΔLR=+0.0092298505, ΔPERT=+0.0000076447)\n",
            "[round 5 | client 4] seed LR=0.1798140551 (prev=0.1798140551), seed PERT=0.1400393269 (prev=0.1400393269), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.541148 step=0.0805 g_raw=+0.027 g_sm=+0.002 acc=1 | LR→0.180174 PERT→0.140039 (scale=0.04)\n",
            "[meta] cb#010 loss=0.535026 step=0.06302 g_raw=+0.019 g_sm=+0.006 acc=1 | LR→0.180535 PERT→0.140039 (scale=0.04)\n",
            "[meta] cb#015 loss=0.524376 step=0.02872 g_raw=+0.012 g_sm=+0.009 acc=1 | LR→0.180897 PERT→0.140040 (scale=0.04)\n",
            "[meta] cb#020 loss=0.522740 step=0.003297 g_raw=+0.000 g_sm=+0.009 acc=1 | LR→0.181259 PERT→0.140040 (scale=0.04)\n",
            "[meta] cb#025 loss=0.512992 step=0.06894 g_raw=+0.022 g_sm=+0.012 acc=1 | LR→0.181622 PERT→0.140040 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1798140551, PERT_used=0.1400393269 → LR_next=0.1816224428, PERT_next=0.1400402725\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1798140551→0.1816224428 PERT 0.1400393269→0.1400402725\n",
            "Training Accuracy: 0.54\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.508764 step=0.0736 g_raw=+0.021 g_sm=+0.012 acc=1 | LR→0.181986 PERT→0.140041 (scale=0.04)\n",
            "[meta] cb#035 loss=0.499969 step=0.01269 g_raw=+0.004 g_sm=+0.014 acc=1 | LR→0.182351 PERT→0.140041 (scale=0.04)\n",
            "[meta] cb#040 loss=0.493588 step=0.04618 g_raw=+0.016 g_sm=+0.015 acc=1 | LR→0.182717 PERT→0.140041 (scale=0.04)\n",
            "[meta] cb#045 loss=0.486568 step=0.05003 g_raw=+0.012 g_sm=+0.015 acc=1 | LR→0.183083 PERT→0.140042 (scale=0.04)\n",
            "[meta] cb#050 loss=0.480094 step=0.03488 g_raw=+0.012 g_sm=+0.016 acc=1 | LR→0.183450 PERT→0.140042 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1816224428, PERT_used=0.1400402725 → LR_next=0.1834503154, PERT_next=0.1400422090\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1816224428→0.1834503154 PERT 0.1400402725→0.1400422090\n",
            "Training Accuracy: 0.56\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.472183 step=0.1106 g_raw=+0.030 g_sm=+0.017 acc=1 | LR→0.183818 PERT→0.140043 (scale=0.04)\n",
            "[meta] cb#060 loss=0.465777 step=0.01121 g_raw=+0.005 g_sm=+0.016 acc=1 | LR→0.184187 PERT→0.140043 (scale=0.04)\n",
            "[meta] cb#065 loss=0.461290 step=0.07073 g_raw=+0.018 g_sm=+0.016 acc=1 | LR→0.184556 PERT→0.140044 (scale=0.04)\n",
            "[meta] cb#070 loss=0.448266 step=0.03463 g_raw=+0.012 g_sm=+0.017 acc=1 | LR→0.184926 PERT→0.140044 (scale=0.04)\n",
            "[meta] cb#075 loss=0.446511 step=0.004807 g_raw=-0.000 g_sm=+0.014 acc=1 | LR→0.185297 PERT→0.140044 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1834503154, PERT_used=0.1400422090 → LR_next=0.1852970396, PERT_next=0.1400444899\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1834503154→0.1852970396 PERT 0.1400422090→0.1400444899\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.63\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.446016 step=0.0006722 g_raw=-0.000 g_sm=+0.012 acc=1 | LR→0.185668 PERT→0.140045 (scale=0.04)\n",
            "[meta] cb#085 loss=0.438879 step=0.09255 g_raw=+0.027 g_sm=+0.014 acc=1 | LR→0.186041 PERT→0.140045 (scale=0.04)\n",
            "[meta] cb#090 loss=0.438552 step=0.001936 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.186414 PERT→0.140046 (scale=0.04)\n",
            "[meta] cb#095 loss=0.436103 step=0.02338 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.186787 PERT→0.140046 (scale=0.04)\n",
            "[meta] cb#100 loss=0.431221 step=0.08994 g_raw=+0.026 g_sm=+0.012 acc=1 | LR→0.187162 PERT→0.140046 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1852970396, PERT_used=0.1400444899 → LR_next=0.1871615735, PERT_next=0.1400461867\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1852970396→0.1871615735 PERT 0.1400444899→0.1400461867\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.427850 step=0.05972 g_raw=+0.019 g_sm=+0.012 acc=1 | LR→0.187537 PERT→0.140047 (scale=0.04)\n",
            "[meta] cb#110 loss=0.425355 step=0.01946 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.187913 PERT→0.140047 (scale=0.04)\n",
            "[meta] cb#115 loss=0.419985 step=0.05838 g_raw=+0.014 g_sm=+0.013 acc=1 | LR→0.188289 PERT→0.140047 (scale=0.04)\n",
            "[meta] cb#120 loss=0.415707 step=0.0113 g_raw=+0.003 g_sm=+0.013 acc=1 | LR→0.188667 PERT→0.140048 (scale=0.04)\n",
            "[meta] cb#125 loss=0.412031 step=0.02288 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.189045 PERT→0.140048 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1871615735, PERT_used=0.1400461867 → LR_next=0.1890449436, PERT_next=0.1400479388\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1871615735→0.1890449436 PERT 0.1400461867→0.1400479388\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.66\n",
            "[round 5 | client 4] final LR=0.1890449436, final PERT=0.1400479388  (ΔLR=+0.0092308885, ΔPERT=+0.0000086118)\n",
            "\n",
            "[Round 5] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           1      0.516126      0.800000      0.189041      0.140045\n",
            "           0      0.521345      0.805000      0.189046      0.140048\n",
            "           3      0.542182      0.715000      0.189049      0.140051\n",
            "           2      0.649270      0.675000      0.189037      0.140042\n",
            "           4      0.675872      0.655000      0.189045      0.140048\n",
            "→ [Round 5] best_client=1, best_val=0.516126, prev_global_val=0.537730, improve=+0.021604, action=adopt+mix τ=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  12%|█▏        | 6/50 [1:30:19<11:02:01, 902.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   5] acc_g=0.800 (μ=0.730, σ=0.062, FG=0.140) | t=875.547s, val=0.535 | TEL=FALSE\n",
            "[Round 6] Teleportation OFF | Aggregation=best\n",
            "[round 6 | client 0] seed LR=0.1890456903 (prev=0.1890456903), seed PERT=0.1400484919 (prev=0.1400484919), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.488368 step=0.02978 g_raw=+0.007 g_sm=+0.001 acc=1 | LR→0.189424 PERT→0.140049 (scale=0.04)\n",
            "[meta] cb#010 loss=0.484630 step=0.01314 g_raw=+0.007 g_sm=+0.004 acc=1 | LR→0.189804 PERT→0.140049 (scale=0.04)\n",
            "[meta] cb#015 loss=0.484362 step=0.008889 g_raw=+0.002 g_sm=+0.004 acc=1 | LR→0.190184 PERT→0.140049 (scale=0.04)\n",
            "[meta] cb#020 loss=0.481045 step=0.07364 g_raw=+0.020 g_sm=+0.006 acc=1 | LR→0.190565 PERT→0.140049 (scale=0.04)\n",
            "[meta] cb#025 loss=0.476592 step=0.09585 g_raw=+0.031 g_sm=+0.007 acc=1 | LR→0.190946 PERT→0.140049 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1890456903, PERT_used=0.1400484919 → LR_next=0.1909463570, PERT_next=0.1400490243\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.004 acc_ratio=1.00 | LR 0.1890456903→0.1909463570 PERT 0.1400484919→0.1400490243\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.472664 step=0.02394 g_raw=+0.010 g_sm=+0.009 acc=1 | LR→0.191329 PERT→0.140049 (scale=0.04)\n",
            "[meta] cb#035 loss=0.469415 step=0.008315 g_raw=+0.004 g_sm=+0.009 acc=1 | LR→0.191712 PERT→0.140050 (scale=0.04)\n",
            "[meta] cb#040 loss=0.467326 step=0.07142 g_raw=+0.021 g_sm=+0.009 acc=1 | LR→0.192096 PERT→0.140050 (scale=0.04)\n",
            "[meta] cb#045 loss=0.462944 step=0.06477 g_raw=+0.022 g_sm=+0.011 acc=1 | LR→0.192481 PERT→0.140050 (scale=0.04)\n",
            "[meta] cb#050 loss=0.459910 step=0.0284 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.192867 PERT→0.140050 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1909463570, PERT_used=0.1400490243 → LR_next=0.1928672096, PERT_next=0.1400503385\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1909463570→0.1928672096 PERT 0.1400490243→0.1400503385\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.77\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.455812 step=0.05446 g_raw=+0.014 g_sm=+0.011 acc=1 | LR→0.193254 PERT→0.140051 (scale=0.04)\n",
            "[meta] cb#060 loss=0.452496 step=0.05879 g_raw=+0.017 g_sm=+0.011 acc=1 | LR→0.193641 PERT→0.140051 (scale=0.04)\n",
            "[meta] cb#065 loss=0.448583 step=0.01452 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.194029 PERT→0.140051 (scale=0.04)\n",
            "[meta] cb#070 loss=0.445727 step=0.01773 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.194418 PERT→0.140052 (scale=0.04)\n",
            "[meta] cb#075 loss=0.444153 step=0.02303 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.194808 PERT→0.140052 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1928672096, PERT_used=0.1400503385 → LR_next=0.1948077789, PERT_next=0.1400519357\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1928672096→0.1948077789 PERT 0.1400503385→0.1400519357\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.84\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.440518 step=0.0598 g_raw=+0.015 g_sm=+0.011 acc=1 | LR→0.195198 PERT→0.140052 (scale=0.04)\n",
            "[meta] cb#085 loss=0.439218 step=0.01259 g_raw=-0.000 g_sm=+0.010 acc=1 | LR→0.195589 PERT→0.140053 (scale=0.04)\n",
            "[meta] cb#090 loss=0.433533 step=0.07556 g_raw=+0.017 g_sm=+0.011 acc=1 | LR→0.195981 PERT→0.140053 (scale=0.04)\n",
            "[meta] cb#095 loss=0.432870 step=0.02331 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.196374 PERT→0.140053 (scale=0.04)\n",
            "[meta] cb#100 loss=0.429592 step=0.051 g_raw=+0.013 g_sm=+0.010 acc=1 | LR→0.196768 PERT→0.140053 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1948077789, PERT_used=0.1400519357 → LR_next=0.1967676425, PERT_next=0.1400533684\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1948077789→0.1967676425 PERT 0.1400519357→0.1400533684\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.85\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.428572 step=0.001197 g_raw=-0.001 g_sm=+0.009 acc=1 | LR→0.197162 PERT→0.140054 (scale=0.04)\n",
            "[meta] cb#110 loss=0.425953 step=0.03461 g_raw=+0.011 g_sm=+0.009 acc=1 | LR→0.197557 PERT→0.140054 (scale=0.04)\n",
            "[meta] cb#115 loss=0.423866 step=0.03414 g_raw=+0.011 g_sm=+0.010 acc=1 | LR→0.197953 PERT→0.140054 (scale=0.04)\n",
            "[meta] cb#120 loss=0.420542 step=0.01741 g_raw=+0.001 g_sm=+0.010 acc=1 | LR→0.198350 PERT→0.140054 (scale=0.04)\n",
            "[meta] cb#125 loss=0.418514 step=0.07524 g_raw=+0.021 g_sm=+0.010 acc=1 | LR→0.198747 PERT→0.140055 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1967676425, PERT_used=0.1400533684 → LR_next=0.1987470842, PERT_next=0.1400547031\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1967676425→0.1987470842 PERT 0.1400533684→0.1400547031\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.85\n",
            "[round 6 | client 0] final LR=0.1987470842, final PERT=0.1400547031  (ΔLR=+0.0097013940, ΔPERT=+0.0000062112)\n",
            "[round 6 | client 1] seed LR=0.1890409010 (prev=0.1890409010), seed PERT=0.1400449439 (prev=0.1400449439), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.507121 step=0.1492 g_raw=+0.045 g_sm=+0.006 acc=1 | LR→0.189419 PERT→0.140045 (scale=0.04)\n",
            "[meta] cb#010 loss=0.505240 step=0.0229 g_raw=+0.009 g_sm=+0.007 acc=1 | LR→0.189799 PERT→0.140045 (scale=0.04)\n",
            "[meta] cb#015 loss=0.502216 step=0.06719 g_raw=+0.022 g_sm=+0.008 acc=1 | LR→0.190179 PERT→0.140045 (scale=0.04)\n",
            "[meta] cb#020 loss=0.485211 step=0.07691 g_raw=+0.022 g_sm=+0.013 acc=1 | LR→0.190560 PERT→0.140046 (scale=0.04)\n",
            "[meta] cb#025 loss=0.480547 step=0.09257 g_raw=+0.026 g_sm=+0.013 acc=1 | LR→0.190942 PERT→0.140046 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1890409010, PERT_used=0.1400449439 → LR_next=0.1909423598, PERT_next=0.1400460926\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1890409010→0.1909423598 PERT 0.1400449439→0.1400460926\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.55\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.477154 step=0.04693 g_raw=+0.017 g_sm=+0.013 acc=1 | LR→0.191325 PERT→0.140046 (scale=0.04)\n",
            "[meta] cb#035 loss=0.467228 step=0.05565 g_raw=+0.017 g_sm=+0.015 acc=1 | LR→0.191709 PERT→0.140047 (scale=0.04)\n",
            "[meta] cb#040 loss=0.458910 step=0.04514 g_raw=+0.011 g_sm=+0.015 acc=1 | LR→0.192093 PERT→0.140047 (scale=0.04)\n",
            "[meta] cb#045 loss=0.456978 step=0.06854 g_raw=+0.019 g_sm=+0.014 acc=1 | LR→0.192478 PERT→0.140048 (scale=0.04)\n",
            "[meta] cb#050 loss=0.446505 step=0.09789 g_raw=+0.030 g_sm=+0.016 acc=1 | LR→0.192864 PERT→0.140048 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1909423598, PERT_used=0.1400460926 → LR_next=0.1928640828, PERT_next=0.1400480680\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1909423598→0.1928640828 PERT 0.1400460926→0.1400480680\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.57\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.437839 step=0.03078 g_raw=+0.009 g_sm=+0.016 acc=1 | LR→0.193251 PERT→0.140049 (scale=0.04)\n",
            "[meta] cb#060 loss=0.425317 step=0.1518 g_raw=+0.039 g_sm=+0.018 acc=1 | LR→0.193638 PERT→0.140049 (scale=0.04)\n",
            "[meta] cb#065 loss=0.418247 step=0.08422 g_raw=+0.023 g_sm=+0.018 acc=1 | LR→0.194027 PERT→0.140050 (scale=0.04)\n",
            "[meta] cb#070 loss=0.413816 step=0.03132 g_raw=+0.006 g_sm=+0.016 acc=1 | LR→0.194416 PERT→0.140050 (scale=0.04)\n",
            "[meta] cb#075 loss=0.411582 step=0.01903 g_raw=+0.008 g_sm=+0.015 acc=1 | LR→0.194806 PERT→0.140050 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1928640828, PERT_used=0.1400480680 → LR_next=0.1948056677, PERT_next=0.1400504180\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1928640828→0.1948056677 PERT 0.1400480680→0.1400504180\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.78\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.406899 step=0.09756 g_raw=+0.029 g_sm=+0.014 acc=1 | LR→0.195196 PERT→0.140051 (scale=0.04)\n",
            "[meta] cb#085 loss=0.401388 step=0.02519 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.195588 PERT→0.140051 (scale=0.04)\n",
            "[meta] cb#090 loss=0.397767 step=0.004187 g_raw=+0.005 g_sm=+0.014 acc=1 | LR→0.195980 PERT→0.140052 (scale=0.04)\n",
            "[meta] cb#095 loss=0.395296 step=0.06755 g_raw=+0.015 g_sm=+0.012 acc=1 | LR→0.196373 PERT→0.140052 (scale=0.04)\n",
            "[meta] cb#100 loss=0.391595 step=0.07576 g_raw=+0.021 g_sm=+0.013 acc=1 | LR→0.196766 PERT→0.140052 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1948056677, PERT_used=0.1400504180 → LR_next=0.1967661794, PERT_next=0.1400523270\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1948056677→0.1967661794 PERT 0.1400504180→0.1400523270\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.80\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.390716 step=0.0448 g_raw=+0.011 g_sm=+0.011 acc=1 | LR→0.197161 PERT→0.140053 (scale=0.04)\n",
            "[meta] cb#110 loss=0.389939 step=0.001944 g_raw=-0.001 g_sm=+0.009 acc=1 | LR→0.197556 PERT→0.140053 (scale=0.04)\n",
            "[meta] cb#115 loss=0.388340 step=0.03068 g_raw=+0.007 g_sm=+0.009 acc=1 | LR→0.197952 PERT→0.140053 (scale=0.04)\n",
            "[meta] cb#120 loss=0.386386 step=0.001604 g_raw=-0.002 g_sm=+0.009 acc=1 | LR→0.198348 PERT→0.140053 (scale=0.04)\n",
            "[meta] cb#125 loss=0.384654 step=0.02374 g_raw=+0.007 g_sm=+0.008 acc=1 | LR→0.198746 PERT→0.140054 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1967661794, PERT_used=0.1400523270 → LR_next=0.1987456478, PERT_next=0.1400536909\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.006 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1967661794→0.1987456478 PERT 0.1400523270→0.1400536909\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.80\n",
            "[round 6 | client 1] final LR=0.1987456478, final PERT=0.1400536909  (ΔLR=+0.0097047468, ΔPERT=+0.0000087470)\n",
            "[round 6 | client 2] seed LR=0.1890374369 (prev=0.1890374369), seed PERT=0.1400423776 (prev=0.1400423776), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.452116 step=0.02235 g_raw=+0.004 g_sm=+0.002 acc=1 | LR→0.189416 PERT→0.140042 (scale=0.04)\n",
            "[meta] cb#010 loss=0.446006 step=0.05259 g_raw=+0.014 g_sm=+0.005 acc=1 | LR→0.189795 PERT→0.140043 (scale=0.04)\n",
            "[meta] cb#015 loss=0.436052 step=0.03423 g_raw=+0.006 g_sm=+0.008 acc=1 | LR→0.190176 PERT→0.140043 (scale=0.04)\n",
            "[meta] cb#020 loss=0.431876 step=0.06377 g_raw=+0.018 g_sm=+0.009 acc=1 | LR→0.190557 PERT→0.140043 (scale=0.04)\n",
            "[meta] cb#025 loss=0.426913 step=0.01347 g_raw=+0.007 g_sm=+0.010 acc=1 | LR→0.190938 PERT→0.140043 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1890374369, PERT_used=0.1400423776 → LR_next=0.1909384704, PERT_next=0.1400432399\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1890374369→0.1909384704 PERT 0.1400423776→0.1400432399\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.423643 step=0.05163 g_raw=+0.012 g_sm=+0.010 acc=1 | LR→0.191321 PERT→0.140044 (scale=0.04)\n",
            "[meta] cb#035 loss=0.420084 step=0.002551 g_raw=-0.000 g_sm=+0.010 acc=1 | LR→0.191705 PERT→0.140044 (scale=0.04)\n",
            "[meta] cb#040 loss=0.409519 step=0.008117 g_raw=-0.001 g_sm=+0.012 acc=1 | LR→0.192089 PERT→0.140044 (scale=0.04)\n",
            "[meta] cb#045 loss=0.402634 step=0.03635 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.192474 PERT→0.140044 (scale=0.04)\n",
            "[meta] cb#050 loss=0.401576 step=0.0283 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.192860 PERT→0.140045 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1909384704, PERT_used=0.1400432399 → LR_next=0.1928596071, PERT_next=0.1400448180\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1909384704→0.1928596071 PERT 0.1400432399→0.1400448180\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.77\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.397300 step=0.01359 g_raw=+0.001 g_sm=+0.011 acc=1 | LR→0.193246 PERT→0.140045 (scale=0.04)\n",
            "[meta] cb#060 loss=0.396742 step=0.004764 g_raw=-0.002 g_sm=+0.009 acc=1 | LR→0.193633 PERT→0.140045 (scale=0.04)\n",
            "[meta] cb#065 loss=0.393809 step=0.07378 g_raw=+0.020 g_sm=+0.010 acc=1 | LR→0.194021 PERT→0.140046 (scale=0.04)\n",
            "[meta] cb#070 loss=0.385344 step=8.594e-06 g_raw=-0.003 g_sm=+0.011 acc=1 | LR→0.194410 PERT→0.140046 (scale=0.04)\n",
            "[meta] cb#075 loss=0.381260 step=0.08046 g_raw=+0.021 g_sm=+0.012 acc=1 | LR→0.194800 PERT→0.140046 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1928596071, PERT_used=0.1400448180 → LR_next=0.1947999963, PERT_next=0.1400463406\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1928596071→0.1947999963 PERT 0.1400448180→0.1400463406\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.78\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.379990 step=0.005022 g_raw=-0.000 g_sm=+0.010 acc=1 | LR→0.195190 PERT→0.140047 (scale=0.04)\n",
            "[meta] cb#085 loss=0.374199 step=0.02694 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.195582 PERT→0.140047 (scale=0.04)\n",
            "[meta] cb#090 loss=0.371652 step=0.02328 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.195974 PERT→0.140047 (scale=0.04)\n",
            "[meta] cb#095 loss=0.370089 step=0.001394 g_raw=+0.000 g_sm=+0.010 acc=1 | LR→0.196366 PERT→0.140048 (scale=0.04)\n",
            "[meta] cb#100 loss=0.366489 step=0.05895 g_raw=+0.023 g_sm=+0.011 acc=1 | LR→0.196760 PERT→0.140048 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1947999963, PERT_used=0.1400463406 → LR_next=0.1967599277, PERT_next=0.1400478772\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1947999963→0.1967599277 PERT 0.1400463406→0.1400478772\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.77\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.365745 step=0.009937 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.197154 PERT→0.140048 (scale=0.04)\n",
            "[meta] cb#110 loss=0.363626 step=0.04191 g_raw=+0.013 g_sm=+0.010 acc=1 | LR→0.197549 PERT→0.140048 (scale=0.04)\n",
            "[meta] cb#115 loss=0.362511 step=0.003225 g_raw=+0.001 g_sm=+0.009 acc=1 | LR→0.197945 PERT→0.140049 (scale=0.04)\n",
            "[meta] cb#120 loss=0.361727 step=0.006324 g_raw=-0.002 g_sm=+0.008 acc=1 | LR→0.198342 PERT→0.140049 (scale=0.04)\n",
            "[meta] cb#125 loss=0.359254 step=0.0371 g_raw=+0.010 g_sm=+0.008 acc=1 | LR→0.198739 PERT→0.140049 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1967599277, PERT_used=0.1400478772 → LR_next=0.1987392512, PERT_next=0.1400491833\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1967599277→0.1987392512 PERT 0.1400478772→0.1400491833\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.78\n",
            "[round 6 | client 2] final LR=0.1987392512, final PERT=0.1400491833  (ΔLR=+0.0097018143, ΔPERT=+0.0000068057)\n",
            "[round 6 | client 3] seed LR=0.1890491235 (prev=0.1890491235), seed PERT=0.1400510353 (prev=0.1400510353), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.448932 step=0.06695 g_raw=+0.018 g_sm=+0.004 acc=1 | LR→0.189428 PERT→0.140051 (scale=0.04)\n",
            "[meta] cb#010 loss=0.445743 step=0.03148 g_raw=+0.007 g_sm=+0.006 acc=1 | LR→0.189807 PERT→0.140051 (scale=0.04)\n",
            "[meta] cb#015 loss=0.429410 step=0.04971 g_raw=+0.014 g_sm=+0.010 acc=1 | LR→0.190187 PERT→0.140051 (scale=0.04)\n",
            "[meta] cb#020 loss=0.420705 step=0.09885 g_raw=+0.025 g_sm=+0.012 acc=1 | LR→0.190569 PERT→0.140052 (scale=0.04)\n",
            "[meta] cb#025 loss=0.417058 step=0.04701 g_raw=+0.015 g_sm=+0.012 acc=1 | LR→0.190951 PERT→0.140052 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1890491235, PERT_used=0.1400510353 → LR_next=0.1909506151, PERT_next=0.1400521474\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1890491235→0.1909506151 PERT 0.1400510353→0.1400521474\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.410836 step=0.02726 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.191333 PERT→0.140052 (scale=0.04)\n",
            "[meta] cb#035 loss=0.402413 step=0.07465 g_raw=+0.018 g_sm=+0.012 acc=1 | LR→0.191717 PERT→0.140053 (scale=0.04)\n",
            "[meta] cb#040 loss=0.400737 step=0.02794 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.192101 PERT→0.140053 (scale=0.04)\n",
            "[meta] cb#045 loss=0.394838 step=0.1048 g_raw=+0.030 g_sm=+0.013 acc=1 | LR→0.192486 PERT→0.140054 (scale=0.04)\n",
            "[meta] cb#050 loss=0.392254 step=0.04403 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.192872 PERT→0.140054 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1909506151, PERT_used=0.1400521474 → LR_next=0.1928720605, PERT_next=0.1400538610\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1909506151→0.1928720605 PERT 0.1400521474→0.1400538610\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.78\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.384070 step=0.1467 g_raw=+0.036 g_sm=+0.013 acc=1 | LR→0.193259 PERT→0.140054 (scale=0.04)\n",
            "[meta] cb#060 loss=0.382248 step=0.004064 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.193646 PERT→0.140055 (scale=0.04)\n",
            "[meta] cb#065 loss=0.380700 step=0.01326 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.194034 PERT→0.140055 (scale=0.04)\n",
            "[meta] cb#070 loss=0.378508 step=0.04601 g_raw=+0.015 g_sm=+0.011 acc=1 | LR→0.194423 PERT→0.140055 (scale=0.04)\n",
            "[meta] cb#075 loss=0.377726 step=0.01862 g_raw=+0.006 g_sm=+0.010 acc=1 | LR→0.194813 PERT→0.140056 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1928720605, PERT_used=0.1400538610 → LR_next=0.1948127578, PERT_next=0.1400555152\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1928720605→0.1948127578 PERT 0.1400538610→0.1400555152\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.81\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.375859 step=0.01251 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.195203 PERT→0.140056 (scale=0.04)\n",
            "[meta] cb#085 loss=0.373167 step=0.04451 g_raw=+0.012 g_sm=+0.010 acc=1 | LR→0.195594 PERT→0.140056 (scale=0.04)\n",
            "[meta] cb#090 loss=0.370599 step=0.053 g_raw=+0.014 g_sm=+0.010 acc=1 | LR→0.195986 PERT→0.140056 (scale=0.04)\n",
            "[meta] cb#095 loss=0.366740 step=0.09413 g_raw=+0.020 g_sm=+0.010 acc=1 | LR→0.196379 PERT→0.140057 (scale=0.04)\n",
            "[meta] cb#100 loss=0.366121 step=0.04827 g_raw=+0.011 g_sm=+0.009 acc=1 | LR→0.196773 PERT→0.140057 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1948127578, PERT_used=0.1400555152 → LR_next=0.1967725323, PERT_next=0.1400568488\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1948127578→0.1967725323 PERT 0.1400555152→0.1400568488\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.82\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.365486 step=0.01159 g_raw=+0.003 g_sm=+0.008 acc=1 | LR→0.197167 PERT→0.140057 (scale=0.04)\n",
            "[meta] cb#110 loss=0.365201 step=0.01552 g_raw=+0.001 g_sm=+0.007 acc=1 | LR→0.197562 PERT→0.140057 (scale=0.04)\n",
            "[meta] cb#115 loss=0.363367 step=0.03687 g_raw=+0.009 g_sm=+0.007 acc=1 | LR→0.197958 PERT→0.140058 (scale=0.04)\n",
            "[meta] cb#120 loss=0.362505 step=0.0205 g_raw=+0.005 g_sm=+0.007 acc=1 | LR→0.198354 PERT→0.140058 (scale=0.04)\n",
            "[meta] cb#125 loss=0.359844 step=0.04316 g_raw=+0.009 g_sm=+0.007 acc=1 | LR→0.198752 PERT→0.140058 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1967725323, PERT_used=0.1400568488 → LR_next=0.1987516378, PERT_next=0.1400579120\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.006 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1967725323→0.1987516378 PERT 0.1400568488→0.1400579120\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.80\n",
            "[round 6 | client 3] final LR=0.1987516378, final PERT=0.1400579120  (ΔLR=+0.0097025143, ΔPERT=+0.0000068767)\n",
            "[round 6 | client 4] seed LR=0.1890449436 (prev=0.1890449436), seed PERT=0.1400479388 (prev=0.1400479388), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.443477 step=0.04673 g_raw=+0.012 g_sm=+0.002 acc=1 | LR→0.189423 PERT→0.140048 (scale=0.04)\n",
            "[meta] cb#010 loss=0.423567 step=0.08347 g_raw=+0.022 g_sm=+0.008 acc=1 | LR→0.189803 PERT→0.140048 (scale=0.04)\n",
            "[meta] cb#015 loss=0.415094 step=0.04013 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.190183 PERT→0.140048 (scale=0.04)\n",
            "[meta] cb#020 loss=0.403399 step=0.05362 g_raw=+0.015 g_sm=+0.014 acc=1 | LR→0.190565 PERT→0.140049 (scale=0.04)\n",
            "[meta] cb#025 loss=0.389680 step=0.0271 g_raw=+0.004 g_sm=+0.015 acc=1 | LR→0.190947 PERT→0.140049 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1890449436, PERT_used=0.1400479388 → LR_next=0.1909465816, PERT_next=0.1400491891\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1890449436→0.1909465816 PERT 0.1400479388→0.1400491891\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.387367 step=0.02342 g_raw=+0.006 g_sm=+0.013 acc=1 | LR→0.191329 PERT→0.140050 (scale=0.04)\n",
            "[meta] cb#035 loss=0.386561 step=0.002846 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.191713 PERT→0.140050 (scale=0.04)\n",
            "[meta] cb#040 loss=0.378752 step=0.09364 g_raw=+0.022 g_sm=+0.013 acc=1 | LR→0.192097 PERT→0.140050 (scale=0.04)\n",
            "[meta] cb#045 loss=0.376265 step=0.02365 g_raw=+0.005 g_sm=+0.013 acc=1 | LR→0.192482 PERT→0.140051 (scale=0.04)\n",
            "[meta] cb#050 loss=0.372655 step=0.03981 g_raw=+0.010 g_sm=+0.012 acc=1 | LR→0.192868 PERT→0.140051 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1909465816, PERT_used=0.1400491891 → LR_next=0.1928681305, PERT_next=0.1400510072\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1909465816→0.1928681305 PERT 0.1400491891→0.1400510072\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.368174 step=0.01498 g_raw=+0.005 g_sm=+0.012 acc=1 | LR→0.193255 PERT→0.140051 (scale=0.04)\n",
            "[meta] cb#060 loss=0.367071 step=0.03091 g_raw=+0.007 g_sm=+0.010 acc=1 | LR→0.193642 PERT→0.140052 (scale=0.04)\n",
            "[meta] cb#065 loss=0.365489 step=0.01098 g_raw=+0.000 g_sm=+0.010 acc=1 | LR→0.194030 PERT→0.140052 (scale=0.04)\n",
            "[meta] cb#070 loss=0.362946 step=0.0377 g_raw=+0.008 g_sm=+0.010 acc=1 | LR→0.194419 PERT→0.140052 (scale=0.04)\n",
            "[meta] cb#075 loss=0.360248 step=0.1004 g_raw=+0.021 g_sm=+0.009 acc=1 | LR→0.194809 PERT→0.140052 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1928681305, PERT_used=0.1400510072 → LR_next=0.1948085209, PERT_next=0.1400524691\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1928681305→0.1948085209 PERT 0.1400510072→0.1400524691\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.359548 step=0.01779 g_raw=+0.007 g_sm=+0.008 acc=1 | LR→0.195199 PERT→0.140053 (scale=0.04)\n",
            "[meta] cb#085 loss=0.357042 step=0.04052 g_raw=+0.007 g_sm=+0.009 acc=1 | LR→0.195590 PERT→0.140053 (scale=0.04)\n",
            "[meta] cb#090 loss=0.353999 step=0.04037 g_raw=+0.011 g_sm=+0.009 acc=1 | LR→0.195982 PERT→0.140053 (scale=0.04)\n",
            "[meta] cb#095 loss=0.352519 step=0.00137 g_raw=+0.001 g_sm=+0.009 acc=1 | LR→0.196375 PERT→0.140053 (scale=0.04)\n",
            "[meta] cb#100 loss=0.351830 step=0.01399 g_raw=+0.004 g_sm=+0.008 acc=1 | LR→0.196768 PERT→0.140054 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1948085209, PERT_used=0.1400524691 → LR_next=0.1967681059, PERT_next=0.1400536982\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1948085209→0.1967681059 PERT 0.1400524691→0.1400536982\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.348046 step=0.1024 g_raw=+0.025 g_sm=+0.009 acc=1 | LR→0.197162 PERT→0.140054 (scale=0.04)\n",
            "[meta] cb#110 loss=0.345872 step=0.04305 g_raw=+0.012 g_sm=+0.008 acc=1 | LR→0.197557 PERT→0.140054 (scale=0.04)\n",
            "[meta] cb#115 loss=0.342991 step=0.04281 g_raw=+0.010 g_sm=+0.009 acc=1 | LR→0.197953 PERT→0.140054 (scale=0.04)\n",
            "[meta] cb#120 loss=0.341809 step=0.0462 g_raw=+0.014 g_sm=+0.009 acc=1 | LR→0.198350 PERT→0.140055 (scale=0.04)\n",
            "[meta] cb#125 loss=0.340032 step=0.07634 g_raw=+0.019 g_sm=+0.008 acc=1 | LR→0.198747 PERT→0.140055 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1967681059, PERT_used=0.1400536982 → LR_next=0.1987472922, PERT_next=0.1400548497\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1967681059→0.1987472922 PERT 0.1400536982→0.1400548497\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.70\n",
            "[round 6 | client 4] final LR=0.1987472922, final PERT=0.1400548497  (ΔLR=+0.0097023486, ΔPERT=+0.0000069109)\n",
            "\n",
            "[Round 6] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           2      0.518988      0.780000      0.198739      0.140049\n",
            "           3      0.526751      0.800000      0.198752      0.140058\n",
            "           0      0.548531      0.855000      0.198747      0.140055\n",
            "           1      0.561070      0.800000      0.198746      0.140054\n",
            "           4      0.581878      0.700000      0.198747      0.140055\n",
            "→ [Round 6] best_client=2, best_val=0.518988, prev_global_val=0.534860, improve=+0.015872, action=adopt+mix τ=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  14%|█▍        | 7/50 [1:45:16<10:45:39, 900.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   6] acc_g=0.811 (μ=0.787, σ=0.050, FG=0.101) | t=880.489s, val=0.520 | TEL=FALSE\n",
            "[Round 7] Teleportation OFF | Aggregation=best\n",
            "[round 7 | client 0] seed LR=0.1987470842 (prev=0.1987470842), seed PERT=0.1400547031 (prev=0.1400547031), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.536581 step=0.03813 g_raw=+0.012 g_sm=+0.002 acc=1 | LR→0.199145 PERT→0.140055 (scale=0.04)\n",
            "[meta] cb#010 loss=0.531643 step=0.08643 g_raw=+0.022 g_sm=+0.005 acc=1 | LR→0.199544 PERT→0.140055 (scale=0.04)\n",
            "[meta] cb#015 loss=0.528383 step=0.001929 g_raw=+0.002 g_sm=+0.006 acc=1 | LR→0.199944 PERT→0.140055 (scale=0.04)\n",
            "[meta] cb#020 loss=0.513895 step=0.0148 g_raw=+0.001 g_sm=+0.011 acc=1 | LR→0.200344 PERT→0.140055 (scale=0.04)\n",
            "[meta] cb#025 loss=0.509584 step=0.03217 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.200746 PERT→0.140056 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1987470842, PERT_used=0.1400547031 → LR_next=0.2007457886, PERT_next=0.1400555842\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1987470842→0.2007457886 PERT 0.1400547031→0.1400555842\n",
            "Training Accuracy: 0.52\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.497636 step=0.00359 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.201148 PERT→0.140056 (scale=0.04)\n",
            "[meta] cb#035 loss=0.486814 step=0.1283 g_raw=+0.034 g_sm=+0.014 acc=1 | LR→0.201551 PERT→0.140056 (scale=0.04)\n",
            "[meta] cb#040 loss=0.482833 step=0.1125 g_raw=+0.033 g_sm=+0.013 acc=1 | LR→0.201955 PERT→0.140057 (scale=0.04)\n",
            "[meta] cb#045 loss=0.479052 step=0.04304 g_raw=+0.014 g_sm=+0.013 acc=1 | LR→0.202360 PERT→0.140057 (scale=0.04)\n",
            "[meta] cb#050 loss=0.473791 step=0.006225 g_raw=+0.002 g_sm=+0.014 acc=1 | LR→0.202766 PERT→0.140057 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.2007457886, PERT_used=0.1400555842 → LR_next=0.2027660022, PERT_next=0.1400574388\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.2007457886→0.2027660022 PERT 0.1400555842→0.1400574388\n",
            "Training Accuracy: 0.52\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.471757 step=0.0128 g_raw=+0.002 g_sm=+0.012 acc=1 | LR→0.203172 PERT→0.140058 (scale=0.04)\n",
            "[meta] cb#060 loss=0.465535 step=0.06712 g_raw=+0.018 g_sm=+0.013 acc=1 | LR→0.203580 PERT→0.140058 (scale=0.04)\n",
            "[meta] cb#065 loss=0.464102 step=0.01661 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.203988 PERT→0.140058 (scale=0.04)\n",
            "[meta] cb#070 loss=0.460534 step=0.04935 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.204397 PERT→0.140059 (scale=0.04)\n",
            "[meta] cb#075 loss=0.454294 step=0.03283 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.204806 PERT→0.140059 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.2027660022, PERT_used=0.1400574388 → LR_next=0.2048063294, PERT_next=0.1400591450\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.2027660022→0.2048063294 PERT 0.1400574388→0.1400591450\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.60\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.452130 step=0.002872 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.205217 PERT→0.140059 (scale=0.04)\n",
            "[meta] cb#085 loss=0.450627 step=0.006386 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.205628 PERT→0.140060 (scale=0.04)\n",
            "[meta] cb#090 loss=0.447598 step=0.05496 g_raw=+0.013 g_sm=+0.010 acc=1 | LR→0.206040 PERT→0.140060 (scale=0.04)\n",
            "[meta] cb#095 loss=0.444657 step=0.004767 g_raw=-0.002 g_sm=+0.010 acc=1 | LR→0.206453 PERT→0.140060 (scale=0.04)\n",
            "[meta] cb#100 loss=0.442628 step=0.009876 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.206867 PERT→0.140061 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.2048063294, PERT_used=0.1400591450 → LR_next=0.2068668790, PERT_next=0.1400606425\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.2048063294→0.2068668790 PERT 0.1400591450→0.1400606425\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.60\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.439382 step=0.1065 g_raw=+0.025 g_sm=+0.010 acc=1 | LR→0.207281 PERT→0.140061 (scale=0.04)\n",
            "[meta] cb#110 loss=0.436838 step=0.01034 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.207697 PERT→0.140061 (scale=0.04)\n",
            "[meta] cb#115 loss=0.434769 step=0.03963 g_raw=+0.008 g_sm=+0.010 acc=1 | LR→0.208113 PERT→0.140061 (scale=0.04)\n",
            "[meta] cb#120 loss=0.431695 step=0.02675 g_raw=+0.008 g_sm=+0.010 acc=1 | LR→0.208530 PERT→0.140062 (scale=0.04)\n",
            "[meta] cb#125 loss=0.430120 step=0.06192 g_raw=+0.015 g_sm=+0.010 acc=1 | LR→0.208948 PERT→0.140062 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.2068668790, PERT_used=0.1400606425 → LR_next=0.2089480109, PERT_next=0.1400620403\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.2068668790→0.2089480109 PERT 0.1400606425→0.1400620403\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.67\n",
            "[round 7 | client 0] final LR=0.2089480109, final PERT=0.1400620403  (ΔLR=+0.0102009267, ΔPERT=+0.0000073372)\n",
            "[round 7 | client 1] seed LR=0.1987456478 (prev=0.1987456478), seed PERT=0.1400536909 (prev=0.1400536909), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.478277 step=0.112 g_raw=+0.034 g_sm=+0.003 acc=1 | LR→0.199144 PERT→0.140054 (scale=0.04)\n",
            "[meta] cb#010 loss=0.476543 step=0.03767 g_raw=+0.010 g_sm=+0.004 acc=1 | LR→0.199542 PERT→0.140054 (scale=0.04)\n",
            "[meta] cb#015 loss=0.471687 step=0.05457 g_raw=+0.018 g_sm=+0.007 acc=1 | LR→0.199942 PERT→0.140054 (scale=0.04)\n",
            "[meta] cb#020 loss=0.469945 step=0.027 g_raw=+0.007 g_sm=+0.007 acc=1 | LR→0.200343 PERT→0.140054 (scale=0.04)\n",
            "[meta] cb#025 loss=0.462480 step=0.1449 g_raw=+0.035 g_sm=+0.009 acc=1 | LR→0.200744 PERT→0.140054 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1987456478, PERT_used=0.1400536909 → LR_next=0.2007440521, PERT_next=0.1400543728\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1987456478→0.2007440521 PERT 0.1400536909→0.1400543728\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.73\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.460803 step=0.04321 g_raw=+0.013 g_sm=+0.009 acc=1 | LR→0.201146 PERT→0.140055 (scale=0.04)\n",
            "[meta] cb#035 loss=0.456356 step=0.05325 g_raw=+0.015 g_sm=+0.010 acc=1 | LR→0.201549 PERT→0.140055 (scale=0.04)\n",
            "[meta] cb#040 loss=0.453404 step=0.07461 g_raw=+0.022 g_sm=+0.010 acc=1 | LR→0.201953 PERT→0.140055 (scale=0.04)\n",
            "[meta] cb#045 loss=0.447874 step=0.0154 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.202358 PERT→0.140055 (scale=0.04)\n",
            "[meta] cb#050 loss=0.444137 step=0.02102 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.202764 PERT→0.140056 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.2007440521, PERT_used=0.1400543728 → LR_next=0.2027635757, PERT_next=0.1400557627\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.2007440521→0.2027635757 PERT 0.1400543728→0.1400557627\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.77\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.442070 step=0.01687 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.203170 PERT→0.140056 (scale=0.04)\n",
            "[meta] cb#060 loss=0.434573 step=0.0918 g_raw=+0.023 g_sm=+0.012 acc=1 | LR→0.203577 PERT→0.140056 (scale=0.04)\n",
            "[meta] cb#065 loss=0.432783 step=0.009744 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.203985 PERT→0.140057 (scale=0.04)\n",
            "[meta] cb#070 loss=0.430151 step=0.06041 g_raw=+0.015 g_sm=+0.011 acc=1 | LR→0.204394 PERT→0.140057 (scale=0.04)\n",
            "[meta] cb#075 loss=0.423775 step=0.06506 g_raw=+0.017 g_sm=+0.012 acc=1 | LR→0.204804 PERT→0.140057 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.2027635757, PERT_used=0.1400557627 → LR_next=0.2048036409, PERT_next=0.1400573064\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.2027635757→0.2048036409 PERT 0.1400557627→0.1400573064\n",
            "Training Accuracy: 0.90\n",
            "Test Accuracy: 0.85\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.421750 step=0.02741 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.205214 PERT→0.140058 (scale=0.04)\n",
            "[meta] cb#085 loss=0.420036 step=0.02591 g_raw=+0.009 g_sm=+0.010 acc=1 | LR→0.205625 PERT→0.140058 (scale=0.04)\n",
            "[meta] cb#090 loss=0.418008 step=0.01502 g_raw=+0.001 g_sm=+0.010 acc=1 | LR→0.206037 PERT→0.140058 (scale=0.04)\n",
            "[meta] cb#095 loss=0.416196 step=0.02145 g_raw=+0.001 g_sm=+0.009 acc=1 | LR→0.206450 PERT→0.140058 (scale=0.04)\n",
            "[meta] cb#100 loss=0.413635 step=0.04537 g_raw=+0.009 g_sm=+0.009 acc=1 | LR→0.206864 PERT→0.140059 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.2048036409, PERT_used=0.1400573064 → LR_next=0.2068640303, PERT_next=0.1400587138\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.2048036409→0.2068640303 PERT 0.1400573064→0.1400587138\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.413245 step=0.007896 g_raw=+0.005 g_sm=+0.008 acc=1 | LR→0.207279 PERT→0.140059 (scale=0.04)\n",
            "[meta] cb#110 loss=0.412221 step=0.03657 g_raw=+0.011 g_sm=+0.008 acc=1 | LR→0.207694 PERT→0.140059 (scale=0.04)\n",
            "[meta] cb#115 loss=0.408017 step=0.008997 g_raw=+0.002 g_sm=+0.008 acc=1 | LR→0.208110 PERT→0.140059 (scale=0.04)\n",
            "[meta] cb#120 loss=0.406918 step=0.008708 g_raw=+0.003 g_sm=+0.008 acc=1 | LR→0.208527 PERT→0.140060 (scale=0.04)\n",
            "[meta] cb#125 loss=0.405219 step=0.06825 g_raw=+0.017 g_sm=+0.007 acc=1 | LR→0.208945 PERT→0.140060 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.2068640303, PERT_used=0.1400587138 → LR_next=0.2089446756, PERT_next=0.1400598046\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.2068640303→0.2089446756 PERT 0.1400587138→0.1400598046\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.65\n",
            "[round 7 | client 1] final LR=0.2089446756, final PERT=0.1400598046  (ΔLR=+0.0101990278, ΔPERT=+0.0000061137)\n",
            "[round 7 | client 2] seed LR=0.1987392512 (prev=0.1987392512), seed PERT=0.1400491833 (prev=0.1400491833), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.460446 step=0.0572 g_raw=+0.013 g_sm=+0.001 acc=1 | LR→0.199137 PERT→0.140049 (scale=0.04)\n",
            "[meta] cb#010 loss=0.449419 step=0.01749 g_raw=+0.005 g_sm=+0.006 acc=1 | LR→0.199536 PERT→0.140049 (scale=0.04)\n",
            "[meta] cb#015 loss=0.442592 step=0.06384 g_raw=+0.016 g_sm=+0.008 acc=1 | LR→0.199936 PERT→0.140050 (scale=0.04)\n",
            "[meta] cb#020 loss=0.435407 step=0.06747 g_raw=+0.012 g_sm=+0.010 acc=1 | LR→0.200336 PERT→0.140050 (scale=0.04)\n",
            "[meta] cb#025 loss=0.431917 step=0.04831 g_raw=+0.014 g_sm=+0.011 acc=1 | LR→0.200738 PERT→0.140050 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1987392512, PERT_used=0.1400491833 → LR_next=0.2007379377, PERT_next=0.1400501069\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1987392512→0.2007379377 PERT 0.1400491833→0.1400501069\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.79\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.428991 step=0.07887 g_raw=+0.019 g_sm=+0.011 acc=1 | LR→0.201140 PERT→0.140050 (scale=0.04)\n",
            "[meta] cb#035 loss=0.421414 step=0.0127 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.201543 PERT→0.140051 (scale=0.04)\n",
            "[meta] cb#040 loss=0.414972 step=0.04172 g_raw=+0.011 g_sm=+0.013 acc=1 | LR→0.201947 PERT→0.140051 (scale=0.04)\n",
            "[meta] cb#045 loss=0.410121 step=0.01842 g_raw=+0.005 g_sm=+0.013 acc=1 | LR→0.202352 PERT→0.140051 (scale=0.04)\n",
            "[meta] cb#050 loss=0.407211 step=0.08899 g_raw=+0.016 g_sm=+0.012 acc=1 | LR→0.202758 PERT→0.140052 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.2007379377, PERT_used=0.1400501069 → LR_next=0.2027578350, PERT_next=0.1400517974\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.2007379377→0.2027578350 PERT 0.1400501069→0.1400517974\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.80\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.403159 step=0.004397 g_raw=+0.000 g_sm=+0.012 acc=1 | LR→0.203164 PERT→0.140052 (scale=0.04)\n",
            "[meta] cb#060 loss=0.402266 step=0.01012 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.203571 PERT→0.140052 (scale=0.04)\n",
            "[meta] cb#065 loss=0.397583 step=0.04826 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.203979 PERT→0.140053 (scale=0.04)\n",
            "[meta] cb#070 loss=0.391746 step=0.02783 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.204388 PERT→0.140053 (scale=0.04)\n",
            "[meta] cb#075 loss=0.387700 step=0.03187 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.204798 PERT→0.140053 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.2027578350, PERT_used=0.1400517974 → LR_next=0.2047979694, PERT_next=0.1400534279\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.2027578350→0.2047979694 PERT 0.1400517974→0.1400534279\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.383279 step=0.02428 g_raw=+0.005 g_sm=+0.012 acc=1 | LR→0.205208 PERT→0.140054 (scale=0.04)\n",
            "[meta] cb#085 loss=0.382529 step=0.003531 g_raw=-0.000 g_sm=+0.010 acc=1 | LR→0.205620 PERT→0.140054 (scale=0.04)\n",
            "[meta] cb#090 loss=0.379467 step=0.05919 g_raw=+0.013 g_sm=+0.010 acc=1 | LR→0.206032 PERT→0.140054 (scale=0.04)\n",
            "[meta] cb#095 loss=0.377700 step=0.01988 g_raw=+0.008 g_sm=+0.009 acc=1 | LR→0.206445 PERT→0.140055 (scale=0.04)\n",
            "[meta] cb#100 loss=0.373419 step=0.09709 g_raw=+0.025 g_sm=+0.010 acc=1 | LR→0.206858 PERT→0.140055 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.2047979694, PERT_used=0.1400534279 → LR_next=0.2068583402, PERT_next=0.1400548613\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.2047979694→0.2068583402 PERT 0.1400534279→0.1400548613\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.371555 step=0.02385 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.207273 PERT→0.140055 (scale=0.04)\n",
            "[meta] cb#110 loss=0.370467 step=0.05168 g_raw=+0.013 g_sm=+0.009 acc=1 | LR→0.207688 PERT→0.140055 (scale=0.04)\n",
            "[meta] cb#115 loss=0.369335 step=0.007305 g_raw=+0.005 g_sm=+0.008 acc=1 | LR→0.208104 PERT→0.140056 (scale=0.04)\n",
            "[meta] cb#120 loss=0.368117 step=0.03848 g_raw=+0.010 g_sm=+0.008 acc=1 | LR→0.208521 PERT→0.140056 (scale=0.04)\n",
            "[meta] cb#125 loss=0.367500 step=0.006621 g_raw=+0.001 g_sm=+0.007 acc=1 | LR→0.208939 PERT→0.140056 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.2068583402, PERT_used=0.1400548613 → LR_next=0.2089391151, PERT_next=0.1400560772\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.006 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.2068583402→0.2089391151 PERT 0.1400548613→0.1400560772\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.70\n",
            "[round 7 | client 2] final LR=0.2089391151, final PERT=0.1400560772  (ΔLR=+0.0101998639, ΔPERT=+0.0000068939)\n",
            "[round 7 | client 3] seed LR=0.1987516378 (prev=0.1987516378), seed PERT=0.1400579120 (prev=0.1400579120), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.504152 step=0.02554 g_raw=+0.008 g_sm=+0.003 acc=1 | LR→0.199150 PERT→0.140058 (scale=0.04)\n",
            "[meta] cb#010 loss=0.502102 step=0.05918 g_raw=+0.019 g_sm=+0.004 acc=1 | LR→0.199548 PERT→0.140058 (scale=0.04)\n",
            "[meta] cb#015 loss=0.499376 step=0.0499 g_raw=+0.014 g_sm=+0.006 acc=1 | LR→0.199948 PERT→0.140058 (scale=0.04)\n",
            "[meta] cb#020 loss=0.490773 step=0.0003706 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.200349 PERT→0.140058 (scale=0.04)\n",
            "[meta] cb#025 loss=0.476286 step=0.01953 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.200750 PERT→0.140059 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1987516378, PERT_used=0.1400579120 → LR_next=0.2007503491, PERT_next=0.1400587660\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1987516378→0.2007503491 PERT 0.1400579120→0.1400587660\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.462473 step=0.08797 g_raw=+0.023 g_sm=+0.015 acc=1 | LR→0.201153 PERT→0.140059 (scale=0.04)\n",
            "[meta] cb#035 loss=0.458334 step=0.004963 g_raw=+0.000 g_sm=+0.013 acc=1 | LR→0.201556 PERT→0.140060 (scale=0.04)\n",
            "[meta] cb#040 loss=0.453518 step=0.04375 g_raw=+0.009 g_sm=+0.014 acc=1 | LR→0.201960 PERT→0.140060 (scale=0.04)\n",
            "[meta] cb#045 loss=0.448386 step=0.03229 g_raw=+0.011 g_sm=+0.013 acc=1 | LR→0.202365 PERT→0.140060 (scale=0.04)\n",
            "[meta] cb#050 loss=0.444104 step=0.03608 g_raw=+0.014 g_sm=+0.013 acc=1 | LR→0.202771 PERT→0.140061 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.2007503491, PERT_used=0.1400587660 → LR_next=0.2027706848, PERT_next=0.1400606732\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.2007503491→0.2027706848 PERT 0.1400587660→0.1400606732\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.435747 step=0.1104 g_raw=+0.029 g_sm=+0.015 acc=1 | LR→0.203177 PERT→0.140061 (scale=0.04)\n",
            "[meta] cb#060 loss=0.411205 step=0.1001 g_raw=+0.027 g_sm=+0.019 acc=1 | LR→0.203585 PERT→0.140062 (scale=0.04)\n",
            "[meta] cb#065 loss=0.408086 step=0.04815 g_raw=+0.009 g_sm=+0.017 acc=1 | LR→0.203993 PERT→0.140062 (scale=0.04)\n",
            "[meta] cb#070 loss=0.403872 step=0.04891 g_raw=+0.016 g_sm=+0.016 acc=1 | LR→0.204402 PERT→0.140062 (scale=0.04)\n",
            "[meta] cb#075 loss=0.397436 step=0.09608 g_raw=+0.022 g_sm=+0.016 acc=1 | LR→0.204812 PERT→0.140063 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.2027706848, PERT_used=0.1400606732 → LR_next=0.2048118677, PERT_next=0.1400629325\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.2027706848→0.2048118677 PERT 0.1400606732→0.1400629325\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.389960 step=0.03514 g_raw=+0.007 g_sm=+0.016 acc=1 | LR→0.205223 PERT→0.140063 (scale=0.04)\n",
            "[meta] cb#085 loss=0.383009 step=0.1303 g_raw=+0.032 g_sm=+0.016 acc=1 | LR→0.205634 PERT→0.140064 (scale=0.04)\n",
            "[meta] cb#090 loss=0.378795 step=0.04598 g_raw=+0.014 g_sm=+0.015 acc=1 | LR→0.206046 PERT→0.140064 (scale=0.04)\n",
            "[meta] cb#095 loss=0.366571 step=0.05114 g_raw=+0.016 g_sm=+0.017 acc=1 | LR→0.206460 PERT→0.140065 (scale=0.04)\n",
            "[meta] cb#100 loss=0.364497 step=0.03751 g_raw=+0.009 g_sm=+0.015 acc=1 | LR→0.206874 PERT→0.140065 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.2048118677, PERT_used=0.1400629325 → LR_next=0.2068735633, PERT_next=0.1400651682\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.2048118677→0.2068735633 PERT 0.1400629325→0.1400651682\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.360116 step=0.07371 g_raw=+0.015 g_sm=+0.015 acc=1 | LR→0.207288 PERT→0.140066 (scale=0.04)\n",
            "[meta] cb#110 loss=0.356407 step=0.08599 g_raw=+0.020 g_sm=+0.014 acc=1 | LR→0.207704 PERT→0.140066 (scale=0.04)\n",
            "[meta] cb#115 loss=0.351474 step=0.04013 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.208120 PERT→0.140066 (scale=0.04)\n",
            "[meta] cb#120 loss=0.350857 step=0.02649 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.208537 PERT→0.140067 (scale=0.04)\n",
            "[meta] cb#125 loss=0.349422 step=0.009457 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.208955 PERT→0.140067 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.2068735633, PERT_used=0.1400651682 → LR_next=0.2089553934, PERT_next=0.1400669889\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.2068735633→0.2089553934 PERT 0.1400651682→0.1400669889\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.69\n",
            "[round 7 | client 3] final LR=0.2089553934, final PERT=0.1400669889  (ΔLR=+0.0102037556, ΔPERT=+0.0000090769)\n",
            "[round 7 | client 4] seed LR=0.1987472922 (prev=0.1987472922), seed PERT=0.1400548497 (prev=0.1400548497), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.522410 step=0.06969 g_raw=+0.019 g_sm=+0.003 acc=1 | LR→0.199145 PERT→0.140055 (scale=0.04)\n",
            "[meta] cb#010 loss=0.499514 step=0.1834 g_raw=+0.054 g_sm=+0.009 acc=1 | LR→0.199544 PERT→0.140055 (scale=0.04)\n",
            "[meta] cb#015 loss=0.487534 step=0.01947 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.199944 PERT→0.140055 (scale=0.04)\n",
            "[meta] cb#020 loss=0.478625 step=0.1532 g_raw=+0.043 g_sm=+0.013 acc=1 | LR→0.200345 PERT→0.140056 (scale=0.04)\n",
            "[meta] cb#025 loss=0.465769 step=0.05064 g_raw=+0.010 g_sm=+0.015 acc=1 | LR→0.200747 PERT→0.140056 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1987472922, PERT_used=0.1400548497 → LR_next=0.2007465520, PERT_next=0.1400561169\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1987472922→0.2007465520 PERT 0.1400548497→0.1400561169\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.457688 step=0.05099 g_raw=+0.013 g_sm=+0.015 acc=1 | LR→0.201149 PERT→0.140057 (scale=0.04)\n",
            "[meta] cb#035 loss=0.444952 step=0.03958 g_raw=+0.012 g_sm=+0.016 acc=1 | LR→0.201552 PERT→0.140057 (scale=0.04)\n",
            "[meta] cb#040 loss=0.440676 step=0.0417 g_raw=+0.013 g_sm=+0.016 acc=1 | LR→0.201957 PERT→0.140057 (scale=0.04)\n",
            "[meta] cb#045 loss=0.433958 step=0.1005 g_raw=+0.031 g_sm=+0.016 acc=1 | LR→0.202362 PERT→0.140058 (scale=0.04)\n",
            "[meta] cb#050 loss=0.425615 step=0.009901 g_raw=+0.002 g_sm=+0.016 acc=1 | LR→0.202767 PERT→0.140058 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.2007465520, PERT_used=0.1400561169 → LR_next=0.2027673303, PERT_next=0.1400583562\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.2007465520→0.2027673303 PERT 0.1400561169→0.1400583562\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.79\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.417251 step=0.1586 g_raw=+0.037 g_sm=+0.016 acc=1 | LR→0.203174 PERT→0.140059 (scale=0.04)\n",
            "[meta] cb#060 loss=0.412811 step=0.06665 g_raw=+0.019 g_sm=+0.016 acc=1 | LR→0.203581 PERT→0.140059 (scale=0.04)\n",
            "[meta] cb#065 loss=0.410557 step=0.06229 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.203989 PERT→0.140060 (scale=0.04)\n",
            "[meta] cb#070 loss=0.408755 step=0.01236 g_raw=+0.003 g_sm=+0.013 acc=1 | LR→0.204398 PERT→0.140060 (scale=0.04)\n",
            "[meta] cb#075 loss=0.406972 step=0.04252 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.204808 PERT→0.140060 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.2027673303, PERT_used=0.1400583562 → LR_next=0.2048080881, PERT_next=0.1400603478\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.2027673303→0.2048080881 PERT 0.1400583562→0.1400603478\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.79\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.404854 step=0.009095 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.205219 PERT→0.140061 (scale=0.04)\n",
            "[meta] cb#085 loss=0.401673 step=0.01258 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.205630 PERT→0.140061 (scale=0.04)\n",
            "[meta] cb#090 loss=0.400824 step=0.001279 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.206042 PERT→0.140061 (scale=0.04)\n",
            "[meta] cb#095 loss=0.400171 step=0.006675 g_raw=+0.003 g_sm=+0.008 acc=1 | LR→0.206455 PERT→0.140061 (scale=0.04)\n",
            "[meta] cb#100 loss=0.398815 step=0.02529 g_raw=+0.006 g_sm=+0.008 acc=1 | LR→0.206868 PERT→0.140062 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.2048080881, PERT_used=0.1400603478 → LR_next=0.2068684250, PERT_next=0.1400616893\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.2048080881→0.2068684250 PERT 0.1400603478→0.1400616893\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.75\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.396846 step=0.06206 g_raw=+0.012 g_sm=+0.008 acc=1 | LR→0.207283 PERT→0.140062 (scale=0.04)\n",
            "[meta] cb#110 loss=0.396440 step=0.01998 g_raw=+0.001 g_sm=+0.007 acc=1 | LR→0.207698 PERT→0.140062 (scale=0.04)\n",
            "[meta] cb#115 loss=0.395483 step=0.02003 g_raw=+0.005 g_sm=+0.007 acc=1 | LR→0.208114 PERT→0.140062 (scale=0.04)\n",
            "[meta] cb#120 loss=0.395201 step=0.01225 g_raw=+0.004 g_sm=+0.006 acc=1 | LR→0.208531 PERT→0.140062 (scale=0.04)\n",
            "[meta] cb#125 loss=0.394759 step=0.02114 g_raw=+0.004 g_sm=+0.005 acc=1 | LR→0.208949 PERT→0.140063 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.2068684250, PERT_used=0.1400616893 → LR_next=0.2089489035, PERT_next=0.1400626386\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.005 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.2068684250→0.2089489035 PERT 0.1400616893→0.1400626386\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.78\n",
            "[round 7 | client 4] final LR=0.2089489035, final PERT=0.1400626386  (ΔLR=+0.0102016112, ΔPERT=+0.0000077889)\n",
            "\n",
            "[Round 7] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           3      0.539987      0.690000      0.208955      0.140067\n",
            "           2      0.541554      0.705000      0.208939      0.140056\n",
            "           4      0.557310      0.775000      0.208949      0.140063\n",
            "           1      0.569528      0.645000      0.208945      0.140060\n",
            "           0      0.622445      0.670000      0.208948      0.140062\n",
            "→ [Round 7] best_client=3, best_val=0.539987, prev_global_val=0.520339, improve=-0.019648, action=hold (τ=0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  16%|█▌        | 8/50 [2:00:16<10:30:22, 900.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   7] acc_g=0.792 (μ=0.697, σ=0.044, FG=0.092) | t=883.789s, val=0.527 | TEL=FALSE\n",
            "[Round 8] Teleportation OFF | Aggregation=best\n",
            "[round 8 | client 0] seed LR=0.2089480109 (prev=0.2089480109), seed PERT=0.1400620403 (prev=0.1400620403), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.526813 step=0.206 g_raw=+0.057 g_sm=+0.005 acc=1 | LR→0.209366 PERT→0.140062 (scale=0.04)\n",
            "[meta] cb#010 loss=0.515369 step=0.04261 g_raw=+0.010 g_sm=+0.008 acc=1 | LR→0.209786 PERT→0.140062 (scale=0.04)\n",
            "[meta] cb#015 loss=0.494112 step=0.089 g_raw=+0.021 g_sm=+0.013 acc=1 | LR→0.210206 PERT→0.140063 (scale=0.04)\n",
            "[meta] cb#020 loss=0.485954 step=0.1158 g_raw=+0.027 g_sm=+0.014 acc=1 | LR→0.210628 PERT→0.140063 (scale=0.04)\n",
            "[meta] cb#025 loss=0.483559 step=0.01939 g_raw=+0.006 g_sm=+0.013 acc=1 | LR→0.211050 PERT→0.140063 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.2089480109, PERT_used=0.1400620403 → LR_next=0.2110500060, PERT_next=0.1400633892\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.2089480109→0.2110500060 PERT 0.1400620403→0.1400633892\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.45\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.463681 step=0.0333 g_raw=+0.007 g_sm=+0.015 acc=1 | LR→0.211473 PERT→0.140064 (scale=0.04)\n",
            "[meta] cb#035 loss=0.459606 step=0.07849 g_raw=+0.023 g_sm=+0.015 acc=1 | LR→0.211897 PERT→0.140064 (scale=0.04)\n",
            "[meta] cb#040 loss=0.452982 step=0.03941 g_raw=+0.009 g_sm=+0.015 acc=1 | LR→0.212322 PERT→0.140065 (scale=0.04)\n",
            "[meta] cb#045 loss=0.448650 step=0.02107 g_raw=+0.006 g_sm=+0.015 acc=1 | LR→0.212748 PERT→0.140065 (scale=0.04)\n",
            "[meta] cb#050 loss=0.443016 step=0.009863 g_raw=+0.001 g_sm=+0.014 acc=1 | LR→0.213174 PERT→0.140065 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.2110500060, PERT_used=0.1400633892 → LR_next=0.2131742930, PERT_next=0.1400654913\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.2110500060→0.2131742930 PERT 0.1400633892→0.1400654913\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.435674 step=0.02272 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.213602 PERT→0.140066 (scale=0.04)\n",
            "[meta] cb#060 loss=0.428326 step=0.04625 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.214030 PERT→0.140066 (scale=0.04)\n",
            "[meta] cb#065 loss=0.425542 step=0.02237 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.214459 PERT→0.140067 (scale=0.04)\n",
            "[meta] cb#070 loss=0.424467 step=0.04114 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.214889 PERT→0.140067 (scale=0.04)\n",
            "[meta] cb#075 loss=0.416924 step=0.04428 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.215320 PERT→0.140067 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.2131742930, PERT_used=0.1400654913 → LR_next=0.2153195038, PERT_next=0.1400672955\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.2131742930→0.2153195038 PERT 0.1400654913→0.1400672955\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.65\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.408720 step=0.02193 g_raw=+0.003 g_sm=+0.013 acc=1 | LR→0.215751 PERT→0.140068 (scale=0.04)\n",
            "[meta] cb#085 loss=0.405735 step=0.04943 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.216184 PERT→0.140068 (scale=0.04)\n",
            "[meta] cb#090 loss=0.404919 step=0.02555 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.216617 PERT→0.140068 (scale=0.04)\n",
            "[meta] cb#095 loss=0.402803 step=0.03869 g_raw=+0.010 g_sm=+0.010 acc=1 | LR→0.217051 PERT→0.140069 (scale=0.04)\n",
            "[meta] cb#100 loss=0.399952 step=0.05542 g_raw=+0.016 g_sm=+0.010 acc=1 | LR→0.217486 PERT→0.140069 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.2153195038, PERT_used=0.1400672955 → LR_next=0.2174859833, PERT_next=0.1400688943\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.2153195038→0.2174859833 PERT 0.1400672955→0.1400688943\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.396527 step=0.03409 g_raw=+0.008 g_sm=+0.010 acc=1 | LR→0.217922 PERT→0.140069 (scale=0.04)\n",
            "[meta] cb#110 loss=0.390733 step=0.01776 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.218359 PERT→0.140069 (scale=0.04)\n",
            "[meta] cb#115 loss=0.390210 step=0.03719 g_raw=+0.008 g_sm=+0.010 acc=1 | LR→0.218796 PERT→0.140070 (scale=0.04)\n",
            "[meta] cb#120 loss=0.388749 step=0.04225 g_raw=+0.009 g_sm=+0.009 acc=1 | LR→0.219235 PERT→0.140070 (scale=0.04)\n",
            "[meta] cb#125 loss=0.387359 step=0.01712 g_raw=+0.002 g_sm=+0.008 acc=1 | LR→0.219674 PERT→0.140070 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.2174859833, PERT_used=0.1400688943 → LR_next=0.2196739583, PERT_next=0.1400703000\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.2174859833→0.2196739583 PERT 0.1400688943→0.1400703000\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.69\n",
            "[round 8 | client 0] final LR=0.2196739583, final PERT=0.1400703000  (ΔLR=+0.0107259474, ΔPERT=+0.0000082597)\n",
            "[round 8 | client 1] seed LR=0.2089446756 (prev=0.2089446756), seed PERT=0.1400598046 (prev=0.1400598046), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.496731 step=0.06713 g_raw=+0.014 g_sm=+0.002 acc=1 | LR→0.209363 PERT→0.140060 (scale=0.04)\n",
            "[meta] cb#010 loss=0.488013 step=0.04256 g_raw=+0.013 g_sm=+0.006 acc=1 | LR→0.209782 PERT→0.140060 (scale=0.04)\n",
            "[meta] cb#015 loss=0.470212 step=0.03042 g_raw=+0.008 g_sm=+0.009 acc=1 | LR→0.210203 PERT→0.140060 (scale=0.04)\n",
            "[meta] cb#020 loss=0.452811 step=0.121 g_raw=+0.030 g_sm=+0.013 acc=1 | LR→0.210624 PERT→0.140061 (scale=0.04)\n",
            "[meta] cb#025 loss=0.433330 step=0.2192 g_raw=+0.053 g_sm=+0.016 acc=1 | LR→0.211046 PERT→0.140061 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.2089446756, PERT_used=0.1400598046 → LR_next=0.2110462709, PERT_next=0.1400609105\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.2089446756→0.2110462709 PERT 0.1400598046→0.1400609105\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.423226 step=0.0855 g_raw=+0.018 g_sm=+0.017 acc=1 | LR→0.211469 PERT→0.140061 (scale=0.04)\n",
            "[meta] cb#035 loss=0.415187 step=0.166 g_raw=+0.039 g_sm=+0.017 acc=1 | LR→0.211894 PERT→0.140062 (scale=0.04)\n",
            "[meta] cb#040 loss=0.409064 step=0.08528 g_raw=+0.023 g_sm=+0.017 acc=1 | LR→0.212318 PERT→0.140062 (scale=0.04)\n",
            "[meta] cb#045 loss=0.406468 step=0.04627 g_raw=+0.010 g_sm=+0.015 acc=1 | LR→0.212744 PERT→0.140063 (scale=0.04)\n",
            "[meta] cb#050 loss=0.400910 step=0.09143 g_raw=+0.021 g_sm=+0.015 acc=1 | LR→0.213171 PERT→0.140063 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.2110462709, PERT_used=0.1400609105 → LR_next=0.2131707263, PERT_next=0.1400631478\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.2110462709→0.2131707263 PERT 0.1400609105→0.1400631478\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.397050 step=0.07453 g_raw=+0.016 g_sm=+0.014 acc=1 | LR→0.213598 PERT→0.140064 (scale=0.04)\n",
            "[meta] cb#060 loss=0.394856 step=0.05989 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.214026 PERT→0.140064 (scale=0.04)\n",
            "[meta] cb#065 loss=0.394341 step=0.01885 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.214455 PERT→0.140064 (scale=0.04)\n",
            "[meta] cb#070 loss=0.391389 step=0.04195 g_raw=+0.012 g_sm=+0.011 acc=1 | LR→0.214885 PERT→0.140065 (scale=0.04)\n",
            "[meta] cb#075 loss=0.388092 step=0.003415 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.215316 PERT→0.140065 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.2131707263, PERT_used=0.1400631478 → LR_next=0.2153157268, PERT_next=0.1400648385\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.2131707263→0.2153157268 PERT 0.1400631478→0.1400648385\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.73\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.385872 step=0.007965 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.215747 PERT→0.140065 (scale=0.04)\n",
            "[meta] cb#085 loss=0.384991 step=0.01358 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.216180 PERT→0.140065 (scale=0.04)\n",
            "[meta] cb#090 loss=0.383821 step=0.04777 g_raw=+0.009 g_sm=+0.008 acc=1 | LR→0.216613 PERT→0.140066 (scale=0.04)\n",
            "[meta] cb#095 loss=0.383090 step=0.01576 g_raw=+0.007 g_sm=+0.007 acc=1 | LR→0.217047 PERT→0.140066 (scale=0.04)\n",
            "[meta] cb#100 loss=0.382224 step=0.0397 g_raw=+0.010 g_sm=+0.007 acc=1 | LR→0.217482 PERT→0.140066 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.2153157268, PERT_used=0.1400648385 → LR_next=0.2174815053, PERT_next=0.1400660103\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.006 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.2153157268→0.2174815053 PERT 0.1400648385→0.1400660103\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.380856 step=0.03368 g_raw=+0.005 g_sm=+0.007 acc=1 | LR→0.217917 PERT→0.140066 (scale=0.04)\n",
            "[meta] cb#110 loss=0.380302 step=0.02638 g_raw=+0.005 g_sm=+0.006 acc=1 | LR→0.218354 PERT→0.140066 (scale=0.04)\n",
            "[meta] cb#115 loss=0.379872 step=0.02142 g_raw=+0.001 g_sm=+0.006 acc=1 | LR→0.218791 PERT→0.140067 (scale=0.04)\n",
            "[meta] cb#120 loss=0.378962 step=0.00507 g_raw=+0.003 g_sm=+0.005 acc=1 | LR→0.219229 PERT→0.140067 (scale=0.04)\n",
            "[meta] cb#125 loss=0.377842 step=0.02665 g_raw=+0.006 g_sm=+0.006 acc=1 | LR→0.219669 PERT→0.140067 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.2174815053, PERT_used=0.1400660103 → LR_next=0.2196685773, PERT_next=0.1400668689\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.005 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.2174815053→0.2196685773 PERT 0.1400660103→0.1400668689\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.69\n",
            "[round 8 | client 1] final LR=0.2196685773, final PERT=0.1400668689  (ΔLR=+0.0107239017, ΔPERT=+0.0000070643)\n",
            "[round 8 | client 2] seed LR=0.2089391151 (prev=0.2089391151), seed PERT=0.1400560772 (prev=0.1400560772), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.477769 step=0.1339 g_raw=+0.035 g_sm=+0.005 acc=1 | LR→0.209357 PERT→0.140056 (scale=0.04)\n",
            "[meta] cb#010 loss=0.469290 step=0.03891 g_raw=+0.008 g_sm=+0.007 acc=1 | LR→0.209777 PERT→0.140056 (scale=0.04)\n",
            "[meta] cb#015 loss=0.459548 step=0.1387 g_raw=+0.037 g_sm=+0.010 acc=1 | LR→0.210197 PERT→0.140057 (scale=0.04)\n",
            "[meta] cb#020 loss=0.452015 step=0.1045 g_raw=+0.023 g_sm=+0.011 acc=1 | LR→0.210618 PERT→0.140057 (scale=0.04)\n",
            "[meta] cb#025 loss=0.446363 step=0.03508 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.211041 PERT→0.140057 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.2089391151, PERT_used=0.1400560772 → LR_next=0.2110406464, PERT_next=0.1400571778\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.2089391151→0.2110406464 PERT 0.1400560772→0.1400571778\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.438774 step=0.1017 g_raw=+0.026 g_sm=+0.014 acc=1 | LR→0.211464 PERT→0.140058 (scale=0.04)\n",
            "[meta] cb#035 loss=0.435445 step=0.04244 g_raw=+0.008 g_sm=+0.013 acc=1 | LR→0.211888 PERT→0.140058 (scale=0.04)\n",
            "[meta] cb#040 loss=0.430462 step=0.05058 g_raw=+0.011 g_sm=+0.013 acc=1 | LR→0.212312 PERT→0.140058 (scale=0.04)\n",
            "[meta] cb#045 loss=0.428900 step=0.04747 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.212738 PERT→0.140059 (scale=0.04)\n",
            "[meta] cb#050 loss=0.422782 step=0.09914 g_raw=+0.024 g_sm=+0.013 acc=1 | LR→0.213164 PERT→0.140059 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.2110406464, PERT_used=0.1400571778 → LR_next=0.2131643340, PERT_next=0.1400589478\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.2110406464→0.2131643340 PERT 0.1400571778→0.1400589478\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.420967 step=0.05544 g_raw=+0.013 g_sm=+0.012 acc=1 | LR→0.213592 PERT→0.140059 (scale=0.04)\n",
            "[meta] cb#060 loss=0.418637 step=0.07466 g_raw=+0.017 g_sm=+0.011 acc=1 | LR→0.214020 PERT→0.140060 (scale=0.04)\n",
            "[meta] cb#065 loss=0.416099 step=0.03199 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.214449 PERT→0.140060 (scale=0.04)\n",
            "[meta] cb#070 loss=0.415110 step=0.003799 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.214878 PERT→0.140060 (scale=0.04)\n",
            "[meta] cb#075 loss=0.411900 step=0.007042 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.215309 PERT→0.140060 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.2131643340, PERT_used=0.1400589478 → LR_next=0.2153089996, PERT_next=0.1400604624\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.2131643340→0.2153089996 PERT 0.1400589478→0.1400604624\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.409595 step=0.07238 g_raw=+0.015 g_sm=+0.010 acc=1 | LR→0.215740 PERT→0.140061 (scale=0.04)\n",
            "[meta] cb#085 loss=0.407185 step=0.04247 g_raw=+0.010 g_sm=+0.010 acc=1 | LR→0.216173 PERT→0.140061 (scale=0.04)\n",
            "[meta] cb#090 loss=0.406372 step=0.01114 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.216606 PERT→0.140061 (scale=0.04)\n",
            "[meta] cb#095 loss=0.404644 step=0.05855 g_raw=+0.014 g_sm=+0.008 acc=1 | LR→0.217040 PERT→0.140061 (scale=0.04)\n",
            "[meta] cb#100 loss=0.403098 step=0.05334 g_raw=+0.013 g_sm=+0.008 acc=1 | LR→0.217475 PERT→0.140062 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.2153089996, PERT_used=0.1400604624 → LR_next=0.2174748287, PERT_next=0.1400617103\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.2153089996→0.2174748287 PERT 0.1400604624→0.1400617103\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.402102 step=0.04325 g_raw=+0.008 g_sm=+0.008 acc=1 | LR→0.217911 PERT→0.140062 (scale=0.04)\n",
            "[meta] cb#110 loss=0.400426 step=0.02375 g_raw=+0.007 g_sm=+0.008 acc=1 | LR→0.218347 PERT→0.140062 (scale=0.04)\n",
            "[meta] cb#115 loss=0.398076 step=0.06847 g_raw=+0.016 g_sm=+0.008 acc=1 | LR→0.218785 PERT→0.140062 (scale=0.04)\n",
            "[meta] cb#120 loss=0.397642 step=0.01812 g_raw=+0.002 g_sm=+0.007 acc=1 | LR→0.219223 PERT→0.140063 (scale=0.04)\n",
            "[meta] cb#125 loss=0.396170 step=0.01797 g_raw=+0.008 g_sm=+0.007 acc=1 | LR→0.219662 PERT→0.140063 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.2174748287, PERT_used=0.1400617103 → LR_next=0.2196621514, PERT_next=0.1400627716\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.2174748287→0.2196621514 PERT 0.1400617103→0.1400627716\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.68\n",
            "[round 8 | client 2] final LR=0.2196621514, final PERT=0.1400627716  (ΔLR=+0.0107230363, ΔPERT=+0.0000066943)\n",
            "[round 8 | client 3] seed LR=0.2089553934 (prev=0.2089553934), seed PERT=0.1400669889 (prev=0.1400669889), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.456450 step=0.05517 g_raw=+0.016 g_sm=+0.004 acc=1 | LR→0.209374 PERT→0.140067 (scale=0.04)\n",
            "[meta] cb#010 loss=0.433737 step=0.1889 g_raw=+0.047 g_sm=+0.011 acc=1 | LR→0.209793 PERT→0.140067 (scale=0.04)\n",
            "[meta] cb#015 loss=0.430522 step=0.05045 g_raw=+0.011 g_sm=+0.011 acc=1 | LR→0.210214 PERT→0.140068 (scale=0.04)\n",
            "[meta] cb#020 loss=0.427516 step=0.04835 g_raw=+0.010 g_sm=+0.011 acc=1 | LR→0.210635 PERT→0.140068 (scale=0.04)\n",
            "[meta] cb#025 loss=0.416230 step=0.1355 g_raw=+0.030 g_sm=+0.013 acc=1 | LR→0.211057 PERT→0.140068 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.2089553934, PERT_used=0.1400669889 → LR_next=0.2110573100, PERT_next=0.1400682366\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.2089553934→0.2110573100 PERT 0.1400669889→0.1400682366\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.77\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.409630 step=0.1224 g_raw=+0.031 g_sm=+0.013 acc=1 | LR→0.211480 PERT→0.140069 (scale=0.04)\n",
            "[meta] cb#035 loss=0.404854 step=0.003717 g_raw=-0.000 g_sm=+0.013 acc=1 | LR→0.211904 PERT→0.140069 (scale=0.04)\n",
            "[meta] cb#040 loss=0.395331 step=0.03981 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.212329 PERT→0.140069 (scale=0.04)\n",
            "[meta] cb#045 loss=0.393455 step=0.05198 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.212755 PERT→0.140070 (scale=0.04)\n",
            "[meta] cb#050 loss=0.389908 step=0.07167 g_raw=+0.017 g_sm=+0.012 acc=1 | LR→0.213181 PERT→0.140070 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.2110573100, PERT_used=0.1400682366 → LR_next=0.2131812333, PERT_next=0.1400700514\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.2110573100→0.2131812333 PERT 0.1400682366→0.1400700514\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.73\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.387859 step=0.02266 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.213608 PERT→0.140070 (scale=0.04)\n",
            "[meta] cb#060 loss=0.386599 step=0.03113 g_raw=+0.009 g_sm=+0.010 acc=1 | LR→0.214037 PERT→0.140071 (scale=0.04)\n",
            "[meta] cb#065 loss=0.380675 step=0.02213 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.214466 PERT→0.140071 (scale=0.04)\n",
            "[meta] cb#070 loss=0.376198 step=0.1199 g_raw=+0.025 g_sm=+0.011 acc=1 | LR→0.214895 PERT→0.140071 (scale=0.04)\n",
            "[meta] cb#075 loss=0.370694 step=0.05037 g_raw=+0.011 g_sm=+0.011 acc=1 | LR→0.215326 PERT→0.140072 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.2131812333, PERT_used=0.1400700514 → LR_next=0.2153260215, PERT_next=0.1400715353\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.2131812333→0.2153260215 PERT 0.1400700514→0.1400715353\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.73\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.369834 step=0.05139 g_raw=+0.013 g_sm=+0.010 acc=1 | LR→0.215758 PERT→0.140072 (scale=0.04)\n",
            "[meta] cb#085 loss=0.363718 step=0.06288 g_raw=+0.021 g_sm=+0.012 acc=1 | LR→0.216190 PERT→0.140072 (scale=0.04)\n",
            "[meta] cb#090 loss=0.362344 step=0.002328 g_raw=-0.001 g_sm=+0.011 acc=1 | LR→0.216623 PERT→0.140072 (scale=0.04)\n",
            "[meta] cb#095 loss=0.359022 step=0.01182 g_raw=-0.000 g_sm=+0.010 acc=1 | LR→0.217057 PERT→0.140073 (scale=0.04)\n",
            "[meta] cb#100 loss=0.356554 step=0.08458 g_raw=+0.021 g_sm=+0.009 acc=1 | LR→0.217492 PERT→0.140073 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.2153260215, PERT_used=0.1400715353 → LR_next=0.2174923580, PERT_next=0.1400729998\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.2153260215→0.2174923580 PERT 0.1400715353→0.1400729998\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.353789 step=0.08275 g_raw=+0.019 g_sm=+0.009 acc=1 | LR→0.217928 PERT→0.140073 (scale=0.04)\n",
            "[meta] cb#110 loss=0.352117 step=0.02892 g_raw=+0.005 g_sm=+0.009 acc=1 | LR→0.218365 PERT→0.140074 (scale=0.04)\n",
            "[meta] cb#115 loss=0.350783 step=0.02515 g_raw=+0.009 g_sm=+0.009 acc=1 | LR→0.218802 PERT→0.140074 (scale=0.04)\n",
            "[meta] cb#120 loss=0.348396 step=0.07236 g_raw=+0.016 g_sm=+0.009 acc=1 | LR→0.219241 PERT→0.140074 (scale=0.04)\n",
            "[meta] cb#125 loss=0.347261 step=0.03757 g_raw=+0.005 g_sm=+0.008 acc=1 | LR→0.219680 PERT→0.140074 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.2174923580, PERT_used=0.1400729998 → LR_next=0.2196801312, PERT_next=0.1400742360\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.2174923580→0.2196801312 PERT 0.1400729998→0.1400742360\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.70\n",
            "[round 8 | client 3] final LR=0.2196801312, final PERT=0.1400742360  (ΔLR=+0.0107247378, ΔPERT=+0.0000072471)\n",
            "[round 8 | client 4] seed LR=0.2089489035 (prev=0.2089489035), seed PERT=0.1400626386 (prev=0.1400626386), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.517080 step=0.06457 g_raw=+0.018 g_sm=+0.004 acc=1 | LR→0.209367 PERT→0.140063 (scale=0.04)\n",
            "[meta] cb#010 loss=0.514809 step=0.01006 g_raw=+0.002 g_sm=+0.005 acc=1 | LR→0.209787 PERT→0.140063 (scale=0.04)\n",
            "[meta] cb#015 loss=0.505958 step=0.1373 g_raw=+0.034 g_sm=+0.008 acc=1 | LR→0.210207 PERT→0.140063 (scale=0.04)\n",
            "[meta] cb#020 loss=0.499283 step=0.01746 g_raw=+0.004 g_sm=+0.009 acc=1 | LR→0.210628 PERT→0.140063 (scale=0.04)\n",
            "[meta] cb#025 loss=0.498354 step=0.01577 g_raw=+0.007 g_sm=+0.008 acc=1 | LR→0.211050 PERT→0.140063 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.2089489035, PERT_used=0.1400626386 → LR_next=0.2110501352, PERT_next=0.1400634750\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.2089489035→0.2110501352 PERT 0.1400626386→0.1400634750\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.492111 step=0.08522 g_raw=+0.024 g_sm=+0.010 acc=1 | LR→0.211473 PERT→0.140064 (scale=0.04)\n",
            "[meta] cb#035 loss=0.480413 step=0.02159 g_raw=+0.008 g_sm=+0.013 acc=1 | LR→0.211897 PERT→0.140064 (scale=0.04)\n",
            "[meta] cb#040 loss=0.475378 step=0.1308 g_raw=+0.034 g_sm=+0.013 acc=1 | LR→0.212322 PERT→0.140064 (scale=0.04)\n",
            "[meta] cb#045 loss=0.471915 step=0.02911 g_raw=+0.008 g_sm=+0.013 acc=1 | LR→0.212747 PERT→0.140065 (scale=0.04)\n",
            "[meta] cb#050 loss=0.460144 step=0.04943 g_raw=+0.015 g_sm=+0.014 acc=1 | LR→0.213174 PERT→0.140065 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.2110501352, PERT_used=0.1400634750 → LR_next=0.2131737856, PERT_next=0.1400651579\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.2110501352→0.2131737856 PERT 0.1400634750→0.1400651579\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.456818 step=0.06872 g_raw=+0.017 g_sm=+0.013 acc=1 | LR→0.213601 PERT→0.140066 (scale=0.04)\n",
            "[meta] cb#060 loss=0.449942 step=0.05681 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.214029 PERT→0.140066 (scale=0.04)\n",
            "[meta] cb#065 loss=0.442253 step=0.07676 g_raw=+0.019 g_sm=+0.015 acc=1 | LR→0.214458 PERT→0.140066 (scale=0.04)\n",
            "[meta] cb#070 loss=0.439665 step=0.05104 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.214888 PERT→0.140067 (scale=0.04)\n",
            "[meta] cb#075 loss=0.436875 step=0.03937 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.215319 PERT→0.140067 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.2131737856, PERT_used=0.1400651579 → LR_next=0.2153191232, PERT_next=0.1400670479\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.2131737856→0.2153191232 PERT 0.1400651579→0.1400670479\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.431079 step=0.07681 g_raw=+0.021 g_sm=+0.013 acc=1 | LR→0.215751 PERT→0.140067 (scale=0.04)\n",
            "[meta] cb#085 loss=0.415672 step=0.09342 g_raw=+0.023 g_sm=+0.015 acc=1 | LR→0.216183 PERT→0.140068 (scale=0.04)\n",
            "[meta] cb#090 loss=0.412146 step=0.003232 g_raw=-0.001 g_sm=+0.014 acc=1 | LR→0.216617 PERT→0.140068 (scale=0.04)\n",
            "[meta] cb#095 loss=0.408291 step=0.03586 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.217051 PERT→0.140069 (scale=0.04)\n",
            "[meta] cb#100 loss=0.403469 step=0.0144 g_raw=+0.005 g_sm=+0.012 acc=1 | LR→0.217486 PERT→0.140069 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.2153191232, PERT_used=0.1400670479 → LR_next=0.2174860501, PERT_next=0.1400689373\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.2153191232→0.2174860501 PERT 0.1400670479→0.1400689373\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.62\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.403137 step=0.00518 g_raw=+0.001 g_sm=+0.010 acc=1 | LR→0.217922 PERT→0.140069 (scale=0.04)\n",
            "[meta] cb#110 loss=0.397561 step=0.0404 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.218359 PERT→0.140070 (scale=0.04)\n",
            "[meta] cb#115 loss=0.393408 step=0.007632 g_raw=-0.002 g_sm=+0.011 acc=1 | LR→0.218796 PERT→0.140070 (scale=0.04)\n",
            "[meta] cb#120 loss=0.390157 step=0.003021 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.219235 PERT→0.140070 (scale=0.04)\n",
            "[meta] cb#125 loss=0.382039 step=0.1102 g_raw=+0.024 g_sm=+0.012 acc=1 | LR→0.219674 PERT→0.140070 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.2174860501, PERT_used=0.1400689373 → LR_next=0.2196741887, PERT_next=0.1400704469\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.2174860501→0.2196741887 PERT 0.1400689373→0.1400704469\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.63\n",
            "[round 8 | client 4] final LR=0.2196741887, final PERT=0.1400704469  (ΔLR=+0.0107252852, ΔPERT=+0.0000078083)\n",
            "\n",
            "[Round 8] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           3      0.533060      0.705000      0.219680      0.140074\n",
            "           2      0.566547      0.680000      0.219662      0.140063\n",
            "           1      0.571210      0.685000      0.219669      0.140067\n",
            "           4      0.614784      0.630000      0.219674      0.140070\n",
            "           0      0.615336      0.695000      0.219674      0.140070\n",
            "→ [Round 8] best_client=3, best_val=0.533060, prev_global_val=0.527344, improve=-0.005717, action=hold (τ=0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  18%|█▊        | 9/50 [2:15:11<10:14:06, 898.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   8] acc_g=0.773 (μ=0.679, σ=0.026, FG=0.051) | t=873.561s, val=0.529 | TEL=FALSE\n",
            "[Round 9] Teleportation OFF | Aggregation=best\n",
            "[round 9 | client 0] seed LR=0.2196739583 (prev=0.2196739583), seed PERT=0.1400703000 (prev=0.1400703000), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.512122 step=0.1136 g_raw=+0.030 g_sm=+0.004 acc=1 | LR→0.220114 PERT→0.140070 (scale=0.04)\n",
            "[meta] cb#010 loss=0.495458 step=0.08394 g_raw=+0.022 g_sm=+0.009 acc=1 | LR→0.220555 PERT→0.140071 (scale=0.04)\n",
            "[meta] cb#015 loss=0.484709 step=0.06592 g_raw=+0.014 g_sm=+0.011 acc=1 | LR→0.220997 PERT→0.140071 (scale=0.04)\n",
            "[meta] cb#020 loss=0.475572 step=0.03656 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.221440 PERT→0.140071 (scale=0.04)\n",
            "[meta] cb#025 loss=0.465012 step=0.01562 g_raw=+0.005 g_sm=+0.014 acc=1 | LR→0.221884 PERT→0.140072 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.2196739583, PERT_used=0.1400703000 → LR_next=0.2218837349, PERT_next=0.1400715731\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.2196739583→0.2218837349 PERT 0.1400703000→0.1400715731\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.443432 step=0.1574 g_raw=+0.040 g_sm=+0.018 acc=1 | LR→0.222329 PERT→0.140072 (scale=0.04)\n",
            "[meta] cb#035 loss=0.414335 step=0.03452 g_raw=+0.008 g_sm=+0.021 acc=1 | LR→0.222775 PERT→0.140073 (scale=0.04)\n",
            "[meta] cb#040 loss=0.412541 step=0.03368 g_raw=+0.009 g_sm=+0.018 acc=1 | LR→0.223222 PERT→0.140073 (scale=0.04)\n",
            "[meta] cb#045 loss=0.402344 step=0.1298 g_raw=+0.032 g_sm=+0.018 acc=1 | LR→0.223669 PERT→0.140074 (scale=0.04)\n",
            "[meta] cb#050 loss=0.395976 step=0.03065 g_raw=+0.008 g_sm=+0.017 acc=1 | LR→0.224118 PERT→0.140074 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.2218837349, PERT_used=0.1400715731 → LR_next=0.2241178494, PERT_next=0.1400741642\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.2218837349→0.2241178494 PERT 0.1400715731→0.1400741642\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.389340 step=0.129 g_raw=+0.027 g_sm=+0.017 acc=1 | LR→0.224567 PERT→0.140075 (scale=0.04)\n",
            "[meta] cb#060 loss=0.385126 step=0.01736 g_raw=+0.003 g_sm=+0.014 acc=1 | LR→0.225018 PERT→0.140075 (scale=0.04)\n",
            "[meta] cb#065 loss=0.375978 step=0.06822 g_raw=+0.017 g_sm=+0.015 acc=1 | LR→0.225469 PERT→0.140075 (scale=0.04)\n",
            "[meta] cb#070 loss=0.371593 step=0.003881 g_raw=+0.001 g_sm=+0.014 acc=1 | LR→0.225921 PERT→0.140076 (scale=0.04)\n",
            "[meta] cb#075 loss=0.364817 step=0.02159 g_raw=-0.000 g_sm=+0.013 acc=1 | LR→0.226374 PERT→0.140076 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.2241178494, PERT_used=0.1400741642 → LR_next=0.2263736577, PERT_next=0.1400762597\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.2241178494→0.2263736577 PERT 0.1400741642→0.1400762597\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.362119 step=0.04679 g_raw=+0.013 g_sm=+0.012 acc=1 | LR→0.226827 PERT→0.140077 (scale=0.04)\n",
            "[meta] cb#085 loss=0.357481 step=0.0682 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.227282 PERT→0.140077 (scale=0.04)\n",
            "[meta] cb#090 loss=0.354614 step=0.02596 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.227738 PERT→0.140077 (scale=0.04)\n",
            "[meta] cb#095 loss=0.352678 step=0.02474 g_raw=+0.009 g_sm=+0.010 acc=1 | LR→0.228194 PERT→0.140078 (scale=0.04)\n",
            "[meta] cb#100 loss=0.352423 step=0.0141 g_raw=+0.001 g_sm=+0.009 acc=1 | LR→0.228651 PERT→0.140078 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.2263736577, PERT_used=0.1400762597 → LR_next=0.2286513357, PERT_next=0.1400778433\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.2263736577→0.2286513357 PERT 0.1400762597→0.1400778433\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.351527 step=0.0116 g_raw=+0.004 g_sm=+0.008 acc=1 | LR→0.229109 PERT→0.140078 (scale=0.04)\n",
            "[meta] cb#110 loss=0.346932 step=0.009878 g_raw=+0.004 g_sm=+0.009 acc=1 | LR→0.229569 PERT→0.140078 (scale=0.04)\n",
            "[meta] cb#115 loss=0.345837 step=0.003642 g_raw=+0.002 g_sm=+0.008 acc=1 | LR→0.230029 PERT→0.140079 (scale=0.04)\n",
            "[meta] cb#120 loss=0.344104 step=0.06743 g_raw=+0.011 g_sm=+0.008 acc=1 | LR→0.230489 PERT→0.140079 (scale=0.04)\n",
            "[meta] cb#125 loss=0.343033 step=0.04468 g_raw=+0.006 g_sm=+0.007 acc=1 | LR→0.230951 PERT→0.140079 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.2286513357, PERT_used=0.1400778433 → LR_next=0.2309511750, PERT_next=0.1400789685\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.2286513357→0.2309511750 PERT 0.1400778433→0.1400789685\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.69\n",
            "[round 9 | client 0] final LR=0.2309511750, final PERT=0.1400789685  (ΔLR=+0.0112772167, ΔPERT=+0.0000086685)\n",
            "[round 9 | client 1] seed LR=0.2196685773 (prev=0.2196685773), seed PERT=0.1400668689 (prev=0.1400668689), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.514068 step=0.04774 g_raw=+0.012 g_sm=+0.002 acc=1 | LR→0.220108 PERT→0.140067 (scale=0.04)\n",
            "[meta] cb#010 loss=0.508370 step=0.09373 g_raw=+0.025 g_sm=+0.005 acc=1 | LR→0.220549 PERT→0.140067 (scale=0.04)\n",
            "[meta] cb#015 loss=0.504826 step=0.04746 g_raw=+0.012 g_sm=+0.007 acc=1 | LR→0.220991 PERT→0.140067 (scale=0.04)\n",
            "[meta] cb#020 loss=0.497995 step=0.1272 g_raw=+0.029 g_sm=+0.009 acc=1 | LR→0.221434 PERT→0.140067 (scale=0.04)\n",
            "[meta] cb#025 loss=0.490044 step=0.1433 g_raw=+0.034 g_sm=+0.011 acc=1 | LR→0.221878 PERT→0.140068 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.2196685773, PERT_used=0.1400668689 → LR_next=0.2218775489, PERT_next=0.1400676679\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.2196685773→0.2218775489 PERT 0.1400668689→0.1400676679\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.55\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.473666 step=0.1323 g_raw=+0.030 g_sm=+0.014 acc=1 | LR→0.222322 PERT→0.140068 (scale=0.04)\n",
            "[meta] cb#035 loss=0.455887 step=0.1725 g_raw=+0.044 g_sm=+0.017 acc=1 | LR→0.222768 PERT→0.140068 (scale=0.04)\n",
            "[meta] cb#040 loss=0.452997 step=0.08775 g_raw=+0.022 g_sm=+0.015 acc=1 | LR→0.223215 PERT→0.140069 (scale=0.04)\n",
            "[meta] cb#045 loss=0.450672 step=0.001057 g_raw=+0.001 g_sm=+0.014 acc=1 | LR→0.223662 PERT→0.140069 (scale=0.04)\n",
            "[meta] cb#050 loss=0.441645 step=0.002782 g_raw=+0.001 g_sm=+0.015 acc=1 | LR→0.224111 PERT→0.140070 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.2218775489, PERT_used=0.1400676679 → LR_next=0.2241107426, PERT_next=0.1400697225\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.2218775489→0.2241107426 PERT 0.1400676679→0.1400697225\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.436167 step=0.1264 g_raw=+0.030 g_sm=+0.015 acc=1 | LR→0.224560 PERT→0.140070 (scale=0.04)\n",
            "[meta] cb#060 loss=0.430318 step=0.0005169 g_raw=-0.000 g_sm=+0.014 acc=1 | LR→0.225010 PERT→0.140071 (scale=0.04)\n",
            "[meta] cb#065 loss=0.428231 step=0.01341 g_raw=+0.004 g_sm=+0.013 acc=1 | LR→0.225461 PERT→0.140071 (scale=0.04)\n",
            "[meta] cb#070 loss=0.416973 step=0.04595 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.225913 PERT→0.140071 (scale=0.04)\n",
            "[meta] cb#075 loss=0.410139 step=0.0212 g_raw=+0.003 g_sm=+0.014 acc=1 | LR→0.226366 PERT→0.140072 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.2241107426, PERT_used=0.1400697225 → LR_next=0.2263663123, PERT_next=0.1400717145\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.2241107426→0.2263663123 PERT 0.1400697225→0.1400717145\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.403648 step=0.08962 g_raw=+0.021 g_sm=+0.014 acc=1 | LR→0.226820 PERT→0.140072 (scale=0.04)\n",
            "[meta] cb#085 loss=0.402256 step=0.02326 g_raw=+0.005 g_sm=+0.013 acc=1 | LR→0.227275 PERT→0.140072 (scale=0.04)\n",
            "[meta] cb#090 loss=0.400983 step=0.02753 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.227730 PERT→0.140073 (scale=0.04)\n",
            "[meta] cb#095 loss=0.397902 step=0.07363 g_raw=+0.014 g_sm=+0.011 acc=1 | LR→0.228187 PERT→0.140073 (scale=0.04)\n",
            "[meta] cb#100 loss=0.393462 step=0.0003699 g_raw=+0.001 g_sm=+0.011 acc=1 | LR→0.228644 PERT→0.140073 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.2263663123, PERT_used=0.1400717145 → LR_next=0.2286441806, PERT_next=0.1400734599\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.2263663123→0.2286441806 PERT 0.1400717145→0.1400734599\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.74\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.389897 step=0.0367 g_raw=+0.010 g_sm=+0.011 acc=1 | LR→0.229102 PERT→0.140074 (scale=0.04)\n",
            "[meta] cb#110 loss=0.385458 step=0.02419 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.229562 PERT→0.140074 (scale=0.04)\n",
            "[meta] cb#115 loss=0.380875 step=0.1235 g_raw=+0.023 g_sm=+0.012 acc=1 | LR→0.230022 PERT→0.140074 (scale=0.04)\n",
            "[meta] cb#120 loss=0.376037 step=0.09462 g_raw=+0.018 g_sm=+0.012 acc=1 | LR→0.230483 PERT→0.140075 (scale=0.04)\n",
            "[meta] cb#125 loss=0.365796 step=0.01713 g_raw=+0.004 g_sm=+0.013 acc=1 | LR→0.230945 PERT→0.140075 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.2286441806, PERT_used=0.1400734599 → LR_next=0.2309448238, PERT_next=0.1400751163\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.2286441806→0.2309448238 PERT 0.1400734599→0.1400751163\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.78\n",
            "[round 9 | client 1] final LR=0.2309448238, final PERT=0.1400751163  (ΔLR=+0.0112762465, ΔPERT=+0.0000082474)\n",
            "[round 9 | client 2] seed LR=0.2196621514 (prev=0.2196621514), seed PERT=0.1400627716 (prev=0.1400627716), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.504820 step=0.04247 g_raw=+0.009 g_sm=+0.003 acc=1 | LR→0.220102 PERT→0.140063 (scale=0.04)\n",
            "[meta] cb#010 loss=0.499918 step=0.01416 g_raw=+0.003 g_sm=+0.005 acc=1 | LR→0.220543 PERT→0.140063 (scale=0.04)\n",
            "[meta] cb#015 loss=0.488999 step=0.0372 g_raw=+0.008 g_sm=+0.008 acc=1 | LR→0.220985 PERT→0.140063 (scale=0.04)\n",
            "[meta] cb#020 loss=0.484325 step=0.05022 g_raw=+0.013 g_sm=+0.009 acc=1 | LR→0.221427 PERT→0.140063 (scale=0.04)\n",
            "[meta] cb#025 loss=0.479765 step=0.01761 g_raw=+0.006 g_sm=+0.010 acc=1 | LR→0.221871 PERT→0.140064 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.2196621514, PERT_used=0.1400627716 → LR_next=0.2218711588, PERT_next=0.1400636340\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.2196621514→0.2218711588 PERT 0.1400627716→0.1400636340\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.478387 step=0.005247 g_raw=+0.001 g_sm=+0.009 acc=1 | LR→0.222316 PERT→0.140064 (scale=0.04)\n",
            "[meta] cb#035 loss=0.461780 step=0.1301 g_raw=+0.037 g_sm=+0.012 acc=1 | LR→0.222761 PERT→0.140064 (scale=0.04)\n",
            "[meta] cb#040 loss=0.447277 step=0.06638 g_raw=+0.014 g_sm=+0.015 acc=1 | LR→0.223208 PERT→0.140065 (scale=0.04)\n",
            "[meta] cb#045 loss=0.438216 step=0.02686 g_raw=+0.003 g_sm=+0.015 acc=1 | LR→0.223655 PERT→0.140065 (scale=0.04)\n",
            "[meta] cb#050 loss=0.425781 step=0.1298 g_raw=+0.027 g_sm=+0.017 acc=1 | LR→0.224104 PERT→0.140065 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.2218711588, PERT_used=0.1400636340 → LR_next=0.2241039034, PERT_next=0.1400654480\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.2218711588→0.2241039034 PERT 0.1400636340→0.1400654480\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.419502 step=0.09337 g_raw=+0.022 g_sm=+0.016 acc=1 | LR→0.224553 PERT→0.140066 (scale=0.04)\n",
            "[meta] cb#060 loss=0.412596 step=0.09502 g_raw=+0.020 g_sm=+0.016 acc=1 | LR→0.225004 PERT→0.140066 (scale=0.04)\n",
            "[meta] cb#065 loss=0.408701 step=0.04159 g_raw=+0.011 g_sm=+0.015 acc=1 | LR→0.225455 PERT→0.140067 (scale=0.04)\n",
            "[meta] cb#070 loss=0.406218 step=0.04444 g_raw=+0.007 g_sm=+0.014 acc=1 | LR→0.225907 PERT→0.140067 (scale=0.04)\n",
            "[meta] cb#075 loss=0.403949 step=0.09069 g_raw=+0.017 g_sm=+0.012 acc=1 | LR→0.226360 PERT→0.140068 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.2241039034, PERT_used=0.1400654480 → LR_next=0.2263595775, PERT_next=0.1400675471\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.2241039034→0.2263595775 PERT 0.1400654480→0.1400675471\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.398724 step=0.05925 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.226813 PERT→0.140068 (scale=0.04)\n",
            "[meta] cb#085 loss=0.397069 step=0.05969 g_raw=+0.016 g_sm=+0.012 acc=1 | LR→0.227268 PERT→0.140068 (scale=0.04)\n",
            "[meta] cb#090 loss=0.392959 step=0.04634 g_raw=+0.010 g_sm=+0.012 acc=1 | LR→0.227723 PERT→0.140069 (scale=0.04)\n",
            "[meta] cb#095 loss=0.391704 step=0.03792 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.228180 PERT→0.140069 (scale=0.04)\n",
            "[meta] cb#100 loss=0.391378 step=0.0069 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.228637 PERT→0.140069 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.2263595775, PERT_used=0.1400675471 → LR_next=0.2286370929, PERT_next=0.1400691178\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.2263595775→0.2286370929 PERT 0.1400675471→0.1400691178\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.389507 step=0.04133 g_raw=+0.009 g_sm=+0.009 acc=1 | LR→0.229095 PERT→0.140069 (scale=0.04)\n",
            "[meta] cb#110 loss=0.386407 step=0.01322 g_raw=-0.000 g_sm=+0.008 acc=1 | LR→0.229554 PERT→0.140070 (scale=0.04)\n",
            "[meta] cb#115 loss=0.384957 step=0.04242 g_raw=+0.009 g_sm=+0.008 acc=1 | LR→0.230014 PERT→0.140070 (scale=0.04)\n",
            "[meta] cb#120 loss=0.384813 step=0.003501 g_raw=+0.003 g_sm=+0.007 acc=1 | LR→0.230475 PERT→0.140070 (scale=0.04)\n",
            "[meta] cb#125 loss=0.381409 step=0.02249 g_raw=+0.009 g_sm=+0.008 acc=1 | LR→0.230937 PERT→0.140070 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.2286370929, PERT_used=0.1400691178 → LR_next=0.2309367561, PERT_next=0.1400702230\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.2286370929→0.2309367561 PERT 0.1400691178→0.1400702230\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.56\n",
            "[round 9 | client 2] final LR=0.2309367561, final PERT=0.1400702230  (ΔLR=+0.0112746047, ΔPERT=+0.0000074515)\n",
            "[round 9 | client 3] seed LR=0.2196801312 (prev=0.2196801312), seed PERT=0.1400742360 (prev=0.1400742360), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.479348 step=0.1207 g_raw=+0.037 g_sm=+0.007 acc=1 | LR→0.220120 PERT→0.140074 (scale=0.04)\n",
            "[meta] cb#010 loss=0.467804 step=0.0223 g_raw=+0.007 g_sm=+0.009 acc=1 | LR→0.220561 PERT→0.140075 (scale=0.04)\n",
            "[meta] cb#015 loss=0.454987 step=0.1198 g_raw=+0.031 g_sm=+0.012 acc=1 | LR→0.221003 PERT→0.140075 (scale=0.04)\n",
            "[meta] cb#020 loss=0.445249 step=0.008088 g_raw=+0.000 g_sm=+0.013 acc=1 | LR→0.221446 PERT→0.140075 (scale=0.04)\n",
            "[meta] cb#025 loss=0.441171 step=0.07777 g_raw=+0.017 g_sm=+0.013 acc=1 | LR→0.221890 PERT→0.140076 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.2196801312, PERT_used=0.1400742360 → LR_next=0.2218900452, PERT_next=0.1400755566\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.2196801312→0.2218900452 PERT 0.1400742360→0.1400755566\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.432228 step=0.04688 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.222335 PERT→0.140076 (scale=0.04)\n",
            "[meta] cb#035 loss=0.423544 step=0.05364 g_raw=+0.013 g_sm=+0.015 acc=1 | LR→0.222781 PERT→0.140076 (scale=0.04)\n",
            "[meta] cb#040 loss=0.423105 step=0.007959 g_raw=+0.004 g_sm=+0.013 acc=1 | LR→0.223227 PERT→0.140077 (scale=0.04)\n",
            "[meta] cb#045 loss=0.412976 step=0.07783 g_raw=+0.017 g_sm=+0.014 acc=1 | LR→0.223675 PERT→0.140077 (scale=0.04)\n",
            "[meta] cb#050 loss=0.405947 step=0.1057 g_raw=+0.022 g_sm=+0.014 acc=1 | LR→0.224123 PERT→0.140078 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.2218900452, PERT_used=0.1400755566 → LR_next=0.2241232218, PERT_next=0.1400775220\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.2218900452→0.2241232218 PERT 0.1400755566→0.1400775220\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.403992 step=0.009033 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.224573 PERT→0.140078 (scale=0.04)\n",
            "[meta] cb#060 loss=0.403037 step=0.006709 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.225023 PERT→0.140078 (scale=0.04)\n",
            "[meta] cb#065 loss=0.400164 step=0.05318 g_raw=+0.012 g_sm=+0.010 acc=1 | LR→0.225474 PERT→0.140079 (scale=0.04)\n",
            "[meta] cb#070 loss=0.397649 step=0.007115 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.225925 PERT→0.140079 (scale=0.04)\n",
            "[meta] cb#075 loss=0.394164 step=0.06675 g_raw=+0.016 g_sm=+0.010 acc=1 | LR→0.226378 PERT→0.140079 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.2241232218, PERT_used=0.1400775220 → LR_next=0.2263782480, PERT_next=0.1400791002\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.2241232218→0.2263782480 PERT 0.1400775220→0.1400791002\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.393588 step=0.04213 g_raw=+0.006 g_sm=+0.009 acc=1 | LR→0.226832 PERT→0.140079 (scale=0.04)\n",
            "[meta] cb#085 loss=0.392282 step=0.04284 g_raw=+0.006 g_sm=+0.008 acc=1 | LR→0.227286 PERT→0.140080 (scale=0.04)\n",
            "[meta] cb#090 loss=0.391219 step=0.03136 g_raw=+0.008 g_sm=+0.008 acc=1 | LR→0.227742 PERT→0.140080 (scale=0.04)\n",
            "[meta] cb#095 loss=0.389876 step=0.028 g_raw=+0.007 g_sm=+0.007 acc=1 | LR→0.228198 PERT→0.140080 (scale=0.04)\n",
            "[meta] cb#100 loss=0.387617 step=0.07704 g_raw=+0.013 g_sm=+0.008 acc=1 | LR→0.228655 PERT→0.140080 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.2263782480, PERT_used=0.1400791002 → LR_next=0.2286552244, PERT_next=0.1400802256\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.006 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.2263782480→0.2286552244 PERT 0.1400791002→0.1400802256\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.386885 step=0.02913 g_raw=+0.010 g_sm=+0.007 acc=1 | LR→0.229113 PERT→0.140080 (scale=0.04)\n",
            "[meta] cb#110 loss=0.385905 step=0.00961 g_raw=-0.000 g_sm=+0.007 acc=1 | LR→0.229572 PERT→0.140081 (scale=0.04)\n",
            "[meta] cb#115 loss=0.384528 step=0.04098 g_raw=+0.007 g_sm=+0.007 acc=1 | LR→0.230032 PERT→0.140081 (scale=0.04)\n",
            "[meta] cb#120 loss=0.383924 step=0.03294 g_raw=+0.007 g_sm=+0.006 acc=1 | LR→0.230493 PERT→0.140081 (scale=0.04)\n",
            "[meta] cb#125 loss=0.383249 step=0.02674 g_raw=+0.007 g_sm=+0.006 acc=1 | LR→0.230955 PERT→0.140081 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.2286552244, PERT_used=0.1400802256 → LR_next=0.2309548081, PERT_next=0.1400811721\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.006 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.2286552244→0.2309548081 PERT 0.1400802256→0.1400811721\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.54\n",
            "[round 9 | client 3] final LR=0.2309548081, final PERT=0.1400811721  (ΔLR=+0.0112746769, ΔPERT=+0.0000069361)\n",
            "[round 9 | client 4] seed LR=0.2196741887 (prev=0.2196741887), seed PERT=0.1400704469 (prev=0.1400704469), gamma=1.00\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.446977 step=0.06106 g_raw=+0.015 g_sm=+0.003 acc=1 | LR→0.220114 PERT→0.140071 (scale=0.04)\n",
            "[meta] cb#010 loss=0.438402 step=0.06962 g_raw=+0.012 g_sm=+0.006 acc=1 | LR→0.220555 PERT→0.140071 (scale=0.04)\n",
            "[meta] cb#015 loss=0.427871 step=0.01886 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.220997 PERT→0.140071 (scale=0.04)\n",
            "[meta] cb#020 loss=0.422038 step=0.02507 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.221440 PERT→0.140071 (scale=0.04)\n",
            "[meta] cb#025 loss=0.417621 step=0.0289 g_raw=+0.008 g_sm=+0.010 acc=1 | LR→0.221884 PERT→0.140071 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.2196741887, PERT_used=0.1400704469 → LR_next=0.2218835343, PERT_next=0.1400714464\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.2196741887→0.2218835343 PERT 0.1400704469→0.1400714464\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.414795 step=0.08294 g_raw=+0.021 g_sm=+0.010 acc=1 | LR→0.222328 PERT→0.140072 (scale=0.04)\n",
            "[meta] cb#035 loss=0.413298 step=0.03275 g_raw=+0.009 g_sm=+0.010 acc=1 | LR→0.222774 PERT→0.140072 (scale=0.04)\n",
            "[meta] cb#040 loss=0.410782 step=0.05908 g_raw=+0.013 g_sm=+0.010 acc=1 | LR→0.223220 PERT→0.140072 (scale=0.04)\n",
            "[meta] cb#045 loss=0.408407 step=0.07725 g_raw=+0.020 g_sm=+0.010 acc=1 | LR→0.223667 PERT→0.140073 (scale=0.04)\n",
            "[meta] cb#050 loss=0.406679 step=0.04223 g_raw=+0.011 g_sm=+0.009 acc=1 | LR→0.224116 PERT→0.140073 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.2218835343, PERT_used=0.1400714464 → LR_next=0.2241156739, PERT_next=0.1400728046\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.2218835343→0.2241156739 PERT 0.1400714464→0.1400728046\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.404404 step=0.0854 g_raw=+0.020 g_sm=+0.009 acc=1 | LR→0.224565 PERT→0.140073 (scale=0.04)\n",
            "[meta] cb#060 loss=0.403828 step=0.04717 g_raw=+0.010 g_sm=+0.008 acc=1 | LR→0.225015 PERT→0.140073 (scale=0.04)\n",
            "[meta] cb#065 loss=0.402415 step=0.05356 g_raw=+0.014 g_sm=+0.008 acc=1 | LR→0.225466 PERT→0.140073 (scale=0.04)\n",
            "[meta] cb#070 loss=0.401319 step=0.04771 g_raw=+0.012 g_sm=+0.007 acc=1 | LR→0.225917 PERT→0.140074 (scale=0.04)\n",
            "[meta] cb#075 loss=0.398915 step=0.06302 g_raw=+0.010 g_sm=+0.008 acc=1 | LR→0.226370 PERT→0.140074 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.2241156739, PERT_used=0.1400728046 → LR_next=0.2263698483, PERT_next=0.1400739025\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.2241156739→0.2263698483 PERT 0.1400728046→0.1400739025\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.398478 step=0.005652 g_raw=+0.003 g_sm=+0.007 acc=1 | LR→0.226823 PERT→0.140074 (scale=0.04)\n",
            "[meta] cb#085 loss=0.396451 step=0.05076 g_raw=+0.008 g_sm=+0.007 acc=1 | LR→0.227278 PERT→0.140074 (scale=0.04)\n",
            "[meta] cb#090 loss=0.394451 step=0.002563 g_raw=+0.001 g_sm=+0.008 acc=1 | LR→0.227733 PERT→0.140075 (scale=0.04)\n",
            "[meta] cb#095 loss=0.393923 step=0.0168 g_raw=+0.004 g_sm=+0.007 acc=1 | LR→0.228189 PERT→0.140075 (scale=0.04)\n",
            "[meta] cb#100 loss=0.393690 step=0.005659 g_raw=+0.003 g_sm=+0.006 acc=1 | LR→0.228647 PERT→0.140075 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.2263698483, PERT_used=0.1400739025 → LR_next=0.2286465459, PERT_next=0.1400749090\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.006 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.2263698483→0.2286465459 PERT 0.1400739025→0.1400749090\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.392946 step=0.009087 g_raw=+0.005 g_sm=+0.005 acc=1 | LR→0.229105 PERT→0.140075 (scale=0.04)\n",
            "[meta] cb#110 loss=0.391516 step=0.03354 g_raw=+0.007 g_sm=+0.006 acc=1 | LR→0.229563 PERT→0.140075 (scale=0.04)\n",
            "[meta] cb#115 loss=0.389998 step=0.02946 g_raw=+0.005 g_sm=+0.006 acc=1 | LR→0.230023 PERT→0.140075 (scale=0.04)\n",
            "[meta] cb#120 loss=0.389672 step=0.0202 g_raw=-0.000 g_sm=+0.005 acc=1 | LR→0.230484 PERT→0.140076 (scale=0.04)\n",
            "[meta] cb#125 loss=0.388145 step=0.03293 g_raw=+0.009 g_sm=+0.006 acc=1 | LR→0.230946 PERT→0.140076 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.2286465459, PERT_used=0.1400749090 → LR_next=0.2309457999, PERT_next=0.1400757084\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.006 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.2286465459→0.2309457999 PERT 0.1400749090→0.1400757084\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.70\n",
            "[round 9 | client 4] final LR=0.2309457999, final PERT=0.1400757084  (ΔLR=+0.0112716112, ΔPERT=+0.0000052615)\n",
            "\n",
            "[Round 9] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           1      0.507160      0.780000      0.230945      0.140075\n",
            "           0      0.537873      0.695000      0.230951      0.140079\n",
            "           4      0.559236      0.705000      0.230946      0.140076\n",
            "           3      0.581404      0.535000      0.230955      0.140081\n",
            "           2      0.583014      0.560000      0.230937      0.140070\n",
            "→ [Round 9] best_client=1, best_val=0.507160, prev_global_val=0.529172, improve=+0.022012, action=adopt+mix τ=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 50/50 [2:31:11<00:00, 181.43s/it]   "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   9] acc_g=0.754 (μ=0.655, σ=0.093, FG=0.205) | t=943.841s, val=0.549 | TEL=FALSE\n",
            "[Round 10] Teleportation OFF | Aggregation=best\n",
            "[Round 10] No eligible clients; skipping global update.\n",
            "[Round 11] Teleportation OFF | Aggregation=best\n",
            "[Round 11] No eligible clients; skipping global update.\n",
            "[Round 12] Teleportation OFF | Aggregation=best\n",
            "[Round 12] No eligible clients; skipping global update.\n",
            "[Round 13] Teleportation OFF | Aggregation=best\n",
            "[Round 13] No eligible clients; skipping global update.\n",
            "[Round 14] Teleportation OFF | Aggregation=best\n",
            "[Round 14] No eligible clients; skipping global update.\n",
            "[Round 15] Teleportation OFF | Aggregation=best\n",
            "[Round 15] No eligible clients; skipping global update.\n",
            "[Round 16] Teleportation OFF | Aggregation=best\n",
            "[Round 16] No eligible clients; skipping global update.\n",
            "[Round 17] Teleportation OFF | Aggregation=best\n",
            "[Round 17] No eligible clients; skipping global update.\n",
            "[Round 18] Teleportation OFF | Aggregation=best\n",
            "[Round 18] No eligible clients; skipping global update.\n",
            "[Round 19] Teleportation OFF | Aggregation=best\n",
            "[Round 19] No eligible clients; skipping global update.\n",
            "[Round 20] Teleportation OFF | Aggregation=best\n",
            "[Round 20] No eligible clients; skipping global update.\n",
            "[Round 21] Teleportation OFF | Aggregation=best\n",
            "[Round 21] No eligible clients; skipping global update.\n",
            "[Round 22] Teleportation OFF | Aggregation=best\n",
            "[Round 22] No eligible clients; skipping global update.\n",
            "[Round 23] Teleportation OFF | Aggregation=best\n",
            "[Round 23] No eligible clients; skipping global update.\n",
            "[Round 24] Teleportation OFF | Aggregation=best\n",
            "[Round 24] No eligible clients; skipping global update.\n",
            "[Round 25] Teleportation OFF | Aggregation=best\n",
            "[Round 25] No eligible clients; skipping global update.\n",
            "[Round 26] Teleportation OFF | Aggregation=best\n",
            "[Round 26] No eligible clients; skipping global update.\n",
            "[Round 27] Teleportation OFF | Aggregation=best\n",
            "[Round 27] No eligible clients; skipping global update.\n",
            "[Round 28] Teleportation OFF | Aggregation=best\n",
            "[Round 28] No eligible clients; skipping global update.\n",
            "[Round 29] Teleportation OFF | Aggregation=best\n",
            "[Round 29] No eligible clients; skipping global update.\n",
            "[Round 30] Teleportation OFF | Aggregation=best\n",
            "[Round 30] No eligible clients; skipping global update.\n",
            "[Round 31] Teleportation OFF | Aggregation=best\n",
            "[Round 31] No eligible clients; skipping global update.\n",
            "[Round 32] Teleportation OFF | Aggregation=best\n",
            "[Round 32] No eligible clients; skipping global update.\n",
            "[Round 33] Teleportation OFF | Aggregation=best\n",
            "[Round 33] No eligible clients; skipping global update.\n",
            "[Round 34] Teleportation OFF | Aggregation=best\n",
            "[Round 34] No eligible clients; skipping global update.\n",
            "[Round 35] Teleportation OFF | Aggregation=best\n",
            "[Round 35] No eligible clients; skipping global update.\n",
            "[Round 36] Teleportation OFF | Aggregation=best\n",
            "[Round 36] No eligible clients; skipping global update.\n",
            "[Round 37] Teleportation OFF | Aggregation=best\n",
            "[Round 37] No eligible clients; skipping global update.\n",
            "[Round 38] Teleportation OFF | Aggregation=best\n",
            "[Round 38] No eligible clients; skipping global update.\n",
            "[Round 39] Teleportation OFF | Aggregation=best\n",
            "[Round 39] No eligible clients; skipping global update.\n",
            "[Round 40] Teleportation OFF | Aggregation=best\n",
            "[Round 40] No eligible clients; skipping global update.\n",
            "[Round 41] Teleportation OFF | Aggregation=best\n",
            "[Round 41] No eligible clients; skipping global update.\n",
            "[Round 42] Teleportation OFF | Aggregation=best\n",
            "[Round 42] No eligible clients; skipping global update.\n",
            "[Round 43] Teleportation OFF | Aggregation=best\n",
            "[Round 43] No eligible clients; skipping global update.\n",
            "[Round 44] Teleportation OFF | Aggregation=best\n",
            "[Round 44] No eligible clients; skipping global update.\n",
            "[Round 45] Teleportation OFF | Aggregation=best\n",
            "[Round 45] No eligible clients; skipping global update.\n",
            "[Round 46] Teleportation OFF | Aggregation=best\n",
            "[Round 46] No eligible clients; skipping global update.\n",
            "[Round 47] Teleportation OFF | Aggregation=best\n",
            "[Round 47] No eligible clients; skipping global update.\n",
            "[Round 48] Teleportation OFF | Aggregation=best\n",
            "[Round 48] No eligible clients; skipping global update.\n",
            "[Round 49] Teleportation OFF | Aggregation=best\n",
            "[Round 49] No eligible clients; skipping global update.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 650x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAGGCAYAAADrfDCjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAhJBJREFUeJzt3Xd8U/X6B/BPko50l+5JB7tQyi5lyFRcFRzIkKnCDwRB6/UKClQcgHrlorLUCzgA4XoVFQcClb0KlNFKKXRAoXSX7p2c3x9pQkNb2pSmJ2k+79erL9KTM57kpOXpdzxfiSAIAoiIiIjIZEjFDoCIiIiIWhcTQCIiIiITwwSQiIiIyMQwASQiIiIyMUwAiYiIiEwME0AiIiIiE8MEkIiIiMjEMAEkIiIiMjFMAImIiIhMDBNAojbo7bffhkQiadax/v7+ePzxx1sslmvXrkEikeCrr75qsXNSw6Kjo2FhYYHr16+LHUqbtXHjRrRv3x4VFRVih0LUbEwAiYxESkoK5s+fj86dO8Pa2hrW1tYICgrCvHnzcPHiRbHDIwPx1ltvYdKkSfDz89NsGz58OCQSCSQSCaRSKezt7dGlSxdMnToV+/bt0zpe/cdDY1/Dhw+v9/oHDx7U2s/S0hLu7u4YPnw4VqxYgezs7DrHqK+Zk5NT7zl79OhR7/Vyc3Px+uuvo0uXLpDL5XBycsKYMWPw22+/1dlX/YdIfV8DBw7U7DdjxgzY2trWG0ftfSorK/H555/fcz8iQ2YmdgBE1Lhff/0VEyZMgJmZGZ577jmEhIRAKpXi8uXL+PHHH7FhwwakpKRo/adPpuf8+fPYv38/jh8/Xuc5Hx8frFy5EgBQUlKCxMRE/Pjjj9i6dSueffZZbN26Febm5njqqafQsWNHzXHFxcWYO3cunnzySTz11FOa7e7u7veMZcGCBejfvz8UCgWys7Nx/PhxREZGYvXq1fjvf/+LkSNH3tdrTUhIwKhRo5CdnY2ZM2eiX79+yM/Px7Zt2/D444/jjTfewKpVq+ocN2nSJDz66KNa21xdXXW6tlwux/Tp07F69Wq8/PLLzW5tJxITE0AiA5eUlISJEyfCz88PUVFR8PT01Hr+gw8+wPr16yGVskG/NZWUlMDGxkbsMLRs2bIF7du312rRUnNwcMCUKVO0tq1atQoLFizA+vXr4e/vjw8++AA9e/ZEz549Nfvk5ORg7ty56NmzZ53j72Xo0KF45plntLZduHABDz30EJ5++mlcunSpzme5qaqqqvDMM8/g9u3bOHz4MEJDQzXPvfrqq3juuefwwQcfoG/fvhg/frzWsX369NHpdTTk2WefxYcffogDBw7cdzJLJAb+j0Fk4D788EOUlJRgy5Yt9f6HaWZmhgULFsDX1/ee56mursa7776LDh06wNLSEv7+/njzzTcbHMe0d+9e9OrVC3K5HEFBQfjxxx+1ns/Ly8M//vEPBAcHw9bWFvb29njkkUdw4cKFZr1OXc5XXl6Ot99+G507d4ZcLoenpyeeeuopJCUlafZRKpX45JNPEBwcDLlcDldXVzz88MM4c+YMgHuPTZRIJHj77bc136u7KC9duoTJkyejXbt2GDJkCADg4sWLmDFjBgIDAyGXy+Hh4YHnn38eubm5dc6blpaGF154AV5eXrC0tERAQADmzp2LyspKJCcnQyKR4N///ned444fPw6JRILvvvvunu/hTz/9hJEjRza5RUomk+HTTz9FUFAQ1q5di4KCgiYd11whISFYs2YN8vPzsXbt2maf54cffkBcXBwWLVqklfwBqtf0+eefw9HREZGRkfcbcoP69u0LJycn/Pzzz3q7BpE+MQEkMnC//vorOnbsWOc/Ol29+OKLWLZsGfr06YN///vfGDZsGFauXImJEyfW2ffq1auYMGECHnnkEaxcuRJmZmYYP3681nix5ORk/PTTT3j88cexevVqvP7664iNjcWwYcNw69YtneNr6vkUCgUef/xxLF++HH379sXHH3+MhQsXoqCgAHFxcZr9XnjhBbzyyivw9fXFBx98gEWLFkEul+PkyZM6x6Y2fvx4lJaWYsWKFZg1axYAYN++fUhOTsbMmTPx2WefYeLEidixYwceffRRCIKgOfbWrVsYMGAAduzYgQkTJuDTTz/F1KlTcejQIZSWliIwMBCDBw/Gtm3b6lx327ZtsLOzw9ixYxuMLS0tDampqejTp49Or0kmk2HSpEkoLS3F0aNHdTq2OZ555hlYWVlh7969zT7H7t27AQDTpk2r93kHBweMHTsW8fHxWn8UAEBpaSlycnK0vqqqqpoVR58+fXDs2LFmHUskOoGIDFZBQYEAQBg3blyd527fvi1kZ2drvkpLSzXPRUZGCrV/vM+fPy8AEF588UWtc/zjH/8QAAh//fWXZpufn58AQPjhhx+04vD09BR69+6t2VZeXi4oFAqt86WkpAiWlpbCO++8o7UNgLBly5Z7vtamnm/z5s0CAGH16tV1zqFUKgVBEIS//vpLACAsWLCgwX3uFRcAITIyUvO9+v2cNGlSnX1rv+9q3333nQBAOHz4sGbbtGnTBKlUKpw+fbrBmD7//HMBgBAfH695rrKyUnBxcRGmT59e57ja9u/fLwAQdu/eXee5YcOGCd27d2/w2F27dgkAhE8++aTOc9nZ2XXej3s5cOCAAED4/vvvG9wnJCREaNeuneZ79fubnZ1d7/7du3cXhg0bpvm+V69egoODwz3jWL16tQBA+OWXXwRBuHO/6/s6cOCA5rjp06cLNjY2jb9QQRBmz54tWFlZNWlfIkPDFkAiA1ZYWAgA9c5KHD58OFxdXTVf69ata/A8v//+OwAgIiJCa/trr70GAHVmTXp5eeHJJ5/UfG9vb49p06bh3LlzyMjIAABYWlpqxh0qFArk5ubC1tYWXbp0QUxMjK4vtcnn++GHH+Di4oKXX365zjnUXZ8//PADJBJJvV2A9zNgf86cOXW2WVlZaR6Xl5cjJydHMwZPHbdSqcRPP/2E8PBw9OvXr8GYnn32Wcjlcq1WwD///BM5OTmNjltTdzm3a9dOx1d15/NVVFSk87HNYWtre1/XKioqgp2d3T33UT9/93Vmz56Nffv2aX2FhIQ0K4527dqhrKwMpaWlzTqeSEycBEJkwNT/iRUXF9d57vPPP0dRUREyMzMbTQ6uX78OqVSqNbsTADw8PODo6FinZlzHjh3rJEqdO3cGoBo75+HhoRljt379eqSkpEChUGj2dXZ2bvqLrNHU8yUlJaFLly4wM2v411dSUhK8vLzg5OSkcxz3EhAQUGdbXl4eli9fjh07diArK0vrOfWYuuzsbBQWFqJHjx73PL+joyPCw8Oxfft2vPvuuwBU3b/e3t5Nnmgg1Op2bir156uxpKo29R8Cag4ODlrJcGPX0+VagHbibmdn12DJGDV14ufm5qa1vVOnThg9erRO126I+r3mLGAyRmwBJDJgDg4O8PT01BrbphYaGorRo0dj8ODBTT5fS/5HtWLFCkREROCBBx7A1q1b8eeff2Lfvn3o3r07lEql6OdrTEPvRe3E8271JTjPPvssvvzyS8yZMwc//vgj9u7diz179gBAs+KeNm0akpOTcfz4cRQVFeGXX37BpEmTGp3lrU6Sb9++rfM11Z+vu/9AuBdPT0+tr507dzbpuKqqKly5ckXrWnK5HABQVlZW7zGlpaWafQAgKCgIBQUFSE1NbfA66tqYgYGBTYqrOW7fvg1ra+smJ75EhoQtgEQG7rHHHsN//vMfREdHY8CAAc06h5+fH5RKJa5evYpu3bpptmdmZiI/P79O/cDExEQIgqCVJF25cgWAaqUQAPjf//6HESNGYNOmTVrH5ufnw8XFRecYm3q+Dh064NSpU6iqqoK5uXm95+rQoQP+/PNP5OXlNdgKqO4qzc/P19quywoat2/fRlRUFJYvX45ly5Zptl+9elVrP1dXV9jb29ebyN/t4YcfhqurK7Zt24bQ0FCUlpZi6tSpjR7XtWtXAKqC4bpQKBTYvn07rK2tNTObm+LuAtLdu3dv0nH/+9//UFZWhjFjxmi2qT9/CQkJdWazl5aW4saNG3jooYc029StpN988w2WLFlS5xqFhYX4+eef0adPH70mgCkpKVo/T0TGhC2ARAbun//8J6ytrfH8888jMzOzzvNN6fJTF75ds2aN1vbVq1cDUCWZtd26dQu7du3SfF9YWIhvvvkGvXr1goeHBwDV7NG7r/39998jLS2t8RdVj6ae7+mnn0ZOTk69ZUTUxz/99NMQBAHLly9vcB97e3u4uLjg8OHDWs+vX79ep5hrn1Pt7vdZKpVi3Lhx2L17t6YMTX0xAaqyPpMmTcJ///tffPXVVwgODtaqy9cQb29v+Pr61nv+higUCixYsADx8fFYsGAB7O3tm3zs6NGjtb6aUtPvwoULeOWVV9CuXTvMmzdPs33UqFGwsLDAhg0b6rSafvHFF6iursYjjzyi2fb000+je/fuWLVqVZ3Xq1QqMXfuXNy+fRtvvfVWk19Pc8TExGDQoEF6vQaRvrAFkMjAderUCdu3b8ekSZPQpUsXzUoggiAgJSUF27dvh1QqhY+PT4PnCAkJwfTp0/HFF18gPz8fw4YNQ3R0NL7++muMGzcOI0aM0Nq/c+fOeOGFF3D69Gm4u7tj8+bNyMzMxJYtWzT7PP7443jnnXcwc+ZMDBo0CLGxsdi2bVuzW1yaer5p06bhm2++QUREBKKjozF06FCUlJRg//79eOmllzB27FiMGDECU6dOxaeffoqrV6/i4YcfhlKpxJEjRzBixAjMnz8fgKo0zqpVq/Diiy+iX79+OHz4sKalsyns7e3xwAMP4MMPP0RVVRW8vb2xd+/eelvhVqxYgb1792LYsGGYPXs2unXrhvT0dHz//fc4evQoHB0dtV7jp59+igMHDuCDDz5ocjxjx47Frl276rTeAqrxiFu3bgWgalVTrwSiLjSuHnPYUo4cOYLy8nLNhJ5jx47hl19+gYODA3bt2qX5QwJQjdNbtmwZlixZggceeABPPPEErK2tcfz4cXz33Xd46KGHEB4ertnf3NwcP/zwA0aOHIkhQ4ZorQSyfft2xMTE4M0339RauUQXVVVVeO+99+psd3JywksvvQQAOHv2LPLy8u5ZmofIoIky95iIdJaYmCjMnTtX6NixoyCXywUrKyuha9euwpw5c4Tz589r7Xt3GRhBEISqqiph+fLlQkBAgGBubi74+voKixcvFsrLy7X28/PzEx577DHhzz//FHr27ClYWloKXbt2rVPWo7y8XHjttdcET09PwcrKShg8eLBw4sQJYdiwYVolO3QpA9OU8wmCqvTKW2+9pXktHh4ewjPPPCMkJSVp9qmurhY++ugjoWvXroKFhYXg6uoqPPLII8LZs2e1zvPCCy8IDg4Ogp2dnfDss88KWVlZDZaBqa9Myc2bN4Unn3xScHR0FBwcHITx48cLt27dqrd0yvXr14Vp06YJrq6ugqWlpRAYGCjMmzdPqKioqHPe7t27C1KpVLh58+Y937faYmJiBADCkSNHtLYPGzZMq+yJra2t0KlTJ2HKlCnC3r1773nO5paBUX+Zm5sLrq6uwgMPPCC8//77QlZWVoPHbt26VRg4cKBgY2Oj+dwtX768zme0dmyvvfaa0LFjR8HCwkJzzU2bNtXZV/05/Oijj+4Z//Tp0xssF9OhQwfNfm+88YbQvn17TQkfImMjEYRmTBkjIiK96t27N5ycnBAVFaXTcaNGjYKXlxe+/fZbPUVmuGJjYzF06FD4+vri6NGjcHBw0Mt1Kioq4O/vj0WLFmHhwoV6uQaRvnEMIBGRgTlz5gzOnz/f4EoX97JixQrs3LlTp8ksbUVwcDB+/vlnXL16FePGjUNlZaVerrNlyxaYm5vXWxeSyFiwBZCIyEDExcXh7Nmz+Pjjj5GTk4Pk5GSt8idERC2FLYBERAbif//7H2bOnImqqip89913TP6ISG/YAkhERERkYtgCSERERGRimAASERERmRgWgq6HUqnErVu3YGdnx0W+iYiIyCgIgoCioiJ4eXk1un44E8B63Lp1q856lERERETG4MaNG/dcHQpgAlgvOzs7AKo3UJe1MXWlVCqRnZ0NV1fXRjN1Mky8h8aP99D48R4aP97DllFYWAhfX19NHnMvTADroe72tbe313sCWF5eDnt7e37gjRTvofHjPTR+vIfGj/ewZTVl+BrfZSIiIiITwwSQiIiIyMQwASQiIiIyMUwAiYiIiEwME0AiIiIiE8MEkIiIiMjEMAEkaiaFUsDJ5FzsvZyHk8m5UCgFsUMiIiJqEtYBJGqGPXHpWL77EtILymu2pMDTQY7I8CA83MNT1NiIiIgawxZAIh3tiUvH3K0xtZI/lYyCcszdGoM9cekiRUZERNQ0TACJdKBQCli++xLq6+xVb1u++xK7g4mIyKAxASTSQXRKXp2Wv9oEAOkF5YhOyWu9oIiIiHTEBJBIB1lFDSd/zdmPiIhIDEwAiXTgZidv0f2IiIjEwASQSAcDApzg6dBwcicB4Okgx4AAp9YLioiISEdMAIl0IJNKEBkeVO9zkpp/I8ODIJNK6t2HiIjIEDABJNLRwz08MbiDc53tTjYW2DClD+sAEhGRwWMCSNQMt0ur6mybGubH5I+IiIwCE0AiHZVXKXAlswgA4Gxjodl+MjlXrJCIiIh0wgSQSEeX0gtRXVPoeURXV3jaq5LAmNR8lFcpxAyNiIioSZgAEuko9maB5nGwtwP6+tgBACqrlYhJvS1WWERERE3GBJBIRxdrJYA9vR3Q19dO8/3JJHYDExGR4TMTOwAiY3PxZj4AwFwmQVdPO8gqizXPneA4QCIiMgJsASTSQUlFNRKzVQlfFw87WJrJ4GZnAT9nawDA+Rv5KKvkOEAiIjJsTACJdPD3rUIIqvkfCPZ21GwfFKiqC1ilEHDmep4IkRERETUdE0AiHai7fwEgxMdB83hg4J2l305wHCARERk4JoBEOqg9ASRYKwG8szLIcSaARERk4JgAEukgNk2VAFqaSdHZ/c7sX1c7S3R0s9XsU1xRLUp8RERETcEEkKiJCsqqkJJTAgAI8rKHuUz7xyesphVQoRRwOoXjAImIyHAxASRqorg07fp/dwvrcKcbmOVgiIjIkDEBJGoi7fF/jnWerz0OkBNBiIjIkDEBJGqihmYAqznZWKCrh2pc4N+3ClBQVtVaoREREelE9ARw3bp18Pf3h1wuR2hoKKKjo++5/5o1a9ClSxdYWVnB19cXr776KsrLy7X2SUtLw5QpU+Ds7AwrKysEBwfjzJkz+nwZZALULYDWFjIEutrWu4+6G1gpANEcB0hERAZK1ARw586diIiIQGRkJGJiYhASEoIxY8YgKyur3v23b9+ORYsWITIyEvHx8di0aRN27tyJN998U7PP7du3MXjwYJibm+OPP/7ApUuX8PHHH6Ndu3at9bKoDcotrkBafhkAoIeXA2RSSb37hWmVg8lpldiIiIh0JepawKtXr8asWbMwc+ZMAMDGjRvx22+/YfPmzVi0aFGd/Y8fP47Bgwdj8uTJAAB/f39MmjQJp06d0uzzwQcfwNfXF1u2bNFsCwgI0PMrobbuYu0JIPV0/6qFBjhDIgEEgeMAiYjIcImWAFZWVuLs2bNYvHixZptUKsXo0aNx4sSJeo8ZNGgQtm7diujoaAwYMADJycn4/fffMXXqVM0+v/zyC8aMGYPx48fj0KFD8Pb2xksvvYRZs2Y1GEtFRQUqKio03xcWFgIAlEollErl/b7UBimVSgiCoNdrUMu4eCNf87iHt73mnt19D+3kMnT3tEfcrUJczihCTlE5nGwsxAiZmog/h8aP99D48R62DF3eP9ESwJycHCgUCri7u2ttd3d3x+XLl+s9ZvLkycjJycGQIUMgCAKqq6sxZ84crS7g5ORkbNiwAREREXjzzTdx+vRpLFiwABYWFpg+fXq95125ciWWL19eZ3t2dnad8YUtSalUoqCgAIIgQCoVfTgm3cOZ5DvDErzk1ZphCvXdw54eVoi7pfojYu/5FIzsxOEHhow/h8aP99D48R62jKKioibvK2oXsK4OHjyIFStWYP369QgNDUViYiIWLlyId999F0uXLgWg+hD169cPK1asAAD07t0bcXFx2LhxY4MJ4OLFixEREaH5vrCwEL6+vnB1dYW9vb3eXo9SqYREIoGrqys/8AbuSk4cAMBOboY+nXwhrRkDWN89HNkD2B6TCQCIz63GxMFu4gRNTcKfQ+PHe2j8eA9bhlwub/K+oiWALi4ukMlkyMzM1NqemZkJDw+Peo9ZunQppk6dihdffBEAEBwcjJKSEsyePRtvvfUWpFIpPD09ERQUpHVct27d8MMPPzQYi6WlJSwtLetsl0qlev8gSiSSVrkONV9mYTkyC1VDBHr6OMDMTKb1/N33MDTQGTKpBAqlgJPJeby3RoA/h8aP99D48R7eP13eO9HeZQsLC/Tt2xdRUVGabUqlElFRUQgLC6v3mNLS0jovTiZT/WcsCAIAYPDgwUhISNDa58qVK/Dz82vJ8MmEaBWA9nZsdH87uTmCa1YKuZpVjOyiikaOICIial2iptkRERH48ssv8fXXXyM+Ph5z585FSUmJZlbwtGnTtCaJhIeHY8OGDdixYwdSUlKwb98+LF26FOHh4ZpE8NVXX8XJkyexYsUKJCYmYvv27fjiiy8wb948UV4jGb/YWgWg7zUDuDYuC0dERIZM1DGAEyZMQHZ2NpYtW4aMjAz06tULe/bs0UwMSU1N1WrxW7JkCSQSCZYsWYK0tDS4uroiPDwc77//vmaf/v37Y9euXVi8eDHeeecdBAQEYM2aNXjuueda/fVR23DhZtNKwNQWFuiMDQeTAKjKwTwR4qWX2IiIiJpDIqj7TkmjsLAQDg4OKCgo0PskkKysLLi5uXHMg4ESBAF939uPvJJKONlY4OyS0ZBI7hSBbugellZWI2T5XlQpBAS42ODAP4aLED01BX8OjR/vofHjPWwZuuQvfJeJ7iEtvwx5JZUAgGBvB63k716sLcwQ4uMIAEjJKUFGgf7KCREREemKCSDRPdSeABLSxO5fNe1xgFwWzhCpZmrnYu/lPJxMzoVCyQ4RIjINRlUHkKi1ac0ArmnRa6qwDs747K9EAKpxgE/29mnJ0Og+7YlLx/Ldl5CuaZ1NgaeDHJHhQXi4h6eosRER6RtbAInuITYtX/O4qRNA1Pq0bwcLM9WPGGcCG5Y9cemYuzWmVvKnklFQjrlbY7AnLl2kyIiIWgcTQKIGKJWCpgXQ3d4S7vZNr7AOAHJzGfq0dwQA3Mgrw4280pYOkZpBoRSwfPcl1NfZq962fPcldgcTUZvGBJCoAdfzSlFUXg2gaQWg6xMW6KJ5zFZAwxCdklen5a82AUB6QTmiU/JaLygiolbGBJCoARebUQD6brUngpxMYgJoCLKKmjYju6n7EREZIyaARA242IwC0HcL8XWA3PzOOECW3RSfm13TuvKbuh8RkTFiAkjUgFitNYCblwBamsnQz88JgKpb8XouxwGKbUCAEzwdGk7uJAA8HeQYEODUekEREbUyJoBE9VAoBcTdUiWA3o5WcLa1bPa5uC6wYZFJJYgMD7rnPpHhQZBJm1b0m4jIGDEBJKpHUnYxSisVAFTduPdDKwHkOECDMLKrO+Rm9f/6mzjAl3UAiajNYwJIVA+tAtDNnAF853gH2FjIAHAcoKE4lZKL8molAGBwB2f8X5iX5rkjV3NQpVCKFRoRUatgAkhUj9gWmAGsZi6Ton/NeLLsogokZRff1/no/u2/lKl5PGmAL2aGemJoJ1XJnpu3y/DL+VtihUZE1CqYABLV40KtFsAezZwAUltYILuBDYUgCNgfnwUAMJdJNInfvOEdNPusP5gIJQtBE1EbxgSQ6C5VCiUupRcCAAJcbOBgZX7f5+REEMMRn16EtPwyAEBYBxfYyVX3d0CAE/r7twMAJGWXYM/fGaLFSESkb0wAie5yJbMIlTXjw5pb/uVu3b0cYCc3AwCcTM5j65KI9sff6f59sJub1nPzRnTUPF53IJHjNYmozWICSHSX2BYoAH03mVSC0ABVK2BeSSWuZBW1yHlJd/tqjf8b1c1d67lhnV01Sf/ftwpxMCG7VWMjImotTACJ7nJBKwF0bLHzshyM+NILyhCbprq/3b3s4eVopfW8RCLBvBF3xgKuZSsgEbVRTACJ7hKblg8AkEhUSUJL4UQQ8UXVTP4AgNF3tf6pPRTkgU5utgCAs9dv42RyXqvERkTUmpgAEtVSXqVAQoaqe7ajqy1sLM1a7NxdPezQzlo14eBkci4UHAfY6rTG/wXVnwBKpZI6YwGJiNoaJoBEtVzOKEKVQpWYtWT3L6BKLNTjAAvLqxFfM9OYWkdJRTWOJ6paXj0d5Pds3X28pyfaO1kDAI4m5uD8jfzWCJGIqNUwASSqpSULQNeH4wDFc+RqNiprVvgY3c0dEknDa/2ayaSYW6su4Nq/2ApIRG0LE0CiWrSWgNN3Ash6gK1qb63Zv6Mb6P6t7ak+3vCwlwNQdR1fzmCLLRG1HUwAiWpRJ4BmUgmCPFtuAohaJzdbuNhaAACiU/JQzTVnW0W1QokDl1UTQGwsZBgY6NToMZZmMsx+IFDz/boDSXqLj4iotTEBJKpRWlmNqzX1+Tq720FuLmvxa0gkEgysmQ1cXFGNuFtsVWoNMan5uF1aBQAY1sUVlmZNu7eTBrSHs40qYf/t4i2k5JToLUYiotbEBJCoxqVbhVBPzNXH+D81jgNsfbVn/zZU/qU+VhYyPD8kAACgFIANBzkWkIjaBiaARDX0VQD6brXrAR5PytHbdeiO/TXj/2RSCUZ2dWtkb21Tw/w0y/j9GJOmWUeYiMiYMQEkqqHvGcBqAS42cLe3BACcuXZbs+4w6UdSdjGSa7pu+/m1g6O1hU7H28vNMWOQPwCgWingi0McC0hExo8JIFGNizVLhFnIpOjsbqe360gkEk0rYFmVAhdrJZ7U8mqv/dtQ8efGzBwcAKuaMaE7Tt9AVlF5i8RGRCQWJoBEAArLq5CcrWol6uZpBwsz/f5ocBxg69lfKwEcpcP4v9qcbCzwXGh7AEBFtRKbjqS0SGxERGJhAkgEIC6tdcb/qYUFumgesx6g/uQWV+Bs6m0AQEc3WwS42DT7XLMeCISFTPUrc+vJ68gvrWyRGImIxMAEkAhArJ4LQN/N18kK3o5WAICz12+jolqh92uaor8uZ0Gomdnd3O5fNXd7Ocb38wEAlFQqsOXYtfuMjohIPAaRAK5btw7+/v6Qy+UIDQ1FdHT0Pfdfs2YNunTpAisrK/j6+uLVV19FeXn9Y3JWrVoFiUSCV155RQ+RU1txUWsGsP4TQIlEoukGrqhW4lxqvt6vaYqaW/6lIXOGdYBMqlpC7qvj11BcUX3f5yQiEoPoCeDOnTsRERGByMhIxMTEICQkBGPGjEFWVla9+2/fvh2LFi1CZGQk4uPjsWnTJuzcuRNvvvlmnX1Pnz6Nzz//HD179tT3yyAjdzEtHwBgZS5DR1fbVrlm7XIwHAfY8sqrFDh8RVVmx8XWAr18He/7nL5O1hjbywsAUFBWha0nr9/3OYmIxCB6Arh69WrMmjULM2fORFBQEDZu3Ahra2ts3ry53v2PHz+OwYMHY/LkyfD398dDDz2ESZMm1Wk1LC4uxnPPPYcvv/wS7dq1a42XQkbqdkklbuSpart197KHmax1fiw4EUS/jifloKxK1bU+squbpuXufr00vCMkNaf6z5EUlFex+56IjI+oCWBlZSXOnj2L0aNHa7ZJpVKMHj0aJ06cqPeYQYMG4ezZs5qELzk5Gb///jseffRRrf3mzZuHxx57TOvcRPW5mNa64//UvByt4OdsDQA4d+M2yiqZSLSkfZfu9CK0RPevWkc3WzzSwwMAkFNcgZ2nb7TYuYmIWouZmBfPycmBQqGAu7v2L2d3d3dcvny53mMmT56MnJwcDBkyBIIgoLq6GnPmzNHqAt6xYwdiYmJw+vTpJsVRUVGBiooKzfeFhar1WZVKJZRK/RXpVSqVEARBr9egxl28cVvzONjbXqf7cb/3cGCAE67nlqJKIeD0tVwM6ejS+EHUKKVSQFTN+D9LMykGdXBq8B415x7OHRaI32MzAAAbDyVhQj8fvZcOoobxd6nx4z1sGbq8f6ImgM1x8OBBrFixAuvXr0doaCgSExOxcOFCvPvuu1i6dClu3LiBhQsXYt++fZDL5U0658qVK7F8+fI627OzsxucXNISlEolCgoKIAgCpFL+5yGWM8nZmsfeckWD40/rc7/3MMjFXPM4KvYGOtvzl19LuJRRgqwi1R91/dvboTg/D8UN7Nuce+hqBgzyt8fxa4VILyjHt0cuI7w7k3ex8Hep8eM9bBlFRUVN3lfUBNDFxQUymQyZmZla2zMzM+Hh4VHvMUuXLsXUqVPx4osvAgCCg4NRUlKC2bNn46233sLZs2eRlZWFPn36aI5RKBQ4fPgw1q5di4qKCshkMq1zLl68GBEREZrvCwsL4evrC1dXV9jb27fUy61DqVRCIpHA1dWVH3gRXcn5GwBga2mGvp19IdVhrNj93sMxcntE7lEVFY7NLIebm27r1FL9tl64onn8WIjvPd/X5t7DV8eY4/jnJwEA22KyMWNYtxYbZ0i64e9S48d72DKa2vAFiJwAWlhYoG/fvoiKisK4ceMAqD4EUVFRmD9/fr3HlJaW1vlwqBM6QRAwatQoxMbGaj0/c+ZMdO3aFW+88Uad5A8ALC0tYWlpWWe7VCrV+wdRIpG0ynWofllF5UgvULXyBns7wMys7uejMfdzDz0crdHB1QZJ2SW4eLMAZVVK2FgaXcO8wdkff6cVd1SQe6P3pjn3sH+AMwYGOuFkch6u5Zbij78z8USIV7NjpvvD36XGj/fw/uny3on+P01ERASmT5+Ofv36YcCAAVizZg1KSkowc+ZMAMC0adPg7e2NlStXAgDCw8OxevVq9O7dW9MFvHTpUoSHh0Mmk8HOzg49evTQuoaNjQ2cnZ3rbCeKbeX6f/UJ6+CMpOwSVCsFnL6Wh+Fd2Ap4P27kleJyhqobpJevI9zsmv4Xsa5eHtkJJ5NPAQDWH0jE48GeOrUgExGJRfQEcMKECcjOzsayZcuQkZGBXr16Yc+ePZqJIampqVoZ7ZIlSyCRSLBkyRKkpaXB1dUV4eHheP/998V6CWTELrbyCiD1CQt0wdaTqQBU5WCYAN6f2sWf73f1j8YM6uCMXr6OOH8jH5czihB1OUvv1yQiagmiJ4AAMH/+/Aa7fA8ePKj1vZmZGSIjIxEZGdnk8999DiK1izfzNY9DWmEN4PoMDHTSPOa6wPevpVf/uBeJRIL5IzrixW/OAADWHkjE6G5ukEjYCkhEho0d7WSyBEFAbE0NQEdrc/i0sxIlDmdbS3RxtwMAxKUVoLC8SpQ42oKCsiqcSs4DALR3skZnd/2v6jKqmxu6eqju34Ub+TiWyCSeiAwfE0AyWekF5cgprgSgmgAiZquNelUQpQBE1yQwpLtDV7JRrRQAqFr/WuOeSiQSzBvRUfP92gNX9X5NIqL7xQSQTJYhdP+qaS0Lx27gZtt/qVb3b1DrjaV8NNgTgS42AICTyXk4e51JPBEZNiaAZLIMYQKI2sAAZ836slwXuHmqFEocSFCVf7GXm6G/v1MjR7QcmVSCOcM7aL5f+1diq12biKg5mACSyYpNE78EjJqDtTmCPFVFx+MzCnG7pFLUeIxRdEoeisqrAQAjurrBXNa6v96e7O0Nb0fVONIDCdmIq/X5IiIyNEwAySQJgqBpAXSxtYSHvf5qxTVVWKCqG1gQgFMpbAXU1b5LrTf7tz7mMin+b1ig5vv1B9kKSESGiwkgmaTUvFIUlKlm24b4iDsBRE1rHCC7gXUiCIKm/Iu5TIJhXVxFiePZfr5wsVWtKvRHXAYSs5q+LicRUWtiAkgmyZDG/6n1D3CCehEJTgTRTUJmEW7eLgMADAx0hr3cXJQ45OYyzBoaAEDVkrv+YJIocRARNYYJIJmk2jOAxR7/p2YvN0ewtyqWK5nFyCmuEDki47Hvb3G7f2t7bqAfHKxUCejP52/hRl6pqPEQEdWHCSCZJK0WQG9H8QK5S1gHF83jk2wFbLLaq3+M6ibuUnq2lmaYOdgfAKBQCth4iK2ARGR4mACSyVEqBc0MTS8HOVztLEWO6A6OA9RdZmE5LtQk9N087eHTzlrkiIAZg/xhYyEDAHx/5iYyCspFjoiISBsTQDI5yTnFKKlUADCc8X9q/fzawaxmICDHATZNVHyW5vGDIrf+qTlaW2BKmB8AoFKhxJdHkkWOiIhIGxNAMjm1u397irwCyN1sLM0Q4usIAEjOLkFmIVuOGlO7+/fBIA8RI9H24pBAWJqpfsVuP5WKPNZ2JCIDwgSQTI52AmhYLYDAnXqAALuBG1NaWY2jiTkAAHd7S/Twthc5ojtc7Swxsb8vAKCsSoHNR1NEjoiI6A4mgGRyas8AVs+6NSQcB9h0h6/koLJaCUA1+9cQ6jnWNntYB02X/tcnrqGwvErkiIiIVJgAkkmpVijx961CAICfszUcrS1Ejqiuvn7tYFGzjBnHAd5b7e7f0UHiln+pj7ejFZ7q4w0AKCqvxrcnroscERGRChNAMilXs4pRUdNiZIitf4CqmHDv9o4AVCuWpOWXiRuQgVIoBfx1WTUBxNpCptV1bkjmDu+oKfC96WgKSiurxQ2IiAhMAMnExBr4+D81dgM37lzqbc3Eigc6uUJuLhM5ovoFuNjgsZ5eAIC8kkp8F31D5IiIiJgAkom5oLUCiKNocTSGE0Eat09r9q/hdf/WNm9EB83jLw4noaJaIWI0RERMAMnExNYUgJZIgO5ehjNj9G692jtqSoicTM6FIAgiR2R49l9SJYBSCTCiq2HU/2tIVw97TZKaWViBH86miRwREZk6JoBkMiqqFYhPV00ACXSxgZ3cXOSIGmZpJkM//3YAgLT8MqRyPVktydnFSMouAQD083OCk43hTea52/wRHTWPNx5KQrVCKWI0RGTqmACSyUjIKEKVQtWSFmLA3b9q7AZumPbsX8Nu/VML8XXE0E6qtZ5T80qx++ItkSMiIlPGBJBMRu0C0Ia2BFx9tCaCsByMlv2X7iz/NrqbYY//q21erVbA9QeSoFSya5+IxMEEkEyGscwAVuvp4whrC9XM1hNJHAeolldSiTPX8wAAga42CHS1FTmipgsNcEI/P1XX/tWsYuy9lCFyRERkqpgAkslQzwCWSSUI8jT8BNBcJkV/fycAQFZRBZJzSkSOyDAcuJwFdcOZoc/+vZtEIsG8kXdaAdceSGRiT0SiYAJIJqGsUoGrWcUAgE5utrCyMMyacXdjPcC6ao//e9CIun/Vhnd21axZHJdWiENXskWOiIhMERNAMgmX0guhqGk2MobuXzWtiSAcB4jyKoUmYXKysUDv9u1Ejkh3EokE84bfaQVcdyBRxGiIyFQxASSTcLFWAehgI5gBrNbdyx52lmYAgJMcB4gTybkorVQVUR7Z1Q0y9RprRmZMdw90dFONXTx97TZOMbknolbGBJBMQu0JICFG1AJoJpNiQIBqHGBuSSWuZBaLHJG41MWfAeOa/Xs3qVSCl4bfWR1kLVsBiaiVMQEkk3CxZgUQc5kEXTzsRI5GN9rjAHNEjERcgiBoxv9ZmEk1NfWM1RMhXvB1sgIAHLmagws38sUNiIhMChNAavOKK6qRlK1qOevqYQ9LM+OYAKLGeoAqcWmFyCysAAAM6egCm5qucWNlJpNizrA7rYAcC0hErYkJILV5cWkFUA+dM6YJIGrdPOzhaK1atu5USp7JFg/eF982un9re6avD9ztLQEAey9lIiGjSOSIiMhUMAGkNs/YCkDfTSqVILRmHGB+aRXiMwpFjkgc+2qN/xvVzTiWf2uMpZkMs4YGar5ff5CtgETUOgwiAVy3bh38/f0hl8sRGhqK6Ojoe+6/Zs0adOnSBVZWVvD19cWrr76K8vJyzfMrV65E//79YWdnBzc3N4wbNw4JCQn6fhlkoC7UngHs7ShaHPfD1NcFvnm7FPHpqsQ3xMcB7vZykSNqOZND28PJxgIAsPvCLVxjwW8iagWiJ4A7d+5EREQEIiMjERMTg5CQEIwZMwZZWVn17r99+3YsWrQIkZGRiI+Px6ZNm7Bz5068+eabmn0OHTqEefPm4eTJk9i3bx+qqqrw0EMPoaSEv1hNUWzNBBBLMyk6uxvPsmG1hXW4M+HBFBPAqHjjXPu3KawtzPD8YH8AgFIANhxMEjcgIjIJOieA/v7+eOedd5CamtoiAaxevRqzZs3CzJkzERQUhI0bN8La2hqbN2+ud//jx49j8ODBmDx5Mvz9/fHQQw9h0qRJWq2Ge/bswYwZM9C9e3eEhITgq6++QmpqKs6ePdsiMZPxKCitwvXcUgCqmnpmMtH/5mmWzu62cK5pJYpOyUO1QilyRK2r9uofo41s+bemmBrmr6n3+OO5m7iVXyZyRETU1uk8je6VV17BV199hXfeeQcjRozACy+8gCeffBKWlpY6X7yyshJnz57F4sWLNdukUilGjx6NEydO1HvMoEGDsHXrVkRHR2PAgAFITk7G77//jqlTpzZ4nYICVQuQk5NTvc9XVFSgoqJC831hoaqrSalUQqnU33+0SqUSgiDo9Rqm7vyN25rHwd4OLf5et+Y9DA1wwu9xGSiqqEZsWj5CjKig9f0oLK/CyZrZzz7trNDZzaZF329D+Dm0s5Rhapgf1h9MQpVCwOeHkhAZHiRaPMbGEO4h3R/ew5ahy/vXrATwlVdeQUxMDL766iu8/PLLeOmllzB58mQ8//zz6NOnT5PPlZOTA4VCAXd37b/o3d3dcfny5XqPmTx5MnJycjBkyBAIgoDq6mrMmTNHqwu4NqVSiVdeeQWDBw9Gjx496t1n5cqVWL58eZ3t2dnZWmMLW5pSqURBQQEEQYBUapwtU4buZEK65rG/vaTBoQXN1Zr3sIebBX6vebz/Yio8LSr1ej1Dsf9KHqoUqpnPg/zskJ3dsmvnGsrPYXhnG2w+KkV5tRI7olPxbA8HONuYixaPMTGUe0jNx3vYMoqKml5JoNmFtPr06YM+ffrg448/xvr16/HGG29gw4YNCA4OxoIFCzBz5kxIJC2/TNPBgwexYsUKrF+/HqGhoUhMTMTChQvx7rvvYunSpXX2nzdvHuLi4nD06NEGz7l48WJERERovi8sLISvry9cXV1hb2/f4q9BTalUQiKRwNXVlR94PUkuuKl5PLibL9zcWnYMYGvew4dCrPHhX6qhF3FZFXBzaxszYRsTfeCW5nF4Hz+4ubVsAWhD+Tl0AzAptBBbjl1DhULALwnFeOPhLqLFY0wM5R5S8/Eetgy5vOkT5JqdAFZVVWHXrl3YsmUL9u3bh4EDB+KFF17AzZs38eabb2L//v3Yvn37Pc/h4uICmUyGzMxMre2ZmZnw8PCo95ilS5di6tSpePHFFwEAwcHBKCkpwezZs/HWW29pfXDmz5+PX3/9FYcPH4aPj0+DcVhaWtbbhS2VSvX+QZRIJK1yHVMVl6bqzrexkKGDmx2kelg7trXuYQc3O7jZWSKrqAKnr92GQgDMjXRMY1NVKZQ4mKBq8bOTm2FgBxe9vM+G8nP4fw90wLaTqahUKLHtVCpeGt4RDtZsBWwKQ7mH1Hy8h/dPl/dO53c5JiYGL7/8Mjw9PTF//nx0795d08I2c+ZMLF26FPv378euXbsaPZeFhQX69u2LqKgozTalUomoqCiEhYXVe0xpaWmdFyiTqVZ2EGqq/QqCgPnz52PXrl3466+/EBAQoOvLpDYgp7gCaTWD6Xt4O0Cmh+SvNUkkEs2qIKWVClysVd+wrTp9LQ+F5dUAgOFd3Np8wuvhIMcz/VR/rBZXVOOr49fEDYiI2iydf5v2798fV69exYYNG5CWloZ//etf6Nq1q9Y+AQEBmDhxYpPOFxERgS+//BJff/014uPjMXfuXJSUlGDmzJkAgGnTpmlNEgkPD8eGDRuwY8cOpKSkYN++fVi6dCnCw8M1ieC8efOwdetWbN++HXZ2dsjIyEBGRgbKyjizzpQYewHo+tSuB3jSBJaF23+pdvkX0+jynjusg+aPlS3HU1BSUS1yRETUFuncBZycnAw/P7977mNjY4MtW7Y06XwTJkxAdnY2li1bhoyMDPTq1Qt79uzRTAxJTU3VavFbsmQJJBIJlixZgrS0NLi6uiI8PBzvv/++Zp8NGzYAAIYPH651rS1btmDGjBlNiouMX+0WsuA2MmO29rrAx5NyMG9ERxGj0S9BELAvPgMAYCaVYHgX00gAfZ2sMTbECz+eS0N+aRW2nbqO2Q90aPxAIiId6JwAZmVlISMjA6GhoVrbT506BZlMhn79+ukcxPz58zF//vx6nzt48KDW92ZmZoiMjERkZGSD51N3BZNpu1hrBZCe3m2jBbC9kzW8HOS4VVCOM9duo6JaAUszmdhh6cXVrGLcyFO12ocGOsHBynTGwr00ogN2nU+DIABfHknBtDB/yM3b5n0mInHo3AU8b9483Lhxo872tLQ0zJs3r0WCIrpfgiDgYs0KIPZyM/g5W4scUctQjQNUzYKtqFbifGq+uAHpUe21f9va6h+N6ehmh4e7qybCZRdV4PszdX/nEhHdD50TwEuXLtVb66937964dOlSiwRFdL8yCyuQXaQq7t3Tx1EvJYnEUrsb+EQbHgdoygkgAK3u/Y2HklFlYqu/EJF+6ZwAWlpa1inbAgDp6ekwM2t2VRmiFnWhVvdvcBuZAKKmlQC20XWBs4rKcf5GPgCgq4cdfJ3aRguuLnp4O2B4F1cAQFp+GX46lyZyRETUluicAD700ENYvHixZnk1AMjPz8ebb76JBx98sEWDI2qu2jOAQ9pYAujtaIX2NQnRudR8lFcpRI6o5f0VX3v2r+m1/qnNr9UKuOFgEhRKjm8mopahcwL4r3/9Czdu3ICfnx9GjBiBESNGICAgABkZGfj444/1ESORztTj/4C2MwO4NnU5mEqFEjHXbzeyt/HZH3+nl+HBINNNAPv5OyE0QLWGeXJOCf6IS2/kCCKiptE5AfT29sbFixfx4YcfIigoCH379sUnn3yC2NhY+Pr66iNGIp0IgqCZAexsYwEvh6YvjWMstMvBtK1u4LJKBY5czQEAuNlZIriNzOBurvkj77QCrjuQxCoHRNQimjVoz8bGBrNnz27pWIhaxM3bZcgvrQKgKgDdliaAqLXliSBHrmajolo14WFUN3e9LN9nTIZ0dEGIjwMu3CxAfHoh/rqchVEm3C1ORC2j2bM2Ll26hNTUVFRWVmptf+KJJ+47KKL70RYLQN/N3V6OQFcbJGeX4MKNfJRUVMPGsm1MwtLu/jWN4s/3IpFIMG9ER8z+9iwAYO2BRIzs6tYm/7AhotbTrJVAnnzyScTGxkIikWi6I9S/jBSKtjcgnYxLWywAXZ+wQGckZ5egWingzPXbGNbZVeyQ7ptCKSCqZgKIlbkMg2pqHpq60d3c0cXdDgmZRTiXmo8TSbkY1JHvDaD6zJxKzkXizTx0LJYhNNDF6Nf9JmoNOo8BXLhwIQICApCVlQVra2v8/fffOHz4MPr161dn1Q4iMVxsg2sA16ctloM5fyMfuSWqXoWhnVy4+kUNqVSCl0bcWQ5u7YFEEaMxHHvi0jHkg78w+T/RWLYnBZP/E40hH/yFPZwsQ9QonRPAEydO4J133oGLiwukUimkUimGDBmClStXYsGCBfqIkajJlEoBcTUzgD3s5XCzb3sTQNQGBra9cYCc/duwx3t6wb9mRZvjSbmISW17s791sScuHXO3xiC9oFxre0ZBOeZujWESSNQInRNAhUIBOzs7AICLiwtu3boFAPDz80NCQkLLRkeko5TcEhRVVANoewWg7+Zia4nO7rYAgNib+SgsrxI5ovu3v2b1D4kEGNmV4/9qk0klmDv8Tivgur9MtxVQoRSwfPcl1DcfWr1t+e5LrJtIdA86J4A9evTAhQsXAAChoaH48MMPcezYMbzzzjsIDAxs8QCJdNGWC0DXR10PUCkAp1PyRI7m/lzLKcHVrGIAQN/27eBsaylyRIbnyd4+mrJGUZezcOlWocgRiSM6Ja9Oy19tAoD0gnJEG/nPBJE+6ZwALlmyBEqlqkTDO++8g5SUFAwdOhS///47Pv300xYPkEgXpjADuLa2NA6wdvfvaHb/1svCTIrZD9z5Q3vdQdNqBaxWKPFHbDqW/hzbpP2zihpOEolMnc6zgMeMGaN53LFjR1y+fBl5eXlo164dyxKQ6GrPADaFAsKhAc6QSABBMP5xgPsu1UoAWeeuQRMHtMfaA4nIKa7E77HpSMouRgdXW7HD0qvc4grsOH0DW09ev2fL391c2YpM1CCdWgCrqqpgZmaGuLg4re1OTk5M/kh01Qol/q7pEvN1soKTjYXIEelfOxsLdPOwBwBcSi9EfmllI0cYptsllThTs6RdgIsNOrjaiByR4ZKby/DCEFUroCAA6w8kiRyR/ly8mY+I/55H2Mq/8NGfCVrJX1NKvWw4lITsogp9hkhktHRKAM3NzdG+fXvW+iODlJRdgrIq1Wezp7ejuMG0InU3sCAAp4x0zNPBK1maAfsPBrnzD8pGTBnYHvZyVQfOT+fTcCOvVOSIWk5FtQI/nUvDuHXH8MTaY/gxJg2VCtWwI4kEGNXVDd88PwCfTewNCYB7fVKOXM3BI58cwdGapQWJ6A6dxwC+9dZbePPNN5GXZ5z/0VDbpdX9awITQNTCAo1/HOD+S1max+z+bZyd3BwzBgcAUM2I/fyw8bcCZhSUY/XeBAxedQCv7DyP8zfyNc/Zy80wa2gADv1jBDbN6I8HOrvi0Z6e2DClDzzuWuvb00GOhaM6wdVO1f2bU1yBqZtP4YM9l1FVk0gSUTPGAK5duxaJiYnw8vKCn58fbGy0u2piYmJaLDgiXWgVgDaB8X9qAwKdIJWoZgKfNMJxgBXVChxMUCWA7azN0ae9o7gBGYmZg/yx6UgySioV+O+Zm1gwspPR1b0UBAGnr93G1yeu4c+4DFTfVbalq4cdpg/yx7he3rCyqFsU/OEenngwyAOnknOQeDMbHX1cNSuBTA3zQ8R/L+DwlWwIArDhYBJOJufi04m94etk3Vovkchg6ZwAjhs3Tg9hEN2/i2l3EsAeJtQCaC83Rw9vB1y8WYDLGUXILa4wqhIqJ5PzUFKp6rof0dUNZjKdOyZMUjsbC0wZ6IfPDyejslqJL48k463HgsQOq0nKKhX4+Xwavj5xHfHp2qVsZFIJHu7ugWlhfhgQ0Pj4cplUgoGBzgi0VcDNzRnSmrGBLraW+GpGf/znaDI+3JOAaqWAc6n5ePTTI1j1VE881tNTb6+PyBjonABGRkbqIw6i+1JZrdT8RxLoYgN7ubnIEbWusEBnTQvoyeQ8o/rPbX+t2b8PsvtXJy8MDcCW49dQWa3EtlOpeGl4R7Qz4MlPN/JKsfXkdew4fQMFZdqFy11sLTBpQHtMDm0PTwerFrmeVCrB7Ac6YECAMxZ8dw6peaUoKq/GvO0xOJrYHsseD6q3ZZHIFPBPbWoTrmQWobJaNb7HlMb/qWnVA0w2ngHvgiBo6v9ZyKQY2tlV5IiMi5udHBP7+wIASisV2HIsReSI6hIEAUeuZuPFr8/ggY8O4PPDyVrJX4ivI/49IQTHFo3Eaw91abHkr7Zevo74bcEQhId4abZ9F52KseuOIiGjqMWvR2QMdG4BlEql92yS5wxhEoPW+D8TKAB9t/7+TjCTSlCtFIxqIsjftwo1pT0GdXSGraXOv5JM3v8N64Dtp1JRrRTw1fFrmPVAIOwMoAW8uKIaP5y9ia9PXENydonWcxYyKR7v6Ylpg/zRy9exVeKxk5vj04m9MLSjCyJ/+RtlVQpcySzGE2uPYll4ECYPaM/Z52RSdP5tu2vXLq3vq6qqcO7cOXz99ddYvnx5iwVGpIvYtHzN454m2AJoY2mGnj4OiEnNR1J2CbIKy41iQoDW6h/s/m0Wb0crPNnbG9+fvYnC8mp8e/I6XhreUbR4krKL8c3xa/ghJg3FNetyq3nYyzFlYHtMHNAeLiKMU5VIJHi2vy/6+Dli/vZzuJxRhIpqJd7aFYejV3Ow6umecLASP3kmag06J4Bjx46ts+2ZZ55B9+7dsXPnTrzwwgstEhiRLi7cULUASiVAdy97kaMRR1gHZ8Sk5gNQrQoytpe3uAE1Qe3VP0Z1cxMxEuM2d3gH/BBzE0oB2HQkBTMHBbTq2DaFUsCBy1n4+sQ1HKmn5l5ogBOmD/LHQ0HuBjHJp6ObHX6aNxgrfo/HNyeuAwD+iMvAxZsF+HRSb/T1aydyhET612I/iQMHDkRUVFRLnY6oycqrFLiSqRrH08nNDtYWptmNGBboonlsDOVgbuWXaVZuCfZ20MvYL1MR6GqLR4NVE39ySyqx43Rqq1w3v7QSXxxOwvB/HcCL35zRSv7k5lJMGtAefywcip3/F4ZHgz0NIvlTk5vL8M7YHtg4pa+m1S8tvwzPfn4C6w4kagqTE7VVLfI/ZVlZGT799FN4ext+iwO1PfHphZr6YaY4AUStr187mMskqFIYxzjAKHb/tqh5Izri14vpAIAvDifjuVA/WJjpJ+G6dKsQ35y4hp/Op6G8Sru4cnsna0wL88P4vr5wsDb87tSHe3gg2McBr+w4h9PXbkOhFPDRnwk4npSDfz/byyiGUhA1h84JYLt27bQGygqCgKKiIlhbW2Pr1q0tGhxRU2hPADHdBNDKQobevu0QfS0P13JLcSu/DF6Ohtuqti++1uofQez+vV/dPO0xupsb9sdnIb2gHD/G3MTEAe1b7PxVCiX+/DsD3xy/juhrdVeCeqCzK2YM8sOwzm5NWqfXkHg7WuG7WQPx6V+J+OyvqxAE4FhiLh755Ag+fjYEw7vw80ltj84J4L///W+tBFAqlcLV1RWhoaFo147jJqj1mfoM4NrCOjhr/nM+kZSLp/v6iBxR/YrKq3AiSdVd6O1ohSBP0xy32dLmjeiI/TWJ9YZDSXimr899d7tmF1Xgu+hUbDt1HZmFFVrP2Vqa4Zm+PpgW5odAV9v7uo7YzGRSRDzYGQMDnfDqzvPILKxAbkklZmw5jVlDA/D6mK56a1ElEoPOCeCMGTP0EAZR86lnAJtJJejqYSduMCIL6+CMT6KuAlBNBDHUBPDI1RxUKVTd9qO7ubH8Rgvp3b4dBnd0xrHEXFzPLcVvsenNngx0LvU2vj5+Db/FpmvulVpHN1tMD/PDk3182lzpnkEdXPDHwgfw+vcXEHVZlUx/eSQFp1Ly8OnE3vB3sWnkDETGQeef3C1btsDW1hbjx4/X2v7999+jtLQU06dPb7HgiBpTUlGNxKxiAEAXDzvIzU27qn/v9o6wNJOiolpp0OMAa8/+HR3E8X8tad6IjjiWqLr36w4kIrynl2Z5tMaUVynw28V0fHPiGi7UalkHVDPsR3dzx/RB/hjUwblNJ+1ONhb4z/R+2HLsGlb+EY8qhYCLNwvw+GdH8f6TPYxihj1RY3Ruz165ciVcXFzqbHdzc8OKFStaJCiipvr7ViHUk/VMvfsXACzNZJoSFmn5ZbiRVypyRHVVK5T4q6ZlxdbSDKEBzo0cQboIC3RGn/aOAIArmcXYV2uyTUNu5Zfhoz8vY/Cqv/Da9xe0kj9Ha3PMGdYBh14fgS+m9cPgji5tOvlTk0gkeH5IAHa9NBgBNa1+xRXVWLjjPF7//gJKK6sbOQORYdM5AUxNTUVAQECd7X5+fkhNbV7pgXXr1sHf3x9yuRyhoaGIjo6+5/5r1qxBly5dYGVlBV9fX7z66qsoLy+/r3OScbp4M1/z2JQngNQWFlhrWTgDbAU8c/22ZimwYV1cOa6qhUkkEswfeacQ9Ad/XMbP59JwIilXq7SJIAg4mZyLuVvPYuiHB7DuQBJySyo1z3f3sseHz/TEycWjsOiRrvB1sm7V12Eoeng7YPfLQ/BU7zutft+fvYnHPzuKv28V3ONIIsOmcxewm5sbLl68CH9/f63tFy5cgLOz7n/J79y5ExEREdi4cSNCQ0OxZs0ajBkzBgkJCXBzqzvzavv27Vi0aBE2b96MQYMG4cqVK5gxYwYkEglWr17drHOS8ao9ASTYmwkgULMu8D7V4xPJuXi2Zq1YQ7G/Vvfvgyz/ohcjurjBx9EKN/PLkJxTgoU7zwMAPB3kWPRIV5RUKPDNiWu4fNc6uGZSCR4J9sSMQX7o076dSbT0NYWtpRlWT+iFIZ1csOSnOJRWKpCcXYIn1x/HW492w7QwP75XZHR0/tN70qRJWLBgAQ4cOACFQgGFQoG//voLCxcuxMSJE3UOYPXq1Zg1axZmzpyJoKAgbNy4EdbW1ti8eXO9+x8/fhyDBw/G5MmT4e/vj4ceegiTJk3SauHT9ZxkvGLTVAmghZkUXUx8AohaTx9HWNWMhTyelANBMJyCtoIgaLokZVIJRrC8hl78+XcGbuaX1dmeXlCOhTvO481dsVrJn6udJRaO6oTji0bis0m90dfPiQlNPZ7q44NfXx6iWW2oslqJyF/+xuxvzyK/tLKRo4kMi84J4LvvvovQ0FCMGjUKVlZWsLKywkMPPYSRI0fqPAawsrISZ8+exejRo+8EJJVi9OjROHHiRL3HDBo0CGfPntUkfMnJyfj999/x6KOPNvucZJwKyqqQkqNaZD7I0x7mBrTKgJgszKToH+AEAMgsrNC8R4YgKbsY13NV4xIH+DsZRaFgY6NQCli++1KT9u3r1w6fTOyFY2+MxKsPdmbR4yYIdLXFjy8NwvOD7wyF2ncpE498cgTRKXXrIxIZKp27gC0sLLBz50689957OH/+PKysrBAcHAw/Pz+dL56TkwOFQgF3d+1uIHd3d1y+fLneYyZPnoycnBwMGTIEgiCguroac+bMwZtvvtnsc1ZUVKCi4k59q8JC1fJUSqUSSqWy3mNaglKphCAIer1GW3bxxm3N42Bve1HeR0O9hwMD2uHwlWwAwPHEHPg7G8b4rT//ztA8HtXN1SDeN0O9h811KjkX6QXlje73/rjumFSrULQxv/7WvofmUgmWPNYVYR2c8M//XcTt0iqkF5Rj4hcnsGBkR8wb0dHoimGLra39HIpFl/ev2QWcOnXqhE6dOjX38GY7ePAgVqxYgfXr1yM0NBSJiYlYuHAh3n33XSxdurRZ51y5ciWWL19eZ3t2dnadySUtSalUoqCgAIIgQCpl65WuTiTcSSb87CTIysq6x976Yaj3sEu7O7EcjL+F0QGG0bKz52Ka5nEvVzNR7tndDPUeNlfizaa1QinKSw3i/W8JYt3DYCfg68ld8faeFMTcLIZSANZEJeLQ5QwsfzgAbnYWrRaLsWtrP4diKSoqanynGjongE8//TQGDBiAN954Q2v7hx9+iNOnT+P7779v8rlcXFwgk8mQmaldpiAzMxMeHh71HrN06VJMnToVL774IgAgODgYJSUlmD17Nt56661mnXPx4sWIiIjQfF9YWAhfX1+4urrC3l5/KxQolUpIJBK4urryA98MKQV3kokhQb5wc2v9MYCGeg+dnJWwtbyK4goFzt8qgaurq+hjurKLKhCXoeqO7uxmiz6dDWNyiqHew+bqWCwDkNL4fj6ucHNrGyV4xLyHbm7AzjneWH8wCZ9EXYVSAM6lFWP6d5fx4dPBGMWJTk3S1n4OxSKXN/2PfZ0TwMOHD+Ptt9+us/2RRx7Bxx9/rNO5LCws0LdvX0RFRWHcuHEAVB+CqKgozJ8/v95jSktL63w4ZDLVgHdBEJp1TktLS1haWtbZLpVK9f5BlEgkrXKdtkg9AcTKXIZO7vZNLnbb0gzxHlpIpRgQ4Iy/Lmchp7gSyTml6OQu7iSZQ1dyoJ6PMjrI3aDeL0O8h80VGugCTwc5MgrKUd/0HwkADwc5QgNdRPuZ0Qcx76FUCiwc3RmDOrpg4XfncKugHLdLqzDr2xjMGOSPxY92haWZaRepb4q29HMoFl3eO53f5eLiYlhY1G3WNjc314yd00VERAS+/PJLfP3114iPj8fcuXNRUlKCmTNnAgCmTZuGxYsXa/YPDw/Hhg0bsGPHDqSkpGDfvn1YunQpwsPDNYlgY+ck45dbXIGbt1WzHHt423O8TT206gEmi18PsHZB4ge5+ofeyKQSRIYHAVAle7Wpv48MD+LPjB7093fC7wuH4qFan++vjl/DU+uPIzm7WMTIiOrSuQUwODgYO3fuxLJly7S279ixA0FBQToHMGHCBGRnZ2PZsmXIyMhAr169sGfPHs0kjtTUVK2MdsmSJZBIJFiyZAnS0tLg6uqK8PBwvP/++00+Jxk/desfwBVAGhLWQbsg9LQwf9FiKa9S4MhV1aQUF1tLhPCe6dXDPTyxYUofLN99SWtCiIeDHJHhQXi4h6eI0bVtjtYW+HxqX3x78jre+y0eldVK/H2rEI9/dhTvju1hsOtzk+mRCDoWCdu9ezeeeuopTJ48GSNHjgQAREVFYfv27fjf//6n6XY1ZoWFhXBwcEBBQYHexwBmZWXBzc2NTd46+izqKj7edwUA8MnEXqKtzWnI91ChFNDn3X0oKKuCo7U5YpY8KFqX3/5LmXjxmzMAgIn9fbHq6Z6ixFEfQ76H90uhFBCdkoesonK42ckxIMCpTbb8Geo9vHSrEC9/F4Ok7DulmJ7s7Y13x/WArWWz52C2SYZ6D42NLvmLzu9yeHg4fvrpJyQmJuKll17Ca6+9hrS0NPz111/o2LFj4ycgagEXuAJIo2RSCUJr6gHml1bVWfWhNe2v1f07moPiW41MKkFYB2eM7eWNsA7ObTL5M2RBXvbY/fIQPNvvTqvfrnNpePzTI4i9yWXkSFzNSrMfe+wxHDt2DCUlJUhOTsazzz6Lf/zjHwgJCWnp+IjqFZuWDwCwk5vB39lG3GAMmFY3sEjjAJVKAfvjVeVG5OZSDO7oIkocRGKwtjDDh8+E4JOJvTStftdyS/HUhmP4z5Fkg1qph0xLs9tZDx8+jOnTp8PLywsff/wxRo4ciZMnT7ZkbET1yiwsR2ahqnB3sLdDm5rJ2NLuHgcohgs385FTrLpfQzq6wsqCsyHJ9Izt5Y3fFgxBiI+qx6JKIeC93+Lx/FenkVtc0cjRRC1PpwQwIyMDq1atQqdOnTB+/HjY29ujoqICP/30E1atWoX+/fvrK04ijYu1u3992P17L53d7OBko5q1fyolFwpl67c21O7+fYizf8mE+Tnb4Ps5g/B/DwRqth1IyMYjnxzB8aQcESMjU9TkBDA8PBxdunTBxYsXsWbNGty6dQufffaZPmMjqlfszXzNY84mvTepVIKBgapxgEXl1bh0S/dSTfdr/yVV969EAozo6tbq1ycyJBZmUix+tBu+mtkfzjV/nGUVVeC5/5zCx3sTUK3gUmjUOpqcAP7xxx944YUXsHz5cjz22GOamntEre1iGieA6EK7HmDrtjKk5pYiIVM1+aS3ryNc7eoWXCcyRcO7uOGPhUMxpGZMrCAAn/2ViIlfnERafpnI0ZEpaHICePToURQVFaFv374IDQ3F2rVrkZPDJmtqXYIgaLqA21mbw6edlcgRGb7a4wCPt/I4wNrFn0ez+5dIi5u9HN88PwD/fLiLZob2meu38ciaw9gTlw5AVcrnRFIufj6fhhNJ4gzjoLapyYWIBg4ciIEDB2LNmjXYuXMnNm/ejIiICCiVSuzbtw++vr6wsxN3qSlq+9Lyy5BXUglAVQBa7PVtjUEHV1u42lkiu6gCp1PyUKVQwlzWOnW29l+qtfoHy78Q1SGVSvDS8I4IDXDGgu/OIS2/DIXl1ZizNQYPdHbBlYwiZBTemSTiyWLe1EJ0/l/AxsYGzz//PI4ePYrY2Fi89tprWLVqFdzc3PDEE0/oI0Yijdq1s3pyAkiTSCQSTTdwSaVCaxUVfSoorUL0tTwAgJ+zNTq62bbKdYmMUV+/dvh94VA8FnwnsTt8JUcr+QOAjIJyzN0ao2khJGqu+2oG6NKlCz788EPcvHkT3333XUvFRNQgFoBuHjHKwRy8kqXprnqwmztba4ka4WBljrWTe+O9cT0a3EfdAbx89yV2B9N9aZF+IJlMhnHjxuGXX35pidMRNUhdABrgGsC6qD0R5GQrFYTed4nj/4h0JZFI0MH13q3lAoD0gnJEp+S1TlDUJnHBPTIatSeAuNlZwsNBLnJExsPP2RqeNe/XmWu3UVmt31ITldVKHErIBqBq1ejn106v1yNqS7KKylt0P6L6MAEko3EttxRF5dUAOP5PV7XHAZZVKXChVi1FfTiVkouiCtW9GtnVDWatNOmEqC1ws2vaH7eutiyrRM3H38pkNC7WSlqCvR1Fi8NYDaxdDiZRv93AtWf/jubsXyKdDAhwgqeDHI2Nml1/MBHZRVxGjpqHCSAZDa0ZwL5sAdTVoA6tUxBaEATsj1et/mEuk+CBzi56uxZRWySTShAZHgQA90wCjybm4pFPjuDI1ezWCYzaFCaAZDQucgbwffFpZw1fJ1Xh7JjUfJRXKfRynfj0Is1KBmEdXGAnN9fLdYjasod7eGLDlD51xjp7OsjxyqhOmlV1coorMHVTNFb9cRlVXEaOdNDkQtBEYlIoBcTdUiWA3o5WcOHYl2YJC3TGjbybqKxWIib1NgZ1aPnWuf3xtYs/c+1fouZ6uIcnHgzyQHRKHrKKyuFmJ8eAACfIpBJMCfPDa/+9gENXVK1/Gw8l4WRyLj6b1Bu+TtYiR07GgC2AZBSSs4tRWqlqseIEkOarXQ/wpJ7qAdYu/zKK4/+I7otMKkFYB2eM7eWNsA7OmiXjXGwtsWVGf7z1aDeY1Ww7fyMfj35yBL9evCVmyGQkmACSUdDq/mUC2GxhgXda/E7ooR5gekGZZqWR7l728HLkWs1E+iKVSjDrgUD8MHcQ2te0+hVVVGP+9nNY/ONFlFXqZ5gHtQ1MAMko1J4B3JMzgJvNw0GOABcbAKrWgtLK6hY9f1TN5A+As3+JWkuIryN+WzAEY3t5abZ9F30DT6w9issZhSJGRoaMCSAZhYtpnADSUgbW1AOsUgg4c+12i55ba/wfV/8gajV2cnOsmdALHz3TE1bmMgDA1axijF17DFtPXocgcNk40sYEkAxelUKJS7dUf8X6O1vDwZqzSu+HdjmYlusGLqmo1tQX9HSQo7uXfYudm4gaJ5FIML6fL3a/PARdPewAABXVSiz5KQ4vbYtBQWmVyBGSIWECSAbvSmYRKmqWLgvm+r/3bWCtdYFPtOBEkCNXs1FZU4ZidDd3SCSNlbElIn3o6GaLn+YNxvQwP822P+Iy8OinR3DmGtcPJhUmgGTwaheADuEEkPvmameJTm6qxeZj0wpQXNEy4wD31l79g92/RKKSm8uwfGwPfDG1LxysVL0mafllmPDFSaw7kAiFkl3Cpo4JIBk8jv9reepyMAqlgNMp998iUK1Q4sBl1QQQGwsZBgY63fc5iej+PdTdA38sHIoB/qqfSYVSwEd/JmDqplPILCwXOToSExNAMnjqGcASCdCdCWCLCAts2XGAMan5uF0zvmhYF1dYmsnu+5xE1DK8HK2wfVYoFozqhJqSgTiepFpGTv2HG5keJoBk0MqrFEjIKAIAdHS1ha0lF69pCaEtPA6w9uxfln8hMjxmMikiHuyMbS8OhLu9aiWlvJJKzPzqNN779RIqq7mMnKlhAkgGLSGjCFUK1VgVFoBuOU42FppZgn/fKrjv2YH7a8b/yaQSjOzK5d+IDFVYB2f8sfABjKr1c/qfoyl4esNxXMspETEyam1MAMmgaReAZgLYktTrACsF4FRK81sBE7OKkVzzH0c/v3ZwtLZokfiISD+cbCzwn+n9EBkeBAuZKg2ITSvAY58ewU/n0kSOjloLE0AyaNpLwDmKF0gbFNZC9QBZ/JnI+EgkEswcHIAfXxqkWR2opFKBV3aex2v/vYCSFqoOQIaLCSAZNPW6sjKphIWFW9iAACfNgPD7GQe4v1b5l1Ec/0dkVHp4O+DXl4fg6T4+mm0/xNxE+GdH8fetgnscScaOCSAZrNLKalzJVE0A6exuB7k5Z5a2JAcrc3T3UnWrX84oQl5Jpc7nyC2uwNlU1XJyHd1sNS0JRGQ8bCzN8PGzIfj3hBDYWKh+zybnlODJdcfx1bEULiPXRjEBJIN16VYh1LVKOf5PP2p3A59qRjfwX5ezoP6/gd2/RMbtyd4++HXBUPTwVvW2VCqUeHv3Jcz65ixuN+MPRDJsBpEArlu3Dv7+/pDL5QgNDUV0dHSD+w4fPhwSiaTO12OPPabZp7i4GPPnz4ePjw+srKwQFBSEjRs3tsZLoRZUe/xfT18mgPpwv/UAWf6FqG0JcLHBD3MH4YUhAZpt++Mz8cgnR5r1RyIZLtETwJ07dyIiIgKRkZGIiYlBSEgIxowZg6ys+otT/vjjj0hPT9d8xcXFQSaTYfz48Zp9IiIisGfPHmzduhXx8fF45ZVXMH/+fPzyyy+t9bKoBWjPAHYULY62rH+AE2Q1AwF1HQdYXqXA4Ss5AAAXWwv08nVs6fCISASWZjIsfTwIm2f0g5ONalZ/RmE5Jn15Emv2X+Eycm2E6Ang6tWrMWvWLMycOVPTUmdtbY3NmzfXu7+TkxM8PDw0X/v27YO1tbVWAnj8+HFMnz4dw4cPh7+/P2bPno2QkJB7tiyS4VEvAWchk6JLTc06alm2lmboWVNf8WpWMbKKmr401PGkHJRVKQAAI7u6aRJJImobRnZ1xx8Lh2p6CpQCsGb/VUz68iTSC8pEjo7ul6jLKlRWVuLs2bNYvHixZptUKsXo0aNx4sSJJp1j06ZNmDhxImxs7gw+HzRoEH755Rc8//zz8PLywsGDB3HlyhX8+9//rvccFRUVqKio0HxfWFgIAFAqlVAq9VcdXalUQhAEvV7DWBWVVyE5W1VbrqunHcykMMj3qS3cw4EBTjiXmg8AOJGYg/AQryYdt+/vWrN/u7oZ7XvQFu6hqeM91B9XWwt883x/bDiYhDVRV6EUgOiUPDyy5gg+fCa4xYZ+8B62DF3eP1ETwJycHCgUCri7a3+A3N3dcfny5UaPj46ORlxcHDZt2qS1/bPPPsPs2bPh4+MDMzMzSKVSfPnll3jggQfqPc/KlSuxfPnyOtuzs7NRXq6/xbKVSiUKCgogCAKkUtEbYw3K2RtFmscdnSwaHBIgtrZwD7s63ZldfeDvNIR6Nv5rQSkI2HcpAwBgKZOgs4PSYO9RY9rCPTR1vIf692wPe3Ru1wWRe5KRWVSF/LIqzP42BuN7uWL+EB9Ymt3f+8572DKKiooa36mGUS+sumnTJgQHB2PAgAFa2z/77DOcPHkSv/zyC/z8/HD48GHMmzcPXl5eGD16dJ3zLF68GBEREZrvCwsL4evrC1dXV9jb66/2nFKphEQigaurKz/wd7lxuVjzeEBHd7i5GebyYm3hHo52dIb5L4moUgg4n17apPf6ws185JSolo8b0skVft6e+g5Tb9rCPTR1vIet4yE3Nwzo4oNFP8Zhb039z+/PZ+PvzHJ8OrEXAl1tm31u3sOWIZfLm7yvqAmgi4sLZDIZMjMztbZnZmbCw8PjnseWlJRgx44deOedd7S2l5WV4c0338SuXbs0M4N79uyJ8+fP41//+le9CaClpSUsLS3rbJdKpXr/IEokkla5jrGJvVWoedyrfTuDfn+M/R7ayKXo5euI09du41puKbKKKuHhcO9fIn9dztY8fjDI3Whfu5qx30PiPWwtTrZyfD61L7aeSsW7v15CZbUSl9KL8MS641j+RHc809cHEknzxgPzHt4/Xd47Ud9lCwsL9O3bF1FRUZptSqUSUVFRCAsLu+ex33//PSoqKjBlyhSt7VVVVaiqqqrzJshkMo4tMCKxNSVg5OZSdLyPvyqpabTLweQ0uv++Wqt/jOxmmK2zRKQfEokEUwf64ed5g9HRTfX7ubRSgdf/dxGv7jyPYi4jZxRET7MjIiLw5Zdf4uuvv0Z8fDzmzp2LkpISzJw5EwAwbdo0rUkiaps2bcK4cePg7Oystd3e3h7Dhg3D66+/joMHDyIlJQVfffUVvvnmGzz55JOt8pro/twuqURqXikAoLuXA8xkon9M27yBtdcFbqQczI28UlzOUI0z6eXrCDe7pnc5EFHb0c3THr/MH4wJ/Xw12346fwuPfXpEq4wXGSbRxwBOmDAB2dnZWLZsGTIyMtCrVy/s2bNHMzEkNTW1TmteQkICjh49ir1799Z7zh07dmDx4sV47rnnkJeXBz8/P7z//vuYM2eO3l8P3T/1+r8ANCVKSL/6tG8HCzMpKquVON5IAli7+DNX/yAybdYWZvjgmZ4Y0skFb/4Yi6KKalzPLcXTG47jjYe74vnBAZCyRJRBEj0BBID58+dj/vz59T538ODBOtu6dOlyz7UJPTw8sGXLlpYKj1oZE8DWJzeXoW/7djiRnIubt8twI68Uvk7W9e7L1T+I6G7hIV4I8XHEyzvO4cKNfFQpBLz3WzyOJubg4/EhcLatO86exMW+NTI4F27kax4HcwWQVlN7XeCGloUrKKvCqeQ8AEB7J2t0duf4TCJSae9sje//Lwz/NyxQs+1gQjYe+eQIjic2PraYWhcTQDI46hZAW0szBLrYNLI3tZTaCeDJBrqBD13JRnXNMlCju7k3e7YfEbVNFmZSLH6kG75+fgBcbFXLyGUVVeC5Tafw0Z+XUa3gZExDwQSQDEpWUTnSC1TFt3t423PsSCsK8XGElbmqKPSJ5Nx6h1nUnv07Ooizf4mofsM6u+L3hUMxtJMLAEAQgHUHkjDhi5O4ebtU5OgIYAJIBkZd/gUAevo4iheICbIwk6KffzsAQHpBOa7nav+SrqxW4mCCarUPe7kZ+vs7tXqMRGQ83Ozk+HrmALzxcFeY1fwxf/b6bTz6yRH8EZsucnTEBJAMysVaCWCwNyeAtLaBgQ2PAzx9LQ9F5ar6XiO6usGc5XmIqBFSqQRzh3fAf+eEwaedFQCgsLwac7fF4K1dsSivUkChFHAyORd7L+fhZHIuFMqGJ3lSyzGIWcBEarVnAIewBbDVDbqrHuCkAe0132t1/3L2LxHpoE/7dvhtwVC8uSsWv11Utf5tO5WKA5ezUKlQIqe4smbPFHg6yBEZHoSHexjvEpPGgH/Ck8EQBEFTPNTByhy+TlbiBmSCgr0dYGup+rvweNKdcYCCIGjKv5jLJBjWxVW0GInIODlYmWPtpN5Y9VQw5Oaq9ONWQXmt5E8lo6Acc7fGYE8cu4n1iQkgGYz0Wr8Ievo4cIapCMxkUvSvGQeYU1yBpOxiAEBCZhFu3i4DoOomtpebixYjERkviUSCiQPa46eXBmvGBd5N3QG8fPcldgfrERNAMhgXb7IAtCEIq2dZuH1/s/uXiFrO7dIqTUmp+ghQNQpEp+S1XlAmhgkgGYzaa0eyALR4wgJdNI/VE0Fqr/4xqhvLvxDR/ckqKm/R/Uh3TADJYHAJOMMQ5GUPe7lqHODJ5DxkFJTjQk3rbDdPe/i0q3+JOCKipnKzkzdpPwszpin6wneWDIJqAogqyXCxtYSnQ9N+OVDLk0klGBCg6gbOK6nEhoOJmuceZOsfEbWAAQFO8HSQo7GR3kt2xeLwlexWicnUMAEkg5CaV4qCsioAnABiCGqXg/nm5HXN4weDPMQIh4jaGJlUgsjwIAC4ZxKYW1KFaZujsfKPeFRxGbkWxQSQDAILQBsWZa1l4NQPpRJwCSciajEP9/DEhil94HFXj4+ngxwfPtMTw2uVm/r8UDKe2XgCqbn8HdRSWAiaDIJWAWhfJoBi2hOXjvd/i6+zXSkAL22LwYYpfViglYhaxMM9PPFgkAdOJecg8WY2Ovq4IjTQBTKpBM/08cHmYyn4YM9lVCkEXLiRj8c+PYIVTwUjPMRL7NCNHlsAySBcuJGvedyDLYCiUSgFLN99CfeqvMXaXETUkmRSCQYGOuOhrk4YGOgMWU19QKlUgheHBuKHuYPg56yafFZUUY2XvzuHRT9cRFmlQsywjR4TQBKdUikgrqYF0NNB3uTZYdTyolPykF7QcNkF1uYiotbW08cRv748BGN73Wn123H6BsLXHsXljEIRIzNuTABJdMk5JSip+UuO5V/ExdpcRGSI7OTmWDOhFz56pieszGUAgMSsYjyx9hi+PXlds2wlNR0TQBJdbFq+5nFPH0fR4qCm1+ZiKy0RtTaJRILx/Xzx64Ih6OZpDwCorFZi6U9xmLP1LApKq0SO0LgwASTRXbjBGcCGorHaXBKouukHBDi1ZlhERBodXG2x66VBmDHIX7Ptz78z8einR3DmGoenNBUTQBIdVwAxHPeqzaX+PjI8SDNIm4hIDHJzGd5+oju+mNoXjtbmAIC0/DJM+OIkPou6yolqTcAEkERVrVDi71uqBLC9kzUcrS1Ejogaqs3l4SBnCRgiMigPdffAHwuHYoC/qldCoRTw8b4rmPKfU8gs5Fjle2EdQBLV1axilFepqrsHs/XPYKhrc0Wn5CGrqBxudqpuX7b8EZGh8XSwwvZZofjsr0R89tdVKAXgRHIuHvnkCP41vidGdnUXO0SDxBZAElVsrRVAenL8n0GRSSUI6+CMsb28EdbBmckfERksM5kUrz7YGdtnDYSHvar3Iq+kEs9/dQbv/noJFdWsGXg3JoAkqoucAUxERC1kYKAz/lg4FKO7uWm2bTqagqc3HEdKTomIkRkeJoAkqtprAPfwthcxEiIiagva2Vjgy2n98HZ4ECxkqjQnLq0Qj396BLvO3RQ5OsPBBJBEU1GtQHy6qop7oKsN7OTmIkdERERtgUQiwYzBAfjxpUEIdLEBAJRUKvDqzgt47b8XUFJRLXKE4mMCSKK5klGMKoVqqn4Iu3+JiKiF9fB2wO6Xh+CZvj6abT/E3ET4Z0c1S5CaKiaAJJoLN/M1j1kAmoiI9MHG0gz/Gh+CNRN6wcZCtYxcck4Jnlp/HFuOpZjsMnJMAEk0WjOAWQKGiIj0aFxvb/y6YKimwaFSocTy3Zcw65szyCupFDm61scEkERzsab5XSoBunsxASQiIv0KcLHBD3MH4cUhAZpt++Oz8OgnR3AyOVfEyFofE0ASRVmlAlcyiwAAnd3tYFXTLE9ERKRPFmZSLHk8CFtm9IeTjWr1qYzCckz+8iT+ve8KqhVKkSNsHUwASRSX0gs1azVy/B8REbW2EV3d8MfCoQgLdAYAKAXgk6irmPzlKdzKLxM5Ov0ziARw3bp18Pf3h1wuR2hoKKKjoxvcd/jw4ZBIJHW+HnvsMa394uPj8cQTT8DBwQE2Njbo378/UlNT9f1SqIlia00A6enrKFocRERkutzt5dj6Yij+8VBnzWpH0dfy8OinR7D37wyRo9Mv0RPAnTt3IiIiApGRkYiJiUFISAjGjBmDrKysevf/8ccfkZ6ervmKi4uDTCbD+PHjNfskJSVhyJAh6Nq1Kw4ePIiLFy9i6dKlkMvl9Z6TWt9FLgFHREQGQCaVYP7ITtg5eyC8Ha0AAPmlVZj97VlE/hyH8qq2uYyc6Ang6tWrMWvWLMycORNBQUHYuHEjrK2tsXnz5nr3d3JygoeHh+Zr3759sLa21koA33rrLTz66KP48MMP0bt3b3To0AFPPPEE3Nzc6j0ntT71BBBzmQRdPe1EjoaIiExdP38n/L5gKB7u7qHZ9vWJ63hy/XEkZReLGJl+mIl58crKSpw9exaLFy/WbJNKpRg9ejROnDjRpHNs2rQJEydOhI2NqtK3UqnEb7/9hn/+858YM2YMzp07h4CAACxevBjjxo2r9xwVFRWoqKjQfF9YWKg5l1Kpv8GgSqUSgiDo9RqGqLiiWvPD1MXDDuZSidG+B6Z6D9sS3kPjx3to/AzlHtrJZVg3uRe2R9/Au7/Fo7Jaifj0Qjz+6VG8/UQQnunjDYlEImqM96LL+ydqApiTkwOFQgF3d3et7e7u7rh8+XKjx0dHRyMuLg6bNm3SbMvKykJxcTFWrVqF9957Dx988AH27NmDp556CgcOHMCwYcPqnGflypVYvnx5ne3Z2dkoLy9vxitrGqVSiYKCAgiCAKlU9MbYVhNzswjqupudnCwa7O43BqZ6D9sS3kPjx3to/AztHj4YIEfAxK5Y8nsyruWVo6xKgTd+iEVUXBreGNkeNpaGWbmiqKioyfuKmgDer02bNiE4OBgDBgzQbFNnv2PHjsWrr74KAOjVqxeOHz+OjRs31psALl68GBEREZrvCwsL4evrC1dXV9jb2+stfqVSCYlEAldXV4P4wLeWmwklmscDOnoYdde8qd7DtoT30PjxHho/Q7yHbm7Arx298e6v8dh55iYAYG9CHhKyy/HJxF4GuYCBLnMdRE0AXVxcIJPJkJmZqbU9MzMTHh4eDRylUlJSgh07duCdd96pc04zMzMEBQVpbe/WrRuOHj1a77ksLS1haWlZZ7tUKtX7B1EikbTKdQxJ7K1CzeMQ33ZG/9pN8R62NbyHxo/30PgZ4j20lVvgg2dCMKSTK978MRZFFdW4nleK8Z+fwD/HdMULQwIglRpOl7Au752o77KFhQX69u2LqKgozTalUomoqCiEhYXd89jvv/8eFRUVmDJlSp1z9u/fHwkJCVrbr1y5Aj8/v5YLnppNXQLG0kyKTu624gZDRETUiPAQL/y+cChCasqWVSkEvP97PJ7/+jRyiivufbCBEj3NjoiIwJdffomvv/4a8fHxmDt3LkpKSjBz5kwAwLRp07Qmiaht2rQJ48aNg7Ozc53nXn/9dezcuRNffvklEhMTsXbtWuzevRsvvfSS3l8P3VtBaRWu5ZYCAIK87GEuE/0jSERE1ChfJ2v8b04Y/m9YoGbbwYRsPPLJERxLzBExsuYRfQzghAkTkJ2djWXLliEjIwO9evXCnj17NBNDUlNT6zRpJiQk4OjRo9i7d2+953zyySexceNGrFy5EgsWLECXLl3www8/YMiQIXp/PXRvsWms/0dERMbJXCbF4ke6YXAHF0T89zxyiiuRXVSBKZtO4aXhHfDK6M5G07AhEQT1fExSKywshIODAwoKCvQ+CSQrKwtubm4GNeZBn9YfTMSHe1Td8x+PD8HTfX1Ejuj+mOI9bGt4D40f76HxM8Z7mFVUjtf+ewFHrt5p/evT3hGfTuoNn3bWosSkS/5iHO8ytRkXb9RqATTAGVRERERN4WYnx9czB2DRI11hVjMRJCY1H49+cgR/xKaLHF3jmABSq1J3AVtbyBDoygkgRERkvKRSCeYM64Dv54TBp51qGbnC8mrM3RaDN3fFapaRUygFnEjKxc/n03AiKRcKpfidr6KPASTTkVNcgbT8MgBAD28HzcLbRERExqx3+3b4feFQLP4xFr9dVLX+bT+VirPXbmNCf198eSQZ6QV3FpbwdJAjMjwID/fwFCtktgBS64m9yQkgRETUNtnLzbF2Um+seioYcnNVepWQWYR3fr2klfwBQEZBOeZujcGeOPG6ipkAUqu5WCsBDOb4PyIiamMkEgkmDmiP3fOHoLNbw8Oc1B3Ay3dfEq07mAkgtZrYtHzN4xAfR9HiICIi0qdO7nZ46/Fu99xHAJBeUI7olLzWCeouTACpVQiCgAs1LYB2cjP4OYszRZ6IiKg15JdWNWm/rKLyxnfSAyaA1CoyCyuQXaRaLqenjwMkEk4AISKitsvNTt6i+7U0JoDUKi7WrP8LAD3Z/UtERG3cgAAneDrI0VBzhwSq2cADApxaMywNJoDUKi5yBjAREZkQmVSCyPAgAKiTBKq/jwwPEq0kGhNAahUX0zgDmIiITMvDPTyxYUofeDhod/N6OMixYUofUesAshA06Z0gCIit6QJ2trGAt6OVuAERERG1kod7eOLBIA9Ep+Qhq6gcbnaqbl+xF0NgAkh6d/N2GW7XzIYK5gQQIiIyMTKpBGEdnMUOQwu7gEnvOP6PiIjIsDABJL27WKsANGcAExERiY8JIOndxRucAEJERGRImACKRKEUcDI5F3sv5+Fkcq5oawHqm1IpIK5mBrC7vSXc7cUpeElERER3cBKICPbEpWP57ktIL1Av/5ICTwc5IsODRJ0Srg/XcktQVFENAAj2dhQ3GCIiIgLAFsBWtycuHXO3xtRK/lQyCsoxd2sM9sSlixSZfsTWqv8Xwu5fIiIig8AEsBUplAKW776E+jp71duW777UprqDL3D8HxERkcFhAtiKolPy6rT81SYASC8ox7/+TMCJpFxczy1BRbWi9QLUg1jOACYiIjI4HAPYirKKGk7+attwKAkbDiVpvnextYS3oxyeDlbwcrSCl6O85l8reDnI4WJrCanIFcXro1AKiEsrBAD4tLOCk42FyBERERERwASwVbnZNW8GbE5xBXKKK3ChVkHl2sxlEng6WMHTQQ5vRyt4qhPEWgmjndz8fkJvlsSsYpRVqVowe7L7l4iIyGAwAWxFAwKc4OkgR0ZBeb3jAAGgnbU55o/siMzCCqTll+FWfhnS88uRWVQOoYGDqhQCUvNKkZpX2uC17SzN4KWVHNZuRbSCh4McFmYtNyJAoRSwK+am5vvuXkwAiYiIDAUTwFYkk0oQGR6EuVtjIAG0kkB1B+7Kp4LrLQVTpVAis7Act/LLcSu/DLcK7iSHafllSC8oR0FZVYPXLqqoRkJmERIyi+p9XiJRdTXXTQ7lmsTRxaZpXc11y9wAm46moIOrTZsrc0NERGSMmAC2sod7eGLDlD51EiSPRuoAmsuk8GlnDZ921g2eu7iiGun5ZbhVUF6THJYhrSZhTC9Qba+sVtZ7rCAA2UUVyC6qwIUb9Z/fQiaFh4P8zhjEmi5mT8earmcHOY4l5mDu1pg6LZy3Syoxd2sMNkzpwySQiIhIZEwARfBwD088GOSBU8k5SLyZjY4+rggNdIHsPidy2FqaoZO7HTq529X7vCAIyC2pVLUg5pdpWhPTC9StiGXIKqposKu5UqFstKv57pZNzbVrnlu++xIeDPK479dKREREzccEUCQyqQQDA50RaKuAm5tzq8zilUgkcLG1hIutZYMlWSqr1V3N6m7mck3CqE4Ui8qrG7zGvSoYqsvcRKfkIayD8329FiIiImo+JoCkxcJMCl8na/g6NdzVXFRedafVsNaYxIs385GYVdLoNZpaDoeIiIj0gwkg6cxObg47uTk639XVfCIpF5O+PNno8c0th0NEREQtgyuBUItRl7lpqDNbAsDTQY4BAU6tGRYRERHdhQkgtRh1mRsAdZJA9feR4UGcAEJERCQyg0gA161bB39/f8jlcoSGhiI6OrrBfYcPHw6JRFLn67HHHqt3/zlz5kAikWDNmjV6ip5qU5e58XDQ7ub1cJCzBAwREZGBEH0M4M6dOxEREYGNGzciNDQUa9aswZgxY5CQkAA3N7c6+//444+orKzUfJ+bm4uQkBCMHz++zr67du3CyZMn4eXlpdfXQNrUZW6iU/KQVVQONztVty9b/oiIiAyD6C2Aq1evxqxZszBz5kwEBQVh48aNsLa2xubNm+vd38nJCR4eHpqvffv2wdrauk4CmJaWhpdffhnbtm2DuXnrr4Nr6mRSCcI6OGNsL2+EdXBm8kdERGRARE0AKysrcfbsWYwePVqzTSqVYvTo0Thx4kSTzrFp0yZMnDgRNjY2mm1KpRJTp07F66+/ju7du7d43ERERETGTNQu4JycHCgUCri7u2ttd3d3x+XLlxs9Pjo6GnFxcdi0aZPW9g8++ABmZmZYsGBBk+KoqKhARUWF5vvCwkIAqkRSqax/6bSWoFQqIQiCXq9B+sV7aPx4D40f76Hx4z1sGbq8f6KPAbwfmzZtQnBwMAYMGKDZdvbsWXzyySeIiYmBRNK0bseVK1di+fLldbZnZ2ejvFx/RYuVSiUKCgogCAKkUtF746kZeA+NH++h8eM9NH68hy2jqKioyfuKmgC6uLhAJpMhMzNTa3tmZiY8PDzueWxJSQl27NiBd955R2v7kSNHkJWVhfbt22u2KRQKvPbaa1izZg2uXbtW51yLFy9GRESE5vvCwkL4+vrC1dUV9vb2zXhlTaNUKiGRSODq6soPvJHiPTR+vIfGj/fQ+PEetgy5vOkLLYiaAFpYWKBv376IiorCuHHjAKg+BFFRUZg/f/49j/3+++9RUVGBKVOmaG2fOnWq1phCABgzZgymTp2KmTNn1nsuS0tLWFpa1tkulUr1/kGUSCStch3SH95D48d7aPx4D40f7+H90+W9E70LOCIiAtOnT0e/fv0wYMAArFmzBiUlJZpkbdq0afD29sbKlSu1jtu0aRPGjRsHZ2dnre3Ozs51tpmbm8PDwwNdunTR74shIiIiMgKiJ4ATJkxAdnY2li1bhoyMDPTq1Qt79uzRTAxJTU2tk9EmJCTg6NGj2Lt3r15iEgQBwJ3JIPqiVCpRVFQEuVzOv3iMFO+h8eM9NH68h8aP97BlqPMWdR5zLxKhKXuZmJs3b8LX11fsMIiIiIh0duPGDfj4+NxzHyaA9VAqlbh16xbs7OyaPJO4OdSTTW7cuKHXySakP7yHxo/30PjxHho/3sOWIQgCioqK4OXl1WhLquhdwIZIKpU2mjm3JHt7e37gjRzvofHjPTR+vIfGj/fw/jk4ODRpP3a0ExEREZkYJoBEREREJoYJoIgsLS0RGRlZbw1CMg68h8aP99D48R4aP97D1sdJIEREREQmhi2ARERERCaGCSARERGRiWECSERERGRimACKZN26dfD394dcLkdoaCiio6PFDomaaOXKlejfvz/s7Ozg5uaGcePGISEhQeyw6D6sWrUKEokEr7zyitihkA7S0tIwZcoUODs7w8rKCsHBwThz5ozYYZEOFAoFli5dioCAAFhZWaFDhw549913m7SUGd0fJoAi2LlzJyIiIhAZGYmYmBiEhIRgzJgxyMrKEjs0aoJDhw5h3rx5OHnyJPbt24eqqio89NBDKCkpETs0aobTp0/j888/R8+ePcUOhXRw+/ZtDB48GObm5vjjjz9w6dIlfPzxx2jXrp3YoZEOPvjgA2zYsAFr165FfHw8PvjgA3z44Yf47LPPxA6tzeMsYBGEhoaif//+WLt2LQDV0nO+vr54+eWXsWjRIpGjI11lZ2fDzc0Nhw4dwgMPPCB2OKSD4uJi9OnTB+vXr8d7772HXr16Yc2aNWKHRU2waNEiHDt2DEeOHBE7FLoPjz/+ONzd3bFp0ybNtqeffhpWVlbYunWriJG1fWwBbGWVlZU4e/YsRo8erdkmlUoxevRonDhxQsTIqLkKCgoAAE5OTiJHQrqaN28eHnvsMa2fRzIOv/zyC/r164fx48fDzc0NvXv3xpdffil2WKSjQYMGISoqCleuXAEAXLhwAUePHsUjjzwicmRtH9cCbmU5OTlQKBRwd3fX2u7u7o7Lly+LFBU1l1KpxCuvvILBgwejR48eYodDOtixYwdiYmJw+vRpsUOhZkhOTsaGDRsQERGBN998E6dPn8aCBQtgYWGB6dOnix0eNdGiRYtQWFiIrl27QiaTQaFQ4P3338dzzz0ndmhtHhNAovswb948xMXF4ejRo2KHQjq4ceMGFi5ciH379kEul4sdDjWDUqlEv379sGLFCgBA7969ERcXh40bNzIBNCL//e9/sW3bNmzfvh3du3fH+fPn8corr8DLy4v3Uc+YALYyFxcXyGQyZGZmam3PzMyEh4eHSFFRc8yfPx+//vorDh8+DB8fH7HDIR2cPXsWWVlZ6NOnj2abQqHA4cOHsXbtWlRUVEAmk4kYITXG09MTQUFBWtu6deuGH374QaSIqDlef/11LFq0CBMnTgQABAcH4/r161i5ciUTQD3jGMBWZmFhgb59+yIqKkqzTalUIioqCmFhYSJGRk0lCALmz5+PXbt24a+//kJAQIDYIZGORo0ahdjYWJw/f17z1a9fPzz33HM4f/48kz8jMHjw4Drll65cuQI/Pz+RIqLmKC0thVSqnYrIZDIolUqRIjIdbAEUQUREBKZPn45+/fphwIABWLNmDUpKSjBz5kyxQ6MmmDdvHrZv346ff/4ZdnZ2yMjIAAA4ODjAyspK5OioKezs7OqM2bSxsYGzszPHchqJV199FYMGDcKKFSvw7LPPIjo6Gl988QW++OILsUMjHYSHh+P9999H+/bt0b17d5w7dw6rV6/G888/L3ZobR7LwIhk7dq1+Oijj5CRkYFevXrh008/RWhoqNhhURNIJJJ6t2/ZsgUzZsxo3WCoxQwfPpxlYIzMr7/+isWLF+Pq1asICAhAREQEZs2aJXZYpIOioiIsXboUu3btQlZWFry8vDBp0iQsW7YMFhYWYofXpjEBJCIiIjIxHANIREREZGKYABIRERGZGCaARERERCaGCSARERGRiWECSERERGRimAASERERmRgmgEREREQmhgkgERERkYlhAkhEJkEikeCnn34SOwydHDx4EBKJBPn5+WKH0mRvv/02evXqJXYYRNQIJoBEZHBmzJgBiURS5ysxMVHs0BpljEkbEZkeM7EDICKqz8MPP4wtW7ZobXN1dRUpGqCystIo1iatqqqCubm52GEQkYFjCyARGSRLS0t4eHhofclkMgDAzz//jD59+kAulyMwMBDLly9HdXW15tirV6/igQcegFwuR1BQEPbt21fn/Ddu3MCzzz4LR0dHODk5YezYsbh27Zrm+RkzZmDcuHF4//334eXlhS5dugAAvv32W/Tr1w92dnbw8PDA5MmTkZWVBQC4du0aRowYAQBo164dJBIJZsyYAQBQKpVYuXIlAgICYGVlhZCQEPzvf//Tiun3339H586dYWVlhREjRmjF0xCJRIINGzbgiSeegI2NDd5//30AwIYNG9ChQwdYWFigS5cu+PbbbzXHXLt2DRKJBOfPn9dsy8/Ph0QiwcGDBwHcacmMiopCv379YG1tjUGDBiEhIUHr+qtWrYK7uzvs7OzwwgsvoLy8vNGYiUh8TACJyKgcOXIE06ZNw8KFC3Hp0iV8/vnn+OqrrzSJj1KpxFNPPQULCwucOnUKGzduxBtvvKF1jqqqKowZMwZ2dnY4cuQIjh07BltbWzz88MOorKzU7BcVFYWEhATs27cPv/76q+bYd999FxcuXMBPP/2Ea9euaZI8X19f/PDDDwCAhIQEpKen45NPPgEArFy5Et988w02btyIv//+G6+++iqmTJmCQ4cOAVAlpE899RTCw8Nx/vx5vPjii1i0aFGT3pO3334bTz75JGJjY/H8889j165dWLhwIV577TXExcXh//7v/zBz5kwcOHBA5/f7rbfewscff4wzZ87AzMwMzz//vOa5//73v3j77bexYsUKnDlzBp6enli/fr3O1yAiEQhERAZm+vTpgkwmE2xsbDRfzzzzjCAIgjBq1ChhxYoVWvt/++23gqenpyAIgvDnn38KZmZmQlpamub5P/74QwAg7Nq1S7N/ly5dBKVSqdmnoqJCsLKyEv78809NDO7u7kJFRcU9Yz19+rQAQCgqKhIEQRAOHDggABBu376t2ae8vFywtrYWjh8/rnXsCy+8IEyaNEkQBEFYvHixEBQUpPX8G2+8UedcdwMgvPLKK1rbBg0aJMyaNUtr2/jx44VHH31UEARBSElJEQAI586d0zx/+/ZtAYBw4MABrdexf/9+zT6//fabAEAoKysTBEEQwsLChJdeeknrOqGhoUJISEiD8RKRYeAYQCIySCNGjMCGDRs039vY2AAALly4gGPHjmla/ABAoVCgvLwcpaWliI+Ph6+vL7y8vDTPh4WFaZ37woULSExMhJ2dndb28vJyJCUlab4PDg6uM+7v7NmzePvtt3HhwgXcvn0bSqUSAJCamoqgoKB6X0tiYiJKS0vx4IMPam2vrKxE7969AQDx8fEIDQ3Vev7uuBvSr18/re/j4+Mxe/ZsrW2DBw/WtEbqomfPnprHnp6eAICsrCy0b98e8fHxmDNnTp2Ym9PSSEStiwkgERkkGxsbdOzYsc724uJiLF++HE899VSd5+RyeZPOXVxcjL59+2Lbtm11nqs90USddKqVlJRgzJgxGDNmDLZt2wZXV1ekpqZizJgxWl3H9V0PAH777Td4e3trPWdpadmkmO/l7jgbI5WqRv8IgqDZVlVVVe++tSeUSCQSANAkvURkvJgAEpFR6dOnDxISEupNDgGgW7duuHHjBtLT0zUtVidPnqxzjp07d8LNzQ329vZNvvbly5eRm5uLVatWwdfXFwBw5swZrX3ULYYKhUKzLSgoCJaWlkhNTcWwYcMajPuXX37R2nZ33E3VrVs3HDt2DNOnT9dsO3bsmKaFUp3kpqena1oga08I0eU6p06dwrRp0+47ZiJqXUwAicioLFu2DI8//jjat2+PZ555BlKpFBcuXEBcXBzee+89jB49Gp07d8b06dPx0UcfobCwEG+99ZbWOZ577jl89NFHGDt2LN555x34+Pjg+vXr+PHHH/HPf/4TPj4+9V67ffv2sLCwwGeffYY5c+YgLi4O7777rtY+fn5+kEgk+PXXX/Hoo4/CysoKdnZ2+Mc//oFXX30VSqUSQ4YMQUFBAY4dOwZ7e3tMnz4dc+bMwccff4zXX38dL774Is6ePYuvvvqqWe/R66+/jmeffRa9e/fG6NGjsXv3bvz444/Yv38/AMDKygoDBw7EqlWrEBAQgKysLCxZskTn6yxcuBAzZsxAv379MHjwYGzbtg1///03AgMDmxU3EbUisQchEhHdbfr06cLYsWMbfH7Pnj3CoEGDBCsrK8He3l4YMGCA8MUXX2ieT0hIEIYMGSJYWFgInTt3Fvbs2aM1CUQQBCE9PV2YNm2a4OLiIlhaWgqBgYHCrFmzhIKCgnvGsH37dsHf31+wtLQUwsLChF9++aXOhIp33nlH8PDwECQSiTB9+nRBEARBqVQKa9asEbp06SKYm5sLrq6uwpgxY4RDhw5pjtu9e7fQsWNHwdLSUhg6dKiwefPmJk0Cqf261NavXy8EBgYK5ubmQufOnYVvvvlG6/lLly4JYWFhgpWVldCrVy9h79699U4CqX3tc+fOCQCElJQUzbb3339fcHFxEWxtbYXp06cL//znPzkJhMgISASh1iAQIiIiImrzWAeQiIiIyMQwASQiIiIyMUwAiYiIiEwME0AiIiIiE8MEkIiIiMjEMAEkIiIiMjFMAImIiIhMDBNAIiIiIhPDBJCIiIjIxDABJCIiIjIxTACJiIiITAwTQCIiIiIT8/+HO6kQQU8D5gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 650x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAGGCAYAAADrfDCjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAZlRJREFUeJzt3XlcVOX+B/DPmYGZYZd9FwRXNEFUENwT0zSXbLHFNCsr01vGzVvWvZl61VavlbnmUpr32q+03LKUrNw31FxRFHBjFRj2beb8/hiYHAEFnOHMMJ/368Ur58yZc74zZ8iPz3Oe5xFEURRBRERERFZDJnUBRERERNS8GACJiIiIrAwDIBEREZGVYQAkIiIisjIMgERERERWhgGQiIiIyMowABIRERFZGQZAIiIiIivDAEhERERkZRgAicgqPPvsswgODm728w4YMAADBgzQP05NTYUgCFizZs1dX2uKmtesWQNBEJCammrU4zZEcHAwnn322WY/LxHVxgBIRAYuXbqEl156CSEhIVCpVHB2dkbv3r3x6aeforS01GTnvXHjBt577z2cOHHCZOewJvPmzcMPP/wgdRlEZKZspC6AiMzHtm3b8Nhjj0GpVGL8+PHo0qULKioqsHfvXkyfPh1nzpzB8uXLTXLuGzduYNasWQgODkZERIRJzmEOgoKCUFpaCltbW5OeZ968eXj00UcxevRog+3PPPMMnnjiCSiVSpOen4jMGwMgEQEAUlJS8MQTTyAoKAi//vorfH199c9NmTIFycnJ2LZtm4QVGiopKYG9vb3UZTSaIAhQqVSSnV8ul0Mul0t2fiIyD+wCJiIAwIcffoiioiKsXLnSIPzVaNu2LV577TWDbevWrUP37t1hZ2cHNzc3PPHEE7h69arBPgMGDECXLl1w9uxZDBw4EPb29vD398eHH36o3+e3335Dz549AQATJ06EIAgG98nVHOPYsWPo168f7O3t8fbbbwMAfvzxRwwfPhx+fn5QKpUIDQ3FnDlzoNFoGv0ZPPTQQwgJCanzuZiYGPTo0UP/ePXq1bj//vvh5eUFpVKJsLAwLFmy5K7nqO8ewB9++AFdunSBSqVCly5dsGnTpjpf//HHHyM2Nhbu7u6ws7ND9+7d8d133xnsIwgCiouL8dVXX+k/y5p77+q7B3Dx4sXo3LkzlEol/Pz8MGXKFOTn5xvs05Br2ViXL1/GY489Bjc3N9jb26NXr151/kPj888/R+fOnWFvbw9XV1f06NED69ev1z9fWFiIadOmITg4GEqlEl5eXhg8eDASExObXBtRS8YASEQAgC1btiAkJASxsbEN2n/u3LkYP3482rVrhwULFmDatGlISEhAv379agWHvLw8DB06FOHh4fjkk0/QsWNHvPnmm/jpp58AAJ06dcLs2bMBAC+++CLWrl2LtWvXol+/fvpj3Lx5Ew8++CAiIiKwcOFCDBw4EIAu0Dg6OiI+Ph6ffvopunfvjnfffRdvvfVWoz+DsWPHIiUlBUeOHDHYnpaWhoMHD+KJJ57Qb1uyZAmCgoLw9ttv45NPPkFgYCBeeeUVfPHFF40+7y+//IJHHnkEgiBg/vz5GD16NCZOnIijR4/W2vfTTz9Ft27dMHv2bMybNw82NjZ47LHHDELT2rVroVQq0bdvX/1n+dJLL9V7/vfeew9TpkyBn58fPvnkEzzyyCNYtmwZHnjgAVRWVhrse7dr2RiZmZmIjY3Fzz//jFdeeQVz585FWVkZRo4caRCAV6xYgVdffRVhYWFYuHAhZs2ahYiICBw6dEi/z8svv4wlS5bgkUceweLFi/HGG2/Azs4O586da3RdRFZBJCKrp1arRQDiqFGjGrR/amqqKJfLxblz5xpsP3XqlGhjY2OwvX///iIA8euvv9ZvKy8vF318fMRHHnlEv+3IkSMiAHH16tW1zldzjKVLl9Z6rqSkpNa2l156SbS3txfLysr02yZMmCAGBQXd8X2p1WpRqVSKf//73w22f/jhh6IgCGJaWtodzztkyBAxJCSkVu39+/fXP05JSan1PiMiIkRfX18xPz9fv+2XX34RAdSq+fbzVlRUiF26dBHvv/9+g+0ODg7ihAkTatW4evVqEYCYkpIiiqIoZmVliQqFQnzggQdEjUaj32/RokUiAHHVqlUG76Uh17I+QUFBBjVNmzZNBCDu2bNHv62wsFBs06aNGBwcrK9n1KhRYufOne94bBcXF3HKlCl3rYGIdNgCSEQoKCgAADg5OTVo/40bN0Kr1eLxxx9HTk6O/sfHxwft2rXD7t27DfZ3dHTEuHHj9I8VCgWioqJw+fLlBteoVCoxceLEWtvt7Oz0fy4sLEROTg769u2LkpISnD9/vsHHBwBnZ2c8+OCD+PbbbyGKon77hg0b0KtXL7Ru3brO86rVauTk5KB///64fPky1Gp1g8+Znp6OEydOYMKECXBxcdFvHzx4MMLCwmrtf+t58/LyoFar0bdv3yZ3de7atQsVFRWYNm0aZLK//kqYNGkSnJ2da3XHGuNa1ti+fTuioqLQp08fg+O/+OKLSE1NxdmzZwEArVq1wrVr12q1zN6qVatWOHToEG7cuNHoOoisEQMgEcHZ2RmALkA1xMWLFyGKItq1awdPT0+Dn3PnziErK8tg/4CAAAiCYLDN1dUVeXl5Da7R398fCoWi1vYzZ87g4YcfhouLC5ydneHp6akPKI0JYjXGjh2Lq1ev4sCBAwB00+IcO3YMY8eONdhv3759iIuLg4ODA1q1agVPT0/9fYmNOW9aWhoAoF27drWe69ChQ61tW7duRa9evaBSqeDm5gZPT08sWbKkSe/11vPffi6FQoGQkBD98zWMcS1vPXdd77FTp04Gtb355ptwdHREVFQU2rVrhylTpmDfvn0Gr/nwww9x+vRpBAYGIioqCu+9916TQimRteAoYCKCs7Mz/Pz8cPr06Qbtr9VqIQgCfvrppzpHlDo6Oho8rm/U6a2tbHdza8tXjfz8fPTv3x/Ozs6YPXs2QkNDoVKpkJiYiDfffBNarbbBx68xYsQI2Nvb49tvv0VsbCy+/fZbyGQyPPbYY/p9Ll26hEGDBqFjx45YsGABAgMDoVAosH37dvznP/9p0nkbYs+ePRg5ciT69euHxYsXw9fXF7a2tli9erXBgAhTMsa1bKxOnTohKSkJW7duxY4dO/D9999j8eLFePfddzFr1iwAwOOPP46+ffti06ZN+OWXX/DRRx/hgw8+wMaNG/Hggw+arDYiS8UASEQAdCNgly9fjgMHDiAmJuaO+4aGhkIURbRp0wbt27c3yvlvb1VqiN9++w03b97Exo0bDQaMpKSkNLkOBwcHPPTQQ/i///s/LFiwABs2bEDfvn3h5+en32fLli0oLy/H5s2bDbqFb+/6boigoCAAulbV2yUlJRk8/v7776FSqfDzzz8bzOO3evXqWq9t6OdZc/6kpCSDEdAVFRVISUlBXFxcg47TFEFBQbXeIwB9131NbYDuuowdOxZjx45FRUUFxowZg7lz52LGjBn6aXV8fX3xyiuv4JVXXkFWVhYiIyMxd+5cBkCiOrALmIgAAP/4xz/g4OCAF154AZmZmbWev3TpEj799FMAwJgxYyCXyzFr1qxaLT+iKOLmzZuNPr+DgwMA1BpBfCc1rVG31lBRUYHFixc3+vy3Gjt2LG7cuIEvv/wSJ0+erNX9W9d51Wp1nUHsbnx9fREREYGvvvrKoBt3586d+nvgbj2vIAgGU9ykpqbWueKHg4NDgz7LuLg4KBQKfPbZZwbvZ+XKlVCr1Rg+fHij31NDDRs2DIcPH9Z3twNAcXExli9fjuDgYP09kLd/nxQKBcLCwiCKIiorK6HRaGp1gXt5ecHPzw/l5eUmq5/IkrEFkIgA6Fr11q9fj7Fjx6JTp04GK4Hs378f//d//6efSy40NBT//ve/MWPGDKSmpmL06NFwcnJCSkoKNm3ahBdffBFvvPFGo8/fqlUrLF26FE5OTnBwcEB0dDTatGlT72tiY2Ph6uqKCRMm4NVXX4UgCFi7du09d0cOGzYMTk5OeOONNyCXy/HII48YPP/AAw9AoVBgxIgReOmll1BUVIQVK1bAy8sL6enpjT7f/PnzMXz4cPTp0wfPPfcccnNz9fPeFRUV6fcbPnw4FixYgKFDh+Kpp55CVlYWvvjiC7Rt2xZ//vmnwTG7d++OXbt2YcGCBfDz80ObNm0QHR1d69yenp6YMWMGZs2ahaFDh2LkyJFISkrC4sWL0bNnT4MBH8b21ltv4b///S8efPBBvPrqq3Bzc8NXX32FlJQUfP/99/pBKQ888AB8fHzQu3dveHt749y5c1i0aBGGDx8OJycn5OfnIyAgAI8++ijCw8Ph6OiIXbt24ciRI/jkk09MVj+RRZNm8DERmasLFy6IkyZNEoODg0WFQiE6OTmJvXv3Fj///HODaVVEURS///57sU+fPqKDg4Po4OAgduzYUZwyZYqYlJSk36d///51TuFR17QsP/74oxgWFiba2NgYTJVS3zFEURT37dsn9urVS7SzsxP9/PzEf/zjH+LPP/8sAhB37959x/PdydNPPy0CEOPi4up8fvPmzWLXrl1FlUolBgcHix988IG4atUqgylWamq/2zQwoqj7LDt16iQqlUoxLCxM3LhxY501r1y5UmzXrp2oVCrFjh07iqtXrxZnzpwp3v6/8/Pnz4v9+vUT7ezsRAD66VdunwamxqJFi8SOHTuKtra2ore3tzh58mQxLy/PYJ/GXMu63D4NjCiK4qVLl8RHH31UbNWqlahSqcSoqChx69atBvssW7ZM7Nevn+ju7i4qlUoxNDRUnD59uqhWq0VR1E1FM336dDE8PFx0cnISHRwcxPDwcHHx4sV3rYnIWgmiaMI7d4mIiIjI7PAeQCIiIiIrwwBIREREZGUYAImIiIisDAMgERERkZVhACQiIiKyMgyARERERFaGE0HXQavV4saNG3BycmrS8lREREREzU0URRQWFsLPz08/kXp9GADrcOPGDQQGBkpdBhEREVGjXb16FQEBAXfchwGwDk5OTgB0H6Czs7NJzqHVapGdnQ1PT8+7pnQyX7yOlo/X0PLxGlo+XkPjKCgoQGBgoD7H3AkDYB1qun2dnZ1NGgDLysrg7OzML7sF43W0fLyGlo/X0PLxGhpXQ25f46dMREREZGUYAImIiIisDAMgERERkZVhACQiIiKyMgyARERERFaGAZCIiIjIynAaGDIJjVbE4ZRcZBWWwctJhag2bpDLuKoKERGROWAAJKPbcTods7acRbq6TL/N10WFmSPCMLSLr4SVEREREcAuYDKyHafTMXldokH4A4AMdRkmr0vEjtPpElVGRERENRgAyWg0WhGztpyFWMdzNdtmbTkLjbauPYiIiKi5MACS0RxOya3V8ncrEUC6ugyHU3KbrygiIiKqhQGQjCarsP7w15T9iIiIyDQYAMlovJxURt2PiIiITIMBkIwmqo0bfF3qD3cCdKOBo9q4NV9RREREVAsDIBmNXCZg5oiwO+4zc0QY5wMkIiKSGAMgGdXQLr4I83Wu87kFj4dzHkAiIiIzwABIRlVUXoXkrCIAgLuDLfq09dA/x8lfiIiIzAMDIBnVngvZqNBoAQDD7vPDtLh2+uc2n7whVVlERER0CwZAMqpd57L0fx7UyQuRrV3h38oOALD3Yg5yiyukKo2IiIiqMQCS0Wi0InYn6QKgg0KOmFB3yGQCHuqqu++vSiviJy4FR0REJDkGQDKa41fy9C18fdt5QmkjBwCMCPfT77P5BLuBiYiIpMYASEZze/dvjc5+zgjxdAAAHE7NRcYdlosjIiIi02MAJKPZdS4TACAIwP0d/wqAgiBgZHUroCgCW/9kKyAREZGUGADJKNJuFuunf4ls7Qp3R6XB87d2A2/haGAiIiJJMQCSUdTX/Vsj1NMRnf10E0SfvKZGak5xs9VGREREhhgAySh2nc3U/3lwJ+869xnJVkAiIiKzwABI90xdWokjqbkAgNZu9mjr5Vjnfg/dOhr45A2IItcGISIikgIDIN2z3y9ko0qrC3ODOnlBEIQ69/NvZYeewa4AgItZRTifUdhsNRIREdFfGADpnjWk+7fGyNtaAYmIiKj5MQDSPanUaPFb9eofTiob9Gzjdsf9H7zPF3KZroVwC7uBiYiIJMEASPfkaGoeCsqqAAD923vCVn7nr5SHoxKxoe4AgGt5pTh+Nd/UJRIREdFtGADpntRM/gwAg8Pu3P1bYySXhiMiIpIUAyA1mSiKSKgOgHKZgAHta8//V5chXXygsNF99badSodGy25gIiKi5sQASE12KbsYqTdLAAA9g13hYm/boNc5q2wxsIMnACC7sBwHL980WY1ERERUGwMgNdmt3b9xdxn9ezsuDUdERCQdBkBqsoRbAuCgRgbAQR294aCQAwB+Op2BiiqtUWsjIiKi+jEAUpPkFlfgWFoeACDU0wFtPBwa9Xo7hVw/aERdWok/LmQbvUYiIiKqGwMgNcnu81moGbvR2O7fGiMjOCk0ERGRFBgAqUkSzje9+7dGn7aeaFU9cGTn2UyUVFQZpTYiIiK6MwZAarTyKg1+T9J12bra2yKydasmHUdhI8ODXXwBAKWVGiScyzJWiURERHQHDIDUaIcu56K4QgMAGNjBCzZ3Wf3jTkaE++r/zG5gIiKi5sEASI12L6N/bxfdxh1eTkoAwO9J2VCXVt7T8YiIiOjuGACpUURRxK7qrlpbuYB+7T3u6XhymYCHuuoGg1RotPj5dMY910hERER3xgBIjXI+oxDX80sBAL1C3OGkatjqH3fC0cBERETNiwGQGsWg+7djw9b+vZvwABe0drMHAOy/lIOswjKjHJeIiIjqxgBIjbLzlpG693r/Xw1BEPSDQbQi8NMpdgMTERGZEgMgNVhWYRlOXs0HAHT0cUJgdaudMYwM99f/md3AREREpiV5APziiy8QHBwMlUqF6OhoHD58+I775+fnY8qUKfD19YVSqUT79u2xffv2ezomNczu87e2/hmn+7dGBx8ndPB2AgAcS8vDtbwSox6fiIiI/iJpANywYQPi4+Mxc+ZMJCYmIjw8HEOGDEFWVt0TAldUVGDw4MFITU3Fd999h6SkJKxYsQL+/v5NPiY13M6zf32GTV3+7U5uHQyy5WS60Y9PREREOpIGwAULFmDSpEmYOHEiwsLCsHTpUtjb22PVqlV17r9q1Srk5ubihx9+QO/evREcHIz+/fsjPDy8ycekhimr1GBvsm71Dw9HJcIDWhn9HCO6cjQwERFRc7CR6sQVFRU4duwYZsyYod8mk8kQFxeHAwcO1PmazZs3IyYmBlOmTMGPP/4IT09PPPXUU3jzzTchl8ubdEwAKC8vR3l5uf5xQUEBAECr1UKr1d7rW62TVquFKIomO76x7b2YjbJKXa33d/QEIEKrFY16jgBXFcIDXHDymhrn0gtwIaMAbb0cjXoOY7O060i18RpaPl5Dy8draByN+fwkC4A5OTnQaDTw9jbsSvT29sb58+frfM3ly5fx66+/4umnn8b27duRnJyMV155BZWVlZg5c2aTjgkA8+fPx6xZs2ptz87ORlmZaaYk0Wq1UKvVEEURMpnkt2Le1dbENP2fe/gqTdalPjDECSevqQEAGw4kY1KM311eIS1Lu45UG6+h5eM1tHy8hsZRWFjY4H0lC4BNodVq4eXlheXLl0Mul6N79+64fv06PvroI8ycObPJx50xYwbi4+P1jwsKChAYGAhPT084Ozsbo/RatFotBEGAp6en2X/ZRVHEgSunAQAKGxmGdQ+BvcI0X52xsc74dM81iCKQkKzG2yPDIQiCSc5lDJZ0HaluvIaWj9fQ8vEaGodKpWrwvpIFQA8PD8jlcmRmZhpsz8zMhI+PT52v8fX1ha2tLeRyuX5bp06dkJGRgYqKiiYdEwCUSiWUSmWt7TKZzKRfREEQTH4OYzh1TY3MAl0XeZ+2HnBUKUx2Lt9W9ujVxh0HLt9E6s0SnE0vwn0BLiY7nzFYynWk+vEaWj5eQ8vHa3jvGvPZSfYpKxQKdO/eHQkJCfptWq0WCQkJiImJqfM1vXv3RnJyskEf94ULF+Dr6wuFQtGkY9Ld7bx19Q8jT/9SF8Ol4a6b/HxERETWRtKYHR8fjxUrVuCrr77CuXPnMHnyZBQXF2PixIkAgPHjxxsM6Jg8eTJyc3Px2muv4cKFC9i2bRvmzZuHKVOmNPiY1HiGy78Zf/qX2w3t7AMbma7bd+uf6UYfbEJERGTtJL0HcOzYscjOzsa7776LjIwMREREYMeOHfpBHFeuXDFozgwMDMTPP/+M119/HV27doW/vz9ee+01vPnmmw0+JjXOjfxSnLmhGxV9n78LfFwafn9BU7k6KNCvvSd+PZ+FdHUZjqblIaqNm8nPS0REZC0kHwQydepUTJ06tc7nfvvtt1rbYmJicPDgwSYfkxonwYSrf9zJyHA//Fp97s0nrzMAEhERGRHvtKQ7urX71xSrf9RncJg3VLa6r+f2Uxmo1HBuKCIiImNhAKR6FZdXYX/yTQCAj7MKnf1MMyVOXRyUNhhUHThziyuwLzmn2c5NRETU0jEAUr32XMxBRXXL26BOXs0+Hx+XhiMiIjINBkCql1TdvzUGdPCEk1J3m+ovZzJRVqlp9hqIiIhaIgZAqpNGK+oHYdjZyhET6t7sNahs5RjSRTeBd1F5FX5LMs3yc0RERNaGAZDqdOJqPm4WVwAA+rbzgMpWfpdXmMbIcHYDExERGRsDINXJoPs3TLo5FGND3eHuoFt6LuFcFgrLKiWrhYiIqKVgAKQ67aoOgIIA3N+x+eb/u52NXIZh9/kCAMqrtNh5NvMuryAiIqK7YQCkWq7mluBCZhEAICKwFTwclZLWY7g2MLuBiYiI7hUDINWyS+LRv7fr3toVftVL0O29mIPc6nsTiYiIqGkYAKkWcwuAMpmAEdWDQaq0In46nS5xRURERJaNAZAMFJRV4tDlXABAgKsd2ns7SlyRzohbRwOfYDcwERHRvWAAJAO/J2WjSisC0LX+NffqH/Xp7OeMEA8HAMDh1FxkqMskroiIiMhyMQCSAalX/6iPIPzVDSyKwNY/2QpIRETUVAyApFel0WJ3UjYAwElpg6g2bhJXZOjW0cBbOBqYiIioyRgASe9oWh7UpbqJlvt18ITCxry+HqGejujs5wwAOHlNjdScYokrIiIiskzm9Tc8Scqw+1e6yZ/v5Nal4dgKSERE1DQMgKSXcC4LACATgAHtzTMAPnTb2sCiKEpYDRERkWViACQAwKXsIlyu7lLtEewG1+r1d82Nfys79AhyBQBczCrC+YxCiSsiIiKyPAyABMAyun9rcDAIERHRvWEAJADAruruXwAYZEbTv9Rl2H2+kMt08xNu+ZPdwERERI3FAEjIK67A0VTd6h8hHg4I9TSP1T/q4+GoRGyoOwDgam4pjl/Nl7YgIiIiC8MASPjtQhaqF//AIDPv/q0xkkvDERERNRkDIBl0/5rT6h938kBnHyjkuq/vtlPp0GjZDUxERNRQDIBWrqJKi9+rV/9wsbNF9+oRtubOxc4WAzp4AgCyC8tx8PJNiSsiIiKyHAyAVu5wSi6KyqsAAAM7eMJGbjlfCY4GJiIiahrL+dueTGLXrdO/hFlG92+NQR294aCQAwB+Op2BiiqtxBURERFZBgZAKyaKoj4A2sgE9GvvKXFFjWOnkGNwdWhVl1bijwvZEldERERkGRgArdiFzCJcyysFAESHuMFZZStxRY034ral4YiIiOjuGACtmEH3r4WM/r1d33aecLHTBdedZzNRUlElcUVERETmjwHQirWEAKiwkWHYfT4AgNJKDRJumdKGiIiI6sYAaKWyC8txonoFjfbejgh0s5e2oHvAbmAiIqLGYQC0UrvPZ6FmCV1Lbf2rEd3GHV5OSgDA70nZUJdWSlwRERGReWMAtFK3dv8OsvAAKJcJGN7VFwBQodHi59MZEldERERk3hgArVBZpQZ7LuYAANwdFIgIbCVtQUYwkt3AREREDcYAaIUOXLqJ0koNAOD+jl6QywSJK7p3EYGt0Lr6Psb9l3KQVVgmcUVERETmiwHQCrWk7t8agiBgRLiuG1grAj+dYjcwERFRfRgArYwoivqpUhRyGfq285C4IuMZGe6v/zO7gYmIiOrHAGhlztwoQEaBrns0tq07HJQ2EldkPB18nNDe2xEAcCwtD9fySiSuiIiIyDwxAFqZltj9e6tbB4NsOZkuYSVERETmiwHQyty6UkZcJy8JKzENTgpNRER0dwyAViRDXYZT19UAgM5+zvB1sZO4IuMLcndAePW0NufSC5CcVShtQURERGaIAdCKJJxv2d2/NQznBGQ3MBER0e0YAK3Ird2/g1twAHyoqy+E6qkNt5y8AbFmzTsiIiICwABoNUoqqrA3Wbf6h7ezEl38nSWuyHS8nVWIbuMGAEjJKcbp6wUSV0RERGReGACtxN6LOaio0gIA7u/oDUGw/NU/7sRwTsDrElZCRERkfhgArcSt078MDmt5o39v92AXH9hUL3G39c90aLXsBiYiIqrBAGgFtFoRv57PBgCobGWIDW05q3/Ux9VBgX7tPQEA6eoyHE3Lk7giIiIi8yF5APziiy8QHBwMlUqF6OhoHD58uN5916xZA0EQDH5UKpXBPkVFRZg6dSoCAgJgZ2eHsLAwLF261NRvw6ydvJaPnKJyAECftp5Q2colrqh51KwNDLAbmIiI6FaSBsANGzYgPj4eM2fORGJiIsLDwzFkyBBkZWXV+xpnZ2ekp6frf9LS0gyej4+Px44dO7Bu3TqcO3cO06ZNw9SpU7F582ZTvx2zZW3dvzUGh/lAaaP7im8/lYFKjVbiioiIiMyDpAFwwYIFmDRpEiZOnKhvqbO3t8eqVavqfY0gCPDx8dH/eHsbTmeyf/9+TJgwAQMGDEBwcDBefPFFhIeH37FlsaW7dfqXgR2tJwA6Km0QVz3dTW5xBfZVj4ImIiKydpIFwIqKChw7dgxxcXF/FSOTIS4uDgcOHKj3dUVFRQgKCkJgYCBGjRqFM2fOGDwfGxuLzZs34/r16xBFEbt378aFCxfwwAMPmOy9mLOruSU4n6FbDSM8sBW8nFR3eUXLwqXhiIiIarOR6sQ5OTnQaDS1WvC8vb1x/vz5Ol/ToUMHrFq1Cl27doVarcbHH3+M2NhYnDlzBgEBAQCAzz//HC+++CICAgJgY2MDmUyGFStWoF+/fvXWUl5ejvLycv3jggLdvHFarRZarWm6DbVaLURRNNnxa+w6m6H/c1xHT5Ofz9z0b+cOR6UNisqr8MuZDJSWV0JpxHsgm+s6kunwGlo+XkPLx2toHI35/CQLgE0RExODmJgY/ePY2Fh06tQJy5Ytw5w5cwDoAuDBgwexefNmBAUF4Y8//sCUKVPg5+dn0Np4q/nz52PWrFm1tmdnZ6OsrMwk70Wr1UKtVkMURchkpmuI/enPa/o/R3jZ3PH+ypaqX4gLtp+7iaJyDX44koyBbV2Nduzmuo5kOryGlo/X0PLxGhpHYWFhg/eVLAB6eHhALpcjMzPTYHtmZiZ8fHwadAxbW1t069YNycnJAIDS0lK8/fbb2LRpE4YPHw4A6Nq1K06cOIGPP/643gA4Y8YMxMfH6x8XFBQgMDAQnp6ecHY2zYoZWq0WgiDA09PTZF/2wrJKHL9eBADwa6VCbFhQi58Aui6PRwvYfu4mAOCP1BKMje1gtGM3x3Uk0+I1tHy8hpaP19A4bp8Z5U4kC4AKhQLdu3dHQkICRo8eDUD3BUhISMDUqVMbdAyNRoNTp05h2LBhAIDKykpUVlbW+vLI5fI7NosqlUoolcpa22UymUm/iIIgmPQce5NzUanRTYA8uJM35HLrmP7ldn3aecLdQYGbxRX49XwWiis0cFLZGu34pr6OZHq8hpaP19Dy8Rreu8Z8dpJ+yvHx8VixYgW++uornDt3DpMnT0ZxcTEmTpwIABg/fjxmzJih33/27Nn45ZdfcPnyZSQmJmLcuHFIS0vDCy+8AEA3RUz//v0xffp0/Pbbb0hJScGaNWvw9ddf4+GHH5bkPUop4ZbpXwZ18r7Dni2bjVyGYffp5gQsr9Ji59nMu7yCiIioZZP0HsCxY8ciOzsb7777LjIyMhAREYEdO3boB4ZcuXLFIM3m5eVh0qRJyMjIgKurK7p37479+/cjLCxMv8///vc/zJgxA08//TRyc3MRFBSEuXPn4uWXX2729yelKo0Wu5N09/s5Km0QHeImcUXSGhnhh7UHdXNGbj55A2MiAySuiIiISDqCKIpcJPU2BQUFcHFxgVqtNuk9gFlZWfDy8jJJc/fhlFw8vkw3nc6w+3yw+OnuRj+HJdFqRfT+4Fekq8tgIxNw+J04uDkojHBc015HMj1eQ8vHa2j5eA2NozH5hZ9yC2XQ/dvRert/a8hkgn5OwCqtiJ9Op0tcERERkXQYAFuomuXfZIJ1rf5xJyNvnRT6BCeFJiIi68UA2AKl5BTjUnYxAKB7kKtRujpbgs5+zgjxcAAAHE7NRYbaNHM8EhERmTsGwBaIo3/rJgh/dQOLIrD1T7YCEhGRdWIAbIFuneYkjgHQwK1rA2/h2sBERGSlGABbGHVJJY6m5QEAgt3tEerpIHFF5qWtlyPCfHUjo05eUyM1p1jiioiIiJofA2AL89uFLGi0upl9BnXytsql3+5mZARbAYmIyLoxALYw7P69u1u7gTefvAFOhUlERNaGAbAFqdRo8fuFbACAs8oGPYJdJa7IPPm3skOPIN1nczGrCOczCiWuiIiIqHkxALYgR1JyUVhWBQAY0MELtnJe3vqwG5iIiKwZE0ILsvOW6V/iwtj9eycPdvGFrPr2yC1/shuYiIisCwNgCyGKIhLOZQEAbGQC+rf3lLgi8+bppETvth4AgKu5pTh+NV/agoiIiJoRA2ALkZxVhCu5JQCAnsFucLGzlbgi8zeCS8MREZGVYgBsIdj923hDOvtAUX2f5LZT6frpc4iIiFo6BsAWoqb7FwDiOnlJWInlcLGzxYAOuq7y7MJyHLx8U+KKiIiImgcDYAtws6gciVd0q3+083JEkDtX/2goLg1HRETWiAGwBfj1fBZqBrEO4uTPjRLXyRv2CjkA4KfTGaio0kpcERERkekxALYA7P5tOjuFHIOr75lUl1bij+qJtImIiFoyBkALV1apwR8XdaHFzUGBbq25+kdjjbxtaTgiIqKWjgHQwh28fBMlFRoAwMAOXpDXzG5MDda3nad+2pydZzNRUlElcUVERESmxQBo4dj9e+8UNjI82MUHAFBaqTH4TImIiFqiJgXAq1ev4tq1a/rHhw8fxrRp07B8+XKjFUZ3p1v9Qzf/n0IuQ1+u/tFk7AYmIiJr0qQA+NRTT2H37t0AgIyMDAwePBiHDx/GO++8g9mzZxu1QKrf2fQC3FCXAQB6hbrDUWkjcUWWKzrEHV5OSgDA70nZUJdWSlwRERGR6TQpAJ4+fRpRUVEAgG+//RZdunTB/v378c0332DNmjXGrI/ugN2/xiOXCRje1RcAUKHR4ufTGRJXREREZDpNCoCVlZVQKnWtJbt27cLIkSMBAB07dkR6errxqqM72nXL8m+c/+/esRuYiIisRZMCYOfOnbF06VLs2bMHO3fuxNChQwEAN27cgLu7u1ELpLplFpThz2tqAEAnX2f4t7KTuCLLFxHYCoFuus9x/6UcZBWWSVwRERGRaTQpAH7wwQdYtmwZBgwYgCeffBLh4eEAgM2bN+u7hsm0fj3P7l9jEwQBI7rqWgG1IvDTKXYDExFRy9SkUQMDBgxATk4OCgoK4Or618TDL774Iuzt7Y1WHNVv19m/un/j2P1rNCMj/LD4t0sAdN3AE2KDpS2IiIjIBJrUAlhaWory8nJ9+EtLS8PChQuRlJQELy+2RplaaYUGe5NzAACeTkrc5+8icUUtR0cfZ7T3dgQAHEvLw7W8EokrIiIiMr4mBcBRo0bh66+/BgDk5+cjOjoan3zyCUaPHo0lS5YYtUCqbV9yDsqrtAB03b8yrv5hVLcOBtlykoOaiIio5WlSAExMTETfvn0BAN999x28vb2RlpaGr7/+Gp999plRC6TaDEb/dmT3r7E91JWjgYmIqGVrUgAsKSmBk5MTAOCXX37BmDFjIJPJ0KtXL6SlpRm1QDKk1YpIqB4AorSRoXdbD4kranmCPRwQHqDrVj+XXoDkrEKJKyIiIjKuJgXAtm3b4ocffsDVq1fx888/44EHHgAAZGVlwdnZ2agFkqFT19XILiwHAPRt5wE7hVziilqmEQZzArIbmIiIWpYmBcB3330Xb7zxBoKDgxEVFYWYmBgAutbAbt26GbVAMsTJn5vHiHA/CNW3Vm45eQOiKEpbEBERkRE1KQA++uijuHLlCo4ePYqff/5Zv33QoEH4z3/+Y7TiqLZdtyz/NqgjR1ybirezCtFt3AAAKTnFOH29QOKKiIiIjKdJARAAfHx80K1bN9y4cQPXrl0DAERFRaFjx45GK44MXcsrwbl0XRAJD3CBl7NK4opaNsNu4OsSVkJERGRcTQqAWq0Ws2fPhouLC4KCghAUFIRWrVphzpw50Gq1xq6Rqt26+ge7f01vWBdf2FRPsbP1z3RotewGJiKilqFJK4G88847WLlyJd5//3307t0bALB371689957KCsrw9y5c41aJOkYdP9y+TeTc3VQoG87D+xOyka6ugxH0/IQVd0tTEREZMmaFAC/+uorfPnllxg5cqR+W9euXeHv749XXnmFAdAEisqrcPDSTQCAn4sKYb4cbd0cRkb4YXdSNgBdNzADIBERtQRN6gLOzc2t816/jh07Ijc3956Lotr2XMhGhUbXvT6okzcEgat/NIfBYT5Q2uh+TbafykClhrc4EBGR5WtSAAwPD8eiRYtqbV+0aBG6du16z0VRbez+lYaj0kb/eecWV2Bf9RrMRERElqxJXcAffvghhg8fjl27dunnADxw4ACuXr2K7du3G7VAAjRaEbuTdAHQQSFHTKi7xBVZl5Hhfth+KgOAbmm4AR0YwImIyLI1qQWwf//+uHDhAh5++GHk5+cjPz8fY8aMwZkzZ7B27Vpj12j1jl/JQ25xBQCgbztPKG24+kdzGtDBC05K3b+VfjmTibJKjcQVERER3ZsmtQACgJ+fX63BHidPnsTKlSuxfPnyey6M/sLuX2mpbOV4oLMPvk+8hqLyKvyWlIWhXXylLouIiKjJmjwRNDWfmuXfBAG4n6t/SGJkxK2TQt+QsBIiIqJ7xwBo5tJuFiM5qwgAENnaFe6OSokrsk69Q93h5qAAACScy0JhWaXEFRERETUdA6CZu7X7N46rf0jGRi7DsPt8AADlVVrsPJspcUVERERN16h7AMeMGXPH5/Pz8++lFqrDrluCRhzv/5PUyHB/rDt4BQCw5eQNjIkMkLgiIiKipmlUC6CLi8sdf4KCgjB+/PhGFfDFF18gODgYKpUK0dHROHz4cL37rlmzBoIgGPyoVKpa+507dw4jR46Ei4sLHBwc0LNnT1y5cqVRdZkDdWkljqTqJtZu7WaPtl6OEldk3XoEucLXRfd923MxB3nVI7OJiIgsTaNaAFevXm3Uk2/YsAHx8fFYunQpoqOjsXDhQgwZMgRJSUnw8qq7tcvZ2RlJSUn6x7eviHHp0iX06dMHzz//PGbNmgVnZ2ecOXOmzqBo7n6/kI0qrQhA1/3L1T+kJZMJGBHuh+V/XEaVVsT20+l4smeg1GURERE1mqT3AC5YsACTJk3CxIkTERYWhqVLl8Le3h6rVq2q9zWCIMDHx0f/4+1teF/cO++8g2HDhuHDDz9Et27dEBoaipEjR9YbKM0Zu3/Nz8jwW0YDn+BoYCIiskySBcCKigocO3YMcXFxfxUjkyEuLg4HDhyo93VFRUUICgpCYGAgRo0ahTNnzuif02q12LZtG9q3b48hQ4bAy8sL0dHR+OGHH0z5VkyiUqPFb9WrfzipbNCzjZvEFREAdPZzRhsPBwDA4dRcZKjLJK6IiIio8Zo8EfS9ysnJgUajqdWC5+3tjfPnz9f5mg4dOmDVqlXo2rUr1Go1Pv74Y8TGxuLMmTMICAhAVlYWioqK8P777+Pf//43PvjgA+zYsQNjxozB7t270b9//zqPW15ejvLycv3jgoICALpAqdVqjfSODWm1WoiiWO/xD1++iYKyKgBA//aekAswWS3UOA919cXnvyZDFIFFu5PRwU2O0AIZokPcIZexm97S3O13kcwfr6Hl4zU0jsZ8fpIFwKaIiYnRrz0MALGxsejUqROWLVuGOXPm6N/4qFGj8PrrrwMAIiIisH//fixdurTeADh//nzMmjWr1vbs7GyUlZmmhUer1UKtVkMURchktRtityRe1f+5p58KWVlZtfYhafQOUOLz6j+vP1xznVLh5WiL1wcEYmBbV6lKoya42+8imT9eQ8vHa2gchYWFDd5XsgDo4eEBuVyOzEzD+dQyMzPh4+PToGPY2tqiW7duSE5O1h/TxsYGYWFhBvt16tQJe/furfc4M2bMQHx8vP5xQUEBAgMD4enpCWdn54a+pUbRarUQBAGenp61vuyiKOJA2jkAgFwmYGTPULjY2ZqkDmq8xKyMOrdnF1Xi7a2X8cVT3TC0S8O+wyS9O/0ukmXgNbR8vIbG0ZgBr5IFQIVCge7duyMhIQGjR48GoPsCJCQkYOrUqQ06hkajwalTpzBs2DD9MXv27GkwShgALly4gKCgoHqPo1QqoVTWXmFDJpOZ9IsoCEKd50jOKkRabgkAoGewK1wduPqHudBoRczZdq7O50QAAoA5285hSBdfdgdbkPp+F8ly8BpaPl7De9eYz07SLuD4+HhMmDABPXr0QFRUFBYuXIji4mJMnDgRADB+/Hj4+/tj/vz5AIDZs2ejV69eaNu2LfLz8/HRRx8hLS0NL7zwgv6Y06dPx9ixY9GvXz8MHDgQO3bswJYtW/Dbb79J8RabhKt/mK/DKblIv8PADxFAuroM87afxcAO3mjtZg+/VirYyPk/NCIiMh+SBsCxY8ciOzsb7777LjIyMhAREYEdO3boB4ZcuXLFIM3m5eVh0qRJyMjIgKurK7p37479+/cbdPk+/PDDWLp0KebPn49XX30VHTp0wPfff48+ffo0+/trqoRzf3WLD2IANCtZhQ27J3Tl3lSs3JsKQNeN79/KDq3d7NHa3R6t3ewR5GaPwOrHzip27xMRUfMSRFEUpS7C3BQUFMDFxQVqtdqk9wBmZWXBy8vLIOTmFlegx793QisCoZ4OSPj7AJOcn5rmwKWbeHLFQaMe09XetjocOqC1W3VQdHNAa3d7+Dir2JVsYvX9LpLl4DW0fLyGxtGY/GJRo4Ctwe7zWahe/IPdv2Yoqo0bfF1UyFCXob5/Obk5KDAtrh2u55Ui7WYJruTqforKq+rcP6+kEnklapy8pq71nEIuQ4CrHQLd7BFU3XpY8+dAV3s4KPkrTEREjce/PcxMwnl2/5ozuUzAzBFhmLwuEQJgEAJr2unmPdwFQ7v4GrxOFEXklVTiSm4J0m4W42p1KEy7WYKruSVILyhDXW3xFRotLucU43JOcZ31eDgq/2o1dHfQdS9XB0VPRyVk99B6qNGKOJySi6zCMng5qRDVxo2tkURELQQDoBkpr9Lg96RsALpuwcjWraQtiOo0tIsvloyLxKwtZw0GhPi4qDBzRFit8AfoRre5OSjg5qBARGCrWs+XVWpwPb9U11p40zAcXsktQWmlps5acorKkVNUjsQr+bWeU9rIqruT/7r3sCYgBrjaQ2Urr/c97jidXuv9+d7h/RERkWVhADQjhy7norhC9xf9wA5eHDlqxoZ28cXgMB8cupyD5GvZaBvgiegQjya3kKls5Qj1dESop2Ot50RRRHZROa5Wh8KaLuWaoJhVWF7HEYHyKi0uZhXhYlZRnc/7OKsMupRr/nwpuwhvfvdnrS7uDHUZJq9LxJJxkQyBREQWjgHQjNw6+jcujN2/5k4uE9ArxB0hjhp4ebnfU3frnQiCAC8nFbycVOgeVHtN6NIKDa7m6QJhWm7JLd3LxbiaV4qKqrqXBsooKENGQRkOp+Y2qI6aeQ5nbTmLwWE+7A4mIrJgDIBmQhRF/fx/tnIBfdt5SFwRWQo7hRztvZ3Q3tup1nNarYjMwjJ9a+GV2+49vFlc0ahz1cxzeDglFzGh7kZ6B0RE1NwYAM3E+YxCXM8vBQD0CnGHE+eGIyOQyQT4utjB18UO0SG1A1tRedUt4bAYv1/Ixr7km3c9bkPnQyQiIvPEAGgmDLp/OfqXmomj0gZhfs4I89PNF3Wff6sGBUAvp4avN0lEROaHowzMxM5bln8b1MlLwkrImtXMc3inu/vkMgH+rnbNVhMRERkfA6AZyCosw8mr+QCAjj5OCHC1l7Ygslo18xwCqDcEarQinlx+EGk3656bkIiIzB8DoBn49ZbWP3b/ktRq5jn0cTHs5vVyUsLLSQkAuJ5fiseWHkByVqEUJRIR0T3iPYBmYBe7f8nM1MxzePtKIDeLyzHuy0O4kFmErMJyjF12EGufj9bfQ0hERJaBLYASK6vUYG+ybvUPD0clwgNaSVsQUTW5TEBMqDtGRfgjJtQdcpluPsL/vRiDztWB72ZxBZ5ccVB/CwMREVkGBkCJ7bt0E2WVuol6B3X0MtlkwkTG4uagwPpJvdCteqlCdWklnv7yEI40cEJpIiKSHgOgxH5l9y9ZIBc7W6x9PhrRbXQrkxSVV2H8ysPYn5wjcWVERNQQDIAS0ooifk3SBUCFjQx9uPoHWRBHpQ3WTIzSr1pTWqnBs2uOYPf5rLu8koiIpMYAKKGkrBJkFpQDAPq09YC9gmNyyLLYKeT4ckIP/ej1iiotXlx7FDtOp0tcGRER3QkDoAQ0WhEHL9/EV4cz9NvY/UuWSmkjx5JxkRje1RcAUKkRMWX9cfx44rrElRERUX3Y5NTMdpxOx6wtZ5GuNlxLVSZw8AdZLlu5DJ890Q0qGzm+T7wGjVbEtA0nUFapwdieraUuj4iIbsMWwGa043Q6Jq9LrBX+AODtjafYbUYWTS4T8NGjXfF0tC7wiSLw5ven8NX+VGkLIyKiWhgAm4lGK2LWlrMQ77DPrC1nodHeaQ8i8yaTCfj36C54vk8b/baZm89g2e+XJKyKiIhuxwDYTA6n5NbZ8ldDBJCuLsPhFM6lRpZNEAT8c3gnTB3YVr9t/k/nsXDXBYgi/4FDRGQOeA9gM8kqrD/8NWU/InMmCALeGNIBKlsZPv7lAgBg4a6LKK3U4K2hHSHwnlcisiIarVhraU25xAs/MAA2Ey8nlVH3I7IEU+9vBzuFDeZsPQsAWPb7ZZRVaDBzRGeuekNEVqGuwZ++LirMHBGGoV18JauLXcDNJKqNG3xdVKjvrzwBui9EVPXKCkQtxfN92mDuw130j786kIYZG0/xflciavHqG/yZoS7D5HWJkg7+ZABsJnKZgJkjwgCgVgiseTxzRJjkTcJEpvB0dBA+fiwcNV/vDUevIv7bE6jSaKUtjIjIRO40+LNmm5SDPxkAm9HQLr5YMi4SPi6G3bw+LiosGRcpaVMwkak92j0Anz3ZDTbVKfDHEzcwdf1xVFQxBBJRy2Pugz95D2AzG9rFF4PDfHDocg6Sr2WjbYAnokM82PJHVuGhrn5Q2sgx5ZtEVGi02HEmAy+tPYol47pDZSuXujwiIqMx98GfbAGUgFwmoFeIOx7o6IZeIe4Mf2RVBod548sJPaCy1f3vZ3dSNp7/6ghKKqokroyIyHjMffAnAyARNbt+7T2xZmIUHBS6Vr99yTcxfuVhFJZVSlwZEZFxnLqef8fnpR78yQBIRJLoFeKOtS9Ew0mluxPlaFoexn15CPklFRJXRkR0b9YeSMW87efrfd4cBn8yABKRZCJbu+K/k3rB1d4WAHDymhpPLD+InKJyiSsjImqaDUeu4F8/ntE/fqirL3zNcPAnB4EQkaS6+Lvgfy/G4OkvDyGnqBznMwoxdtkBrJ/UC97OnBidiCzHxsRreGvjKf3jVwaEYvqQDtCKMLuVQNgCSESS6+DjhG9f6qX/V/Kl7GI8vuwAruWVSFwZEVHDbDl5A2/830nULHn+fJ82mD6kAwRBgFwmICbUHaMi/BETah6DPxkAicgshHg64tuXYhDoZgcASLtZgseXHkBqTrHElRER3dmO0xmYtuEEauZ0Hh8ThH8O72TW654zABKR2Qh0s8e3L8UgxMMBAHBDXYbHlx3AxcxCiSsjIqrbr+cz8bf/JupX9HiiZyDeG9HZrMMfwABIRGbG18UOG16KQUcfJwBAVmE5xi4/iDM31BJXRkRk6I8L2Xh5XSIqNbrwN6abP+Y9fB9kZtDFezcMgERkdjydlPjvpF7o4u8MAMgtrsCTyw/ixNV8aQsjIqp24NJNvLj2qH45y4e6+uLDR7taRPgDGACJyEy5OijwzQu9ENm6FQCgoKwK4748JNm6mURENY6m5uL5r46grFIX/oZ09sZ/xkbARm45scpyKiUiq+NiZ4u1z0ejV4hupvyi8ipMWHUYey/mSFwZEVmrE1fz8ezqIyip0AAA7u/ohc+fjIStBYU/gAGQiMycg9IGayZGoX97TwBAaaUGz311BL+ez5S4MiKyNqevqzF+5SEUlevWLu/bzgOLn46Ewsby4pTlVUxEVkdlK8fy8d0xOMwbAFBRpcVLa4/hp1PpEldGRNbifEYBnll5CAVluvDXK8QNy5/pAZWtXOLKmoYBkIgsgtJGjsVPR2JEuB8AoFIjYsr6RGw6fk3iyoiopUvOKsK4Lw8hr6QSANAjyBUrJ/SEncIywx/AAEhEFsRWLsPCsRF4tHsAAEArAvHfnsT/Dl+RuDIiaqlSc4rx1IqDyCmqAACEB7bC6ok94aC07NV0GQCJyKLIZQI+fKQrxvVqDQAQReCtjaewel+KxJURUUtzNbcET604iKzCcgBAZz9nfD0xCk4qW4kru3cMgERkcWQyAXNGdcGkvm3022ZtOYslv12SsCoiaklu5JfiyRUHcUNdBgDo6OOEtc9Hw8Xe8sMfwABIRBZKEAS8PawTXr2/rX7bBzvOY8HOCxBrVmMnImqCrIIyPLXiIK7llQIAQj0dsO6FaLg5KCSuzHgYAInIYgmCgPgHOmD6kA76bZ8lXMT7P51nCCSiJskpKsdTXx5C6s0SAECwuz3WT+oFD0elxJUZFwMgEVm8KQPb4t2HwvSPl/1xGTM3n4FWyxBIRA2XV1yBcV8eQnJWEQAgwNUO6yf1grezSuLKjM8sAuAXX3yB4OBgqFQqREdH4/Dhw/Xuu2bNGgiCYPCjUtV/YV5++WUIgoCFCxeaoHIiMhfP9WmDeQ/fB6F6Gc6vD6ThrY1/QsMQSEQNoC6txLiVh3A+oxAA4Oeiwn8n9YJfKzuJKzMNyQPghg0bEB8fj5kzZyIxMRHh4eEYMmQIsrKy6n2Ns7Mz0tPT9T9paWl17rdp0yYcPHgQfn5+piqfiMzIU9Gt8clj4ahZi/3bo9fw+oYTqNRopS2MiMxaYVklxq86jDM3CgAAXk5KfDOpFwLd7CWuzHQkD4ALFizApEmTMHHiRISFhWHp0qWwt7fHqlWr6n2NIAjw8fHR/3h7e9fa5/r16/jb3/6Gb775Bra2LWPEDhHd3ZjIAHz+ZCRsqlPg5pM3MHV9IsqrNBJXRkTmqLi8ChNXH8HJq/kAAA9HBdZPikYbDwdpCzMxSWcxrKiowLFjxzBjxgz9NplMhri4OBw4cKDe1xUVFSEoKAharRaRkZGYN28eOnfurH9eq9XimWeewfTp0w2216e8vBzl5eX6xwUFBfrjaLWmaTnQarUQRdFkx6fmwetonh7s4g3FuEhM+SYRFRoRP5/JxItfH8OSp7vVWraJ19Dy8RpaPqmuYWmFBi98fRRH0/IAAK72tvj6uSiEeDhY5PepMTVLGgBzcnKg0WhqteB5e3vj/Pnzdb6mQ4cOWLVqFbp27Qq1Wo2PP/4YsbGxOHPmDAICdKsDfPDBB7CxscGrr77aoDrmz5+PWbNm1dqenZ2NsrKyRr6rhtFqtVCr1RBFETKZ5A2x1ES8jubrPjfgo5Ft8Y8tySivEvH7hWw8s+IAPhoZCvtblm/iNbR8vIaWT4prWF6lxT82X8KhK7pGHyelHP8Z3RZuslJkZZU2Sw3GVlhY2OB9LW4dk5iYGMTExOgfx8bGolOnTli2bBnmzJmDY8eO4dNPP0ViYiKEmrvB72LGjBmIj4/XPy4oKEBgYCA8PT3h7Oxs9PcA6L7sgiDA09OT/8OyYLyO5m2Elxe8Pdzw/FdHUVyhwbFrhZi+NRUrn+0B5+qZ/HkNLR+voeVr7mtYUaXFK+sT9eHPUSnH189FITywlcnPbUp3GhR7O0kDoIeHB+RyOTIzMw22Z2ZmwsfHp0HHsLW1Rbdu3ZCcnAwA2LNnD7KystC6dWv9PhqNBn//+9+xcOFCpKam1jqGUqmEUll7fh+ZTGbSL6IgCCY/B5ker6N56xXqgXUvRGPCqsMoKKvCsSv5eGblEXz9XBSc7WxxODUPydfy0LbYBtEhHpDLGvYPRzIv/D20fM11DSs1WkzbcBK/ns8GANgr5FgzMQrdgtxMet7m0JjPTtIAqFAo0L17dyQkJGD06NEAdP8KSEhIwNSpUxt0DI1Gg1OnTmHYsGEAgGeeeQZxcXEG+wwZMgTPPPMMJk6caNT6icgydGvtiv++2AvPrDyM3OIKnLquxkOf70GlRtSv8QmkwNdFhZkjwjC0i6+k9RKRaWi0IuK/PYkdZzIAAEobGVZO6IkewZYf/hpL8i7g+Ph4TJgwAT169EBUVBQWLlyI4uJifVgbP348/P39MX/+fADA7Nmz0atXL7Rt2xb5+fn46KOPkJaWhhdeeAEA4O7uDnd3d4Nz2NrawsfHBx06dAARWafOfi7Y8GIvPPXlIWQXluN6fu37ezPUZZi8LhFLxkUyBBK1MFqtiOnfncSWkzcAAAq5DCvG90BMqPtdXtkySR4Ax44di+zsbLz77rvIyMhAREQEduzYoR8YcuXKFYMmzby8PEyaNAkZGRlwdXVF9+7dsX//foSFhdV3CiIiAEA7byf8d1IvPPCf31HX/NAiAAHArC1nMTjMh93BRC2EVivinR9OYWPidQCArVzA0mci0a+9p8SVSUcQuWBmLQUFBXBxcYFarTbpIJCsrCx4eXnxnhULxutoeQ5cuoknVxy8635TBoZiSGcftPFwgJOKc4maM/4eWj5TXkNRFDFz8xl8fUC3aIRcJuCLpyIxtEvDxhpYksbkF8lbAImImlNWYcOmdvpi9yV8sfsSAMDTSYkQDweEeDogxMMRIZ4OaOPhgEA3e9jKGTiIzJUoipi77Zw+/MkEYOHYiBYZ/hqLAZCIrIqXU+MXdc8uLEd2YTkOpeQabLeRCWjtZq8Lhp6OaOPhUB0UHeHhqGjwVFREZHyiKOLjX5Lw5d4UAIAgAB8/Fo4R4VweFmAAJCIrE9XGDb4uKmSoy1Df/S+u9raY1C8EaTkluJxThJScYuQUVdTar0or4nJOMS7nFAPnDNcvd1La6FsKQzz/ajUM8XCEnUJe61hEZFyfJSTrW/EBYP7D92FMZICEFZkXBkAisipymYCZI8IweV0iBMAgBNa0180fc1+tUcDqkkp9GLycXYyUnGJcytY9Lq+qvfxSYXkVTl5T4+Q1da3n/FxUaHNbd3KopyP8Wtlx4AmRESz57RL+s+uC/vHsUZ3xRFTrO7zC+jAAEpHVGdrFF0vGRWLWlrNIV/91T6DPHeYBdLG3RbfWrujW2tVgu1YrIr2gDJez/wqHNcHwen4p6hpmd0NdhhvqMuxLvmmwXWEjQ7C7PUI8HKsD4l/3Hbo6KBr9PjVaEYdTcpFVWAYvJxWi2rgxYFKLt3JvCj7Y8ddysv8c3gnjY4KlK8hMMQASkVUa2sUXg8N8cOhyDpKvZaNtgGeTVgKRyQT4t7KDfys79G1nOKVEWaUGaTdLcDm7SNdVnF2MyzlFuJxdDHVpZa1jVVRpcSGzCBcyi2o952pva9CdXHOvYWs3e6hsa3cp7zidXivgcqJraunWHkzDnK1n9Y//MbQDXugbImFF5osBkIisllwmoFeIO0IcNfDycofMyK1jKls5Ovg4oYOPk8F2URSRV1JpGAyrWw3TbpagQlO7SzmvpBJ5V/KReCXfYLtMAPxd7XSthh4OCPV0wM2iCixMuFjrGJzomlqyb49cxb9+OK1//NqgdnhlQFsJKzJvDIBERM1MEAS4OSjg5uBWawkqjVbE9bxSXKpuKUzR/7fYoDWvhlYEruaW4mpuKX6/kH3H83Kia2qpNh2/hjc3/ql/PHlAKKbFtZOwIvPHAEhEZEbkMgGt3e3R2t0eA29bvbK4vAopOcW3DET5qwWxqLyqQccXAaSry3A4Jddql8CilmXrnzfw929P6u+3fb5PG/xjSAdOw3QXDIBERBbCQWmDLv4u6OLvYrBdFEVkF5XjcnYxNh2/jg1Hrt71WA2dEJvInP18JgOv/e+EfmnHZ3oF4Z/DOzH8NQADIBGRhRMEAV5OKng5qSCKaFAA5F+PZOl2n8/C1PWJ0FSnvyd6BmLWyM4Mfw3ENYyIiFqQmomu7/ZX4DubTmHX2cxmqYnI2PZczMZL646hUqMLf2O6+WPuw/cZfSBXS8YASETUgtRMdA3cuZWvsFyDF74+ivd/Oo+qOkYdE5mrg5dvYtLXR1FRPQH78K6++PDRrhzU1EgMgERELUzNRNc+LobrHvu6qLDg8XA82MVHv23p75fw1JeHkFXAewLJ/B1Ly8Vza46grFIX/oZ09sbCsRGwkTPONBbvASQiaoFqJrquayWQh7v5Y9W+VMzffg5V1auFDPtsLz57MgKxoR5Sl05Up5NX8/HsqiMoqdAAAO7v6IXPn4yELcNfk/BTIyJqoeQyATGh7hgV4Y+YUHd9F5kgCHi+TxtseCkGvtWthDlF5Rj35SEs+vUitNo61q8jktCZG2o8s/IQCqunO+rbzgOLn46EwoYxpqn4yRERWanuQa7Y9mpf9GuvW8JOKwIf/3IBz311BHnFFRJXR6STlFGIcV8eQkGZLvz1CnHD8md61LkEIjUcAyARkRVzc1BgzbM9ET+4PWpmz/gtKRsPfb4Xx6/kSVscWb3krCI8/eVB5JXo1s7uHuSKlRN6wk7B8HevGACJiKycTCbg1UHtsPa5aLg7KAAA1/NL8fiyA1izLwWiyC5han6pOcV4asVB5BTpWqPDA1ywemJPOCg5fMEYGACJiAgA0KedB7a92hc9glwBAJUaEe9tOYup64+jsKxS4urImlzNLcFTKw4iq7AcANDZzxlfPxcNZ5WtxJW1HAyARESk5+Oiwn9f7IUX+4Xot207lY5Ri/bhfEaBhJWRtbiRX4qnvjyIG2rd1EQdvJ2w9vlouNgz/BkTAyARERmwlcvw9rBOWPZMdzipdN1tl3OKMfqLffju2DWJq6OWRqMVcfDyTfxyPhc/nUrHUysO4mpuKQAg1NMB616Ihlv1rQlkPOxIJyKiOg3p7INOPs6Y/M0xnLlRgLJKLd74v5M4kpKLWaM6cxQm3bMdp9Mxa8tZpKtrT0Qe7G6P9ZN6wdNJKUFlLR9bAImIqF6t3e3x/eRYPBnVWr9tw9GreHjxfqTkFEtYGVm6HafTMXldYp3hDwBe7BcCb2dVnc/RvWMAJCKiO1LZyjF/zH34z9hw2FW3+p1LL8DIz/dix+l0iasjSyCKIorKq3A5uwgHL9/Ej8evY/p3f+JO48s//zUZGk5KbjLsAiYiogZ5uFsAOvu5YPK6Y7iUXYzC8iq8vC4Rz/Vug7ce7MhVGayQRisit7gCWYVlyCosR/YtP1mFZcgqKEd2UTmyCspRWqlp1LHT1WU4nJKLmFB3E1Vv3RgAiYiowdp7O2Hz1D6YsfEUNp+8AQBYtS8FJ67mYdFTkfBrZSdxhS2Lpnqt5tvXcza1skpNnSFOv6065N0srjBpK11WYd3dw3TvGACJiKhRHJQ2+PSJCPRs44Y5W86iQqNF4pV8DP9sDxY+0Q39q5eWo3tT1wAJXxcVZo4Iw9Auvo0+niiKyC+p1Ie5rMKy6kBXO9gVVi+7ZgwudrbwdFLCy0mp/29phQbrDl2562u9nHgPoKkwABIRUaMJgoBnegUhPMAFk9cl4np+KfJKKvHs6sP42/3t8Nqgds3SUtVS1QyQuL1tLUNdhsnrErFkXKQ+BFZUaZFTVK4Pc7WDXTmyC8qQXVSOSo1xWuvkMgGejspawc7TWQVPRyW8nJX65+saLa7Rikg4n4UMdVmd9wEK0M1JGdXGzSj1Um0MgERE1GRdA1ph26t98PdvTyLhfBZEEfgs4SIS0/Kw8IkIeDhyCo/G0mhFzNpyts5gVLPttf+dQJDbBWQXlevXyTUGB4UcXtUhzrM6xHk5K+HlpDIIe272CsjuIeDLZQJmjgjD5HWJEACD91pz1JkjwviPCBNiACQionvSyl6BFeN7YNkfl/HRz+ehFYG9yTkY/tkeLHoqEj2D2YrTGIdTcuudGqVGeZUWF7KKGnQ8QQDcHRTwvC3EeTnVDnbNuc7u0C6+WDIuslY3t889dHNTwzEAEhHRPZPJBEweEIpurVvhb/89juzCcmQWlOOJ5Qfx1tCOeKFvGwgCW3PuRKsVcSQ1F5/uutCg/eUyAb4uqlsC3V9hTtcFq4KXsxLuDgrYyM1zhPbQLr4YHOaDQ5dzkHwtG20DPBEd4sGWv2bAAEhEREbTK8Qd217tg9f+ewIHLt+ERiti7vZzOJKai48eC4eLHddzvV1qTjE2Hr+OTcev6ZdAa4h1z0chJtTDhJU1D7lMQK8Qd4Q4auDl5X5PXcvUcAyARERkVF5OKqx9Pgr/2XUBX+y+BAD45Wwmzn++F4ufjkQXfxeJK5SeuqQSW0/dwMbE6ziWllfr+dvvi7v9Od0ACc6PR03HAEhEREZnI5dh+pCO6BHkhte/PYH8kkpcyS3BmCX78d6IzngyKtDquoQrNVr8cSEbGxOvY+e5TFRUaQ2elwlAn3aeeCTSHwAw7X8nAHCABJkGAyAREZnMwI5e2Pq3Ppiy/jhOXs1HRZUWb286hSOpuZj7cBfYK1r2X0OiKOLMjQJsTLyOzSevI6eootY+7b0d8UhkAEZ38zdY+1ZpI+MACTKZlv2bR0REkgtwtcf/vRSDedvPYc3+VADApuPXceaGGoufjkRbLydpCzSBzIIy/HD8OjYmXkdSZmGt590dFBgV4Y8xkf7o7OdcZ2tozQAJKVYCoZaPAZCIiExOYSPDeyM7o0ewK9787k8UV2hwIbMIIxftw/wx92FUhL/UJd6z0goNfjmbge8Tr2PvxWzcvkKaQi7D4DBvjIn0R7/2nrBtwMhcuUzgWrhkEgyARETUbB7q6odOvs54ZV0ikjILUVKhwWv/O4GjqXn450OdoLSpvWqEOdNqRRxOzcXGxGvYfioDReW1l1DrHuSKMZH+eOg+P7jYcxQ0mQcGQCIialahno74YUpv/POH0/g+8RoAYO3BNJy8lo8vnopEoJu9xBXeXUpOMTYmXsPGxOu4nl976pYAVzuM6eaPhyMD0MbDQYIKie6MAZCIiJqdnUKOjx/riqg2rvjXj2dQUaXFn9fUeOjzvVjweDgGdfKWusRa1CWV2PLnDWxMvIbEK/m1nndU2mD4fb4YE+mPnsFunM+OzBoDIBERSUIQBIzt2Rpd/F3wyjeJSLtZAnVpJZ7/6ihe7h+KNx5oL/kKFpUaLX5PysbG49ew62wWKjS1p27p284TYyL98UCYD+wUltWFTdaLAZCIiCTV2c8FW/7WB//4vz+x40wGAGDp75eQeCUPi57sBq9bpkZpDjVTt3yfeA2bT9zAzeLaU7d08HbCI939MTrCv9nrIzIGBkAiIpKcs8oWS8ZFYuXeFLz/03lUaUUcTsnFsM/24rMnIxDbDEueZRaUYdPx69iYeA0XMotqPe/hqMDIcH880t0fYb51T91CZCkYAImIyCwIgoAX+oagW+tWmPLNcWQUlCGnqBzjvjyEvz/QAZP7hxr9vrqSiir8ciYT3ydew77knNpTt9jopm55JNIffds1bOoWIkvAAEhERGale5Abtr3aB9M2nMCei7pQ9tHPSTiamosFj0fA1UFxT8fXakUcSqmZuiUdxRWaWvv0CHLFmMgADO/qCxc7Tt1CLQ8DIBERmR13RyXWTIzCol+TsTDhAkQR2J2UjYc+34svno5ERGCrRh/zcnYRNiZex6bjd5i6JTIAY7r5I5hTt1ALxwBIRERmSS4T8FpcO0QGtcJr/zuB3OIKXM8vxWNL9+Ofw8MwPiYIWhE4dPkmkq/lom2RHNEhHgZLpeWXVGDLn+nYmHgNx+uYusVJaYPhXX0xJjIAPYJcOXULWQ2zCIBffPEFPvroI2RkZCA8PByff/45oqKi6tx3zZo1mDhxosE2pVKJsjLdYtmVlZX45z//ie3bt+Py5ctwcXFBXFwc3n//ffj5+Zn8vRARkXH1beeJ7a/2xdT1iTialodKjYiZm8/gx5PXcT2vFJkF5dV7psDXRYV3hutWFNmYeA0J5+qeuqVfe0+MiQzAA2HeUNly6hayPpIHwA0bNiA+Ph5Lly5FdHQ0Fi5ciCFDhiApKQleXl51vsbZ2RlJSUn6x7eOxCopKUFiYiL+9a9/ITw8HHl5eXjttdcwcuRIHD161OTvh4iIjM/HRYX/vtgLH+44jxV7UgAAiWn5tfZLV5dh6vrjdR6jo48THokMwKgIP07dQlZP8gC4YMECTJo0Sd+qt3TpUmzbtg2rVq3CW2+9VedrBEGAj49Pnc+5uLhg586dBtsWLVqEqKgoXLlyBa1btzbuGyAiomZhK5fhneFh6BboiinrEyHe/SXwcFRidIQfxkQGIMzP2eQ1ElkKSQNgRUUFjh07hhkzZui3yWQyxMXF4cCBA/W+rqioCEFBQdBqtYiMjMS8efPQuXPnevdXq9UQBAGtWrUyZvlERCQBVwdFg8Lfm0M6YFK/EMlXEyEyR5IGwJycHGg0Gnh7G6756O3tjfPnz9f5mg4dOmDVqlXo2rUr1Go1Pv74Y8TGxuLMmTMICAiotX9ZWRnefPNNPPnkk3B2rvtff+Xl5SgvL9c/LigoAABotVpotdo6X3OvtFotRFE02fGpefA6Wj5eQ8uTWVB7BG9dfFupIBPAa2sB+HtoHI35/CTvAm6smJgYxMTE6B/HxsaiU6dOWLZsGebMmWOwb2VlJR5//HGIooglS5bUe8z58+dj1qxZtbZnZ2frB5cYm1arhVqthiiKkMn4r1NLxeto+XgNLY9tVcMCoG1VKbKyskxcDRkDfw+No7CwsMH7ShoAPTw8IJfLkZmZabA9MzOz3nv8bmdra4tu3bohOTnZYHtN+EtLS8Ovv/5ab+sfAMyYMQPx8fH6xwUFBQgMDISnp+cdX3cvtFotBEGAp6cnv+wWjNfR8vEaWp4HPDzhs/MKMgvK6uwKFqAbNPJAtxCDKWHIfPH30DhUqoYPbpI0ACoUCnTv3h0JCQkYPXo0AN2XICEhAVOnTm3QMTQaDU6dOoVhw4bpt9WEv4sXL2L37t1wd3e/4zGUSiWUSmWt7TKZzKRfREEQTH4OMj1eR8vHa2hZZDLgvZFhmLwuEQJgEAJr4t7MEWGwteH0LpaEv4f3rjGfneSfcnx8PFasWIGvvvoK586dw+TJk1FcXKwfFTx+/HiDQSKzZ8/GL7/8gsuXLyMxMRHjxo1DWloaXnjhBQC68Pfoo4/i6NGj+Oabb6DRaJCRkYGMjAxUVFRI8h6JiMi4hnbxxZJxkfBxMWzx8HFRYcm4SAzt4itRZUSWQfJ7AMeOHYvs7Gy8++67yMjIQEREBHbs2KEfGHLlyhWDRJuXl4dJkyYhIyMDrq6u6N69O/bv34+wsDAAwPXr17F582YAQEREhMG5du/ejQEDBjTL+yIiItMa2sUXg8N8cOhyDpKvZaNtgGetlUCIqG6CKIoNGU1vVQoKCuDi4gK1Wm3SewCzsrLg5eXF5m4Lxuto+XgNLR+voeXjNTSOxuQXfspEREREVoYBkIiIiMjKMAASERERWRkGQCIiIiIrwwBIREREZGUYAImIiIisjOTzAJqjmplxCgoKTHYOrVaLwsJCqFQqDnm3YLyOlo/X0PLxGlo+XkPjqMktDZnhjwGwDjWLKQcGBkpcCREREVHjFBYWwsXF5Y77cCLoOmi1Wty4cQNOTk4QBNPMKF9QUIDAwEBcvXrVZJNNk+nxOlo+XkPLx2to+XgNjUMURRQWFsLPz++uLalsAayDTCZDQEBAs5zL2dmZX/YWgNfR8vEaWj5eQ8vHa3jv7tbyV4Md7URERERWhgGQiIiIyMowAEpEqVRi5syZUCqVUpdC94DX0fLxGlo+XkPLx2vY/DgIhIiIiMjKsAWQiIiIyMowABIRERFZGQZAIiIiIivDACiRL774AsHBwVCpVIiOjsbhw4elLokaaP78+ejZsyecnJzg5eWF0aNHIykpSeqy6B68//77EAQB06ZNk7oUaoTr169j3LhxcHd3h52dHe677z4cPXpU6rKoETQaDf71r3+hTZs2sLOzQ2hoKObMmdOgpczo3jAASmDDhg2Ij4/HzJkzkZiYiPDwcAwZMgRZWVlSl0YN8Pvvv2PKlCk4ePAgdu7cicrKSjzwwAMoLi6WujRqgiNHjmDZsmXo2rWr1KVQI+Tl5aF3796wtbXFTz/9hLNnz+KTTz6Bq6ur1KVRI3zwwQdYsmQJFi1ahHPnzuGDDz7Ahx9+iM8//1zq0lo8jgKWQHR0NHr27IlFixYB0C09FxgYiL/97W946623JK6OGis7OxteXl74/fff0a9fP6nLoUYoKipCZGQkFi9ejH//+9+IiIjAwoULpS6LGuCtt97Cvn37sGfPHqlLoXvw0EMPwdvbGytXrtRve+SRR2BnZ4d169ZJWFnLxxbAZlZRUYFjx44hLi5Ov00mkyEuLg4HDhyQsDJqKrVaDQBwc3OTuBJqrClTpmD48OEGv49kGTZv3owePXrgscceg5eXF7p164YVK1ZIXRY1UmxsLBISEnDhwgUAwMmTJ7F37148+OCDElfW8nEt4GaWk5MDjUYDb29vg+3e3t44f/68RFVRU2m1WkybNg29e/dGly5dpC6HGuF///sfEhMTceTIEalLoSa4fPkylixZgvj4eLz99ts4cuQIXn31VSgUCkyYMEHq8qiB3nrrLRQUFKBjx46Qy+XQaDSYO3cunn76aalLa/EYAInuwZQpU3D69Gns3btX6lKoEa5evYrXXnsNO3fuhEqlkrocagKtVosePXpg3rx5AIBu3brh9OnTWLp0KQOgBfn222/xzTffYP369ejcuTNOnDiBadOmwc/Pj9fRxBgAm5mHhwfkcjkyMzMNtmdmZsLHx0eiqqgppk6diq1bt+KPP/5AQECA1OVQIxw7dgxZWVmIjIzUb9NoNPjjjz+waNEilJeXQy6XS1gh3Y2vry/CwsIMtnXq1Anff/+9RBVRU0yfPh1vvfUWnnjiCQDAfffdh7S0NMyfP58B0MR4D2AzUygU6N69OxISEvTbtFotEhISEBMTI2Fl1FCiKGLq1KnYtGkTfv31V7Rp00bqkqiRBg0ahFOnTuHEiRP6nx49euDpp5/GiRMnGP4sQO/evWtNv3ThwgUEBQVJVBE1RUlJCWQywygil8uh1Wolqsh6sAVQAvHx8ZgwYQJ69OiBqKgoLFy4EMXFxZg4caLUpVEDTJkyBevXr8ePP/4IJycnZGRkAABcXFxgZ2cncXXUEE5OTrXu2XRwcIC7uzvv5bQQr7/+OmJjYzFv3jw8/vjjOHz4MJYvX47ly5dLXRo1wogRIzB37ly0bt0anTt3xvHjx7FgwQI899xzUpfW4nEaGIksWrQIH330ETIyMhAREYHPPvsM0dHRUpdFDSAIQp3bV69ejWeffbZ5iyGjGTBgAKeBsTBbt27FjBkzcPHiRbRp0wbx8fGYNGmS1GVRIxQWFuJf//oXNm3ahKysLPj5+eHJJ5/Eu+++C4VCIXV5LRoDIBEREZGV4T2ARERERFaGAZCIiIjIyjAAEhEREVkZBkAiIiIiK8MASERERGRlGACJiIiIrAwDIBEREZGVYQAkIiIisjIMgETU4gmCgB9++EHqMhrlt99+gyAIyM/Pl7qUBnvvvfcQEREhdRlE1AAMgERkVp599lkIglDrJzk5WerS7soSQxsRWScbqQsgIrrd0KFDsXr1aoNtnp6eElUDVFRUWMS6pJWVlbC1tZW6DCKyAGwBJCKzo1Qq4ePjY/Ajl8sBAD/++CMiIyOhUqkQEhKCWbNmoaqqSv/aixcvol+/flCpVAgLC8POnTtrHf/q1at4/PHH0apVK7i5uWHUqFFITU3VP//ss89i9OjRmDt3Lvz8/NChQwcAwNq1a9GjRw84OTnBx8cHTz31FLKysgAAqampGDhwIADA1dUVgiDg2WefBQBotVrMnz8fbdq0gZ2dHcLDw/Hdd98Z1LR9+3a0b98ednZ2GDhwoEE99REEAUuWLMHIkSPh4OCAuXPnAgCWLFmC0NBQKBQKdOjQAWvXrtW/JjU1FYIg4MSJE/pt+fn5EAQBv/32G4C/WjITEhLQo0cP2NvbIzY2FklJSQbnf//99+Ht7Q0nJyc8//zzKCsru2vNRGQeGACJyGLs2bMH48ePx2uvvYazZ89i2bJlWLNmjT74aLVajBkzBgqFAocOHcLSpUvx5ptvGhyjsrISQ4YMgZOTE/bs2YN9+/bB0dERQ4cORUVFhX6/hIQEJCUlYefOndi6dav+tXPmzMHJkyfxww8/IDU1VR/yAgMD8f333wMAkpKSkJ6ejk8//RQAMH/+fHz99ddYunQpzpw5g9dffx3jxo3D77//DkAXSMeMGYMRI0bgxIkTeOGFF/DWW2816DN577338PDDD+PUqVN47rnnsGnTJrz22mv4+9//jtOnT+Oll17CxIkTsXv37kZ/3u+88w4++eQTHD16FDY2Nnjuuef0z3377bd47733MG/ePBw9ehS+vr5YvHhxo89BRBIRiYjMyIQJE0S5XC46ODjofx599FFRFEVx0KBB4rx58wz2X7t2rejr6yuKoij+/PPPoo2NjXj9+nX98z/99JMIQNy0aZN+/w4dOoharVa/T3l5uWhnZyf+/PPP+hq8vb3F8vLyO9Z65MgREYBYWFgoiqIo7t69WwQg5uXl6fcpKysT7e3txf379xu89vnnnxeffPJJURRFccaMGWJYWJjB82+++WatY90OgDht2jSDbbGxseKkSZMMtj322GPisGHDRFEUxZSUFBGAePz4cf3zeXl5IgBx9+7dBu9j165d+n22bdsmAhBLS0tFURTFmJgY8ZVXXjE4T3R0tBgeHl5vvURkPngPIBGZnYEDB2LJkiX6xw4ODgCAkydPYt++ffoWPwDQaDQoKytDSUkJzp07h8DAQPj5+emfj4mJMTj2yZMnkZycDCcnJ4PtZWVluHTpkv7xfffdV+u+v2PHjuG9997DyZMnkZeXB61WCwC4cuUKwsLC6nwvycnJKCkpweDBgw22V1RUoFu3bgCAc+fOITo62uD52+uuT48ePQwenzt3Di+++KLBtt69e+tbIxuja9eu+j/7+voCALKystC6dWucO3cOL7/8cq2am9LSSETNjwGQiMyOg4MD2rZtW2t7UVERZs2ahTFjxtR6TqVSNejYRUVF6N69O7755ptaz9060KQmdNYoLi7GkCFDMGTIEHzzzTfw9PTElStXMGTIEIOu47rOBwDbtm2Dv7+/wXNKpbJBNd/J7XXejUymu/NHFEX9tsrKyjr3vXVAiSAIAKAPvURk2RgAichiREZGIikpqc5wCACdOnXC1atXkZ6erm+xOnjwYK1jbNiwAV5eXnB2dm7wuc+fP4+bN2/i/fffR2BgIADg6NGjBvvUtBhqNBr9trCwMCiVSly5cgX9+/evt+7NmzcbbLu97obq1KkT9u3bhwkTJui37du3T99CWRNy09PT9S2Qtw4Iacx5Dh06hPHjx99zzUTU/BgAichivPvuu3jooYfQunVrPProo5DJZDh58iROnz6Nf//734iLi0P79u0xYcIEfPTRRygoKMA777xjcIynn34aH330EUaNGoXZs2cjICAAaWlp2LhxI/7xj38gICCgznO3bt0aCoUCn3/+OV5++WWcPn0ac+bMMdgnKCgIgiBg69atGDZsGOzs7ODk5IQ33ngDr7/+OrRaLfr06QO1Wo19+/bB2dkZEyZMwMsvv4xPPvkE06dPxwsvvIBjx45hzZo1TfqMpk+fjscffxzdunVDXFwctmzZgo0bN2LXrl0AADs7O/Tq1Qvvv/8+2rRpg6ysLPzzn/9s9Hlee+01PPvss+jRowd69+6Nb775BmfOnEFISEiT6iaiZib1TYhERLeaMGGCOGrUqHqf37FjhxgbGyva2dmJzs7OYlRUlLh8+XL980lJSWKfPn1EhUIhtm/fXtyxY4fBIBBRFMX09HRx/PjxooeHh6hUKsWQkBBx0qRJolqtvmMN69evF4ODg0WlUinGxMSImzdvrjWgYvbs2aKPj48oCII4YcIEURRFUavVigsXLhQ7dOgg2traip6enuKQIUPE33//Xf+6LVu2iG3bthWVSqXYt29fcdWqVQ0aBHLr+6qxePFiMSQkRLS1tRXbt28vfv311wbPnz17VoyJiRHt7OzEiIgI8ZdffqlzEMit5z5+/LgIQExJSdFvmzt3rujh4SE6OjqKEyZMEP/xj39wEAiRhRBE8ZYbQYiIiIioxeM8gERERERWhgGQiIiIyMowABIRERFZGQZAIiIiIivDAEhERERkZRgAiYiIiKwMAyARERGRlWEAJCIiIrIyDIBEREREVoYBkIiIiMjKMAASERERWRkGQCIiIiIr8/8vK0xTn7zcmwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 650x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from training.loop import run_federated_training\n",
        "from configs.base_config import use_teleportation as CFG_TEL, noise_preset, shots_used,aggregation\n",
        "from training.metrics import metrics_init, metrics_log_round, metrics_finalize, compute_auc,metrics_summarize\n",
        "from viz.plots import plot_accuracy_curve, plot_val_loss, plot_time_per_round, plot_fidelity_vs_delta_acc, plot_beta_hist, plot_client_fairness_last_round\n",
        "# Initialize metrics store once\n",
        "metrics_store = metrics_init(\n",
        "    log_path=os.path.join(drive_root, \"teleport_metrics_Perturb_shrink.csv\")\n",
        ")\n",
        "\n",
        "#new\n",
        "from ml import optimizers as mlopt\n",
        "from configs.base_config import drive_root\n",
        "import os\n",
        "\n",
        "mlopt.meta_trace_enable(\n",
        "    path=os.path.join(drive_root, \"meta_trace.csv\"),  # or None to skip CSV\n",
        "    every=5                                           # print every 5 callbacks\n",
        ")\n",
        "\n",
        "###########\n",
        "global_acc, clients_train, clients_test, round_times, val_losses, info_last = run_federated_training(\n",
        "    clients=clients,\n",
        "    num_federated_layers=num_federated_layers,\n",
        "    num_deep_unfolding_iterations=num_deep_unfolding_iterations,\n",
        "    initial_learning_rate=initial_learning_rate,\n",
        "    initial_perturbation=initial_perturbation,\n",
        "    num_features=num_features,\n",
        "    best_client_csv_file=best_client_csv_file,\n",
        "    global_csv_file=global_csv_file,\n",
        "    local_csv_file=local_csv_file,\n",
        "    validation_csv_file=validation_csv_file,\n",
        "    test_sequences=test_sequences,\n",
        "    test_labels=test_labels,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    use_teleportation=CFG_TEL,          # ← important\n",
        "    noise_preset=noise_preset,\n",
        "    shots_used=shots_used,\n",
        "    metrics=metrics_store,   # <-- pass it in\n",
        "    aggregation=aggregation           # <--- switch here\n",
        ")\n",
        "\n",
        "rows_np = metrics_finalize(metrics_store)   # if you need the in-memory array\n",
        "#summary = metrics_summarize(metrics_store)  # prints a concise summary, returns a dict\n",
        "\n",
        "# quick visuals\n",
        "rounds = list(range(len(global_acc)))\n",
        "plot_accuracy_curve(rounds, global_acc, label=\"Global accuracy (DT-DUQFL)\")\n",
        "plot_val_loss(rounds, val_losses, label=\"Central validation loss\")\n",
        "plot_time_per_round(rounds, round_times)\n",
        "\n",
        "if info_last is not None:\n",
        "    # this uses \"last\" round's info; in your logger you kept per-round arrays; adapt if needed\n",
        "    pass\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}