{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shanikairoshi/Communication-Efficient-DUQFL/blob/main/main_v2_1.4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bee84f36",
      "metadata": {
        "id": "bee84f36"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bc18ac0f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc18ac0f",
        "outputId": "f8d5d4f2-29bc-4990-9baa-6f914c798ee9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: genomic-benchmarks in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: biopython>=1.79 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (1.85)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (2.32.4)\n",
            "Requirement already satisfied: pip>=20.0.1 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (24.1.2)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (4.67.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (6.0.3)\n",
            "Requirement already satisfied: gdown>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (5.2.0)\n",
            "Requirement already satisfied: yarl in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (1.20.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown>=4.2.0->genomic-benchmarks) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown>=4.2.0->genomic-benchmarks) (3.19.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->genomic-benchmarks) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->genomic-benchmarks) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->genomic-benchmarks) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->genomic-benchmarks) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->genomic-benchmarks) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->genomic-benchmarks) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->genomic-benchmarks) (2025.8.3)\n",
            "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.12/dist-packages (from yarl->genomic-benchmarks) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from yarl->genomic-benchmarks) (0.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.4->genomic-benchmarks) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown>=4.2.0->genomic-benchmarks) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown>=4.2.0->genomic-benchmarks) (4.15.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=4.2.0->genomic-benchmarks) (1.7.1)\n",
            "Requirement already satisfied: qiskit in /usr/local/lib/python3.12/dist-packages (1.4.4)\n",
            "Requirement already satisfied: qiskit_machine_learning in /usr/local/lib/python3.12/dist-packages (0.8.4)\n",
            "Requirement already satisfied: qiskit_algorithms in /usr/local/lib/python3.12/dist-packages (0.4.0)\n",
            "Requirement already satisfied: qiskit-aer in /usr/local/lib/python3.12/dist-packages (0.17.2)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.17.1)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.12/dist-packages (from qiskit) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.12/dist-packages (from qiskit) (1.15.3)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.12/dist-packages (from qiskit) (1.13.3)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.3.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from qiskit) (2.9.0.post0)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from qiskit) (5.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qiskit) (4.15.0)\n",
            "Requirement already satisfied: symengine<0.14,>=0.11 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.13.0)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.12/dist-packages (from qiskit_machine_learning) (1.6.1)\n",
            "Requirement already satisfied: setuptools>=40.1 in /usr/local/lib/python3.12/dist-packages (from qiskit_machine_learning) (75.2.0)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.12/dist-packages (from qiskit-aer) (5.9.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->qiskit_machine_learning) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->qiskit_machine_learning) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# %%capture\n",
        "!pip install genomic-benchmarks\n",
        "!pip install qiskit qiskit_machine_learning qiskit_algorithms qiskit-aer\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2d53c335",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d53c335",
        "outputId": "b177c81b-afd4-4892-eee5-e274163417ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5291b3a7",
      "metadata": {
        "id": "5291b3a7"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "PROJ = Path.cwd() / \"tduqfl_Project_AGG\"\n",
        "if str(PROJ) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJ))\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Teleportation/tduqfl_Project_AGG/tDuQFL_Project')\n",
        "# ─── 5. Assemble filenames for each artifact ─────────────────────────────────\n",
        "#drive_root = \"/content/drive/MyDrive/Teleportation/tduqfl_Project_AGG/tDuQFL_Project/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c245a1fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c245a1fd",
        "outputId": "141a6be8-9850-460b-be5a-6ff4f2b0dad9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/genomic_benchmarks/utils/datasets.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Python: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "Qiskit: 1.4.4\n",
            "qiskit_aer available?: True\n"
          ]
        }
      ],
      "source": [
        "from common.imports import *\n",
        "from configs.dataset_genome_iid import *     # swap to other configs as needed\n",
        "from io_utils.naming import stamp_now, flags, build_param_str, make_filenames\n",
        "\n",
        "start_str, date_str = stamp_now()\n",
        "teleport_pl, noise_pl = flags(use_teleportation, use_noise)\n",
        "param_str = build_param_str(num_clients, num_federated_layers, num_deep_unfolding_iterations,\n",
        "                            initial_learning_rate, initial_perturbation)\n",
        "\n",
        "best_client_csv_file, global_csv_file, local_csv_file, validation_csv_file = make_filenames(\n",
        "    drive_root, dataset_name, split_type, date_str, teleport_pl, noise_pl, param_str\n",
        ")\n",
        "from io_utils.csv_logger import init_local_csv, init_best_csv, init_validation_csv\n",
        "\n",
        "# Create folders + write headers\n",
        "init_best_csv(best_client_csv_file)\n",
        "\n",
        "local_headers = [\n",
        "    \"Federated Round\", \"Client Number\", \"Iteration\",\n",
        "    \"Objective Function Value\", \"Training Accuracy\", \"Test Accuracy\",\n",
        "    \"Learning Rate\", \"Perturbation\"\n",
        "]\n",
        "init_local_csv(local_csv_file, local_headers)\n",
        "\n",
        "init_validation_csv(validation_csv_file)\n",
        "\n",
        "# Do NOT pre-init global_csv_file here because your save_accuracies_to_csv()\n",
        "# already writes the header each time it runs (in 'w' mode)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "324178e0",
      "metadata": {
        "id": "324178e0"
      },
      "source": [
        "Load and Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d512e2a5",
      "metadata": {
        "id": "d512e2a5"
      },
      "outputs": [],
      "source": [
        "from data.preprocess_genome import load_and_prepare_dataset\n",
        "from data.splitters import split_dataset_for_epochs\n",
        "from configs.base_config import (\n",
        "    num_clients, num_epochs, samples_per_epoch, split_type,\n",
        "    global_seed\n",
        ")\n",
        "\n",
        "np_train_data, np_test_data = load_and_prepare_dataset(word_size, global_seed)\n",
        "\n",
        "# 2) Compute feasible epoch capacity and cap both epochs and rounds\n",
        "N_train = len(np_train_data)\n",
        "train_capacity = N_train // (num_clients * samples_per_epoch)\n",
        "num_epochs_eff = max(1, min(num_epochs, train_capacity))\n",
        "\n",
        "if train_capacity == 0:\n",
        "    raise ValueError(\n",
        "        f\"Not enough training samples ({N_train}) for \"\n",
        "        f\"{num_clients=} × {samples_per_epoch=} per epoch. \"\n",
        "        \"Reduce samples_per_epoch or num_clients, or enable resampling.\"\n",
        "    )\n",
        "\n",
        "num_federated_layers_eff = min(num_federated_layers, num_epochs_eff)\n",
        "\n",
        "# Build clients\n",
        "if split_type.lower() == \"iid\":\n",
        "    from data.splitters import split_dataset_for_epochs\n",
        "    clients = split_dataset_for_epochs(\n",
        "        num_clients=num_clients,\n",
        "        num_epochs=num_epochs_eff,             # or num_epochs\n",
        "        train_data=np_train_data,\n",
        "        test_data=np_test_data,\n",
        "        samples_per_epoch=samples_per_epoch,\n",
        "    )\n",
        "elif split_type.lower() in {\"noniid\", \"non-iid\", \"non_iid\"}:\n",
        "    from data.noniid import make_non_iid_clients\n",
        "    clients = make_non_iid_clients(\n",
        "        train_data=np_train_data,\n",
        "        test_data=np_test_data,\n",
        "        num_clients=num_clients,\n",
        "        num_epochs=num_epochs_eff,             # or num_epochs\n",
        "        samples_per_epoch=samples_per_epoch,\n",
        "        non_iid_ratio=0.8,                     # tune as needed\n",
        "        quantity_variation=0.5,                # tune as needed\n",
        "        seed=global_seed,\n",
        "        plot=True\n",
        "    )\n",
        "else:\n",
        "    raise ValueError(f\"Unknown split_type: {split_type}\")\n",
        "\n",
        "'''\n",
        "clients = split_dataset_for_epochs(\n",
        "    num_clients=num_clients, num_epochs=num_epochs,\n",
        "    train_data=np_train_data, test_data=np_test_data,\n",
        "    samples_per_epoch=samples_per_epoch\n",
        ")\n",
        "'''\n",
        "# validation/tables\n",
        "test_sequences = np.array([d[\"sequence\"] for d in np_test_data])\n",
        "test_labels    = np.array([d[\"label\"]    for d in np_test_data])\n",
        "X_val, y_val   = test_sequences, test_labels\n",
        "\n",
        "# derive num_features once\n",
        "if clients and clients[0].data and clients[0].data[0]:\n",
        "    num_features = clients[0].data[0][0]['sequence'].shape[0]\n",
        "else:\n",
        "    raise RuntimeError(\"Empty client data – check splitting indices.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cf7dd9c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf7dd9c0",
        "outputId": "80b0b443-f84a-4254-a33c-b42de6ca3e72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] num_features = 5\n"
          ]
        }
      ],
      "source": [
        "# Infer num_features from the first available sample in clients\n",
        "def infer_num_features_from_clients(clients):\n",
        "    for c in clients:\n",
        "        for epoch_data in c.data:              # list of samples for that epoch\n",
        "            if not epoch_data:\n",
        "                continue\n",
        "            sample = epoch_data[0]\n",
        "            if \"sequence\" in sample:           # your Genome pipeline\n",
        "                arr = np.asarray(sample[\"sequence\"])\n",
        "                return int(arr.size)\n",
        "            if \"features\" in sample:           # some other pipelines\n",
        "                arr = np.asarray(sample[\"features\"])\n",
        "                return int(arr.size)\n",
        "            if \"image\" in sample:              # e.g., MNIST before flatten\n",
        "                arr = np.asarray(sample[\"image\"]).reshape(-1)\n",
        "                return int(arr.size)\n",
        "            # add any other key you use\n",
        "    raise RuntimeError(\"Could not infer num_features: no samples found.\")\n",
        "\n",
        "num_features = infer_num_features_from_clients(clients)\n",
        "print(f\"[info] num_features = {num_features}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d847bd00",
      "metadata": {
        "id": "d847bd00"
      },
      "source": [
        "run federated loop and plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bbc26297",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bbc26297",
        "outputId": "6edb305d-8fc2-45c1-a3d3-26950f568a9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 0] Teleportation OFF | Aggregation=best\n",
            "[round 0 | client 0] seed LR=0.1400000000 (prev=0.1400000000), seed PERT=0.1400000000 (prev=0.1400000000), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.466943 step=0.03986 g_raw=+0.015 g_sm=+0.003 acc=1 | LR→0.140280 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#010 loss=0.461107 step=0.02988 g_raw=+0.018 g_sm=+0.006 acc=1 | LR→0.140561 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#015 loss=0.455328 step=0.07372 g_raw=+0.027 g_sm=+0.009 acc=1 | LR→0.140843 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#020 loss=0.451342 step=0.01499 g_raw=+0.008 g_sm=+0.010 acc=1 | LR→0.141125 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#025 loss=0.445726 step=0.05176 g_raw=+0.018 g_sm=+0.012 acc=1 | LR→0.141408 PERT→0.140001 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1400000000, PERT_used=0.1400000000 → LR_next=0.1414080338, PERT_next=0.1400010004\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1400000000→0.1414080338 PERT 0.1400000000→0.1400010004\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.441511 step=0.01814 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.141691 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#035 loss=0.431179 step=0.07754 g_raw=+0.030 g_sm=+0.015 acc=1 | LR→0.141976 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#040 loss=0.422908 step=0.02459 g_raw=+0.008 g_sm=+0.017 acc=1 | LR→0.142260 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#045 loss=0.421454 step=0.0006774 g_raw=-0.001 g_sm=+0.015 acc=1 | LR→0.142546 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#050 loss=0.420808 step=0.03727 g_raw=+0.014 g_sm=+0.013 acc=1 | LR→0.142831 PERT→0.140003 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1414080338, PERT_used=0.1400010004 → LR_next=0.1428312965, PERT_next=0.1400030473\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1414080338→0.1428312965 PERT 0.1400010004→0.1400030473\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.418160 step=0.002674 g_raw=+0.002 g_sm=+0.012 acc=1 | LR→0.143118 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#060 loss=0.414410 step=0.06481 g_raw=+0.018 g_sm=+0.012 acc=1 | LR→0.143404 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#065 loss=0.412219 step=0.02458 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.143692 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#070 loss=0.403825 step=0.04454 g_raw=+0.014 g_sm=+0.014 acc=1 | LR→0.143980 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#075 loss=0.400593 step=0.08693 g_raw=+0.029 g_sm=+0.013 acc=1 | LR→0.144269 PERT→0.140005 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1428312965, PERT_used=0.1400030473 → LR_next=0.1442686448, PERT_next=0.1400048620\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1428312965→0.1442686448 PERT 0.1400030473→0.1400048620\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.58\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.399698 step=0.00676 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.144558 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#085 loss=0.397191 step=0.007712 g_raw=+0.001 g_sm=+0.011 acc=1 | LR→0.144848 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#090 loss=0.394364 step=0.01543 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.145138 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#095 loss=0.390984 step=0.02969 g_raw=+0.010 g_sm=+0.012 acc=1 | LR→0.145429 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#100 loss=0.386371 step=0.05715 g_raw=+0.020 g_sm=+0.013 acc=1 | LR→0.145720 PERT→0.140007 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1442686448, PERT_used=0.1400048620 → LR_next=0.1457203051, PERT_next=0.1400065302\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1442686448→0.1457203051 PERT 0.1400048620→0.1400065302\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.383953 step=0.04086 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.146012 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#110 loss=0.382111 step=0.01982 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.146305 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#115 loss=0.381570 step=0.01074 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.146598 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#120 loss=0.380063 step=0.03201 g_raw=+0.013 g_sm=+0.010 acc=1 | LR→0.146892 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#125 loss=0.378638 step=0.01561 g_raw=+0.006 g_sm=+0.010 acc=1 | LR→0.147187 PERT→0.140008 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1457203051, PERT_used=0.1400065302 → LR_next=0.1471865115, PERT_next=0.1400081407\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1457203051→0.1471865115 PERT 0.1400065302→0.1400081407\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.61\n",
            "[round 0 | client 0] final LR=0.1471865115, final PERT=0.1400081407  (ΔLR=+0.0071865115, ΔPERT=+0.0000081407)\n",
            "[round 0 | client 1] seed LR=0.1400000000 (prev=0.1400000000), seed PERT=0.1400000000 (prev=0.1400000000), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.540319 step=0.06399 g_raw=+0.027 g_sm=+0.003 acc=1 | LR→0.140280 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#010 loss=0.533574 step=0.05231 g_raw=+0.024 g_sm=+0.008 acc=1 | LR→0.140561 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#015 loss=0.526777 step=0.03753 g_raw=+0.013 g_sm=+0.011 acc=1 | LR→0.140843 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#020 loss=0.518041 step=0.08082 g_raw=+0.032 g_sm=+0.014 acc=1 | LR→0.141125 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#025 loss=0.509406 step=0.01846 g_raw=+0.007 g_sm=+0.015 acc=1 | LR→0.141408 PERT→0.140001 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1400000000, PERT_used=0.1400000000 → LR_next=0.1414082956, PERT_next=0.1400012595\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1400000000→0.1414082956 PERT 0.1400000000→0.1400012595\n",
            "Training Accuracy: 0.40\n",
            "Test Accuracy: 0.47\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.501874 step=0.006175 g_raw=+0.002 g_sm=+0.016 acc=1 | LR→0.141692 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#035 loss=0.490485 step=0.03073 g_raw=+0.019 g_sm=+0.018 acc=1 | LR→0.141976 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#040 loss=0.481887 step=0.002604 g_raw=+0.003 g_sm=+0.019 acc=1 | LR→0.142261 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#045 loss=0.472630 step=0.0002596 g_raw=-0.001 g_sm=+0.019 acc=1 | LR→0.142546 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#050 loss=0.466289 step=0.1026 g_raw=+0.039 g_sm=+0.020 acc=1 | LR→0.142832 PERT→0.140004 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1414082956, PERT_used=0.1400012595 → LR_next=0.1428320560, PERT_next=0.1400037918\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1414082956→0.1428320560 PERT 0.1400012595→0.1400037918\n",
            "Training Accuracy: 0.46\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.454168 step=0.02215 g_raw=+0.008 g_sm=+0.020 acc=1 | LR→0.143119 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#060 loss=0.443065 step=0.01067 g_raw=+0.004 g_sm=+0.020 acc=1 | LR→0.143406 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#065 loss=0.438499 step=0.02955 g_raw=+0.011 g_sm=+0.019 acc=1 | LR→0.143693 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#070 loss=0.423235 step=0.0169 g_raw=+0.006 g_sm=+0.021 acc=1 | LR→0.143982 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#075 loss=0.420025 step=0.06901 g_raw=+0.026 g_sm=+0.019 acc=1 | LR→0.144270 PERT→0.140007 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1428320560, PERT_used=0.1400037918 → LR_next=0.1442703880, PERT_next=0.1400065536\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.020 acc_ratio=1.00 | LR 0.1428320560→0.1442703880 PERT 0.1400037918→0.1400065536\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.78\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.414407 step=0.04914 g_raw=+0.016 g_sm=+0.019 acc=1 | LR→0.144560 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#085 loss=0.413768 step=0.01532 g_raw=+0.002 g_sm=+0.016 acc=1 | LR→0.144850 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#090 loss=0.408217 step=0.03438 g_raw=+0.014 g_sm=+0.016 acc=1 | LR→0.145140 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#095 loss=0.405659 step=0.02451 g_raw=+0.011 g_sm=+0.016 acc=1 | LR→0.145431 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#100 loss=0.399382 step=0.0539 g_raw=+0.018 g_sm=+0.016 acc=1 | LR→0.145723 PERT→0.140009 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1442703880, PERT_used=0.1400065536 → LR_next=0.1457228069, PERT_next=0.1400089339\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1442703880→0.1457228069 PERT 0.1400065536→0.1400089339\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.76\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.396066 step=0.01737 g_raw=+0.004 g_sm=+0.015 acc=1 | LR→0.146015 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#110 loss=0.389617 step=0.01299 g_raw=+0.006 g_sm=+0.016 acc=1 | LR→0.146308 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#115 loss=0.387657 step=0.03541 g_raw=+0.016 g_sm=+0.015 acc=1 | LR→0.146601 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#120 loss=0.385961 step=0.05098 g_raw=+0.024 g_sm=+0.014 acc=1 | LR→0.146895 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#125 loss=0.383838 step=0.03322 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.147190 PERT→0.140011 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1457228069, PERT_used=0.1400089339 → LR_next=0.1471895437, PERT_next=0.1400110249\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1457228069→0.1471895437 PERT 0.1400089339→0.1400110249\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.74\n",
            "[round 0 | client 1] final LR=0.1471895437, final PERT=0.1400110249  (ΔLR=+0.0071895437, ΔPERT=+0.0000110249)\n",
            "[round 0 | client 2] seed LR=0.1400000000 (prev=0.1400000000), seed PERT=0.1400000000 (prev=0.1400000000), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.497059 step=0.07114 g_raw=+0.031 g_sm=+0.005 acc=1 | LR→0.140280 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#010 loss=0.495875 step=0.02024 g_raw=+0.010 g_sm=+0.006 acc=1 | LR→0.140561 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#015 loss=0.488678 step=0.1205 g_raw=+0.046 g_sm=+0.008 acc=1 | LR→0.140843 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#020 loss=0.486570 step=0.03736 g_raw=+0.012 g_sm=+0.009 acc=1 | LR→0.141125 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#025 loss=0.482056 step=0.01084 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.141408 PERT→0.140001 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1400000000, PERT_used=0.1400000000 → LR_next=0.1414079676, PERT_next=0.1400009348\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1400000000→0.1414079676 PERT 0.1400000000→0.1400009348\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.478462 step=0.0512 g_raw=+0.018 g_sm=+0.011 acc=1 | LR→0.141691 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#035 loss=0.476873 step=0.02301 g_raw=+0.011 g_sm=+0.011 acc=1 | LR→0.141975 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#040 loss=0.472023 step=0.05625 g_raw=+0.016 g_sm=+0.012 acc=1 | LR→0.142260 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#045 loss=0.469737 step=0.01126 g_raw=+0.003 g_sm=+0.012 acc=1 | LR→0.142545 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#050 loss=0.468928 step=0.02834 g_raw=+0.011 g_sm=+0.011 acc=1 | LR→0.142831 PERT→0.140003 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1414079676, PERT_used=0.1400009348 → LR_next=0.1428308202, PERT_next=0.1400025804\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1414079676→0.1428308202 PERT 0.1400009348→0.1400025804\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.58\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.465777 step=0.003943 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.143117 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#060 loss=0.462004 step=0.063 g_raw=+0.025 g_sm=+0.012 acc=1 | LR→0.143404 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#065 loss=0.456290 step=0.08928 g_raw=+0.032 g_sm=+0.013 acc=1 | LR→0.143691 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#070 loss=0.452785 step=0.05278 g_raw=+0.019 g_sm=+0.013 acc=1 | LR→0.143979 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#075 loss=0.447694 step=0.0225 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.144268 PERT→0.140004 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1428308202, PERT_used=0.1400025804 → LR_next=0.1442680529, PERT_next=0.1400042876\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1428308202→0.1442680529 PERT 0.1400025804→0.1400042876\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.445588 step=0.05148 g_raw=+0.017 g_sm=+0.013 acc=1 | LR→0.144557 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#085 loss=0.443612 step=0.02127 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.144847 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#090 loss=0.438594 step=0.05223 g_raw=+0.021 g_sm=+0.014 acc=1 | LR→0.145137 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#095 loss=0.429297 step=0.1174 g_raw=+0.048 g_sm=+0.016 acc=1 | LR→0.145428 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#100 loss=0.426151 step=0.001044 g_raw=+0.000 g_sm=+0.015 acc=1 | LR→0.145720 PERT→0.140006 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1442680529, PERT_used=0.1400042876 → LR_next=0.1457199918, PERT_next=0.1400062292\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1442680529→0.1457199918 PERT 0.1400042876→0.1400062292\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.424973 step=0.03176 g_raw=+0.011 g_sm=+0.013 acc=1 | LR→0.146012 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#110 loss=0.422106 step=0.02284 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.146305 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#115 loss=0.421519 step=0.01238 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.146598 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#120 loss=0.420920 step=0.003081 g_raw=+0.000 g_sm=+0.010 acc=1 | LR→0.146892 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#125 loss=0.415339 step=0.01939 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.147186 PERT→0.140008 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1457199918, PERT_used=0.1400062292 → LR_next=0.1471862830, PERT_next=0.1400079233\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1457199918→0.1471862830 PERT 0.1400062292→0.1400079233\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.76\n",
            "[round 0 | client 2] final LR=0.1471862830, final PERT=0.1400079233  (ΔLR=+0.0071862830, ΔPERT=+0.0000079233)\n",
            "[round 0 | client 3] seed LR=0.1400000000 (prev=0.1400000000), seed PERT=0.1400000000 (prev=0.1400000000), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.528959 step=0.008577 g_raw=+0.001 g_sm=+0.002 acc=1 | LR→0.140280 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#010 loss=0.525653 step=0.016 g_raw=+0.010 g_sm=+0.005 acc=1 | LR→0.140561 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#015 loss=0.520075 step=0.01203 g_raw=+0.005 g_sm=+0.008 acc=1 | LR→0.140843 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#020 loss=0.515616 step=0.0432 g_raw=+0.016 g_sm=+0.010 acc=1 | LR→0.141125 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#025 loss=0.512703 step=0.0677 g_raw=+0.025 g_sm=+0.010 acc=1 | LR→0.141408 PERT→0.140001 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1400000000, PERT_used=0.1400000000 → LR_next=0.1414078990, PERT_next=0.1400008669\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1400000000→0.1414078990 PERT 0.1400000000→0.1400008669\n",
            "Training Accuracy: 0.50\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.510329 step=0.03676 g_raw=+0.016 g_sm=+0.011 acc=1 | LR→0.141691 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#035 loss=0.507200 step=0.04676 g_raw=+0.019 g_sm=+0.012 acc=1 | LR→0.141975 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#040 loss=0.502413 step=0.06536 g_raw=+0.027 g_sm=+0.013 acc=1 | LR→0.142260 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#045 loss=0.500676 step=0.01049 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.142545 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#050 loss=0.495970 step=0.07915 g_raw=+0.035 g_sm=+0.014 acc=1 | LR→0.142831 PERT→0.140003 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1414078990, PERT_used=0.1400008669 → LR_next=0.1428307946, PERT_next=0.1400025554\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1414078990→0.1428307946 PERT 0.1400008669→0.1400025554\n",
            "Training Accuracy: 0.56\n",
            "Test Accuracy: 0.57\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.494891 step=0.01621 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.143117 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#060 loss=0.492991 step=0.0229 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.143404 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#065 loss=0.489114 step=0.0476 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.143691 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#070 loss=0.482980 step=0.08884 g_raw=+0.035 g_sm=+0.014 acc=1 | LR→0.143979 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#075 loss=0.479006 step=0.02914 g_raw=+0.009 g_sm=+0.014 acc=1 | LR→0.144268 PERT→0.140004 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1428307946, PERT_used=0.1400025554 → LR_next=0.1442681455, PERT_next=0.1400043774\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1428307946→0.1442681455 PERT 0.1400025554→0.1400043774\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.472716 step=0.03912 g_raw=+0.018 g_sm=+0.016 acc=1 | LR→0.144557 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#085 loss=0.469645 step=0.02982 g_raw=+0.016 g_sm=+0.015 acc=1 | LR→0.144847 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#090 loss=0.466904 step=0.003749 g_raw=-0.001 g_sm=+0.014 acc=1 | LR→0.145138 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#095 loss=0.460998 step=0.003108 g_raw=+0.004 g_sm=+0.015 acc=1 | LR→0.145429 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#100 loss=0.456660 step=0.05849 g_raw=+0.020 g_sm=+0.015 acc=1 | LR→0.145720 PERT→0.140006 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1442681455, PERT_used=0.1400043774 → LR_next=0.1457202734, PERT_next=0.1400064998\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1442681455→0.1457202734 PERT 0.1400043774→0.1400064998\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.449471 step=0.03603 g_raw=+0.018 g_sm=+0.017 acc=1 | LR→0.146012 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#110 loss=0.445221 step=0.05573 g_raw=+0.019 g_sm=+0.016 acc=1 | LR→0.146305 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#115 loss=0.442412 step=0.01221 g_raw=+0.004 g_sm=+0.015 acc=1 | LR→0.146599 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#120 loss=0.439262 step=0.01528 g_raw=+0.008 g_sm=+0.015 acc=1 | LR→0.146893 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#125 loss=0.436945 step=0.01119 g_raw=+0.005 g_sm=+0.013 acc=1 | LR→0.147187 PERT→0.140009 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1457202734, PERT_used=0.1400064998 → LR_next=0.1471870654, PERT_next=0.1400086675\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1457202734→0.1471870654 PERT 0.1400064998→0.1400086675\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.76\n",
            "[round 0 | client 3] final LR=0.1471870654, final PERT=0.1400086675  (ΔLR=+0.0071870654, ΔPERT=+0.0000086675)\n",
            "[round 0 | client 4] seed LR=0.1400000000 (prev=0.1400000000), seed PERT=0.1400000000 (prev=0.1400000000), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.499568 step=0.133 g_raw=+0.052 g_sm=+0.005 acc=1 | LR→0.140280 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#010 loss=0.495051 step=0.03667 g_raw=+0.016 g_sm=+0.008 acc=1 | LR→0.140561 PERT→0.140000 (scale=0.04)\n",
            "[meta] cb#015 loss=0.476710 step=0.09788 g_raw=+0.040 g_sm=+0.014 acc=1 | LR→0.140843 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#020 loss=0.474646 step=0.006783 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.141125 PERT→0.140001 (scale=0.04)\n",
            "[meta] cb#025 loss=0.467751 step=0.06995 g_raw=+0.023 g_sm=+0.014 acc=1 | LR→0.141408 PERT→0.140001 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1400000000, PERT_used=0.1400000000 → LR_next=0.1414083259, PERT_next=0.1400012895\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1400000000→0.1414083259 PERT 0.1400000000→0.1400012895\n",
            "Training Accuracy: 0.52\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.464022 step=0.03611 g_raw=+0.012 g_sm=+0.014 acc=1 | LR→0.141692 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#035 loss=0.459520 step=0.05667 g_raw=+0.025 g_sm=+0.015 acc=1 | LR→0.141976 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#040 loss=0.457740 step=0.04097 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.142261 PERT→0.140002 (scale=0.04)\n",
            "[meta] cb#045 loss=0.455344 step=0.03835 g_raw=+0.017 g_sm=+0.013 acc=1 | LR→0.142546 PERT→0.140003 (scale=0.04)\n",
            "[meta] cb#050 loss=0.451541 step=0.01941 g_raw=+0.004 g_sm=+0.013 acc=1 | LR→0.142831 PERT→0.140003 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1414083259, PERT_used=0.1400012895 → LR_next=0.1428314456, PERT_next=0.1400031934\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1414083259→0.1428314456 PERT 0.1400012895→0.1400031934\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.60\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.442519 step=0.003211 g_raw=+0.002 g_sm=+0.014 acc=1 | LR→0.143118 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#060 loss=0.435996 step=0.04451 g_raw=+0.010 g_sm=+0.015 acc=1 | LR→0.143405 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#065 loss=0.426096 step=0.06894 g_raw=+0.026 g_sm=+0.017 acc=1 | LR→0.143692 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#070 loss=0.422511 step=0.007827 g_raw=+0.001 g_sm=+0.016 acc=1 | LR→0.143980 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#075 loss=0.416492 step=0.0123 g_raw=+0.006 g_sm=+0.017 acc=1 | LR→0.144269 PERT→0.140005 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1428314456, PERT_used=0.1400031934 → LR_next=0.1442692018, PERT_next=0.1400054025\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1428314456→0.1442692018 PERT 0.1400031934→0.1400054025\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.412896 step=0.05282 g_raw=+0.018 g_sm=+0.016 acc=1 | LR→0.144558 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#085 loss=0.403631 step=0.08178 g_raw=+0.031 g_sm=+0.018 acc=1 | LR→0.144848 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#090 loss=0.403212 step=0.00592 g_raw=+0.001 g_sm=+0.015 acc=1 | LR→0.145139 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#095 loss=0.400289 step=0.02462 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.145430 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#100 loss=0.395923 step=0.04231 g_raw=+0.015 g_sm=+0.015 acc=1 | LR→0.145721 PERT→0.140008 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1442692018, PERT_used=0.1400054025 → LR_next=0.1457214053, PERT_next=0.1400075873\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1442692018→0.1457214053 PERT 0.1400054025→0.1400075873\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.394967 step=0.02666 g_raw=+0.012 g_sm=+0.013 acc=1 | LR→0.146014 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#110 loss=0.394188 step=0.003804 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.146306 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#115 loss=0.393654 step=0.01265 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.146599 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#120 loss=0.393164 step=0.02489 g_raw=+0.006 g_sm=+0.009 acc=1 | LR→0.146893 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#125 loss=0.391010 step=0.00853 g_raw=+0.003 g_sm=+0.009 acc=1 | LR→0.147188 PERT→0.140009 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1457214053, PERT_used=0.1400075873 → LR_next=0.1471875348, PERT_next=0.1400091140\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.006 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1457214053→0.1471875348 PERT 0.1400075873→0.1400091140\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.67\n",
            "[round 0 | client 4] final LR=0.1471875348, final PERT=0.1400091140  (ΔLR=+0.0071875348, ΔPERT=+0.0000091140)\n",
            "\n",
            "[Round 0] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           1      0.543095      0.740000      0.147190      0.140011\n",
            "           2      0.574380      0.760000      0.147186      0.140008\n",
            "           4      0.583455      0.665000      0.147188      0.140009\n",
            "           3      0.593970      0.755000      0.147187      0.140009\n",
            "           0      0.606501      0.615000      0.147187      0.140008\n",
            "→ [Round 0] action=init_from_best, best_client=1, best_val=0.543095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  10%|█         | 1/10 [09:00<1:21:00, 540.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   0] acc_g=0.729 (μ=0.707, σ=0.057, FG=0.123) | t=530.112s, val=0.543 | TEL=FALSE\n",
            "[Round 1] Teleportation OFF | Aggregation=best\n",
            "[round 1 | client 0] seed LR=0.1435932558 (prev=0.1471865115), seed PERT=0.1400040703 (prev=0.1400081407), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.502480 step=0.02179 g_raw=+0.009 g_sm=+0.004 acc=1 | LR→0.143881 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#010 loss=0.497435 step=0.0811 g_raw=+0.029 g_sm=+0.007 acc=1 | LR→0.144169 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#015 loss=0.492035 step=0.1016 g_raw=+0.038 g_sm=+0.009 acc=1 | LR→0.144458 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#020 loss=0.483584 step=0.002795 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.144747 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#025 loss=0.481949 step=0.04932 g_raw=+0.016 g_sm=+0.011 acc=1 | LR→0.145037 PERT→0.140005 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1435932558, PERT_used=0.1400040703 → LR_next=0.1450374578, PERT_next=0.1400050992\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1435932558→0.1450374578 PERT 0.1400040703→0.1400050992\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.481214 step=0.01462 g_raw=+0.001 g_sm=+0.010 acc=1 | LR→0.145328 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#035 loss=0.476202 step=0.04695 g_raw=+0.016 g_sm=+0.010 acc=1 | LR→0.145619 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#040 loss=0.473119 step=0.01603 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.145911 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#045 loss=0.471274 step=0.01394 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.146204 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#050 loss=0.468391 step=0.05661 g_raw=+0.019 g_sm=+0.011 acc=1 | LR→0.146497 PERT→0.140007 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1450374578, PERT_used=0.1400050992 → LR_next=0.1464966889, PERT_next=0.1400066096\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1450374578→0.1464966889 PERT 0.1400050992→0.1400066096\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.46\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.464948 step=0.0891 g_raw=+0.036 g_sm=+0.011 acc=1 | LR→0.146790 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#060 loss=0.461066 step=0.04559 g_raw=+0.018 g_sm=+0.012 acc=1 | LR→0.147084 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#065 loss=0.458405 step=0.06274 g_raw=+0.023 g_sm=+0.012 acc=1 | LR→0.147379 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#070 loss=0.451057 step=0.07725 g_raw=+0.030 g_sm=+0.014 acc=1 | LR→0.147675 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#075 loss=0.449217 step=0.0131 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.147971 PERT→0.140008 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1464966889, PERT_used=0.1400066096 → LR_next=0.1479707581, PERT_next=0.1400082682\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1464966889→0.1479707581 PERT 0.1400066096→0.1400082682\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.446438 step=0.07582 g_raw=+0.026 g_sm=+0.012 acc=1 | LR→0.148267 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#085 loss=0.444501 step=0.05696 g_raw=+0.018 g_sm=+0.012 acc=1 | LR→0.148565 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#090 loss=0.440287 step=0.04495 g_raw=+0.018 g_sm=+0.012 acc=1 | LR→0.148862 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#095 loss=0.439019 step=0.02714 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.149161 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#100 loss=0.438553 step=0.01068 g_raw=+0.006 g_sm=+0.010 acc=1 | LR→0.149460 PERT→0.140010 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1479707581, PERT_used=0.1400082682 → LR_next=0.1494596160, PERT_next=0.1400098861\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1479707581→0.1494596160 PERT 0.1400082682→0.1400098861\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.434789 step=0.07344 g_raw=+0.029 g_sm=+0.011 acc=1 | LR→0.149759 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#110 loss=0.428512 step=0.02133 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.150059 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#115 loss=0.424589 step=0.05003 g_raw=+0.019 g_sm=+0.013 acc=1 | LR→0.150360 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#120 loss=0.415451 step=0.06811 g_raw=+0.021 g_sm=+0.016 acc=1 | LR→0.150662 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#125 loss=0.413780 step=0.006759 g_raw=+0.002 g_sm=+0.014 acc=1 | LR→0.150964 PERT→0.140012 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1494596160, PERT_used=0.1400098861 → LR_next=0.1509636905, PERT_next=0.1400117228\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1494596160→0.1509636905 PERT 0.1400098861→0.1400117228\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.50\n",
            "[round 1 | client 0] final LR=0.1509636905, final PERT=0.1400117228  (ΔLR=+0.0073704348, ΔPERT=+0.0000076525)\n",
            "[round 1 | client 1] seed LR=0.1435947718 (prev=0.1471895437), seed PERT=0.1400055125 (prev=0.1400110249), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.477950 step=0.03657 g_raw=+0.013 g_sm=+0.003 acc=1 | LR→0.143882 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.474118 step=0.01941 g_raw=+0.007 g_sm=+0.005 acc=1 | LR→0.144170 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.469590 step=0.001788 g_raw=+0.004 g_sm=+0.007 acc=1 | LR→0.144459 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.466251 step=0.05672 g_raw=+0.021 g_sm=+0.009 acc=1 | LR→0.144749 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#025 loss=0.462479 step=0.00284 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.145039 PERT→0.140006 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1435947718, PERT_used=0.1400055125 → LR_next=0.1450387672, PERT_next=0.1400063271\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1435947718→0.1450387672 PERT 0.1400055125→0.1400063271\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.455389 step=0.0201 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.145329 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.453520 step=0.03905 g_raw=+0.016 g_sm=+0.012 acc=1 | LR→0.145621 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#040 loss=0.445635 step=0.08879 g_raw=+0.033 g_sm=+0.014 acc=1 | LR→0.145913 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#045 loss=0.443265 step=0.06211 g_raw=+0.023 g_sm=+0.013 acc=1 | LR→0.146205 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.439775 step=0.01927 g_raw=+0.009 g_sm=+0.014 acc=1 | LR→0.146498 PERT→0.140008 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1450387672, PERT_used=0.1400063271 → LR_next=0.1464982778, PERT_next=0.1400080921\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1450387672→0.1464982778 PERT 0.1400063271→0.1400080921\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.77\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.435802 step=0.003898 g_raw=+0.001 g_sm=+0.014 acc=1 | LR→0.146792 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#060 loss=0.434625 step=7.778e-05 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.147086 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.432886 step=0.01516 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.147381 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.430859 step=0.01523 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.147676 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#075 loss=0.427861 step=0.03035 g_raw=+0.012 g_sm=+0.011 acc=1 | LR→0.147972 PERT→0.140010 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1464982778, PERT_used=0.1400080921 → LR_next=0.1479724140, PERT_next=0.1400097989\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1464982778→0.1479724140 PERT 0.1400080921→0.1400097989\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.81\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.427353 step=0.01895 g_raw=+0.007 g_sm=+0.010 acc=1 | LR→0.148269 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.425426 step=0.04509 g_raw=+0.018 g_sm=+0.010 acc=1 | LR→0.148566 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#090 loss=0.424088 step=0.05387 g_raw=+0.019 g_sm=+0.010 acc=1 | LR→0.148864 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.422804 step=0.02623 g_raw=+0.009 g_sm=+0.009 acc=1 | LR→0.149162 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.421669 step=0.01216 g_raw=+0.004 g_sm=+0.009 acc=1 | LR→0.149461 PERT→0.140011 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1479724140, PERT_used=0.1400097989 → LR_next=0.1494610191, PERT_next=0.1400111644\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1479724140→0.1494610191 PERT 0.1400097989→0.1400111644\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.85\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.419639 step=0.004948 g_raw=+0.003 g_sm=+0.009 acc=1 | LR→0.149761 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#110 loss=0.418508 step=0.03179 g_raw=+0.013 g_sm=+0.009 acc=1 | LR→0.150061 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.415840 step=0.03026 g_raw=+0.011 g_sm=+0.010 acc=1 | LR→0.150361 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.412397 step=0.00471 g_raw=+0.000 g_sm=+0.010 acc=1 | LR→0.150663 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#125 loss=0.411394 step=0.0197 g_raw=+0.004 g_sm=+0.009 acc=1 | LR→0.150965 PERT→0.140013 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1494610191, PERT_used=0.1400111644 → LR_next=0.1509645829, PERT_next=0.1400125144\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1494610191→0.1509645829 PERT 0.1400111644→0.1400125144\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.88\n",
            "[round 1 | client 1] final LR=0.1509645829, final PERT=0.1400125144  (ΔLR=+0.0073698111, ΔPERT=+0.0000070020)\n",
            "[round 1 | client 2] seed LR=0.1435931415 (prev=0.1471862830), seed PERT=0.1400039617 (prev=0.1400079233), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.490354 step=0.02813 g_raw=+0.008 g_sm=+0.001 acc=1 | LR→0.143881 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#010 loss=0.482360 step=0.06632 g_raw=+0.025 g_sm=+0.006 acc=1 | LR→0.144169 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#015 loss=0.476849 step=0.08173 g_raw=+0.030 g_sm=+0.009 acc=1 | LR→0.144458 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#020 loss=0.475221 step=0.01994 g_raw=+0.006 g_sm=+0.009 acc=1 | LR→0.144747 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#025 loss=0.472683 step=0.02162 g_raw=+0.009 g_sm=+0.010 acc=1 | LR→0.145037 PERT→0.140005 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1435931415, PERT_used=0.1400039617 → LR_next=0.1450371661, PERT_next=0.1400048203\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1435931415→0.1450371661 PERT 0.1400039617→0.1400048203\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.471116 step=0.0105 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.145328 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#035 loss=0.468361 step=0.004973 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.145619 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#040 loss=0.464758 step=0.009088 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.145911 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#045 loss=0.459612 step=0.06483 g_raw=+0.027 g_sm=+0.013 acc=1 | LR→0.146203 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#050 loss=0.455531 step=0.06306 g_raw=+0.024 g_sm=+0.013 acc=1 | LR→0.146496 PERT→0.140006 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1450371661, PERT_used=0.1400048203 → LR_next=0.1464963999, PERT_next=0.1400063361\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1450371661→0.1464963999 PERT 0.1400048203→0.1400063361\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.453701 step=0.0342 g_raw=+0.014 g_sm=+0.012 acc=1 | LR→0.146790 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#060 loss=0.449920 step=0.002394 g_raw=-0.001 g_sm=+0.012 acc=1 | LR→0.147084 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#065 loss=0.445316 step=0.03305 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.147379 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#070 loss=0.439908 step=0.07404 g_raw=+0.025 g_sm=+0.014 acc=1 | LR→0.147675 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#075 loss=0.438177 step=0.01146 g_raw=+0.005 g_sm=+0.013 acc=1 | LR→0.147971 PERT→0.140008 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1464963999, PERT_used=0.1400063361 → LR_next=0.1479706242, PERT_next=0.1400081442\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1464963999→0.1479706242 PERT 0.1400063361→0.1400081442\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.74\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.434853 step=0.04465 g_raw=+0.017 g_sm=+0.013 acc=1 | LR→0.148267 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#085 loss=0.433508 step=0.0403 g_raw=+0.015 g_sm=+0.012 acc=1 | LR→0.148564 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#090 loss=0.431028 step=0.06847 g_raw=+0.024 g_sm=+0.012 acc=1 | LR→0.148862 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#095 loss=0.427514 step=0.02863 g_raw=+0.014 g_sm=+0.012 acc=1 | LR→0.149161 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#100 loss=0.425207 step=0.02875 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.149460 PERT→0.140010 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1479706242, PERT_used=0.1400081442 → LR_next=0.1494596181, PERT_next=0.1400098908\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1479706242→0.1494596181 PERT 0.1400081442→0.1400098908\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.79\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.421956 step=0.01397 g_raw=+0.006 g_sm=+0.013 acc=1 | LR→0.149759 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#110 loss=0.416935 step=0.04182 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.150059 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#115 loss=0.415862 step=0.02834 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.150360 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#120 loss=0.412756 step=0.05578 g_raw=+0.024 g_sm=+0.012 acc=1 | LR→0.150662 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#125 loss=0.411154 step=0.01425 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.150964 PERT→0.140012 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1494596181, PERT_used=0.1400098908 → LR_next=0.1509635809, PERT_next=0.1400116239\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1494596181→0.1509635809 PERT 0.1400098908→0.1400116239\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.82\n",
            "[round 1 | client 2] final LR=0.1509635809, final PERT=0.1400116239  (ΔLR=+0.0073704394, ΔPERT=+0.0000076622)\n",
            "[round 1 | client 3] seed LR=0.1435935327 (prev=0.1471870654), seed PERT=0.1400043338 (prev=0.1400086675), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.483355 step=0.03793 g_raw=+0.016 g_sm=+0.003 acc=1 | LR→0.143881 PERT→0.140004 (scale=0.04)\n",
            "[meta] cb#010 loss=0.475253 step=0.1157 g_raw=+0.050 g_sm=+0.007 acc=1 | LR→0.144169 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#015 loss=0.470264 step=0.03172 g_raw=+0.014 g_sm=+0.009 acc=1 | LR→0.144458 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#020 loss=0.464664 step=0.05964 g_raw=+0.022 g_sm=+0.011 acc=1 | LR→0.144748 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#025 loss=0.460837 step=0.06792 g_raw=+0.027 g_sm=+0.012 acc=1 | LR→0.145038 PERT→0.140005 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1435935327, PERT_used=0.1400043338 → LR_next=0.1450376933, PERT_next=0.1400053199\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1435935327→0.1450376933 PERT 0.1400043338→0.1400053199\n",
            "Training Accuracy: 0.56\n",
            "Test Accuracy: 0.47\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.453877 step=0.04217 g_raw=+0.015 g_sm=+0.014 acc=1 | LR→0.145328 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#035 loss=0.446987 step=0.05238 g_raw=+0.021 g_sm=+0.016 acc=1 | LR→0.145620 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#040 loss=0.441678 step=0.05559 g_raw=+0.022 g_sm=+0.016 acc=1 | LR→0.145912 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#045 loss=0.438639 step=0.01529 g_raw=+0.005 g_sm=+0.016 acc=1 | LR→0.146204 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#050 loss=0.435629 step=0.06733 g_raw=+0.029 g_sm=+0.015 acc=1 | LR→0.146498 PERT→0.140007 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1450376933, PERT_used=0.1400053199 → LR_next=0.1464975164, PERT_next=0.1400073938\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1450376933→0.1464975164 PERT 0.1400053199→0.1400073938\n",
            "Training Accuracy: 0.56\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.432288 step=0.02888 g_raw=+0.009 g_sm=+0.015 acc=1 | LR→0.146791 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#060 loss=0.431474 step=0.04265 g_raw=+0.016 g_sm=+0.012 acc=1 | LR→0.147085 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#065 loss=0.430172 step=0.02912 g_raw=+0.012 g_sm=+0.011 acc=1 | LR→0.147380 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.427846 step=0.02058 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.147676 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#075 loss=0.425924 step=0.01581 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.147972 PERT→0.140009 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1464975164, PERT_used=0.1400073938 → LR_next=0.1479717049, PERT_next=0.1400091575\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1464975164→0.1479717049 PERT 0.1400073938→0.1400091575\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.424438 step=0.0449 g_raw=+0.011 g_sm=+0.010 acc=1 | LR→0.148268 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#085 loss=0.421466 step=0.05037 g_raw=+0.018 g_sm=+0.011 acc=1 | LR→0.148565 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#090 loss=0.419671 step=0.06257 g_raw=+0.023 g_sm=+0.010 acc=1 | LR→0.148863 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#095 loss=0.416774 step=0.02757 g_raw=+0.010 g_sm=+0.011 acc=1 | LR→0.149161 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#100 loss=0.413730 step=0.02651 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.149460 PERT→0.140011 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1479717049, PERT_used=0.1400091575 → LR_next=0.1494604078, PERT_next=0.1400106212\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1479717049→0.1494604078 PERT 0.1400091575→0.1400106212\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.63\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.410182 step=0.02279 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.149760 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#110 loss=0.405974 step=0.06165 g_raw=+0.021 g_sm=+0.012 acc=1 | LR→0.150060 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#115 loss=0.405028 step=0.01874 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.150361 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.402051 step=0.008294 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.150662 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#125 loss=0.398310 step=0.03158 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.150964 PERT→0.140012 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1494604078, PERT_used=0.1400106212 → LR_next=0.1509642415, PERT_next=0.1400122273\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1494604078→0.1509642415 PERT 0.1400106212→0.1400122273\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.72\n",
            "[round 1 | client 3] final LR=0.1509642415, final PERT=0.1400122273  (ΔLR=+0.0073707088, ΔPERT=+0.0000078935)\n",
            "[round 1 | client 4] seed LR=0.1435937674 (prev=0.1471875348), seed PERT=0.1400045570 (prev=0.1400091140), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.435208 step=0.06785 g_raw=+0.027 g_sm=+0.003 acc=1 | LR→0.143881 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#010 loss=0.425012 step=0.01689 g_raw=+0.009 g_sm=+0.007 acc=1 | LR→0.144170 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#015 loss=0.423473 step=0.009492 g_raw=+0.004 g_sm=+0.008 acc=1 | LR→0.144458 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#020 loss=0.411462 step=0.09417 g_raw=+0.030 g_sm=+0.011 acc=1 | LR→0.144748 PERT→0.140005 (scale=0.04)\n",
            "[meta] cb#025 loss=0.406350 step=0.01228 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.145038 PERT→0.140006 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1435937674, PERT_used=0.1400045570 → LR_next=0.1450380002, PERT_next=0.1400056106\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1435937674→0.1450380002 PERT 0.1400045570→0.1400056106\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.401886 step=0.02491 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.145329 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#035 loss=0.400767 step=0.003203 g_raw=+0.003 g_sm=+0.012 acc=1 | LR→0.145620 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#040 loss=0.397089 step=0.02291 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.145912 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#045 loss=0.391481 step=0.04602 g_raw=+0.016 g_sm=+0.014 acc=1 | LR→0.146204 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#050 loss=0.388409 step=0.03758 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.146498 PERT→0.140007 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1450380002, PERT_used=0.1400056106 → LR_next=0.1464975595, PERT_next=0.1400074294\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1450380002→0.1464975595 PERT 0.1400056106→0.1400074294\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.386102 step=0.05238 g_raw=+0.017 g_sm=+0.013 acc=1 | LR→0.146791 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#060 loss=0.384162 step=0.03624 g_raw=+0.016 g_sm=+0.012 acc=1 | LR→0.147085 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#065 loss=0.382639 step=0.0217 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.147380 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#070 loss=0.380832 step=0.005219 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.147676 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#075 loss=0.380199 step=0.006391 g_raw=+0.001 g_sm=+0.010 acc=1 | LR→0.147972 PERT→0.140009 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1464975595, PERT_used=0.1400074294 → LR_next=0.1479716581, PERT_next=0.1400091077\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1464975595→0.1479716581 PERT 0.1400074294→0.1400091077\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.376883 step=0.01053 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.148268 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#085 loss=0.376244 step=0.02066 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.148565 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#090 loss=0.371866 step=0.05186 g_raw=+0.016 g_sm=+0.011 acc=1 | LR→0.148863 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#095 loss=0.369430 step=0.01207 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.149161 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#100 loss=0.368233 step=0.04195 g_raw=+0.015 g_sm=+0.010 acc=1 | LR→0.149460 PERT→0.140011 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1479716581, PERT_used=0.1400091077 → LR_next=0.1494603678, PERT_next=0.1400105782\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1479716581→0.1494603678 PERT 0.1400091077→0.1400105782\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.367499 step=0.01663 g_raw=+0.007 g_sm=+0.009 acc=1 | LR→0.149760 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#110 loss=0.367215 step=0.01169 g_raw=+0.007 g_sm=+0.008 acc=1 | LR→0.150060 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#115 loss=0.365931 step=0.002809 g_raw=+0.002 g_sm=+0.008 acc=1 | LR→0.150361 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#120 loss=0.365419 step=0.003824 g_raw=+0.005 g_sm=+0.007 acc=1 | LR→0.150662 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#125 loss=0.364663 step=0.01454 g_raw=+0.004 g_sm=+0.007 acc=1 | LR→0.150964 PERT→0.140012 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1494603678, PERT_used=0.1400105782 → LR_next=0.1509636840, PERT_next=0.1400117046\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.006 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1494603678→0.1509636840 PERT 0.1400105782→0.1400117046\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.68\n",
            "[round 1 | client 4] final LR=0.1509636840, final PERT=0.1400117046  (ΔLR=+0.0073699166, ΔPERT=+0.0000071476)\n",
            "\n",
            "[Round 1] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           1      0.544757      0.875000      0.150965      0.140013\n",
            "           4      0.569172      0.680000      0.150964      0.140012\n",
            "           2      0.571191      0.820000      0.150964      0.140012\n",
            "           3      0.577170      0.725000      0.150964      0.140012\n",
            "           0      0.637300      0.500000      0.150964      0.140012\n",
            "→ [Round 1] best_client=1, best_val=0.544757, prev_global_val=0.543095, improve=-0.001662, action=hold (τ=0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  20%|██        | 2/10 [18:18<1:13:24, 550.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   1] acc_g=0.771 (μ=0.720, σ=0.130, FG=0.281) | t=547.985s, val=0.549 | TEL=FALSE\n",
            "[Round 2] Teleportation OFF | Aggregation=best\n",
            "[round 2 | client 0] seed LR=0.1454818453 (prev=0.1509636905), seed PERT=0.1400058614 (prev=0.1400117228), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.522803 step=0.06445 g_raw=+0.023 g_sm=+0.004 acc=1 | LR→0.145773 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.518119 step=0.01102 g_raw=-0.001 g_sm=+0.006 acc=1 | LR→0.146065 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.513734 step=0.01109 g_raw=+0.005 g_sm=+0.008 acc=1 | LR→0.146358 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.511677 step=0.03366 g_raw=+0.012 g_sm=+0.009 acc=1 | LR→0.146651 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.505963 step=0.009655 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.146945 PERT→0.140007 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1454818453, PERT_used=0.1400058614 → LR_next=0.1469449478, PERT_next=0.1400068006\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1454818453→0.1469449478 PERT 0.1400058614→0.1400068006\n",
            "Training Accuracy: 0.44\n",
            "Test Accuracy: 0.46\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.501874 step=0.02384 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.147239 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.496978 step=0.005916 g_raw=-0.001 g_sm=+0.012 acc=1 | LR→0.147535 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#040 loss=0.495310 step=0.02098 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.147830 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.488502 step=0.02811 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.148127 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.483835 step=0.04567 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.148424 PERT→0.140009 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1469449478, PERT_used=0.1400068006 → LR_next=0.1484236050, PERT_next=0.1400085324\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1469449478→0.1484236050 PERT 0.1400068006→0.1400085324\n",
            "Training Accuracy: 0.48\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.481624 step=0.05356 g_raw=+0.019 g_sm=+0.013 acc=1 | LR→0.148721 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.474930 step=0.01433 g_raw=+0.005 g_sm=+0.015 acc=1 | LR→0.149019 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.466168 step=0.04162 g_raw=+0.015 g_sm=+0.017 acc=1 | LR→0.149318 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.463415 step=0.02073 g_raw=+0.007 g_sm=+0.016 acc=1 | LR→0.149618 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.461761 step=0.03127 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.149918 PERT→0.140011 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1484236050, PERT_used=0.1400085324 → LR_next=0.1499175657, PERT_next=0.1400106605\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1484236050→0.1499175657 PERT 0.1400085324→0.1400106605\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.62\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.458776 step=0.02229 g_raw=+0.009 g_sm=+0.014 acc=1 | LR→0.150218 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.456908 step=0.001138 g_raw=-0.002 g_sm=+0.013 acc=1 | LR→0.150519 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.452376 step=0.06517 g_raw=+0.025 g_sm=+0.013 acc=1 | LR→0.150821 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.448373 step=0.04658 g_raw=+0.018 g_sm=+0.014 acc=1 | LR→0.151123 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.441163 step=0.07736 g_raw=+0.029 g_sm=+0.016 acc=1 | LR→0.151426 PERT→0.140013 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1499175657, PERT_used=0.1400106605 → LR_next=0.1514263622, PERT_next=0.1400126022\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1499175657→0.1514263622 PERT 0.1400106605→0.1400126022\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.438639 step=0.003371 g_raw=+0.003 g_sm=+0.014 acc=1 | LR→0.151730 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#110 loss=0.434536 step=0.05969 g_raw=+0.022 g_sm=+0.015 acc=1 | LR→0.152034 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.429443 step=0.07005 g_raw=+0.028 g_sm=+0.016 acc=1 | LR→0.152339 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#120 loss=0.428477 step=0.03532 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.152644 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#125 loss=0.423062 step=0.01761 g_raw=+0.006 g_sm=+0.014 acc=1 | LR→0.152950 PERT→0.140015 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1514263622, PERT_used=0.1400126022 → LR_next=0.1529504889, PERT_next=0.1400146769\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1514263622→0.1529504889 PERT 0.1400126022→0.1400146769\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.67\n",
            "[round 2 | client 0] final LR=0.1529504889, final PERT=0.1400146769  (ΔLR=+0.0074686436, ΔPERT=+0.0000088155)\n",
            "[round 2 | client 1] seed LR=0.1454822915 (prev=0.1509645829), seed PERT=0.1400062572 (prev=0.1400125144), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.490312 step=0.06919 g_raw=+0.019 g_sm=+0.003 acc=1 | LR→0.145774 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.487912 step=0.03061 g_raw=+0.011 g_sm=+0.005 acc=1 | LR→0.146066 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.486663 step=0.04432 g_raw=+0.020 g_sm=+0.005 acc=1 | LR→0.146358 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.477936 step=0.05397 g_raw=+0.020 g_sm=+0.010 acc=1 | LR→0.146651 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.471458 step=0.01566 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.146945 PERT→0.140007 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1454822915, PERT_used=0.1400062572 → LR_next=0.1469452686, PERT_next=0.1400070726\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1454822915→0.1469452686 PERT 0.1400062572→0.1400070726\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.469937 step=0.03646 g_raw=+0.015 g_sm=+0.011 acc=1 | LR→0.147240 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.467774 step=0.04977 g_raw=+0.018 g_sm=+0.011 acc=1 | LR→0.147535 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.467203 step=0.00986 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.147831 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.457178 step=0.09424 g_raw=+0.037 g_sm=+0.013 acc=1 | LR→0.148127 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.454287 step=0.01838 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.148424 PERT→0.140009 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1469452686, PERT_used=0.1400070726 → LR_next=0.1484237452, PERT_next=0.1400086310\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1469452686→0.1484237452 PERT 0.1400070726→0.1400086310\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.75\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.449687 step=0.06001 g_raw=+0.021 g_sm=+0.013 acc=1 | LR→0.148721 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.445683 step=0.03265 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.149019 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.442189 step=0.03551 g_raw=+0.014 g_sm=+0.014 acc=1 | LR→0.149318 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.437462 step=0.05985 g_raw=+0.023 g_sm=+0.014 acc=1 | LR→0.149618 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.434616 step=0.03911 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.149917 PERT→0.140011 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1484237452, PERT_used=0.1400086310 → LR_next=0.1499174610, PERT_next=0.1400105291\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1484237452→0.1499174610 PERT 0.1400086310→0.1400105291\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.76\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.429721 step=0.05667 g_raw=+0.022 g_sm=+0.014 acc=1 | LR→0.150218 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.424785 step=0.001573 g_raw=+0.001 g_sm=+0.015 acc=1 | LR→0.150519 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.422130 step=0.00178 g_raw=+0.003 g_sm=+0.014 acc=1 | LR→0.150821 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.419256 step=0.0273 g_raw=+0.011 g_sm=+0.013 acc=1 | LR→0.151123 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.418676 step=0.03558 g_raw=+0.013 g_sm=+0.012 acc=1 | LR→0.151426 PERT→0.140012 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1499174610, PERT_used=0.1400105291 → LR_next=0.1514262218, PERT_next=0.1400124387\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1499174610→0.1514262218 PERT 0.1400105291→0.1400124387\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.74\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.416867 step=0.06024 g_raw=+0.021 g_sm=+0.011 acc=1 | LR→0.151730 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#110 loss=0.415973 step=0.009565 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.152034 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.412473 step=0.05524 g_raw=+0.018 g_sm=+0.011 acc=1 | LR→0.152338 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.411481 step=0.009495 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.152644 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#125 loss=0.410144 step=0.03723 g_raw=+0.015 g_sm=+0.010 acc=1 | LR→0.152950 PERT→0.140014 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1514262218, PERT_used=0.1400124387 → LR_next=0.1529496690, PERT_next=0.1400138928\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1514262218→0.1529496690 PERT 0.1400124387→0.1400138928\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.71\n",
            "[round 2 | client 1] final LR=0.1529496690, final PERT=0.1400138928  (ΔLR=+0.0074673776, ΔPERT=+0.0000076355)\n",
            "[round 2 | client 2] seed LR=0.1454817904 (prev=0.1509635809), seed PERT=0.1400058119 (prev=0.1400116239), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.469460 step=0.007227 g_raw=+0.003 g_sm=+0.002 acc=1 | LR→0.145773 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.468839 step=0.01756 g_raw=+0.006 g_sm=+0.003 acc=1 | LR→0.146065 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.467249 step=0.05508 g_raw=+0.022 g_sm=+0.004 acc=1 | LR→0.146358 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.456155 step=0.00469 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.146651 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#025 loss=0.451505 step=0.0319 g_raw=+0.011 g_sm=+0.011 acc=1 | LR→0.146945 PERT→0.140007 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1454817904, PERT_used=0.1400058119 → LR_next=0.1469446574, PERT_next=0.1400065272\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1454817904→0.1469446574 PERT 0.1400058119→0.1400065272\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.60\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.451145 step=0.01018 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.147239 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.450128 step=0.03188 g_raw=+0.012 g_sm=+0.009 acc=1 | LR→0.147534 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#040 loss=0.448902 step=0.02944 g_raw=+0.008 g_sm=+0.009 acc=1 | LR→0.147830 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#045 loss=0.445358 step=0.06244 g_raw=+0.022 g_sm=+0.010 acc=1 | LR→0.148126 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.444324 step=0.03244 g_raw=+0.011 g_sm=+0.009 acc=1 | LR→0.148423 PERT→0.140008 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1469446574, PERT_used=0.1400065272 → LR_next=0.1484228616, PERT_next=0.1400078344\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1469446574→0.1484228616 PERT 0.1400065272→0.1400078344\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.440890 step=0.0568 g_raw=+0.021 g_sm=+0.010 acc=1 | LR→0.148720 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#060 loss=0.437203 step=0.01035 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.149018 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#065 loss=0.435355 step=0.04173 g_raw=+0.017 g_sm=+0.010 acc=1 | LR→0.149317 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.434214 step=0.02596 g_raw=+0.010 g_sm=+0.010 acc=1 | LR→0.149616 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#075 loss=0.430395 step=0.006059 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.149916 PERT→0.140009 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1484228616, PERT_used=0.1400078344 → LR_next=0.1499160276, PERT_next=0.1400092273\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1484228616→0.1499160276 PERT 0.1400078344→0.1400092273\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.76\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.429376 step=0.01469 g_raw=+0.006 g_sm=+0.010 acc=1 | LR→0.150216 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.428722 step=0.01801 g_raw=+0.007 g_sm=+0.009 acc=1 | LR→0.150517 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#090 loss=0.426772 step=0.04653 g_raw=+0.015 g_sm=+0.009 acc=1 | LR→0.150819 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#095 loss=0.426257 step=0.009955 g_raw=+0.002 g_sm=+0.008 acc=1 | LR→0.151121 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#100 loss=0.423080 step=0.03931 g_raw=+0.014 g_sm=+0.010 acc=1 | LR→0.151424 PERT→0.140011 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1499160276, PERT_used=0.1400092273 → LR_next=0.1514240871, PERT_next=0.1400105018\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1499160276→0.1514240871 PERT 0.1400092273→0.1400105018\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.74\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.422292 step=0.001593 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.151728 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#110 loss=0.420490 step=0.01625 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.152032 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#115 loss=0.414214 step=0.02127 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.152336 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#120 loss=0.410299 step=0.01177 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.152642 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#125 loss=0.407972 step=0.02655 g_raw=+0.011 g_sm=+0.011 acc=1 | LR→0.152948 PERT→0.140012 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1514240871, PERT_used=0.1400105018 → LR_next=0.1529475164, PERT_next=0.1400119590\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1514240871→0.1529475164 PERT 0.1400105018→0.1400119590\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.83\n",
            "[round 2 | client 2] final LR=0.1529475164, final PERT=0.1400119590  (ΔLR=+0.0074657259, ΔPERT=+0.0000061471)\n",
            "[round 2 | client 3] seed LR=0.1454821208 (prev=0.1509642415), seed PERT=0.1400061136 (prev=0.1400122273), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.482826 step=0.06092 g_raw=+0.022 g_sm=+0.003 acc=1 | LR→0.145773 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.474515 step=0.01321 g_raw=+0.004 g_sm=+0.007 acc=1 | LR→0.146065 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.467677 step=0.08327 g_raw=+0.030 g_sm=+0.010 acc=1 | LR→0.146358 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.463564 step=0.06995 g_raw=+0.028 g_sm=+0.011 acc=1 | LR→0.146651 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.460846 step=0.0247 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.146945 PERT→0.140007 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1454821208, PERT_used=0.1400061136 → LR_next=0.1469453494, PERT_next=0.1400071703\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1454821208→0.1469453494 PERT 0.1400061136→0.1400071703\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.442386 step=0.07875 g_raw=+0.031 g_sm=+0.016 acc=1 | LR→0.147240 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.436725 step=0.07006 g_raw=+0.022 g_sm=+0.016 acc=1 | LR→0.147535 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.433331 step=0.06811 g_raw=+0.026 g_sm=+0.015 acc=1 | LR→0.147831 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.428836 step=0.0184 g_raw=+0.008 g_sm=+0.015 acc=1 | LR→0.148127 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.421739 step=0.0466 g_raw=+0.016 g_sm=+0.016 acc=1 | LR→0.148424 PERT→0.140009 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1469453494, PERT_used=0.1400071703 → LR_next=0.1484244430, PERT_next=0.1400093099\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1469453494→0.1484244430 PERT 0.1400071703→0.1400093099\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.57\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.416522 step=0.01004 g_raw=+0.004 g_sm=+0.016 acc=1 | LR→0.148722 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.410447 step=0.02734 g_raw=+0.009 g_sm=+0.016 acc=1 | LR→0.149020 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.405959 step=0.05059 g_raw=+0.017 g_sm=+0.016 acc=1 | LR→0.149319 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#070 loss=0.401716 step=0.02768 g_raw=+0.010 g_sm=+0.016 acc=1 | LR→0.149619 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#075 loss=0.397749 step=0.04007 g_raw=+0.013 g_sm=+0.015 acc=1 | LR→0.149919 PERT→0.140012 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1484244430, PERT_used=0.1400093099 → LR_next=0.1499185433, PERT_next=0.1400115606\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1484244430→0.1499185433 PERT 0.1400093099→0.1400115606\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.394990 step=0.04385 g_raw=+0.016 g_sm=+0.014 acc=1 | LR→0.150219 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#085 loss=0.390201 step=0.06831 g_raw=+0.026 g_sm=+0.014 acc=1 | LR→0.150520 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#090 loss=0.388026 step=0.03935 g_raw=+0.017 g_sm=+0.014 acc=1 | LR→0.150822 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#095 loss=0.386441 step=0.01239 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.151124 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#100 loss=0.382333 step=0.1025 g_raw=+0.032 g_sm=+0.013 acc=1 | LR→0.151427 PERT→0.140013 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1499185433, PERT_used=0.1400115606 → LR_next=0.1514272643, PERT_next=0.1400134233\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1499185433→0.1514272643 PERT 0.1400115606→0.1400134233\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.379755 step=0.02963 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.151731 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#110 loss=0.377944 step=0.05883 g_raw=+0.019 g_sm=+0.011 acc=1 | LR→0.152035 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#115 loss=0.376476 step=0.0248 g_raw=+0.008 g_sm=+0.010 acc=1 | LR→0.152340 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#120 loss=0.375737 step=0.004885 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.152645 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#125 loss=0.372433 step=0.03234 g_raw=+0.012 g_sm=+0.010 acc=1 | LR→0.152951 PERT→0.140015 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1514272643, PERT_used=0.1400134233 → LR_next=0.1529507543, PERT_next=0.1400149069\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1514272643→0.1529507543 PERT 0.1400134233→0.1400149069\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.68\n",
            "[round 2 | client 3] final LR=0.1529507543, final PERT=0.1400149069  (ΔLR=+0.0074686335, ΔPERT=+0.0000087933)\n",
            "[round 2 | client 4] seed LR=0.1454818420 (prev=0.1509636840), seed PERT=0.1400058523 (prev=0.1400117046), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.483641 step=0.00767 g_raw=+0.003 g_sm=+0.004 acc=1 | LR→0.145773 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.459908 step=0.1337 g_raw=+0.049 g_sm=+0.011 acc=1 | LR→0.146065 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.446187 step=0.01283 g_raw=+0.004 g_sm=+0.014 acc=1 | LR→0.146358 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.440678 step=0.01603 g_raw=+0.005 g_sm=+0.014 acc=1 | LR→0.146652 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.431473 step=0.00843 g_raw=+0.001 g_sm=+0.016 acc=1 | LR→0.146946 PERT→0.140007 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1454818420, PERT_used=0.1400058523 → LR_next=0.1469455680, PERT_next=0.1400073855\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.023 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1454818420→0.1469455680 PERT 0.1400058523→0.1400073855\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.57\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.421277 step=0.09897 g_raw=+0.038 g_sm=+0.017 acc=1 | LR→0.147240 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.419463 step=0.03743 g_raw=+0.011 g_sm=+0.015 acc=1 | LR→0.147535 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.412006 step=0.1149 g_raw=+0.039 g_sm=+0.016 acc=1 | LR→0.147831 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.411013 step=0.01642 g_raw=+0.004 g_sm=+0.014 acc=1 | LR→0.148128 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.404348 step=0.02478 g_raw=+0.007 g_sm=+0.015 acc=1 | LR→0.148425 PERT→0.140010 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1469455680, PERT_used=0.1400073855 → LR_next=0.1484246925, PERT_next=0.1400095523\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1469455680→0.1484246925 PERT 0.1400073855→0.1400095523\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.57\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.400439 step=0.02117 g_raw=+0.004 g_sm=+0.014 acc=1 | LR→0.148722 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.395432 step=0.03218 g_raw=+0.011 g_sm=+0.015 acc=1 | LR→0.149020 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.393205 step=0.002355 g_raw=+0.003 g_sm=+0.014 acc=1 | LR→0.149319 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#070 loss=0.390813 step=0.002533 g_raw=-0.001 g_sm=+0.013 acc=1 | LR→0.149619 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#075 loss=0.388028 step=0.02143 g_raw=+0.006 g_sm=+0.013 acc=1 | LR→0.149918 PERT→0.140012 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1484246925, PERT_used=0.1400095523 → LR_next=0.1499184986, PERT_next=0.1400115257\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1484246925→0.1499184986 PERT 0.1400095523→0.1400115257\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.57\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.386249 step=0.01348 g_raw=+0.005 g_sm=+0.012 acc=1 | LR→0.150219 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#085 loss=0.383687 step=0.04913 g_raw=+0.018 g_sm=+0.012 acc=1 | LR→0.150520 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#090 loss=0.382727 step=0.02087 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.150822 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#095 loss=0.381413 step=0.02751 g_raw=+0.010 g_sm=+0.010 acc=1 | LR→0.151124 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#100 loss=0.379672 step=0.002283 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.151427 PERT→0.140013 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1499184986, PERT_used=0.1400115257 → LR_next=0.1514268694, PERT_next=0.1400130651\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1499184986→0.1514268694 PERT 0.1400115257→0.1400130651\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.57\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.377232 step=0.00173 g_raw=-0.006 g_sm=+0.009 acc=1 | LR→0.151730 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#110 loss=0.376781 step=0.01988 g_raw=-0.000 g_sm=+0.008 acc=1 | LR→0.152034 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#115 loss=0.374050 step=0.001419 g_raw=-0.002 g_sm=+0.009 acc=1 | LR→0.152339 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#120 loss=0.373264 step=0.02808 g_raw=+0.011 g_sm=+0.008 acc=1 | LR→0.152644 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#125 loss=0.372034 step=0.03604 g_raw=+0.012 g_sm=+0.008 acc=1 | LR→0.152950 PERT→0.140014 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1514268694, PERT_used=0.1400130651 → LR_next=0.1529500786, PERT_next=0.1400142953\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1514268694→0.1529500786 PERT 0.1400130651→0.1400142953\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.57\n",
            "[round 2 | client 4] final LR=0.1529500786, final PERT=0.1400142953  (ΔLR=+0.0074682366, ΔPERT=+0.0000084430)\n",
            "\n",
            "[Round 2] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           2      0.564876      0.830000      0.152948      0.140012\n",
            "           3      0.566898      0.675000      0.152951      0.140015\n",
            "           0      0.588220      0.665000      0.152950      0.140015\n",
            "           1      0.589687      0.710000      0.152950      0.140014\n",
            "           4      0.640890      0.570000      0.152950      0.140014\n",
            "→ [Round 2] best_client=2, best_val=0.564876, prev_global_val=0.548673, improve=-0.016203, action=hold (τ=0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  30%|███       | 3/10 [27:21<1:03:51, 547.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   2] acc_g=0.782 (μ=0.690, σ=0.084, FG=0.174) | t=533.779s, val=0.560 | TEL=FALSE\n",
            "[Round 3] Teleportation OFF | Aggregation=best\n",
            "[round 3 | client 0] seed LR=0.1464752445 (prev=0.1529504889), seed PERT=0.1400073385 (prev=0.1400146769), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.521531 step=0.03438 g_raw=+0.011 g_sm=+0.002 acc=1 | LR→0.146769 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.518907 step=0.05999 g_raw=+0.022 g_sm=+0.004 acc=1 | LR→0.147062 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.511852 step=0.03943 g_raw=+0.016 g_sm=+0.008 acc=1 | LR→0.147357 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.497307 step=0.1283 g_raw=+0.053 g_sm=+0.013 acc=1 | LR→0.147652 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.494876 step=0.03223 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.147948 PERT→0.140008 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1464752445, PERT_used=0.1400073385 → LR_next=0.1479483765, PERT_next=0.1400083145\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1464752445→0.1479483765 PERT 0.1400073385→0.1400083145\n",
            "Training Accuracy: 0.56\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.490373 step=0.01678 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.148245 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.486245 step=0.06916 g_raw=+0.027 g_sm=+0.014 acc=1 | LR→0.148542 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.477311 step=0.06519 g_raw=+0.024 g_sm=+0.016 acc=1 | LR→0.148840 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#045 loss=0.471819 step=0.0088 g_raw=+0.005 g_sm=+0.016 acc=1 | LR→0.149138 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.465825 step=0.007303 g_raw=+0.004 g_sm=+0.016 acc=1 | LR→0.149438 PERT→0.140010 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1479483765, PERT_used=0.1400083145 → LR_next=0.1494375165, PERT_next=0.1400104076\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1479483765→0.1494375165 PERT 0.1400083145→0.1400104076\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.83\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.461418 step=0.08911 g_raw=+0.035 g_sm=+0.016 acc=1 | LR→0.149737 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#060 loss=0.456186 step=0.06471 g_raw=+0.023 g_sm=+0.017 acc=1 | LR→0.150037 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.454278 step=0.02059 g_raw=+0.006 g_sm=+0.015 acc=1 | LR→0.150338 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#070 loss=0.449096 step=0.009068 g_raw=+0.005 g_sm=+0.015 acc=1 | LR→0.150640 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#075 loss=0.448180 step=0.00207 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.150942 PERT→0.140013 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1494375165, PERT_used=0.1400104076 → LR_next=0.1509417306, PERT_next=0.1400125801\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1494375165→0.1509417306 PERT 0.1400104076→0.1400125801\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.86\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.440533 step=0.001857 g_raw=+0.000 g_sm=+0.014 acc=1 | LR→0.151244 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#085 loss=0.434416 step=0.1084 g_raw=+0.043 g_sm=+0.015 acc=1 | LR→0.151548 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#090 loss=0.432930 step=0.03651 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.151851 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#095 loss=0.430537 step=0.01999 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.152156 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#100 loss=0.424754 step=0.05383 g_raw=+0.020 g_sm=+0.014 acc=1 | LR→0.152461 PERT→0.140014 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1509417306, PERT_used=0.1400125801 → LR_next=0.1524607792, PERT_next=0.1400144710\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1509417306→0.1524607792 PERT 0.1400125801→0.1400144710\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.84\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.422258 step=0.006852 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.152766 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#110 loss=0.417740 step=0.05305 g_raw=+0.024 g_sm=+0.014 acc=1 | LR→0.153073 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#115 loss=0.413872 step=0.03295 g_raw=+0.012 g_sm=+0.014 acc=1 | LR→0.153380 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#120 loss=0.412353 step=0.0331 g_raw=+0.012 g_sm=+0.013 acc=1 | LR→0.153687 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#125 loss=0.410186 step=0.03939 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.153995 PERT→0.140016 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1524607792, PERT_used=0.1400144710 → LR_next=0.1539950916, PERT_next=0.1400163405\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1524607792→0.1539950916 PERT 0.1400144710→0.1400163405\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.83\n",
            "[round 3 | client 0] final LR=0.1539950916, final PERT=0.1400163405  (ΔLR=+0.0075198471, ΔPERT=+0.0000090020)\n",
            "[round 3 | client 1] seed LR=0.1464748345 (prev=0.1529496690), seed PERT=0.1400069464 (prev=0.1400138928), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.446317 step=0.05627 g_raw=+0.024 g_sm=+0.005 acc=1 | LR→0.146768 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.444082 step=0.03865 g_raw=+0.015 g_sm=+0.006 acc=1 | LR→0.147062 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.437613 step=0.06622 g_raw=+0.022 g_sm=+0.009 acc=1 | LR→0.147357 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.422342 step=0.05601 g_raw=+0.022 g_sm=+0.013 acc=1 | LR→0.147652 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.421067 step=0.001315 g_raw=+0.002 g_sm=+0.012 acc=1 | LR→0.147948 PERT→0.140008 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1464748345, PERT_used=0.1400069464 → LR_next=0.1479481444, PERT_next=0.1400080946\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1464748345→0.1479481444 PERT 0.1400069464→0.1400080946\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.74\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.415430 step=0.02341 g_raw=+0.008 g_sm=+0.013 acc=1 | LR→0.148245 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.413810 step=0.05238 g_raw=+0.014 g_sm=+0.012 acc=1 | LR→0.148542 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.412323 step=0.04204 g_raw=+0.015 g_sm=+0.012 acc=1 | LR→0.148840 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.404396 step=0.07805 g_raw=+0.027 g_sm=+0.014 acc=1 | LR→0.149138 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.399575 step=0.07277 g_raw=+0.024 g_sm=+0.015 acc=1 | LR→0.149437 PERT→0.140010 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1479481444, PERT_used=0.1400080946 → LR_next=0.1494369852, PERT_next=0.1400099096\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1479481444→0.1494369852 PERT 0.1400080946→0.1400099096\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.73\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.397989 step=0.06078 g_raw=+0.020 g_sm=+0.013 acc=1 | LR→0.149737 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.395037 step=0.02674 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.150037 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.391378 step=0.05573 g_raw=+0.018 g_sm=+0.013 acc=1 | LR→0.150337 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#070 loss=0.390354 step=0.0299 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.150639 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#075 loss=0.389522 step=0.0235 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.150941 PERT→0.140012 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1494369852, PERT_used=0.1400099096 → LR_next=0.1509407684, PERT_next=0.1400116873\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1494369852→0.1509407684 PERT 0.1400099096→0.1400116873\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.388624 step=0.004925 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.151243 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#085 loss=0.386267 step=0.0628 g_raw=+0.020 g_sm=+0.010 acc=1 | LR→0.151546 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#090 loss=0.385728 step=0.003559 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.151850 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#095 loss=0.385322 step=0.01087 g_raw=+0.001 g_sm=+0.008 acc=1 | LR→0.152154 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#100 loss=0.384662 step=0.005277 g_raw=+0.004 g_sm=+0.008 acc=1 | LR→0.152459 PERT→0.140013 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1509407684, PERT_used=0.1400116873 → LR_next=0.1524591435, PERT_next=0.1400129686\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1509407684→0.1524591435 PERT 0.1400116873→0.1400129686\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.384278 step=0.01726 g_raw=+0.005 g_sm=+0.007 acc=1 | LR→0.152765 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#110 loss=0.384243 step=0.006592 g_raw=+0.002 g_sm=+0.006 acc=1 | LR→0.153071 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.384224 step=0.006871 g_raw=+0.003 g_sm=+0.004 acc=1 | LR→0.153377 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.383895 step=0.012 g_raw=-0.000 g_sm=+0.004 acc=1 | LR→0.153684 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#125 loss=0.383304 step=0.006991 g_raw=+0.003 g_sm=+0.005 acc=1 | LR→0.153992 PERT→0.140014 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1524591435, PERT_used=0.1400129686 → LR_next=0.1539922089, PERT_next=0.1400137192\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.003 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1524591435→0.1539922089 PERT 0.1400129686→0.1400137192\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.70\n",
            "[round 3 | client 1] final LR=0.1539922089, final PERT=0.1400137192  (ΔLR=+0.0075173744, ΔPERT=+0.0000067729)\n",
            "[round 3 | client 2] seed LR=0.1464737582 (prev=0.1529475164), seed PERT=0.1400059795 (prev=0.1400119590), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.506802 step=0.01648 g_raw=+0.003 g_sm=+0.001 acc=1 | LR→0.146767 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.501237 step=0.01076 g_raw=+0.005 g_sm=+0.005 acc=1 | LR→0.147061 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.499450 step=0.02815 g_raw=+0.011 g_sm=+0.006 acc=1 | LR→0.147356 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.487341 step=0.1196 g_raw=+0.043 g_sm=+0.011 acc=1 | LR→0.147651 PERT→0.140006 (scale=0.04)\n",
            "[meta] cb#025 loss=0.478426 step=0.04826 g_raw=+0.021 g_sm=+0.012 acc=1 | LR→0.147947 PERT→0.140007 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1464737582, PERT_used=0.1400059795 → LR_next=0.1479467482, PERT_next=0.1400068353\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1464737582→0.1479467482 PERT 0.1400059795→0.1400068353\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.65\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.477205 step=0.01608 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.148243 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.464699 step=0.1435 g_raw=+0.053 g_sm=+0.014 acc=1 | LR→0.148540 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.461085 step=0.05835 g_raw=+0.023 g_sm=+0.015 acc=1 | LR→0.148838 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.458956 step=0.01834 g_raw=+0.006 g_sm=+0.013 acc=1 | LR→0.149137 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.455108 step=0.04636 g_raw=+0.015 g_sm=+0.014 acc=1 | LR→0.149436 PERT→0.140009 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1479467482, PERT_used=0.1400068353 → LR_next=0.1494356399, PERT_next=0.1400087111\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1479467482→0.1494356399 PERT 0.1400068353→0.1400087111\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.81\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.448359 step=0.001015 g_raw=+0.000 g_sm=+0.015 acc=1 | LR→0.149735 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.444470 step=0.02263 g_raw=+0.009 g_sm=+0.015 acc=1 | LR→0.150035 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.439055 step=0.1102 g_raw=+0.039 g_sm=+0.015 acc=1 | LR→0.150336 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.435374 step=0.02889 g_raw=+0.009 g_sm=+0.014 acc=1 | LR→0.150638 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.433447 step=0.0479 g_raw=+0.018 g_sm=+0.014 acc=1 | LR→0.150940 PERT→0.140011 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1494356399, PERT_used=0.1400087111 → LR_next=0.1509396577, PERT_next=0.1400107190\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1494356399→0.1509396577 PERT 0.1400087111→0.1400107190\n",
            "Training Accuracy: 0.96\n",
            "Test Accuracy: 0.98\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.432272 step=0.01438 g_raw=+0.005 g_sm=+0.012 acc=1 | LR→0.151242 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.428068 step=0.08334 g_raw=+0.032 g_sm=+0.013 acc=1 | LR→0.151545 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.417154 step=0.02503 g_raw=+0.012 g_sm=+0.015 acc=1 | LR→0.151849 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.410392 step=0.01669 g_raw=+0.007 g_sm=+0.016 acc=1 | LR→0.152154 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.407331 step=0.007159 g_raw=+0.003 g_sm=+0.015 acc=1 | LR→0.152459 PERT→0.140013 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1509396577, PERT_used=0.1400107190 → LR_next=0.1524587612, PERT_next=0.1400126795\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1509396577→0.1524587612 PERT 0.1400107190→0.1400126795\n",
            "Training Accuracy: 0.96\n",
            "Test Accuracy: 0.95\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.402154 step=0.08158 g_raw=+0.027 g_sm=+0.015 acc=1 | LR→0.152764 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#110 loss=0.399532 step=0.04538 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.153071 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.395798 step=0.03841 g_raw=+0.012 g_sm=+0.015 acc=1 | LR→0.153378 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#120 loss=0.394260 step=0.04656 g_raw=+0.014 g_sm=+0.013 acc=1 | LR→0.153685 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#125 loss=0.393318 step=0.004756 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.153993 PERT→0.140015 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1524587612, PERT_used=0.1400126795 → LR_next=0.1539931273, PERT_next=0.1400146162\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1524587612→0.1539931273 PERT 0.1400126795→0.1400146162\n",
            "Training Accuracy: 0.96\n",
            "Test Accuracy: 0.91\n",
            "[round 3 | client 2] final LR=0.1539931273, final PERT=0.1400146162  (ΔLR=+0.0075193691, ΔPERT=+0.0000086367)\n",
            "[round 3 | client 3] seed LR=0.1464753771 (prev=0.1529507543), seed PERT=0.1400074535 (prev=0.1400149069), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.531583 step=0.03956 g_raw=+0.013 g_sm=+0.002 acc=1 | LR→0.146769 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.521514 step=0.1355 g_raw=+0.047 g_sm=+0.006 acc=1 | LR→0.147063 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.518771 step=0.06452 g_raw=+0.028 g_sm=+0.007 acc=1 | LR→0.147357 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.515689 step=0.01426 g_raw=+0.006 g_sm=+0.009 acc=1 | LR→0.147652 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.513062 step=0.04124 g_raw=+0.014 g_sm=+0.009 acc=1 | LR→0.147948 PERT→0.140008 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1464753771, PERT_used=0.1400074535 → LR_next=0.1479483211, PERT_next=0.1400082502\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1464753771→0.1479483211 PERT 0.1400074535→0.1400082502\n",
            "Training Accuracy: 0.48\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.509722 step=0.05261 g_raw=+0.027 g_sm=+0.010 acc=1 | LR→0.148245 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.493379 step=0.145 g_raw=+0.055 g_sm=+0.015 acc=1 | LR→0.148542 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.490524 step=0.02309 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.148840 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.486497 step=0.06422 g_raw=+0.023 g_sm=+0.014 acc=1 | LR→0.149138 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.484558 step=0.01443 g_raw=+0.004 g_sm=+0.014 acc=1 | LR→0.149437 PERT→0.140010 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1479483211, PERT_used=0.1400082502 → LR_next=0.1494371848, PERT_next=0.1400100851\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1479483211→0.1494371848 PERT 0.1400082502→0.1400100851\n",
            "Training Accuracy: 0.50\n",
            "Test Accuracy: 0.57\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.480178 step=0.05388 g_raw=+0.018 g_sm=+0.014 acc=1 | LR→0.149737 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.479294 step=0.01665 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.150037 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.474941 step=0.007605 g_raw=+0.003 g_sm=+0.013 acc=1 | LR→0.150338 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#070 loss=0.470140 step=0.02058 g_raw=+0.006 g_sm=+0.014 acc=1 | LR→0.150639 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#075 loss=0.461873 step=0.1061 g_raw=+0.037 g_sm=+0.015 acc=1 | LR→0.150941 PERT→0.140012 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1494371848, PERT_used=0.1400100851 → LR_next=0.1509411419, PERT_next=0.1400120222\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1494371848→0.1509411419 PERT 0.1400100851→0.1400120222\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.458620 step=0.04565 g_raw=+0.018 g_sm=+0.015 acc=1 | LR→0.151244 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#085 loss=0.455346 step=0.0425 g_raw=+0.014 g_sm=+0.014 acc=1 | LR→0.151547 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#090 loss=0.451757 step=0.07533 g_raw=+0.025 g_sm=+0.014 acc=1 | LR→0.151851 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#095 loss=0.447252 step=0.02706 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.152155 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#100 loss=0.441005 step=0.0193 g_raw=+0.008 g_sm=+0.015 acc=1 | LR→0.152460 PERT→0.140014 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1509411419, PERT_used=0.1400120222 → LR_next=0.1524603725, PERT_next=0.1400140858\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1509411419→0.1524603725 PERT 0.1400120222→0.1400140858\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.60\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.437437 step=0.07623 g_raw=+0.027 g_sm=+0.015 acc=1 | LR→0.152766 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#110 loss=0.434149 step=0.05419 g_raw=+0.020 g_sm=+0.014 acc=1 | LR→0.153072 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#115 loss=0.426725 step=0.1167 g_raw=+0.041 g_sm=+0.015 acc=1 | LR→0.153379 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#120 loss=0.419993 step=0.06051 g_raw=+0.021 g_sm=+0.016 acc=1 | LR→0.153687 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#125 loss=0.417759 step=0.01483 g_raw=+0.000 g_sm=+0.014 acc=1 | LR→0.153995 PERT→0.140016 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1524603725, PERT_used=0.1400140858 → LR_next=0.1539949054, PERT_next=0.1400161594\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1524603725→0.1539949054 PERT 0.1400140858→0.1400161594\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.61\n",
            "[round 3 | client 3] final LR=0.1539949054, final PERT=0.1400161594  (ΔLR=+0.0075195283, ΔPERT=+0.0000087060)\n",
            "[round 3 | client 4] seed LR=0.1464750393 (prev=0.1529500786), seed PERT=0.1400071477 (prev=0.1400142953), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.496031 step=0.07352 g_raw=+0.026 g_sm=+0.004 acc=1 | LR→0.146768 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.492421 step=0.02555 g_raw=+0.010 g_sm=+0.006 acc=1 | LR→0.147062 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.487352 step=0.0527 g_raw=+0.017 g_sm=+0.009 acc=1 | LR→0.147357 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.477815 step=0.09151 g_raw=+0.035 g_sm=+0.013 acc=1 | LR→0.147652 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.473339 step=0.04133 g_raw=+0.017 g_sm=+0.014 acc=1 | LR→0.147948 PERT→0.140008 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1464750393, PERT_used=0.1400071477 → LR_next=0.1479483172, PERT_next=0.1400082636\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1464750393→0.1479483172 PERT 0.1400071477→0.1400082636\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.467364 step=0.09834 g_raw=+0.041 g_sm=+0.015 acc=1 | LR→0.148245 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.462834 step=0.02177 g_raw=+0.008 g_sm=+0.015 acc=1 | LR→0.148542 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.456576 step=0.103 g_raw=+0.037 g_sm=+0.015 acc=1 | LR→0.148840 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.451886 step=0.03028 g_raw=+0.013 g_sm=+0.016 acc=1 | LR→0.149138 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.448245 step=0.05349 g_raw=+0.019 g_sm=+0.015 acc=1 | LR→0.149437 PERT→0.140010 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1479483172, PERT_used=0.1400082636 → LR_next=0.1494374380, PERT_next=0.1400103394\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1479483172→0.1494374380 PERT 0.1400082636→0.1400103394\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.441617 step=0.07213 g_raw=+0.029 g_sm=+0.016 acc=1 | LR→0.149737 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#060 loss=0.437704 step=0.05182 g_raw=+0.016 g_sm=+0.016 acc=1 | LR→0.150037 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.433076 step=0.03655 g_raw=+0.012 g_sm=+0.016 acc=1 | LR→0.150338 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#070 loss=0.431383 step=0.01527 g_raw=+0.005 g_sm=+0.014 acc=1 | LR→0.150640 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#075 loss=0.429546 step=0.01909 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.150942 PERT→0.140012 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1494374380, PERT_used=0.1400103394 → LR_next=0.1509415882, PERT_next=0.1400124533\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1494374380→0.1509415882 PERT 0.1400103394→0.1400124533\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.424800 step=0.023 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.151244 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#085 loss=0.423684 step=0.03315 g_raw=+0.016 g_sm=+0.012 acc=1 | LR→0.151547 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#090 loss=0.420907 step=0.02143 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.151851 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#095 loss=0.419356 step=0.01532 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.152155 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#100 loss=0.417970 step=0.02916 g_raw=+0.013 g_sm=+0.011 acc=1 | LR→0.152460 PERT→0.140014 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1509415882, PERT_used=0.1400124533 → LR_next=0.1524604154, PERT_next=0.1400141423\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1509415882→0.1524604154 PERT 0.1400124533→0.1400141423\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.76\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.415405 step=0.01751 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.152766 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#110 loss=0.412966 step=0.004279 g_raw=-0.002 g_sm=+0.010 acc=1 | LR→0.153072 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#115 loss=0.411528 step=0.00655 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.153379 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#120 loss=0.408240 step=0.007107 g_raw=+0.001 g_sm=+0.010 acc=1 | LR→0.153686 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#125 loss=0.405048 step=0.006144 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.153994 PERT→0.140016 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1524604154, PERT_used=0.1400141423 → LR_next=0.1539943017, PERT_next=0.1400156276\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1524604154→0.1539943017 PERT 0.1400141423→0.1400156276\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.75\n",
            "[round 3 | client 4] final LR=0.1539943017, final PERT=0.1400156276  (ΔLR=+0.0075192624, ΔPERT=+0.0000084799)\n",
            "\n",
            "[Round 3] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           2      0.522444      0.910000      0.153993      0.140015\n",
            "           0      0.545055      0.835000      0.153995      0.140016\n",
            "           4      0.555796      0.750000      0.153994      0.140016\n",
            "           1      0.557890      0.700000      0.153992      0.140014\n",
            "           3      0.622492      0.610000      0.153995      0.140016\n",
            "→ [Round 3] best_client=2, best_val=0.522444, prev_global_val=0.559884, improve=+0.037440, action=adopt+mix τ=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  40%|████      | 4/10 [36:29<54:46, 547.69s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   3] acc_g=0.771 (μ=0.761, σ=0.104, FG=0.234) | t=538.205s, val=0.581 | TEL=FALSE\n",
            "[Round 4] Teleportation OFF | Aggregation=best\n",
            "[round 4 | client 0] seed LR=0.1469975458 (prev=0.1539950916), seed PERT=0.1400081702 (prev=0.1400163405), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.480175 step=0.01374 g_raw=+0.005 g_sm=+0.001 acc=1 | LR→0.147292 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.472683 step=0.02096 g_raw=+0.008 g_sm=+0.005 acc=1 | LR→0.147587 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.468686 step=0.04812 g_raw=+0.017 g_sm=+0.008 acc=1 | LR→0.147882 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.462905 step=0.08201 g_raw=+0.031 g_sm=+0.010 acc=1 | LR→0.148179 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#025 loss=0.456340 step=0.00751 g_raw=+0.003 g_sm=+0.012 acc=1 | LR→0.148476 PERT→0.140009 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1469975458, PERT_used=0.1400081702 → LR_next=0.1484758096, PERT_next=0.1400090320\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1469975458→0.1484758096 PERT 0.1400081702→0.1400090320\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.81\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.454184 step=0.004947 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.148773 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.452781 step=0.003198 g_raw=+0.001 g_sm=+0.011 acc=1 | LR→0.149072 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#040 loss=0.448705 step=0.042 g_raw=+0.012 g_sm=+0.011 acc=1 | LR→0.149370 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#045 loss=0.442050 step=0.03985 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.149670 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.440201 step=0.04736 g_raw=+0.015 g_sm=+0.012 acc=1 | LR→0.149970 PERT→0.140011 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1484758096, PERT_used=0.1400090320 → LR_next=0.1499697903, PERT_next=0.1400106882\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1484758096→0.1499697903 PERT 0.1400090320→0.1400106882\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.81\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.434823 step=0.01039 g_raw=+0.007 g_sm=+0.014 acc=1 | LR→0.150270 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#060 loss=0.429067 step=0.01273 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.150572 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.425263 step=0.07111 g_raw=+0.023 g_sm=+0.014 acc=1 | LR→0.150874 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#070 loss=0.421555 step=0.03068 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.151176 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#075 loss=0.419644 step=0.03929 g_raw=+0.014 g_sm=+0.012 acc=1 | LR→0.151479 PERT→0.140013 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1499697903, PERT_used=0.1400106882 → LR_next=0.1514790648, PERT_next=0.1400125859\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1499697903→0.1514790648 PERT 0.1400106882→0.1400125859\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.74\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.415417 step=0.02372 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.151783 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#085 loss=0.415264 step=0.004874 g_raw=-0.001 g_sm=+0.011 acc=1 | LR→0.152087 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#090 loss=0.414164 step=0.01142 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.152392 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#095 loss=0.410362 step=0.05972 g_raw=+0.020 g_sm=+0.011 acc=1 | LR→0.152697 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#100 loss=0.408661 step=0.04463 g_raw=+0.015 g_sm=+0.011 acc=1 | LR→0.153003 PERT→0.140014 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1514790648, PERT_used=0.1400125859 → LR_next=0.1530032395, PERT_next=0.1400142191\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1514790648→0.1530032395 PERT 0.1400125859→0.1400142191\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.85\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.407811 step=0.01273 g_raw=+0.006 g_sm=+0.010 acc=1 | LR→0.153310 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#110 loss=0.407093 step=0.02176 g_raw=+0.009 g_sm=+0.009 acc=1 | LR→0.153617 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#115 loss=0.403368 step=0.03527 g_raw=+0.012 g_sm=+0.010 acc=1 | LR→0.153925 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#120 loss=0.401791 step=0.02231 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.154233 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#125 loss=0.401178 step=0.02227 g_raw=+0.012 g_sm=+0.009 acc=1 | LR→0.154542 PERT→0.140016 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1530032395, PERT_used=0.1400142191 → LR_next=0.1545424864, PERT_next=0.1400156133\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1530032395→0.1545424864 PERT 0.1400142191→0.1400156133\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.86\n",
            "[round 4 | client 0] final LR=0.1545424864, final PERT=0.1400156133  (ΔLR=+0.0075449406, ΔPERT=+0.0000074431)\n",
            "[round 4 | client 1] seed LR=0.1469961045 (prev=0.1539922089), seed PERT=0.1400068596 (prev=0.1400137192), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.508026 step=0.03095 g_raw=+0.015 g_sm=+0.002 acc=1 | LR→0.147290 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.505073 step=0.0367 g_raw=+0.012 g_sm=+0.005 acc=1 | LR→0.147585 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.502094 step=0.03102 g_raw=+0.011 g_sm=+0.006 acc=1 | LR→0.147881 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.497213 step=0.001538 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.148177 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.489466 step=0.09858 g_raw=+0.035 g_sm=+0.012 acc=1 | LR→0.148474 PERT→0.140008 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1469961045, PERT_used=0.1400068596 → LR_next=0.1484743209, PERT_next=0.1400076904\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1469961045→0.1484743209 PERT 0.1400068596→0.1400076904\n",
            "Training Accuracy: 0.50\n",
            "Test Accuracy: 0.57\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.487529 step=0.05528 g_raw=+0.023 g_sm=+0.011 acc=1 | LR→0.148772 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.482815 step=0.01329 g_raw=+0.005 g_sm=+0.013 acc=1 | LR→0.149070 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.477495 step=0.04105 g_raw=+0.015 g_sm=+0.014 acc=1 | LR→0.149369 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.468309 step=0.01562 g_raw=+0.007 g_sm=+0.015 acc=1 | LR→0.149668 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.465967 step=0.02848 g_raw=+0.007 g_sm=+0.014 acc=1 | LR→0.149969 PERT→0.140010 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1484743209, PERT_used=0.1400076904 → LR_next=0.1499685351, PERT_next=0.1400095786\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1484743209→0.1499685351 PERT 0.1400076904→0.1400095786\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.462223 step=0.01064 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.150269 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.457491 step=0.06709 g_raw=+0.023 g_sm=+0.014 acc=1 | LR→0.150570 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.454963 step=0.02208 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.150872 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#070 loss=0.453801 step=0.0373 g_raw=+0.013 g_sm=+0.012 acc=1 | LR→0.151175 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#075 loss=0.446104 step=0.1072 g_raw=+0.037 g_sm=+0.014 acc=1 | LR→0.151478 PERT→0.140011 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1499685351, PERT_used=0.1400095786 → LR_next=0.1514777722, PERT_next=0.1400114533\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1499685351→0.1514777722 PERT 0.1400095786→0.1400114533\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.65\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.441328 step=0.07573 g_raw=+0.026 g_sm=+0.014 acc=1 | LR→0.151781 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#085 loss=0.436254 step=0.003955 g_raw=+0.001 g_sm=+0.015 acc=1 | LR→0.152086 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#090 loss=0.434427 step=0.03744 g_raw=+0.016 g_sm=+0.014 acc=1 | LR→0.152391 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#095 loss=0.431962 step=0.009348 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.152696 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#100 loss=0.430185 step=0.04768 g_raw=+0.018 g_sm=+0.012 acc=1 | LR→0.153002 PERT→0.140013 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1514777722, PERT_used=0.1400114533 → LR_next=0.1530022538, PERT_next=0.1400133793\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1514777722→0.1530022538 PERT 0.1400114533→0.1400133793\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.426825 step=0.007448 g_raw=+0.003 g_sm=+0.012 acc=1 | LR→0.153309 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#110 loss=0.426024 step=0.01106 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.153616 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#115 loss=0.425533 step=0.005334 g_raw=+0.006 g_sm=+0.009 acc=1 | LR→0.153924 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#120 loss=0.424891 step=0.003125 g_raw=+0.001 g_sm=+0.008 acc=1 | LR→0.154232 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#125 loss=0.423937 step=0.02211 g_raw=+0.009 g_sm=+0.008 acc=1 | LR→0.154542 PERT→0.140015 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1530022538, PERT_used=0.1400133793 → LR_next=0.1545415004, PERT_next=0.1400147822\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1530022538→0.1545415004 PERT 0.1400133793→0.1400147822\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.77\n",
            "[round 4 | client 1] final LR=0.1545415004, final PERT=0.1400147822  (ΔLR=+0.0075453960, ΔPERT=+0.0000079226)\n",
            "[round 4 | client 2] seed LR=0.1469965636 (prev=0.1539931273), seed PERT=0.1400073081 (prev=0.1400146162), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.510680 step=0.02951 g_raw=+0.009 g_sm=+0.004 acc=1 | LR→0.147291 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.500432 step=0.1179 g_raw=+0.045 g_sm=+0.009 acc=1 | LR→0.147586 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.493380 step=0.03564 g_raw=+0.014 g_sm=+0.011 acc=1 | LR→0.147882 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.478305 step=0.05714 g_raw=+0.025 g_sm=+0.014 acc=1 | LR→0.148178 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.464365 step=0.1822 g_raw=+0.065 g_sm=+0.016 acc=1 | LR→0.148475 PERT→0.140009 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1469965636, PERT_used=0.1400073081 → LR_next=0.1484752850, PERT_next=0.1400086107\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.022 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1469965636→0.1484752850 PERT 0.1400073081→0.1400086107\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.451322 step=0.07587 g_raw=+0.027 g_sm=+0.019 acc=1 | LR→0.148773 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.446048 step=0.006318 g_raw=+0.007 g_sm=+0.019 acc=1 | LR→0.149071 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#040 loss=0.441801 step=0.0569 g_raw=+0.023 g_sm=+0.017 acc=1 | LR→0.149370 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#045 loss=0.434691 step=0.1093 g_raw=+0.037 g_sm=+0.018 acc=1 | LR→0.149670 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#050 loss=0.431619 step=0.004967 g_raw=-0.000 g_sm=+0.016 acc=1 | LR→0.149970 PERT→0.140011 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1484752850, PERT_used=0.1400086107 → LR_next=0.1499701767, PERT_next=0.1400111222\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1484752850→0.1499701767 PERT 0.1400086107→0.1400111222\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.426124 step=0.08981 g_raw=+0.031 g_sm=+0.016 acc=1 | LR→0.150271 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#060 loss=0.425426 step=0.009313 g_raw=+0.002 g_sm=+0.014 acc=1 | LR→0.150572 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#065 loss=0.424471 step=0.004365 g_raw=+0.002 g_sm=+0.012 acc=1 | LR→0.150874 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#070 loss=0.423015 step=0.01967 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.151176 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#075 loss=0.418601 step=0.01099 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.151479 PERT→0.140013 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1499701767, PERT_used=0.1400111222 → LR_next=0.1514794727, PERT_next=0.1400130362\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1499701767→0.1514794727 PERT 0.1400111222→0.1400130362\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.58\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.417300 step=0.007831 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.151783 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#085 loss=0.414373 step=0.03626 g_raw=+0.013 g_sm=+0.011 acc=1 | LR→0.152087 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#090 loss=0.411129 step=0.006278 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.152392 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#095 loss=0.409446 step=0.002387 g_raw=-0.001 g_sm=+0.011 acc=1 | LR→0.152698 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#100 loss=0.404945 step=0.05552 g_raw=+0.021 g_sm=+0.012 acc=1 | LR→0.153004 PERT→0.140015 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1514794727, PERT_used=0.1400130362 → LR_next=0.1530035888, PERT_next=0.1400146121\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1514794727→0.1530035888 PERT 0.1400130362→0.1400146121\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.55\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.401581 step=0.05212 g_raw=+0.016 g_sm=+0.012 acc=1 | LR→0.153310 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#110 loss=0.398955 step=0.001316 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.153618 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#115 loss=0.396216 step=0.000966 g_raw=-0.002 g_sm=+0.011 acc=1 | LR→0.153925 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#120 loss=0.395192 step=0.03395 g_raw=+0.012 g_sm=+0.010 acc=1 | LR→0.154234 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#125 loss=0.393045 step=0.0172 g_raw=+0.010 g_sm=+0.011 acc=1 | LR→0.154543 PERT→0.140016 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1530035888, PERT_used=0.1400146121 → LR_next=0.1545430481, PERT_next=0.1400161955\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1530035888→0.1545430481 PERT 0.1400146121→0.1400161955\n",
            "Training Accuracy: 0.56\n",
            "Test Accuracy: 0.53\n",
            "[round 4 | client 2] final LR=0.1545430481, final PERT=0.1400161955  (ΔLR=+0.0075464844, ΔPERT=+0.0000088874)\n",
            "[round 4 | client 3] seed LR=0.1469974527 (prev=0.1539949054), seed PERT=0.1400080797 (prev=0.1400161594), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.462920 step=0.03089 g_raw=+0.008 g_sm=+0.002 acc=1 | LR→0.147292 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.458702 step=0.006456 g_raw=+0.003 g_sm=+0.004 acc=1 | LR→0.147587 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.455665 step=0.01056 g_raw=+0.003 g_sm=+0.006 acc=1 | LR→0.147882 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.448844 step=0.04004 g_raw=+0.016 g_sm=+0.009 acc=1 | LR→0.148179 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#025 loss=0.443939 step=0.03631 g_raw=+0.010 g_sm=+0.011 acc=1 | LR→0.148476 PERT→0.140009 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1469974527, PERT_used=0.1400080797 → LR_next=0.1484756566, PERT_next=0.1400088858\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1469974527→0.1484756566 PERT 0.1400080797→0.1400088858\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.441417 step=0.06169 g_raw=+0.021 g_sm=+0.011 acc=1 | LR→0.148773 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.439303 step=0.05821 g_raw=+0.020 g_sm=+0.011 acc=1 | LR→0.149071 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.438565 step=0.003485 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.149370 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#045 loss=0.430016 step=0.04181 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.149670 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.427581 step=0.02075 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.149970 PERT→0.140010 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1484756566, PERT_used=0.1400088858 → LR_next=0.1499695494, PERT_next=0.1400104614\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1484756566→0.1499695494 PERT 0.1400088858→0.1400104614\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.425667 step=0.04817 g_raw=+0.019 g_sm=+0.012 acc=1 | LR→0.150270 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#060 loss=0.422886 step=0.0446 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.150571 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.418419 step=0.05433 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.150873 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#070 loss=0.411802 step=0.05555 g_raw=+0.022 g_sm=+0.015 acc=1 | LR→0.151176 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#075 loss=0.409997 step=0.03105 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.151479 PERT→0.140012 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1499695494, PERT_used=0.1400104614 → LR_next=0.1514787382, PERT_next=0.1400122821\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1499695494→0.1514787382 PERT 0.1400104614→0.1400122821\n",
            "Training Accuracy: 0.90\n",
            "Test Accuracy: 0.77\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.407829 step=0.03959 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.151782 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#085 loss=0.403671 step=0.052 g_raw=+0.017 g_sm=+0.014 acc=1 | LR→0.152087 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#090 loss=0.395226 step=0.002876 g_raw=-0.003 g_sm=+0.015 acc=1 | LR→0.152392 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#095 loss=0.392712 step=0.02055 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.152697 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#100 loss=0.390571 step=0.0002244 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.153003 PERT→0.140014 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1514787382, PERT_used=0.1400122821 → LR_next=0.1530032488, PERT_next=0.1400142258\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1514787382→0.1530032488 PERT 0.1400122821→0.1400142258\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.75\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.389491 step=0.03358 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.153310 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#110 loss=0.388012 step=5.523e-05 g_raw=-0.001 g_sm=+0.011 acc=1 | LR→0.153617 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#115 loss=0.386432 step=0.009453 g_raw=+0.006 g_sm=+0.010 acc=1 | LR→0.153925 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#120 loss=0.383020 step=0.02121 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.154234 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#125 loss=0.378329 step=0.004066 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.154543 PERT→0.140016 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1530032488, PERT_used=0.1400142258 → LR_next=0.1545426835, PERT_next=0.1400157900\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1530032488→0.1545426835 PERT 0.1400142258→0.1400157900\n",
            "Training Accuracy: 0.94\n",
            "Test Accuracy: 0.81\n",
            "[round 4 | client 3] final LR=0.1545426835, final PERT=0.1400157900  (ΔLR=+0.0075452308, ΔPERT=+0.0000077103)\n",
            "[round 4 | client 4] seed LR=0.1469971508 (prev=0.1539943017), seed PERT=0.1400078138 (prev=0.1400156276), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.479129 step=0.002747 g_raw=-0.001 g_sm=+0.001 acc=1 | LR→0.147291 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.475212 step=0.06272 g_raw=+0.025 g_sm=+0.005 acc=1 | LR→0.147586 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.471286 step=0.04764 g_raw=+0.017 g_sm=+0.007 acc=1 | LR→0.147882 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.469076 step=0.02696 g_raw=+0.012 g_sm=+0.008 acc=1 | LR→0.148178 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.468345 step=0.01449 g_raw=+0.002 g_sm=+0.008 acc=1 | LR→0.148475 PERT→0.140009 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1469971508, PERT_used=0.1400078138 → LR_next=0.1484752758, PERT_next=0.1400085484\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1469971508→0.1484752758 PERT 0.1400078138→0.1400085484\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.76\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.466496 step=0.005816 g_raw=+0.003 g_sm=+0.008 acc=1 | LR→0.148773 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.463844 step=0.06623 g_raw=+0.022 g_sm=+0.009 acc=1 | LR→0.149071 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.462103 step=0.02865 g_raw=+0.006 g_sm=+0.009 acc=1 | LR→0.149370 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.456933 step=0.06934 g_raw=+0.026 g_sm=+0.011 acc=1 | LR→0.149669 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.451226 step=0.07181 g_raw=+0.025 g_sm=+0.012 acc=1 | LR→0.149969 PERT→0.140010 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1484752758, PERT_used=0.1400085484 → LR_next=0.1499688120, PERT_next=0.1400097946\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1484752758→0.1499688120 PERT 0.1400085484→0.1400097946\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.76\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.447344 step=0.05432 g_raw=+0.019 g_sm=+0.013 acc=1 | LR→0.150269 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.441268 step=0.03887 g_raw=+0.018 g_sm=+0.014 acc=1 | LR→0.150571 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.439446 step=0.003967 g_raw=-0.000 g_sm=+0.013 acc=1 | LR→0.150872 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#070 loss=0.437878 step=0.008134 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.151175 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#075 loss=0.434204 step=0.004451 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.151478 PERT→0.140012 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1499688120, PERT_used=0.1400097946 → LR_next=0.1514779367, PERT_next=0.1400115629\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1499688120→0.1514779367 PERT 0.1400097946→0.1400115629\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.80\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.432565 step=0.01963 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.151782 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#085 loss=0.426871 step=0.1093 g_raw=+0.042 g_sm=+0.012 acc=1 | LR→0.152086 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#090 loss=0.422330 step=0.004044 g_raw=+0.006 g_sm=+0.013 acc=1 | LR→0.152391 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#095 loss=0.417086 step=0.01789 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.152696 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#100 loss=0.415951 step=0.04686 g_raw=+0.016 g_sm=+0.012 acc=1 | LR→0.153002 PERT→0.140013 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1514779367, PERT_used=0.1400115629 → LR_next=0.1530021900, PERT_next=0.1400132784\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1514779367→0.1530021900 PERT 0.1400115629→0.1400132784\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.79\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.410959 step=0.02742 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.153309 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#110 loss=0.394717 step=0.1129 g_raw=+0.042 g_sm=+0.017 acc=1 | LR→0.153616 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#115 loss=0.389115 step=0.04045 g_raw=+0.014 g_sm=+0.017 acc=1 | LR→0.153924 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#120 loss=0.387059 step=0.04338 g_raw=+0.012 g_sm=+0.015 acc=1 | LR→0.154233 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#125 loss=0.384651 step=0.03525 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.154542 PERT→0.140015 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1530021900, PERT_used=0.1400132784 → LR_next=0.1545422302, PERT_next=0.1400154009\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1530021900→0.1545422302 PERT 0.1400132784→0.1400154009\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.76\n",
            "[round 4 | client 4] final LR=0.1545422302, final PERT=0.1400154009  (ΔLR=+0.0075450794, ΔPERT=+0.0000075871)\n",
            "\n",
            "[Round 4] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           0      0.512328      0.860000      0.154542      0.140016\n",
            "           4      0.517682      0.760000      0.154542      0.140015\n",
            "           3      0.527564      0.810000      0.154543      0.140016\n",
            "           1      0.564249      0.770000      0.154542      0.140015\n",
            "           2      0.646796      0.530000      0.154543      0.140016\n",
            "→ [Round 4] best_client=0, best_val=0.512328, prev_global_val=0.581073, improve=+0.068745, action=adopt+mix τ=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  50%|█████     | 5/10 [45:37<45:38, 547.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   4] acc_g=0.614 (μ=0.746, σ=0.114, FG=0.218) | t=537.487s, val=0.623 | TEL=FALSE\n",
            "[Round 5] Teleportation OFF | Aggregation=best\n",
            "[round 5 | client 0] seed LR=0.1472712432 (prev=0.1545424864), seed PERT=0.1400078066 (prev=0.1400156133), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.516013 step=0.07385 g_raw=+0.028 g_sm=+0.005 acc=1 | LR→0.147566 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.512654 step=0.04615 g_raw=+0.014 g_sm=+0.008 acc=1 | LR→0.147862 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.504329 step=0.02938 g_raw=+0.012 g_sm=+0.010 acc=1 | LR→0.148158 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.502406 step=0.01372 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.148455 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#025 loss=0.495818 step=0.08572 g_raw=+0.031 g_sm=+0.012 acc=1 | LR→0.148753 PERT→0.140009 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1472712432, PERT_used=0.1400078066 → LR_next=0.1487525231, PERT_next=0.1400089166\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1472712432→0.1487525231 PERT 0.1400078066→0.1400089166\n",
            "Training Accuracy: 0.46\n",
            "Test Accuracy: 0.55\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.470787 step=0.07926 g_raw=+0.031 g_sm=+0.018 acc=1 | LR→0.149051 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.464707 step=0.09042 g_raw=+0.033 g_sm=+0.018 acc=1 | LR→0.149350 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#040 loss=0.459349 step=0.06555 g_raw=+0.024 g_sm=+0.018 acc=1 | LR→0.149649 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#045 loss=0.445675 step=0.002769 g_raw=+0.002 g_sm=+0.019 acc=1 | LR→0.149949 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#050 loss=0.440376 step=0.04452 g_raw=+0.017 g_sm=+0.018 acc=1 | LR→0.150250 PERT→0.140011 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1487525231, PERT_used=0.1400089166 → LR_next=0.1502501196, PERT_next=0.1400113477\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.022 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1487525231→0.1502501196 PERT 0.1400089166→0.1400113477\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.437774 step=0.02046 g_raw=+0.008 g_sm=+0.016 acc=1 | LR→0.150551 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#060 loss=0.437034 step=0.01797 g_raw=+0.005 g_sm=+0.014 acc=1 | LR→0.150853 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#065 loss=0.433692 step=0.02967 g_raw=+0.010 g_sm=+0.014 acc=1 | LR→0.151156 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#070 loss=0.423732 step=0.04843 g_raw=+0.015 g_sm=+0.016 acc=1 | LR→0.151459 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#075 loss=0.422358 step=0.006828 g_raw=+0.002 g_sm=+0.014 acc=1 | LR→0.151762 PERT→0.140013 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1502501196, PERT_used=0.1400113477 → LR_next=0.1517624519, PERT_next=0.1400134636\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1502501196→0.1517624519 PERT 0.1400113477→0.1400134636\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.420561 step=0.02093 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.152067 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#085 loss=0.416944 step=0.05439 g_raw=+0.021 g_sm=+0.013 acc=1 | LR→0.152372 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#090 loss=0.410057 step=0.02586 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.152677 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#095 loss=0.406471 step=0.02422 g_raw=+0.007 g_sm=+0.014 acc=1 | LR→0.152983 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#100 loss=0.403390 step=0.000139 g_raw=-0.002 g_sm=+0.013 acc=1 | LR→0.153290 PERT→0.140015 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1517624519, PERT_used=0.1400134636 → LR_next=0.1532897520, PERT_next=0.1400153471\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1517624519→0.1532897520 PERT 0.1400134636→0.1400153471\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.83\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.402332 step=0.02137 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.153597 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#110 loss=0.401131 step=0.01854 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.153905 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#115 loss=0.399766 step=0.000224 g_raw=-0.002 g_sm=+0.010 acc=1 | LR→0.154213 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#120 loss=0.397026 step=0.0004936 g_raw=-0.001 g_sm=+0.010 acc=1 | LR→0.154522 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#125 loss=0.393969 step=0.006269 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.154832 PERT→0.140017 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1532897520, PERT_used=0.1400153471 → LR_next=0.1548320484, PERT_next=0.1400168923\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1532897520→0.1548320484 PERT 0.1400153471→0.1400168923\n",
            "Training Accuracy: 0.90\n",
            "Test Accuracy: 0.85\n",
            "[round 5 | client 0] final LR=0.1548320484, final PERT=0.1400168923  (ΔLR=+0.0075608052, ΔPERT=+0.0000090857)\n",
            "[round 5 | client 1] seed LR=0.1472707502 (prev=0.1545415004), seed PERT=0.1400073911 (prev=0.1400147822), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.498516 step=0.01916 g_raw=+0.010 g_sm=+0.004 acc=1 | LR→0.147566 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.480633 step=0.1625 g_raw=+0.062 g_sm=+0.011 acc=1 | LR→0.147861 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.476513 step=0.08166 g_raw=+0.027 g_sm=+0.011 acc=1 | LR→0.148158 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.462751 step=0.006595 g_raw=+0.002 g_sm=+0.014 acc=1 | LR→0.148455 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.454245 step=0.1407 g_raw=+0.048 g_sm=+0.015 acc=1 | LR→0.148752 PERT→0.140009 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1472707502, PERT_used=0.1400073911 → LR_next=0.1487522892, PERT_next=0.1400087496\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1472707502→0.1487522892 PERT 0.1400073911→0.1400087496\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.439734 step=0.09637 g_raw=+0.037 g_sm=+0.017 acc=1 | LR→0.149051 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.423122 step=0.04564 g_raw=+0.015 g_sm=+0.020 acc=1 | LR→0.149350 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#040 loss=0.418944 step=0.01927 g_raw=+0.007 g_sm=+0.018 acc=1 | LR→0.149649 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#045 loss=0.415372 step=0.003601 g_raw=-0.001 g_sm=+0.017 acc=1 | LR→0.149949 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#050 loss=0.403179 step=0.03361 g_raw=+0.011 g_sm=+0.017 acc=1 | LR→0.150250 PERT→0.140011 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1487522892, PERT_used=0.1400087496 → LR_next=0.1502499479, PERT_next=0.1400112408\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1487522892→0.1502499479 PERT 0.1400087496→0.1400112408\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.397389 step=0.03771 g_raw=+0.010 g_sm=+0.016 acc=1 | LR→0.150551 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#060 loss=0.393404 step=0.03857 g_raw=+0.017 g_sm=+0.016 acc=1 | LR→0.150853 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#065 loss=0.390934 step=0.05488 g_raw=+0.020 g_sm=+0.015 acc=1 | LR→0.151156 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#070 loss=0.374760 step=0.1279 g_raw=+0.043 g_sm=+0.018 acc=1 | LR→0.151459 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#075 loss=0.369402 step=0.1022 g_raw=+0.032 g_sm=+0.017 acc=1 | LR→0.151762 PERT→0.140013 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1502499479, PERT_used=0.1400112408 → LR_next=0.1517624294, PERT_next=0.1400134960\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1502499479→0.1517624294 PERT 0.1400112408→0.1400134960\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.366071 step=0.0622 g_raw=+0.020 g_sm=+0.016 acc=1 | LR→0.152067 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#085 loss=0.363775 step=0.003955 g_raw=+0.003 g_sm=+0.014 acc=1 | LR→0.152372 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#090 loss=0.360631 step=0.01597 g_raw=+0.009 g_sm=+0.014 acc=1 | LR→0.152677 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#095 loss=0.357645 step=0.007563 g_raw=-0.002 g_sm=+0.013 acc=1 | LR→0.152983 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#100 loss=0.353772 step=0.071 g_raw=+0.025 g_sm=+0.013 acc=1 | LR→0.153290 PERT→0.140016 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1517624294, PERT_used=0.1400134960 → LR_next=0.1532899242, PERT_next=0.1400155575\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1517624294→0.1532899242 PERT 0.1400134960→0.1400155575\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.351726 step=0.0263 g_raw=+0.008 g_sm=+0.013 acc=1 | LR→0.153597 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#110 loss=0.343149 step=0.06844 g_raw=+0.025 g_sm=+0.015 acc=1 | LR→0.153905 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#115 loss=0.342034 step=0.01493 g_raw=+0.005 g_sm=+0.013 acc=1 | LR→0.154214 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#120 loss=0.341056 step=0.006531 g_raw=+0.005 g_sm=+0.012 acc=1 | LR→0.154523 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#125 loss=0.340317 step=0.03479 g_raw=+0.008 g_sm=+0.010 acc=1 | LR→0.154832 PERT→0.140017 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1532899242, PERT_used=0.1400155575 → LR_next=0.1548324439, PERT_next=0.1400173032\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1532899242→0.1548324439 PERT 0.1400155575→0.1400173032\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.69\n",
            "[round 5 | client 1] final LR=0.1548324439, final PERT=0.1400173032  (ΔLR=+0.0075616937, ΔPERT=+0.0000099121)\n",
            "[round 5 | client 2] seed LR=0.1472715240 (prev=0.1545430481), seed PERT=0.1400080977 (prev=0.1400161955), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.477823 step=0.06803 g_raw=+0.026 g_sm=+0.005 acc=1 | LR→0.147566 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.469448 step=0.06141 g_raw=+0.024 g_sm=+0.008 acc=1 | LR→0.147862 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.453720 step=0.08667 g_raw=+0.035 g_sm=+0.014 acc=1 | LR→0.148158 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#020 loss=0.448506 step=0.008139 g_raw=+0.010 g_sm=+0.014 acc=1 | LR→0.148455 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#025 loss=0.438401 step=0.03126 g_raw=+0.012 g_sm=+0.016 acc=1 | LR→0.148753 PERT→0.140010 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1472715240, PERT_used=0.1400080977 → LR_next=0.1487531639, PERT_next=0.1400095439\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.023 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1472715240→0.1487531639 PERT 0.1400080977→0.1400095439\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.77\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.433029 step=0.08399 g_raw=+0.033 g_sm=+0.017 acc=1 | LR→0.149051 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#035 loss=0.426282 step=0.05549 g_raw=+0.022 g_sm=+0.017 acc=1 | LR→0.149350 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#040 loss=0.416226 step=0.08617 g_raw=+0.029 g_sm=+0.019 acc=1 | LR→0.149650 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#045 loss=0.408716 step=0.03947 g_raw=+0.008 g_sm=+0.018 acc=1 | LR→0.149950 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#050 loss=0.401102 step=0.07968 g_raw=+0.025 g_sm=+0.019 acc=1 | LR→0.150251 PERT→0.140012 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1487531639, PERT_used=0.1400095439 → LR_next=0.1502507965, PERT_next=0.1400120025\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1487531639→0.1502507965 PERT 0.1400095439→0.1400120025\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.81\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.399672 step=0.04525 g_raw=+0.017 g_sm=+0.017 acc=1 | LR→0.150552 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#060 loss=0.397162 step=0.016 g_raw=+0.009 g_sm=+0.015 acc=1 | LR→0.150854 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#065 loss=0.391473 step=0.01844 g_raw=+0.005 g_sm=+0.015 acc=1 | LR→0.151156 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#070 loss=0.389433 step=0.01093 g_raw=+0.003 g_sm=+0.014 acc=1 | LR→0.151460 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#075 loss=0.384898 step=0.08139 g_raw=+0.025 g_sm=+0.014 acc=1 | LR→0.151763 PERT→0.140014 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1502507965, PERT_used=0.1400120025 → LR_next=0.1517631907, PERT_next=0.1400141693\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1502507965→0.1517631907 PERT 0.1400120025→0.1400141693\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.75\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.383347 step=0.04898 g_raw=+0.014 g_sm=+0.012 acc=1 | LR→0.152067 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#085 loss=0.382275 step=0.0001659 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.152372 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#090 loss=0.381605 step=0.02384 g_raw=+0.009 g_sm=+0.010 acc=1 | LR→0.152678 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#095 loss=0.381000 step=0.001893 g_raw=-0.001 g_sm=+0.008 acc=1 | LR→0.152984 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#100 loss=0.379661 step=0.02159 g_raw=+0.005 g_sm=+0.008 acc=1 | LR→0.153290 PERT→0.140016 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1517631907, PERT_used=0.1400141693 → LR_next=0.1532900355, PERT_next=0.1400156301\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.006 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1517631907→0.1532900355 PERT 0.1400141693→0.1400156301\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.77\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.377667 step=0.001286 g_raw=-0.002 g_sm=+0.008 acc=1 | LR→0.153597 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#110 loss=0.377311 step=0.00437 g_raw=+0.000 g_sm=+0.007 acc=1 | LR→0.153905 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#115 loss=0.376370 step=0.0241 g_raw=+0.006 g_sm=+0.007 acc=1 | LR→0.154213 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#120 loss=0.376170 step=0.001185 g_raw=-0.003 g_sm=+0.006 acc=1 | LR→0.154522 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#125 loss=0.374712 step=0.01218 g_raw=+0.001 g_sm=+0.006 acc=1 | LR→0.154832 PERT→0.140017 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1532900355, PERT_used=0.1400156301 → LR_next=0.1548317532, PERT_next=0.1400166496\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.006 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1532900355→0.1548317532 PERT 0.1400156301→0.1400166496\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.79\n",
            "[round 5 | client 2] final LR=0.1548317532, final PERT=0.1400166496  (ΔLR=+0.0075602292, ΔPERT=+0.0000085518)\n",
            "[round 5 | client 3] seed LR=0.1472713418 (prev=0.1545426835), seed PERT=0.1400078950 (prev=0.1400157900), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.521281 step=0.02055 g_raw=+0.009 g_sm=+0.003 acc=1 | LR→0.147566 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.517877 step=0.01247 g_raw=+0.005 g_sm=+0.005 acc=1 | LR→0.147862 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.511204 step=0.04228 g_raw=+0.017 g_sm=+0.009 acc=1 | LR→0.148158 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.507448 step=0.02321 g_raw=+0.008 g_sm=+0.010 acc=1 | LR→0.148455 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#025 loss=0.504810 step=0.02147 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.148752 PERT→0.140009 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1472713418, PERT_used=0.1400078950 → LR_next=0.1487524803, PERT_next=0.1400088709\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1472713418→0.1487524803 PERT 0.1400078950→0.1400088709\n",
            "Training Accuracy: 0.56\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.503155 step=0.01708 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.149051 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.490085 step=0.1246 g_raw=+0.049 g_sm=+0.015 acc=1 | LR→0.149349 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#040 loss=0.484471 step=0.01701 g_raw=+0.006 g_sm=+0.015 acc=1 | LR→0.149649 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#045 loss=0.480232 step=0.08836 g_raw=+0.034 g_sm=+0.015 acc=1 | LR→0.149949 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.478871 step=0.01235 g_raw=+0.005 g_sm=+0.014 acc=1 | LR→0.150250 PERT→0.140011 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1487524803, PERT_used=0.1400088709 → LR_next=0.1502495122, PERT_next=0.1400107763\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1487524803→0.1502495122 PERT 0.1400088709→0.1400107763\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.63\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.476379 step=0.03911 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.150551 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#060 loss=0.473486 step=0.01022 g_raw=+0.000 g_sm=+0.013 acc=1 | LR→0.150853 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#065 loss=0.468778 step=0.02376 g_raw=+0.008 g_sm=+0.013 acc=1 | LR→0.151155 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#070 loss=0.467934 step=0.01469 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.151458 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#075 loss=0.465151 step=0.03682 g_raw=+0.013 g_sm=+0.012 acc=1 | LR→0.151761 PERT→0.140013 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1502495122, PERT_used=0.1400107763 → LR_next=0.1517614947, PERT_next=0.1400125752\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1502495122→0.1517614947 PERT 0.1400107763→0.1400125752\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.464519 step=0.004964 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.152066 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#085 loss=0.463643 step=0.005847 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.152370 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#090 loss=0.460765 step=0.03942 g_raw=+0.015 g_sm=+0.010 acc=1 | LR→0.152676 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#095 loss=0.458343 step=0.06158 g_raw=+0.024 g_sm=+0.010 acc=1 | LR→0.152982 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#100 loss=0.457313 step=0.01516 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.153288 PERT→0.140014 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1517614947, PERT_used=0.1400125752 → LR_next=0.1532883211, PERT_next=0.1400140348\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1517614947→0.1532883211 PERT 0.1400125752→0.1400140348\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.73\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.455208 step=0.03939 g_raw=+0.013 g_sm=+0.010 acc=1 | LR→0.153596 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#110 loss=0.453909 step=0.002846 g_raw=-0.001 g_sm=+0.009 acc=1 | LR→0.153903 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#115 loss=0.452453 step=0.02889 g_raw=+0.009 g_sm=+0.009 acc=1 | LR→0.154212 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#120 loss=0.452024 step=0.02136 g_raw=+0.007 g_sm=+0.008 acc=1 | LR→0.154521 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#125 loss=0.450188 step=0.003534 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.154830 PERT→0.140015 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1532883211, PERT_used=0.1400140348 → LR_next=0.1548303325, PERT_next=0.1400153353\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1532883211→0.1548303325 PERT 0.1400140348→0.1400153353\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.78\n",
            "[round 5 | client 3] final LR=0.1548303325, final PERT=0.1400153353  (ΔLR=+0.0075589907, ΔPERT=+0.0000074403)\n",
            "[round 5 | client 4] seed LR=0.1472711151 (prev=0.1545422302), seed PERT=0.1400077005 (prev=0.1400154009), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.503086 step=0.03617 g_raw=+0.012 g_sm=+0.001 acc=1 | LR→0.147566 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.502007 step=0.005933 g_raw=+0.003 g_sm=+0.002 acc=1 | LR→0.147861 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.500578 step=0.004088 g_raw=+0.001 g_sm=+0.004 acc=1 | LR→0.148158 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.497901 step=0.001165 g_raw=+0.001 g_sm=+0.005 acc=1 | LR→0.148454 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.488008 step=0.002651 g_raw=+0.001 g_sm=+0.009 acc=1 | LR→0.148752 PERT→0.140008 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1472711151, PERT_used=0.1400077005 → LR_next=0.1487517756, PERT_next=0.1400082286\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.004 acc_ratio=1.00 | LR 0.1472711151→0.1487517756 PERT 0.1400077005→0.1400082286\n",
            "Training Accuracy: 0.50\n",
            "Test Accuracy: 0.41\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.485457 step=0.02542 g_raw=+0.011 g_sm=+0.010 acc=1 | LR→0.149050 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.483796 step=0.04435 g_raw=+0.015 g_sm=+0.010 acc=1 | LR→0.149349 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.482979 step=0.02535 g_raw=+0.010 g_sm=+0.009 acc=1 | LR→0.149648 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.477213 step=0.03114 g_raw=+0.011 g_sm=+0.011 acc=1 | LR→0.149948 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.474744 step=0.01813 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.150248 PERT→0.140010 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1487517756, PERT_used=0.1400082286 → LR_next=0.1502482569, PERT_next=0.1400096275\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1487517756→0.1502482569 PERT 0.1400082286→0.1400096275\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.472575 step=0.03438 g_raw=+0.012 g_sm=+0.011 acc=1 | LR→0.150549 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.468437 step=0.07192 g_raw=+0.024 g_sm=+0.012 acc=1 | LR→0.150851 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.467090 step=0.03483 g_raw=+0.012 g_sm=+0.011 acc=1 | LR→0.151154 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#070 loss=0.461579 step=0.0008509 g_raw=-0.004 g_sm=+0.012 acc=1 | LR→0.151456 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#075 loss=0.459580 step=0.0368 g_raw=+0.013 g_sm=+0.012 acc=1 | LR→0.151760 PERT→0.140011 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1502482569, PERT_used=0.1400096275 → LR_next=0.1517600671, PERT_next=0.1400112790\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1502482569→0.1517600671 PERT 0.1400096275→0.1400112790\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.58\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.458736 step=0.01849 g_raw=+0.010 g_sm=+0.011 acc=1 | LR→0.152064 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#085 loss=0.456921 step=0.02837 g_raw=+0.012 g_sm=+0.011 acc=1 | LR→0.152369 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#090 loss=0.455110 step=0.03867 g_raw=+0.014 g_sm=+0.011 acc=1 | LR→0.152674 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.452963 step=0.05437 g_raw=+0.018 g_sm=+0.011 acc=1 | LR→0.152980 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.451509 step=0.04781 g_raw=+0.017 g_sm=+0.011 acc=1 | LR→0.153287 PERT→0.140013 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1517600671, PERT_used=0.1400112790 → LR_next=0.1532869342, PERT_next=0.1400127889\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1517600671→0.1532869342 PERT 0.1400112790→0.1400127889\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.450992 step=0.02289 g_raw=+0.009 g_sm=+0.009 acc=1 | LR→0.153594 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#110 loss=0.449234 step=0.04336 g_raw=+0.014 g_sm=+0.009 acc=1 | LR→0.153902 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.446631 step=0.06305 g_raw=+0.024 g_sm=+0.010 acc=1 | LR→0.154210 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#120 loss=0.445255 step=0.005801 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.154519 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#125 loss=0.443609 step=0.01312 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.154829 PERT→0.140014 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1532869342, PERT_used=0.1400127889 → LR_next=0.1548289750, PERT_next=0.1400141287\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1532869342→0.1548289750 PERT 0.1400127889→0.1400141287\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.67\n",
            "[round 5 | client 4] final LR=0.1548289750, final PERT=0.1400141287  (ΔLR=+0.0075578599, ΔPERT=+0.0000064282)\n",
            "\n",
            "[Round 5] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           2      0.524822      0.785000      0.154832      0.140017\n",
            "           0      0.541628      0.855000      0.154832      0.140017\n",
            "           1      0.566116      0.685000      0.154832      0.140017\n",
            "           3      0.614068      0.775000      0.154830      0.140015\n",
            "           4      0.628349      0.670000      0.154829      0.140014\n",
            "→ [Round 5] best_client=2, best_val=0.524822, prev_global_val=0.623139, improve=+0.098316, action=adopt+mix τ=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  60%|██████    | 6/10 [54:47<36:34, 548.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   5] acc_g=0.806 (μ=0.754, σ=0.068, FG=0.151) | t=540.535s, val=0.555 | TEL=FALSE\n",
            "[Round 6] Teleportation OFF | Aggregation=best\n",
            "[round 6 | client 0] seed LR=0.1474160242 (prev=0.1548320484), seed PERT=0.1400084462 (prev=0.1400168923), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.538790 step=0.07164 g_raw=+0.022 g_sm=+0.003 acc=1 | LR→0.147711 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.533736 step=0.04373 g_raw=+0.016 g_sm=+0.006 acc=1 | LR→0.148007 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#015 loss=0.531615 step=0.0007992 g_raw=+0.002 g_sm=+0.007 acc=1 | LR→0.148304 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#020 loss=0.519377 step=0.01842 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.148601 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#025 loss=0.510207 step=0.1135 g_raw=+0.043 g_sm=+0.014 acc=1 | LR→0.148899 PERT→0.140009 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1474160242, PERT_used=0.1400084462 → LR_next=0.1488986740, PERT_next=0.1400094750\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1474160242→0.1488986740 PERT 0.1400084462→0.1400094750\n",
            "Training Accuracy: 0.48\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.508472 step=0.03058 g_raw=+0.012 g_sm=+0.013 acc=1 | LR→0.149197 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#035 loss=0.499614 step=0.03931 g_raw=+0.013 g_sm=+0.015 acc=1 | LR→0.149496 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#040 loss=0.495547 step=0.0708 g_raw=+0.029 g_sm=+0.015 acc=1 | LR→0.149796 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#045 loss=0.476305 step=0.1531 g_raw=+0.056 g_sm=+0.019 acc=1 | LR→0.150096 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#050 loss=0.449010 step=0.02451 g_raw=+0.008 g_sm=+0.022 acc=1 | LR→0.150398 PERT→0.140012 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1488986740, PERT_used=0.1400094750 → LR_next=0.1503976262, PERT_next=0.1400117983\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.023 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1488986740→0.1503976262 PERT 0.1400094750→0.1400117983\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.442931 step=0.08688 g_raw=+0.035 g_sm=+0.021 acc=1 | LR→0.150699 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#060 loss=0.422994 step=0.2125 g_raw=+0.080 g_sm=+0.023 acc=1 | LR→0.151002 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#065 loss=0.417828 step=0.09558 g_raw=+0.041 g_sm=+0.022 acc=1 | LR→0.151305 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#070 loss=0.410309 step=0.06912 g_raw=+0.027 g_sm=+0.022 acc=1 | LR→0.151608 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#075 loss=0.394108 step=0.09914 g_raw=+0.035 g_sm=+0.025 acc=1 | LR→0.151912 PERT→0.140015 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1503976262, PERT_used=0.1400117983 → LR_next=0.1519124593, PERT_next=0.1400148508\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.023 g_sm_mean=+0.022 acc_ratio=1.00 | LR 0.1503976262→0.1519124593 PERT 0.1400117983→0.1400148508\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.74\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.387187 step=0.03915 g_raw=+0.013 g_sm=+0.023 acc=1 | LR→0.152217 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#085 loss=0.380457 step=0.1356 g_raw=+0.045 g_sm=+0.021 acc=1 | LR→0.152523 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#090 loss=0.377401 step=0.01483 g_raw=+0.005 g_sm=+0.018 acc=1 | LR→0.152829 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#095 loss=0.368457 step=0.09251 g_raw=+0.033 g_sm=+0.020 acc=1 | LR→0.153135 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#100 loss=0.360536 step=0.04106 g_raw=+0.013 g_sm=+0.020 acc=1 | LR→0.153442 PERT→0.140018 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1519124593, PERT_used=0.1400148508 → LR_next=0.1534423627, PERT_next=0.1400177323\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.021 acc_ratio=1.00 | LR 0.1519124593→0.1534423627 PERT 0.1400148508→0.1400177323\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.81\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.354119 step=0.05139 g_raw=+0.020 g_sm=+0.019 acc=1 | LR→0.153750 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#110 loss=0.347035 step=0.1055 g_raw=+0.030 g_sm=+0.019 acc=1 | LR→0.154059 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#115 loss=0.337891 step=0.1382 g_raw=+0.046 g_sm=+0.019 acc=1 | LR→0.154368 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#120 loss=0.331469 step=0.04095 g_raw=+0.015 g_sm=+0.019 acc=1 | LR→0.154677 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#125 loss=0.329471 step=0.01661 g_raw=+0.006 g_sm=+0.017 acc=1 | LR→0.154987 PERT→0.140020 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1534423627, PERT_used=0.1400177323 → LR_next=0.1549873686, PERT_next=0.1400203382\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1534423627→0.1549873686 PERT 0.1400177323→0.1400203382\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.82\n",
            "[round 6 | client 0] final LR=0.1549873686, final PERT=0.1400203382  (ΔLR=+0.0075713444, ΔPERT=+0.0000118921)\n",
            "[round 6 | client 1] seed LR=0.1474162220 (prev=0.1548324439), seed PERT=0.1400086516 (prev=0.1400173032), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.475039 step=0.07346 g_raw=+0.027 g_sm=+0.004 acc=1 | LR→0.147711 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#010 loss=0.473685 step=0.04836 g_raw=+0.015 g_sm=+0.005 acc=1 | LR→0.148007 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#015 loss=0.470758 step=0.0614 g_raw=+0.022 g_sm=+0.007 acc=1 | LR→0.148304 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#020 loss=0.465663 step=0.04032 g_raw=+0.016 g_sm=+0.009 acc=1 | LR→0.148601 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#025 loss=0.462952 step=0.05747 g_raw=+0.020 g_sm=+0.009 acc=1 | LR→0.148899 PERT→0.140009 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1474162220, PERT_used=0.1400086516 → LR_next=0.1488986541, PERT_next=0.1400094739\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1474162220→0.1488986541 PERT 0.1400086516→0.1400094739\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.461686 step=0.0332 g_raw=+0.011 g_sm=+0.009 acc=1 | LR→0.149197 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#035 loss=0.458692 step=0.006641 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.149496 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#040 loss=0.452881 step=0.001519 g_raw=+0.001 g_sm=+0.011 acc=1 | LR→0.149796 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#045 loss=0.448463 step=0.07984 g_raw=+0.030 g_sm=+0.012 acc=1 | LR→0.150096 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#050 loss=0.445920 step=0.00398 g_raw=-0.002 g_sm=+0.011 acc=1 | LR→0.150397 PERT→0.140011 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1488986541, PERT_used=0.1400094739 → LR_next=0.1503966957, PERT_next=0.1400109497\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1488986541→0.1503966957 PERT 0.1400094739→0.1400109497\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.442458 step=0.005228 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.150698 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#060 loss=0.440398 step=0.0005178 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.151000 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#065 loss=0.438804 step=0.051 g_raw=+0.017 g_sm=+0.010 acc=1 | LR→0.151303 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#070 loss=0.436312 step=0.04571 g_raw=+0.018 g_sm=+0.011 acc=1 | LR→0.151606 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#075 loss=0.430451 step=0.02064 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.151910 PERT→0.140013 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1503966957, PERT_used=0.1400109497 → LR_next=0.1519099084, PERT_next=0.1400125172\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1503966957→0.1519099084 PERT 0.1400109497→0.1400125172\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.430249 step=0.0007539 g_raw=-0.002 g_sm=+0.010 acc=1 | LR→0.152214 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#085 loss=0.429321 step=0.04947 g_raw=+0.018 g_sm=+0.009 acc=1 | LR→0.152519 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#090 loss=0.425079 step=0.06576 g_raw=+0.024 g_sm=+0.010 acc=1 | LR→0.152825 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#095 loss=0.424382 step=0.01138 g_raw=+0.004 g_sm=+0.009 acc=1 | LR→0.153131 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#100 loss=0.423052 step=0.01381 g_raw=+0.004 g_sm=+0.009 acc=1 | LR→0.153438 PERT→0.140014 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1519099084, PERT_used=0.1400125172 → LR_next=0.1534381334, PERT_next=0.1400138906\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1519099084→0.1534381334 PERT 0.1400125172→0.1400138906\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.421451 step=0.005551 g_raw=+0.003 g_sm=+0.008 acc=1 | LR→0.153746 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#110 loss=0.421064 step=0.00601 g_raw=+0.002 g_sm=+0.007 acc=1 | LR→0.154054 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#115 loss=0.417346 step=0.05649 g_raw=+0.023 g_sm=+0.009 acc=1 | LR→0.154362 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#120 loss=0.414591 step=0.001492 g_raw=+0.001 g_sm=+0.009 acc=1 | LR→0.154672 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#125 loss=0.411213 step=0.04829 g_raw=+0.018 g_sm=+0.010 acc=1 | LR→0.154982 PERT→0.140015 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1534381334, PERT_used=0.1400138906 → LR_next=0.1549815573, PERT_next=0.1400151057\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1534381334→0.1549815573 PERT 0.1400138906→0.1400151057\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.71\n",
            "[round 6 | client 1] final LR=0.1549815573, final PERT=0.1400151057  (ΔLR=+0.0075653353, ΔPERT=+0.0000064541)\n",
            "[round 6 | client 2] seed LR=0.1474158766 (prev=0.1548317532), seed PERT=0.1400083248 (prev=0.1400166496), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.505084 step=0.1087 g_raw=+0.043 g_sm=+0.003 acc=1 | LR→0.147711 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.498464 step=0.08945 g_raw=+0.036 g_sm=+0.007 acc=1 | LR→0.148007 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.495861 step=0.006001 g_raw=+0.000 g_sm=+0.007 acc=1 | LR→0.148303 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#020 loss=0.482703 step=0.09774 g_raw=+0.036 g_sm=+0.012 acc=1 | LR→0.148601 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#025 loss=0.475884 step=0.1254 g_raw=+0.042 g_sm=+0.013 acc=1 | LR→0.148898 PERT→0.140009 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1474158766, PERT_used=0.1400083248 → LR_next=0.1488984287, PERT_next=0.1400092631\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1474158766→0.1488984287 PERT 0.1400083248→0.1400092631\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.466345 step=0.02533 g_raw=+0.010 g_sm=+0.015 acc=1 | LR→0.149197 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#035 loss=0.456453 step=0.06689 g_raw=+0.028 g_sm=+0.017 acc=1 | LR→0.149496 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#040 loss=0.451157 step=0.01839 g_raw=+0.009 g_sm=+0.017 acc=1 | LR→0.149796 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#045 loss=0.446310 step=0.0194 g_raw=+0.009 g_sm=+0.017 acc=1 | LR→0.150096 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#050 loss=0.437134 step=0.005629 g_raw=+0.002 g_sm=+0.017 acc=1 | LR→0.150397 PERT→0.140012 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1488984287, PERT_used=0.1400092631 → LR_next=0.1503973850, PERT_next=0.1400115925\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1488984287→0.1503973850 PERT 0.1400092631→0.1400115925\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.424744 step=0.1243 g_raw=+0.046 g_sm=+0.020 acc=1 | LR→0.150699 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#060 loss=0.423197 step=0.04509 g_raw=+0.016 g_sm=+0.018 acc=1 | LR→0.151001 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#065 loss=0.417085 step=0.0002398 g_raw=+0.000 g_sm=+0.017 acc=1 | LR→0.151304 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#070 loss=0.407906 step=0.05594 g_raw=+0.017 g_sm=+0.019 acc=1 | LR→0.151608 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#075 loss=0.402263 step=0.02963 g_raw=+0.011 g_sm=+0.018 acc=1 | LR→0.151912 PERT→0.140014 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1503973850, PERT_used=0.1400115925 → LR_next=0.1519116799, PERT_next=0.1400141511\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1503973850→0.1519116799 PERT 0.1400115925→0.1400141511\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.58\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.397280 step=0.01029 g_raw=+0.002 g_sm=+0.018 acc=1 | LR→0.152216 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#085 loss=0.390267 step=0.08086 g_raw=+0.022 g_sm=+0.018 acc=1 | LR→0.152522 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#090 loss=0.383517 step=0.1014 g_raw=+0.036 g_sm=+0.018 acc=1 | LR→0.152828 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#095 loss=0.378608 step=0.01197 g_raw=+0.004 g_sm=+0.018 acc=1 | LR→0.153134 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#100 loss=0.373179 step=0.03421 g_raw=+0.014 g_sm=+0.017 acc=1 | LR→0.153441 PERT→0.140017 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1519116799, PERT_used=0.1400141511 → LR_next=0.1534411951, PERT_next=0.1400166856\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1519116799→0.1534411951 PERT 0.1400141511→0.1400166856\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.57\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.371394 step=0.005553 g_raw=+0.001 g_sm=+0.016 acc=1 | LR→0.153749 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#110 loss=0.370049 step=0.005459 g_raw=+0.001 g_sm=+0.014 acc=1 | LR→0.154057 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#115 loss=0.362292 step=0.03941 g_raw=+0.010 g_sm=+0.015 acc=1 | LR→0.154366 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#120 loss=0.360149 step=0.0003408 g_raw=+0.004 g_sm=+0.014 acc=1 | LR→0.154676 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#125 loss=0.356567 step=0.02538 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.154986 PERT→0.140019 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1534411951, PERT_used=0.1400166856 → LR_next=0.1549856213, PERT_next=0.1400187784\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1534411951→0.1549856213 PERT 0.1400166856→0.1400187784\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.57\n",
            "[round 6 | client 2] final LR=0.1549856213, final PERT=0.1400187784  (ΔLR=+0.0075697446, ΔPERT=+0.0000104536)\n",
            "[round 6 | client 3] seed LR=0.1474151662 (prev=0.1548303325), seed PERT=0.1400076677 (prev=0.1400153353), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.479223 step=0.02038 g_raw=+0.008 g_sm=+0.003 acc=1 | LR→0.147710 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.474290 step=0.05452 g_raw=+0.020 g_sm=+0.005 acc=1 | LR→0.148006 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.458349 step=0.06806 g_raw=+0.026 g_sm=+0.011 acc=1 | LR→0.148303 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.453489 step=0.0004209 g_raw=+0.002 g_sm=+0.012 acc=1 | LR→0.148600 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.442529 step=0.06808 g_raw=+0.020 g_sm=+0.014 acc=1 | LR→0.148898 PERT→0.140009 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1474151662, PERT_used=0.1400076677 → LR_next=0.1488979106, PERT_next=0.1400087934\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1474151662→0.1488979106 PERT 0.1400076677→0.1400087934\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.60\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.437322 step=0.1175 g_raw=+0.040 g_sm=+0.014 acc=1 | LR→0.149196 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.424737 step=0.135 g_raw=+0.047 g_sm=+0.017 acc=1 | LR→0.149496 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#040 loss=0.408053 step=0.0009527 g_raw=+0.002 g_sm=+0.019 acc=1 | LR→0.149795 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#045 loss=0.403189 step=0.001239 g_raw=+0.003 g_sm=+0.018 acc=1 | LR→0.150096 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#050 loss=0.399800 step=0.08519 g_raw=+0.032 g_sm=+0.017 acc=1 | LR→0.150397 PERT→0.140011 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1488979106, PERT_used=0.1400087934 → LR_next=0.1503968543, PERT_next=0.1400111160\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1488979106→0.1503968543 PERT 0.1400087934→0.1400111160\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.74\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.390662 step=0.06167 g_raw=+0.021 g_sm=+0.018 acc=1 | LR→0.150698 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#060 loss=0.386460 step=0.06914 g_raw=+0.021 g_sm=+0.018 acc=1 | LR→0.151001 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#065 loss=0.384391 step=0.02021 g_raw=+0.007 g_sm=+0.016 acc=1 | LR→0.151304 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#070 loss=0.383812 step=0.001085 g_raw=-0.000 g_sm=+0.013 acc=1 | LR→0.151607 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#075 loss=0.380940 step=0.01273 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.151911 PERT→0.140013 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1503968543, PERT_used=0.1400111160 → LR_next=0.1519107703, PERT_next=0.1400133304\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1503968543→0.1519107703 PERT 0.1400111160→0.1400133304\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.379627 step=0.04279 g_raw=+0.013 g_sm=+0.012 acc=1 | LR→0.152215 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#085 loss=0.376056 step=0.03229 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.152520 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#090 loss=0.371687 step=0.03601 g_raw=+0.012 g_sm=+0.013 acc=1 | LR→0.152826 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#095 loss=0.368637 step=0.05813 g_raw=+0.018 g_sm=+0.013 acc=1 | LR→0.153132 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#100 loss=0.368130 step=0.003813 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.153439 PERT→0.140015 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1519107703, PERT_used=0.1400133304 → LR_next=0.1534393917, PERT_next=0.1400150575\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1519107703→0.1534393917 PERT 0.1400133304→0.1400150575\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.367403 step=0.02274 g_raw=+0.007 g_sm=+0.010 acc=1 | LR→0.153747 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#110 loss=0.365041 step=0.05048 g_raw=+0.014 g_sm=+0.010 acc=1 | LR→0.154055 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#115 loss=0.364153 step=0.02682 g_raw=+0.008 g_sm=+0.010 acc=1 | LR→0.154364 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#120 loss=0.361679 step=0.03016 g_raw=+0.009 g_sm=+0.010 acc=1 | LR→0.154673 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#125 loss=0.360196 step=0.01778 g_raw=+0.006 g_sm=+0.010 acc=1 | LR→0.154983 PERT→0.140016 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1534393917, PERT_used=0.1400150575 → LR_next=0.1549830326, PERT_next=0.1400164573\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1534393917→0.1549830326 PERT 0.1400150575→0.1400164573\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.68\n",
            "[round 6 | client 3] final LR=0.1549830326, final PERT=0.1400164573  (ΔLR=+0.0075678664, ΔPERT=+0.0000087897)\n",
            "[round 6 | client 4] seed LR=0.1474144875 (prev=0.1548289750), seed PERT=0.1400070643 (prev=0.1400141287), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.500701 step=0.03103 g_raw=+0.014 g_sm=+0.002 acc=1 | LR→0.147710 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.495889 step=0.02793 g_raw=+0.010 g_sm=+0.005 acc=1 | LR→0.148005 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.489167 step=0.0071 g_raw=+0.005 g_sm=+0.007 acc=1 | LR→0.148302 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.487666 step=0.002779 g_raw=+0.002 g_sm=+0.007 acc=1 | LR→0.148599 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.483273 step=0.006843 g_raw=-0.001 g_sm=+0.009 acc=1 | LR→0.148897 PERT→0.140008 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1474144875, PERT_used=0.1400070643 → LR_next=0.1488968978, PERT_next=0.1400078824\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1474144875→0.1488968978 PERT 0.1400070643→0.1400078824\n",
            "Training Accuracy: 0.56\n",
            "Test Accuracy: 0.62\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.474985 step=0.03512 g_raw=+0.013 g_sm=+0.011 acc=1 | LR→0.149195 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.469985 step=0.02358 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.149494 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.468063 step=0.0485 g_raw=+0.015 g_sm=+0.012 acc=1 | LR→0.149794 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.462337 step=0.06564 g_raw=+0.028 g_sm=+0.014 acc=1 | LR→0.150094 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.449370 step=0.01438 g_raw=+0.004 g_sm=+0.016 acc=1 | LR→0.150395 PERT→0.140010 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1488968978, PERT_used=0.1400078824 → LR_next=0.1503952573, PERT_next=0.1400096706\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1488968978→0.1503952573 PERT 0.1400078824→0.1400096706\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.440808 step=0.01623 g_raw=+0.008 g_sm=+0.017 acc=1 | LR→0.150697 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.429967 step=0.005892 g_raw=+0.003 g_sm=+0.019 acc=1 | LR→0.150999 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.428166 step=0.01276 g_raw=+0.003 g_sm=+0.016 acc=1 | LR→0.151302 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#070 loss=0.421443 step=0.011 g_raw=+0.007 g_sm=+0.017 acc=1 | LR→0.151605 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#075 loss=0.416033 step=0.01896 g_raw=+0.004 g_sm=+0.017 acc=1 | LR→0.151909 PERT→0.140012 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1503952573, PERT_used=0.1400096706 → LR_next=0.1519094158, PERT_next=0.1400121233\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1503952573→0.1519094158 PERT 0.1400096706→0.1400121233\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.414744 step=0.01173 g_raw=+0.005 g_sm=+0.015 acc=1 | LR→0.152214 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#085 loss=0.412195 step=0.04583 g_raw=+0.017 g_sm=+0.014 acc=1 | LR→0.152519 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#090 loss=0.409928 step=0.04589 g_raw=+0.015 g_sm=+0.014 acc=1 | LR→0.152825 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#095 loss=0.406599 step=0.06142 g_raw=+0.022 g_sm=+0.014 acc=1 | LR→0.153131 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#100 loss=0.405629 step=0.01169 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.153438 PERT→0.140014 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1519094158, PERT_used=0.1400121233 → LR_next=0.1534382693, PERT_next=0.1400140747\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1519094158→0.1534382693 PERT 0.1400121233→0.1400140747\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.404858 step=0.00598 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.153746 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#110 loss=0.404106 step=0.006172 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.154054 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#115 loss=0.399408 step=0.03394 g_raw=+0.012 g_sm=+0.011 acc=1 | LR→0.154363 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#120 loss=0.396412 step=0.04373 g_raw=+0.013 g_sm=+0.011 acc=1 | LR→0.154672 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#125 loss=0.395625 step=0.03842 g_raw=+0.016 g_sm=+0.010 acc=1 | LR→0.154982 PERT→0.140016 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1534382693, PERT_used=0.1400140747 → LR_next=0.1549819617, PERT_next=0.1400155311\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1534382693→0.1549819617 PERT 0.1400140747→0.1400155311\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.62\n",
            "[round 6 | client 4] final LR=0.1549819617, final PERT=0.1400155311  (ΔLR=+0.0075674742, ΔPERT=+0.0000084668)\n",
            "\n",
            "[Round 6] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           0      0.460828      0.825000      0.154987      0.140020\n",
            "           3      0.558615      0.680000      0.154983      0.140016\n",
            "           4      0.582160      0.625000      0.154982      0.140016\n",
            "           1      0.605925      0.710000      0.154982      0.140015\n",
            "           2      0.717076      0.570000      0.154986      0.140019\n",
            "→ [Round 6] best_client=0, best_val=0.460828, prev_global_val=0.555202, improve=+0.094374, action=adopt+mix τ=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  70%|███████   | 7/10 [1:03:55<27:24, 548.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   6] acc_g=0.499 (μ=0.682, σ=0.086, FG=0.187) | t=537.411s, val=0.680 | TEL=FALSE\n",
            "[Round 7] Teleportation OFF | Aggregation=best\n",
            "[round 7 | client 0] seed LR=0.1474936843 (prev=0.1549873686), seed PERT=0.1400101691 (prev=0.1400203382), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.492957 step=0.002101 g_raw=+0.001 g_sm=+0.002 acc=1 | LR→0.147789 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#010 loss=0.488059 step=0.03309 g_raw=+0.013 g_sm=+0.005 acc=1 | LR→0.148085 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#015 loss=0.471851 step=0.06369 g_raw=+0.028 g_sm=+0.012 acc=1 | LR→0.148382 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#020 loss=0.457603 step=0.04633 g_raw=+0.020 g_sm=+0.015 acc=1 | LR→0.148679 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#025 loss=0.450370 step=0.06595 g_raw=+0.023 g_sm=+0.017 acc=1 | LR→0.148977 PERT→0.140011 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1474936843, PERT_used=0.1400101691 → LR_next=0.1489773874, PERT_next=0.1400114537\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.022 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1474936843→0.1489773874 PERT 0.1400101691→0.1400114537\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.65\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.446065 step=0.0833 g_raw=+0.032 g_sm=+0.016 acc=1 | LR→0.149276 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#035 loss=0.442360 step=0.04017 g_raw=+0.014 g_sm=+0.016 acc=1 | LR→0.149575 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#040 loss=0.434693 step=0.1151 g_raw=+0.040 g_sm=+0.017 acc=1 | LR→0.149875 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#045 loss=0.424930 step=0.1038 g_raw=+0.043 g_sm=+0.019 acc=1 | LR→0.150176 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#050 loss=0.421389 step=0.08249 g_raw=+0.027 g_sm=+0.018 acc=1 | LR→0.150477 PERT→0.140014 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1489773874, PERT_used=0.1400114537 → LR_next=0.1504771751, PERT_next=0.1400138172\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1489773874→0.1504771751 PERT 0.1400114537→0.1400138172\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.415301 step=0.05811 g_raw=+0.020 g_sm=+0.018 acc=1 | LR→0.150779 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#060 loss=0.413124 step=0.01571 g_raw=+0.005 g_sm=+0.016 acc=1 | LR→0.151081 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#065 loss=0.408046 step=0.04937 g_raw=+0.022 g_sm=+0.016 acc=1 | LR→0.151384 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#070 loss=0.405973 step=0.04202 g_raw=+0.015 g_sm=+0.015 acc=1 | LR→0.151688 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#075 loss=0.399548 step=0.05602 g_raw=+0.018 g_sm=+0.016 acc=1 | LR→0.151992 PERT→0.140016 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1504771751, PERT_used=0.1400138172 → LR_next=0.1519919446, PERT_next=0.1400160730\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1504771751→0.1519919446 PERT 0.1400138172→0.1400160730\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.396178 step=0.004388 g_raw=+0.003 g_sm=+0.015 acc=1 | LR→0.152297 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#085 loss=0.394281 step=0.01191 g_raw=+0.001 g_sm=+0.014 acc=1 | LR→0.152602 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#090 loss=0.386208 step=0.006634 g_raw=+0.003 g_sm=+0.015 acc=1 | LR→0.152908 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#095 loss=0.384227 step=0.02497 g_raw=+0.007 g_sm=+0.014 acc=1 | LR→0.153215 PERT→0.140018 (scale=0.04)\n",
            "[meta] cb#100 loss=0.381257 step=0.07344 g_raw=+0.022 g_sm=+0.014 acc=1 | LR→0.153522 PERT→0.140018 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1519919446, PERT_used=0.1400160730 → LR_next=0.1535217496, PERT_next=0.1400181348\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1519919446→0.1535217496 PERT 0.1400160730→0.1400181348\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.65\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.378444 step=0.04474 g_raw=+0.014 g_sm=+0.013 acc=1 | LR→0.153830 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#110 loss=0.374872 step=0.07176 g_raw=+0.023 g_sm=+0.014 acc=1 | LR→0.154138 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#115 loss=0.373878 step=0.004083 g_raw=+0.002 g_sm=+0.012 acc=1 | LR→0.154447 PERT→0.140019 (scale=0.04)\n",
            "[meta] cb#120 loss=0.372695 step=0.004007 g_raw=-0.002 g_sm=+0.010 acc=1 | LR→0.154756 PERT→0.140020 (scale=0.04)\n",
            "[meta] cb#125 loss=0.369619 step=0.05705 g_raw=+0.019 g_sm=+0.011 acc=1 | LR→0.155067 PERT→0.140020 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1535217496, PERT_used=0.1400181348 → LR_next=0.1550665677, PERT_next=0.1400198493\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1535217496→0.1550665677 PERT 0.1400181348→0.1400198493\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.65\n",
            "[round 7 | client 0] final LR=0.1550665677, final PERT=0.1400198493  (ΔLR=+0.0075728834, ΔPERT=+0.0000096802)\n",
            "[round 7 | client 1] seed LR=0.1474907786 (prev=0.1549815573), seed PERT=0.1400075528 (prev=0.1400151057), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.489354 step=0.0625 g_raw=+0.026 g_sm=+0.006 acc=1 | LR→0.147786 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.484603 step=0.03481 g_raw=+0.012 g_sm=+0.008 acc=1 | LR→0.148082 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.480344 step=0.09655 g_raw=+0.035 g_sm=+0.009 acc=1 | LR→0.148379 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.475553 step=0.01858 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.148676 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.457978 step=0.1179 g_raw=+0.041 g_sm=+0.013 acc=1 | LR→0.148974 PERT→0.140009 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1474907786, PERT_used=0.1400075528 → LR_next=0.1489742223, PERT_next=0.1400086211\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1474907786→0.1489742223 PERT 0.1400075528→0.1400086211\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.65\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.446414 step=0.1276 g_raw=+0.051 g_sm=+0.016 acc=1 | LR→0.149273 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.440698 step=0.04634 g_raw=+0.017 g_sm=+0.017 acc=1 | LR→0.149572 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.435994 step=0.07239 g_raw=+0.028 g_sm=+0.017 acc=1 | LR→0.149872 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#045 loss=0.430810 step=0.02721 g_raw=+0.008 g_sm=+0.017 acc=1 | LR→0.150173 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.426020 step=0.08523 g_raw=+0.030 g_sm=+0.017 acc=1 | LR→0.150474 PERT→0.140011 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1489742223, PERT_used=0.1400086211 → LR_next=0.1504738499, PERT_next=0.1400108652\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1489742223→0.1504738499 PERT 0.1400086211→0.1400108652\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.414546 step=0.02065 g_raw=+0.008 g_sm=+0.017 acc=1 | LR→0.150776 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#060 loss=0.405786 step=0.01353 g_raw=+0.004 g_sm=+0.018 acc=1 | LR→0.151078 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#065 loss=0.403801 step=0.04583 g_raw=+0.014 g_sm=+0.016 acc=1 | LR→0.151381 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#070 loss=0.397349 step=0.117 g_raw=+0.043 g_sm=+0.016 acc=1 | LR→0.151685 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#075 loss=0.394941 step=0.003713 g_raw=+0.003 g_sm=+0.015 acc=1 | LR→0.151989 PERT→0.140013 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1504738499, PERT_used=0.1400108652 → LR_next=0.1519886551, PERT_next=0.1400131847\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1504738499→0.1519886551 PERT 0.1400108652→0.1400131847\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.388094 step=0.1172 g_raw=+0.041 g_sm=+0.016 acc=1 | LR→0.152293 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#085 loss=0.387669 step=0.001541 g_raw=+0.004 g_sm=+0.013 acc=1 | LR→0.152599 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#090 loss=0.383199 step=0.0421 g_raw=+0.012 g_sm=+0.014 acc=1 | LR→0.152905 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#095 loss=0.379524 step=0.0003969 g_raw=-0.002 g_sm=+0.014 acc=1 | LR→0.153211 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#100 loss=0.376847 step=0.03265 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.153518 PERT→0.140015 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1519886551, PERT_used=0.1400131847 → LR_next=0.1535183393, PERT_next=0.1400151664\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1519886551→0.1535183393 PERT 0.1400131847→0.1400151664\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.76\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.373729 step=0.009936 g_raw=+0.003 g_sm=+0.013 acc=1 | LR→0.153826 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#110 loss=0.369800 step=0.03038 g_raw=+0.011 g_sm=+0.013 acc=1 | LR→0.154134 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#115 loss=0.368380 step=0.02909 g_raw=+0.013 g_sm=+0.012 acc=1 | LR→0.154443 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#120 loss=0.365743 step=0.06212 g_raw=+0.021 g_sm=+0.012 acc=1 | LR→0.154753 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#125 loss=0.363701 step=0.01163 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.155063 PERT→0.140017 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1535183393, PERT_used=0.1400151664 → LR_next=0.1550631773, PERT_next=0.1400169299\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1535183393→0.1550631773 PERT 0.1400151664→0.1400169299\n",
            "Training Accuracy: 0.90\n",
            "Test Accuracy: 0.89\n",
            "[round 7 | client 1] final LR=0.1550631773, final PERT=0.1400169299  (ΔLR=+0.0075723986, ΔPERT=+0.0000093771)\n",
            "[round 7 | client 2] seed LR=0.1474928106 (prev=0.1549856213), seed PERT=0.1400093892 (prev=0.1400187784), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.469410 step=0.002045 g_raw=+0.002 g_sm=+0.001 acc=1 | LR→0.147788 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#010 loss=0.463531 step=0.01244 g_raw=+0.003 g_sm=+0.004 acc=1 | LR→0.148084 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#015 loss=0.460808 step=0.03876 g_raw=+0.013 g_sm=+0.006 acc=1 | LR→0.148381 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#020 loss=0.458403 step=0.06561 g_raw=+0.026 g_sm=+0.008 acc=1 | LR→0.148678 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#025 loss=0.454694 step=0.0369 g_raw=+0.013 g_sm=+0.009 acc=1 | LR→0.148976 PERT→0.140010 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1474928106, PERT_used=0.1400093892 → LR_next=0.1489758733, PERT_next=0.1400100802\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1474928106→0.1489758733 PERT 0.1400093892→0.1400100802\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.450437 step=0.03095 g_raw=+0.007 g_sm=+0.010 acc=1 | LR→0.149274 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#035 loss=0.447509 step=0.01744 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.149574 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#040 loss=0.444090 step=0.01839 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.149873 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#045 loss=0.442339 step=0.04596 g_raw=+0.015 g_sm=+0.011 acc=1 | LR→0.150174 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#050 loss=0.440203 step=0.01541 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.150475 PERT→0.140012 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1489758733, PERT_used=0.1400100802 → LR_next=0.1504747003, PERT_next=0.1400115639\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1489758733→0.1504747003 PERT 0.1400100802→0.1400115639\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.81\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.438645 step=0.06011 g_raw=+0.020 g_sm=+0.010 acc=1 | LR→0.150776 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#060 loss=0.437655 step=0.007167 g_raw=+0.003 g_sm=+0.009 acc=1 | LR→0.151078 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#065 loss=0.436005 step=0.01758 g_raw=+0.008 g_sm=+0.010 acc=1 | LR→0.151381 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#070 loss=0.433218 step=0.01124 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.151685 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#075 loss=0.431068 step=0.0106 g_raw=+0.007 g_sm=+0.010 acc=1 | LR→0.151989 PERT→0.140013 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1504747003, PERT_used=0.1400115639 → LR_next=0.1519885096, PERT_next=0.1400129581\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1504747003→0.1519885096 PERT 0.1400115639→0.1400129581\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.86\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.429095 step=0.01299 g_raw=+0.006 g_sm=+0.010 acc=1 | LR→0.152293 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#085 loss=0.426001 step=0.08056 g_raw=+0.031 g_sm=+0.011 acc=1 | LR→0.152598 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#090 loss=0.425414 step=0.006295 g_raw=+0.001 g_sm=+0.009 acc=1 | LR→0.152904 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#095 loss=0.424191 step=0.02049 g_raw=+0.008 g_sm=+0.009 acc=1 | LR→0.153211 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#100 loss=0.423684 step=0.02624 g_raw=+0.010 g_sm=+0.008 acc=1 | LR→0.153517 PERT→0.140014 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1519885096, PERT_used=0.1400129581 → LR_next=0.1535174954, PERT_next=0.1400143042\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1519885096→0.1535174954 PERT 0.1400129581→0.1400143042\n",
            "Training Accuracy: 0.90\n",
            "Test Accuracy: 0.86\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.421845 step=0.006798 g_raw=+0.004 g_sm=+0.009 acc=1 | LR→0.153825 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#110 loss=0.420948 step=0.004877 g_raw=-0.003 g_sm=+0.008 acc=1 | LR→0.154133 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#115 loss=0.419295 step=0.04135 g_raw=+0.015 g_sm=+0.008 acc=1 | LR→0.154442 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#120 loss=0.418883 step=0.01368 g_raw=+0.001 g_sm=+0.008 acc=1 | LR→0.154752 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#125 loss=0.418030 step=0.02647 g_raw=+0.011 g_sm=+0.007 acc=1 | LR→0.155062 PERT→0.140015 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1535174954, PERT_used=0.1400143042 → LR_next=0.1550616367, PERT_next=0.1400154463\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1535174954→0.1550616367 PERT 0.1400143042→0.1400154463\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.81\n",
            "[round 7 | client 2] final LR=0.1550616367, final PERT=0.1400154463  (ΔLR=+0.0075688261, ΔPERT=+0.0000060571)\n",
            "[round 7 | client 3] seed LR=0.1474915163 (prev=0.1549830326), seed PERT=0.1400082287 (prev=0.1400164573), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.519507 step=0.004125 g_raw=-0.001 g_sm=+0.001 acc=1 | LR→0.147787 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.518386 step=0.004813 g_raw=-0.001 g_sm=+0.002 acc=1 | LR→0.148083 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.516440 step=0.01318 g_raw=+0.005 g_sm=+0.004 acc=1 | LR→0.148379 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.514890 step=0.002817 g_raw=+0.000 g_sm=+0.005 acc=1 | LR→0.148677 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#025 loss=0.513270 step=0.02156 g_raw=+0.009 g_sm=+0.006 acc=1 | LR→0.148974 PERT→0.140009 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1474915163, PERT_used=0.1400082287 → LR_next=0.1489743150, PERT_next=0.1400086838\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.003 acc_ratio=1.00 | LR 0.1474915163→0.1489743150 PERT 0.1400082287→0.1400086838\n",
            "Training Accuracy: 0.48\n",
            "Test Accuracy: 0.55\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.509046 step=0.0002039 g_raw=-0.001 g_sm=+0.008 acc=1 | LR→0.149273 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.508755 step=0.002174 g_raw=-0.002 g_sm=+0.007 acc=1 | LR→0.149572 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.507378 step=0.00477 g_raw=+0.000 g_sm=+0.007 acc=1 | LR→0.149871 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.504157 step=0.06185 g_raw=+0.026 g_sm=+0.009 acc=1 | LR→0.150172 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.503062 step=0.03393 g_raw=+0.014 g_sm=+0.008 acc=1 | LR→0.150473 PERT→0.140010 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1489743150, PERT_used=0.1400086838 → LR_next=0.1504726582, PERT_next=0.1400097319\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1489743150→0.1504726582 PERT 0.1400086838→0.1400097319\n",
            "Training Accuracy: 0.48\n",
            "Test Accuracy: 0.55\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.500962 step=0.0383 g_raw=+0.020 g_sm=+0.009 acc=1 | LR→0.150774 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.497802 step=0.02485 g_raw=+0.012 g_sm=+0.010 acc=1 | LR→0.151076 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.496448 step=0.01894 g_raw=+0.008 g_sm=+0.010 acc=1 | LR→0.151379 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#070 loss=0.494198 step=0.0182 g_raw=+0.007 g_sm=+0.010 acc=1 | LR→0.151682 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#075 loss=0.493276 step=0.01462 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.151986 PERT→0.140011 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1504726582, PERT_used=0.1400097319 → LR_next=0.1519863872, PERT_next=0.1400110711\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1504726582→0.1519863872 PERT 0.1400097319→0.1400110711\n",
            "Training Accuracy: 0.50\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.490214 step=0.03413 g_raw=+0.013 g_sm=+0.010 acc=1 | LR→0.152291 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.489751 step=0.02398 g_raw=+0.009 g_sm=+0.009 acc=1 | LR→0.152596 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#090 loss=0.488287 step=0.03172 g_raw=+0.012 g_sm=+0.009 acc=1 | LR→0.152902 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.484949 step=0.01063 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.153208 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.483348 step=0.003076 g_raw=-0.004 g_sm=+0.009 acc=1 | LR→0.153515 PERT→0.140012 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1519863872, PERT_used=0.1400110711 → LR_next=0.1535153524, PERT_next=0.1400124177\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1519863872→0.1535153524 PERT 0.1400110711→0.1400124177\n",
            "Training Accuracy: 0.54\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.480476 step=0.001013 g_raw=-0.003 g_sm=+0.010 acc=1 | LR→0.153823 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#110 loss=0.474311 step=0.05749 g_raw=+0.023 g_sm=+0.012 acc=1 | LR→0.154131 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.472617 step=0.04875 g_raw=+0.015 g_sm=+0.012 acc=1 | LR→0.154440 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.470631 step=0.05934 g_raw=+0.023 g_sm=+0.011 acc=1 | LR→0.154750 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#125 loss=0.469943 step=0.01746 g_raw=+0.008 g_sm=+0.010 acc=1 | LR→0.155060 PERT→0.140014 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1535153524, PERT_used=0.1400124177 → LR_next=0.1550598867, PERT_next=0.1400139342\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1535153524→0.1550598867 PERT 0.1400124177→0.1400139342\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.67\n",
            "[round 7 | client 3] final LR=0.1550598867, final PERT=0.1400139342  (ΔLR=+0.0075683704, ΔPERT=+0.0000057055)\n",
            "[round 7 | client 4] seed LR=0.1474909809 (prev=0.1549819617), seed PERT=0.1400077656 (prev=0.1400155311), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.451966 step=0.04373 g_raw=+0.014 g_sm=+0.003 acc=1 | LR→0.147786 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.445898 step=0.1078 g_raw=+0.039 g_sm=+0.006 acc=1 | LR→0.148082 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.439190 step=0.08207 g_raw=+0.028 g_sm=+0.009 acc=1 | LR→0.148379 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.437628 step=0.0129 g_raw=+0.007 g_sm=+0.009 acc=1 | LR→0.148676 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.436921 step=0.01003 g_raw=+0.005 g_sm=+0.008 acc=1 | LR→0.148974 PERT→0.140009 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1474909809, PERT_used=0.1400077656 → LR_next=0.1489742145, PERT_next=0.1400086346\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1474909809→0.1489742145 PERT 0.1400077656→0.1400086346\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.55\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.433538 step=0.03307 g_raw=+0.012 g_sm=+0.010 acc=1 | LR→0.149273 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.431139 step=0.02305 g_raw=+0.008 g_sm=+0.010 acc=1 | LR→0.149572 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.429253 step=0.03903 g_raw=+0.018 g_sm=+0.010 acc=1 | LR→0.149872 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.418523 step=0.0005459 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.150172 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.415487 step=0.02477 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.150473 PERT→0.140010 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1489742145, PERT_used=0.1400086346 → LR_next=0.1504730098, PERT_next=0.1400101043\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1489742145→0.1504730098 PERT 0.1400086346→0.1400101043\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.411825 step=0.08267 g_raw=+0.032 g_sm=+0.013 acc=1 | LR→0.150775 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.409306 step=0.02851 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.151077 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.403539 step=0.05718 g_raw=+0.022 g_sm=+0.013 acc=1 | LR→0.151380 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#070 loss=0.402057 step=0.05353 g_raw=+0.019 g_sm=+0.012 acc=1 | LR→0.151683 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#075 loss=0.398468 step=0.04195 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.151987 PERT→0.140012 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1504730098, PERT_used=0.1400101043 → LR_next=0.1519871788, PERT_next=0.1400118455\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1504730098→0.1519871788 PERT 0.1400101043→0.1400118455\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.394911 step=0.04188 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.152292 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#085 loss=0.390814 step=0.04499 g_raw=+0.017 g_sm=+0.014 acc=1 | LR→0.152597 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#090 loss=0.389733 step=0.01202 g_raw=+0.003 g_sm=+0.012 acc=1 | LR→0.152903 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#095 loss=0.388067 step=0.03864 g_raw=+0.012 g_sm=+0.011 acc=1 | LR→0.153210 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#100 loss=0.385444 step=0.01927 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.153517 PERT→0.140014 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1519871788, PERT_used=0.1400118455 → LR_next=0.1535165927, PERT_next=0.1400135942\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1519871788→0.1535165927 PERT 0.1400118455→0.1400135942\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.47\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.383764 step=0.03277 g_raw=+0.010 g_sm=+0.011 acc=1 | LR→0.153824 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#110 loss=0.383010 step=0.00717 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.154133 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#115 loss=0.382081 step=0.04481 g_raw=+0.016 g_sm=+0.009 acc=1 | LR→0.154441 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#120 loss=0.380668 step=0.01055 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.154751 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#125 loss=0.378565 step=0.004333 g_raw=-0.000 g_sm=+0.009 acc=1 | LR→0.155061 PERT→0.140015 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1535165927, PERT_used=0.1400135942 → LR_next=0.1550609802, PERT_next=0.1400149668\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1535165927→0.1550609802 PERT 0.1400135942→0.1400149668\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.49\n",
            "[round 7 | client 4] final LR=0.1550609802, final PERT=0.1400149668  (ΔLR=+0.0075699994, ΔPERT=+0.0000072012)\n",
            "\n",
            "[Round 7] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           1      0.509836      0.885000      0.155063      0.140017\n",
            "           2      0.552818      0.805000      0.155062      0.140015\n",
            "           0      0.603573      0.645000      0.155067      0.140020\n",
            "           4      0.605171      0.495000      0.155061      0.140015\n",
            "           3      0.643734      0.665000      0.155060      0.140014\n",
            "→ [Round 7] best_client=1, best_val=0.509836, prev_global_val=0.680424, improve=+0.170588, action=adopt+mix τ=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  80%|████████  | 8/10 [1:13:00<18:14, 547.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   7] acc_g=0.523 (μ=0.699, σ=0.135, FG=0.298) | t=535.232s, val=0.633 | TEL=FALSE\n",
            "[Round 8] Teleportation OFF | Aggregation=best\n",
            "[round 8 | client 0] seed LR=0.1475332838 (prev=0.1550665677), seed PERT=0.1400099247 (prev=0.1400198493), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.461078 step=0.01322 g_raw=+0.004 g_sm=+0.001 acc=1 | LR→0.147829 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#010 loss=0.454417 step=0.05441 g_raw=+0.021 g_sm=+0.005 acc=1 | LR→0.148125 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#015 loss=0.451436 step=0.01989 g_raw=+0.009 g_sm=+0.007 acc=1 | LR→0.148421 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#020 loss=0.449922 step=0.01537 g_raw=+0.009 g_sm=+0.008 acc=1 | LR→0.148719 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#025 loss=0.444163 step=0.07784 g_raw=+0.025 g_sm=+0.010 acc=1 | LR→0.149017 PERT→0.140011 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1475332838, PERT_used=0.1400099247 → LR_next=0.1490168482, PERT_next=0.1400107047\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1475332838→0.1490168482 PERT 0.1400099247→0.1400107047\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.75\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.435872 step=0.04749 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.149316 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#035 loss=0.434189 step=0.04373 g_raw=+0.010 g_sm=+0.012 acc=1 | LR→0.149615 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#040 loss=0.427286 step=0.01937 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.149915 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#045 loss=0.424001 step=0.01155 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.150215 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#050 loss=0.416968 step=0.067 g_raw=+0.023 g_sm=+0.015 acc=1 | LR→0.150516 PERT→0.140013 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1490168482, PERT_used=0.1400107047 → LR_next=0.1505164246, PERT_next=0.1400125021\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1490168482→0.1505164246 PERT 0.1400107047→0.1400125021\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.80\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.414385 step=0.01616 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.150818 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#060 loss=0.411520 step=0.03261 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.151121 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#065 loss=0.408417 step=0.0007426 g_raw=+0.003 g_sm=+0.013 acc=1 | LR→0.151423 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#070 loss=0.401228 step=0.01213 g_raw=+0.007 g_sm=+0.014 acc=1 | LR→0.151727 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#075 loss=0.398890 step=0.01942 g_raw=+0.006 g_sm=+0.014 acc=1 | LR→0.152031 PERT→0.140014 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1505164246, PERT_used=0.1400125021 → LR_next=0.1520312655, PERT_next=0.1400144597\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1505164246→0.1520312655 PERT 0.1400125021→0.1400144597\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.82\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.397609 step=0.0004944 g_raw=-0.003 g_sm=+0.012 acc=1 | LR→0.152336 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#085 loss=0.395642 step=0.06004 g_raw=+0.019 g_sm=+0.012 acc=1 | LR→0.152641 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#090 loss=0.394447 step=0.02408 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.152947 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#095 loss=0.392159 step=0.03424 g_raw=+0.010 g_sm=+0.011 acc=1 | LR→0.153254 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#100 loss=0.390594 step=0.01507 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.153561 PERT→0.140016 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1520312655, PERT_used=0.1400144597 → LR_next=0.1535609906, PERT_next=0.1400160877\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1520312655→0.1535609906 PERT 0.1400144597→0.1400160877\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.83\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.389552 step=0.0434 g_raw=+0.016 g_sm=+0.010 acc=1 | LR→0.153869 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#110 loss=0.389030 step=0.007663 g_raw=-0.000 g_sm=+0.009 acc=1 | LR→0.154177 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#115 loss=0.387941 step=0.00743 g_raw=+0.003 g_sm=+0.008 acc=1 | LR→0.154486 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#120 loss=0.384597 step=0.04588 g_raw=+0.015 g_sm=+0.009 acc=1 | LR→0.154796 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#125 loss=0.384071 step=0.004578 g_raw=+0.007 g_sm=+0.009 acc=1 | LR→0.155106 PERT→0.140017 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1535609906, PERT_used=0.1400160877 → LR_next=0.1551057292, PERT_next=0.1400173741\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1535609906→0.1551057292 PERT 0.1400160877→0.1400173741\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.83\n",
            "[round 8 | client 0] final LR=0.1551057292, final PERT=0.1400173741  (ΔLR=+0.0075724454, ΔPERT=+0.0000074494)\n",
            "[round 8 | client 1] seed LR=0.1475315886 (prev=0.1550631773), seed PERT=0.1400084649 (prev=0.1400169299), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.477761 step=0.03833 g_raw=+0.013 g_sm=+0.002 acc=1 | LR→0.147827 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#010 loss=0.473526 step=0.07645 g_raw=+0.027 g_sm=+0.006 acc=1 | LR→0.148123 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#015 loss=0.471350 step=0.02146 g_raw=+0.007 g_sm=+0.007 acc=1 | LR→0.148420 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#020 loss=0.469472 step=0.0119 g_raw=+0.005 g_sm=+0.007 acc=1 | LR→0.148717 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#025 loss=0.466560 step=0.08706 g_raw=+0.032 g_sm=+0.008 acc=1 | LR→0.149015 PERT→0.140009 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1475315886, PERT_used=0.1400084649 → LR_next=0.1490150669, PERT_next=0.1400091801\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1475315886→0.1490150669 PERT 0.1400084649→0.1400091801\n",
            "Training Accuracy: 0.42\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.460773 step=0.03433 g_raw=+0.012 g_sm=+0.010 acc=1 | LR→0.149314 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.454927 step=0.1088 g_raw=+0.039 g_sm=+0.011 acc=1 | LR→0.149613 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#040 loss=0.452220 step=0.05196 g_raw=+0.018 g_sm=+0.011 acc=1 | LR→0.149913 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#045 loss=0.448544 step=0.02167 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.150213 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.447424 step=0.03682 g_raw=+0.012 g_sm=+0.011 acc=1 | LR→0.150514 PERT→0.140011 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1490150669, PERT_used=0.1400091801 → LR_next=0.1505143141, PERT_next=0.1400106879\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1490150669→0.1505143141 PERT 0.1400091801→0.1400106879\n",
            "Training Accuracy: 0.54\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.440350 step=0.03364 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.150816 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#060 loss=0.436162 step=0.03284 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.151118 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.434566 step=0.04539 g_raw=+0.013 g_sm=+0.012 acc=1 | LR→0.151421 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#070 loss=0.432821 step=0.01454 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.151725 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#075 loss=0.428150 step=0.03097 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.152029 PERT→0.140012 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1505143141, PERT_used=0.1400106879 → LR_next=0.1520289062, PERT_next=0.1400124360\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1505143141→0.1520289062 PERT 0.1400106879→0.1400124360\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.426763 step=0.02657 g_raw=+0.010 g_sm=+0.012 acc=1 | LR→0.152334 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#085 loss=0.424651 step=0.003842 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.152639 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#090 loss=0.423860 step=0.02589 g_raw=+0.008 g_sm=+0.010 acc=1 | LR→0.152945 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#095 loss=0.419594 step=0.04523 g_raw=+0.019 g_sm=+0.011 acc=1 | LR→0.153251 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#100 loss=0.417685 step=0.005237 g_raw=+0.001 g_sm=+0.011 acc=1 | LR→0.153559 PERT→0.140014 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1520289062, PERT_used=0.1400124360 → LR_next=0.1535585327, PERT_next=0.1400139957\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1520289062→0.1535585327 PERT 0.1400124360→0.1400139957\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.74\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.416169 step=0.01125 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.153866 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#110 loss=0.413786 step=0.02334 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.154175 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#115 loss=0.413415 step=0.006284 g_raw=+0.003 g_sm=+0.009 acc=1 | LR→0.154484 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#120 loss=0.411813 step=0.02076 g_raw=+0.007 g_sm=+0.009 acc=1 | LR→0.154793 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#125 loss=0.411555 step=0.01726 g_raw=+0.007 g_sm=+0.007 acc=1 | LR→0.155103 PERT→0.140015 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1535585327, PERT_used=0.1400139957 → LR_next=0.1551033087, PERT_next=0.1400153380\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1535585327→0.1551033087 PERT 0.1400139957→0.1400153380\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.80\n",
            "[round 8 | client 1] final LR=0.1551033087, final PERT=0.1400153380  (ΔLR=+0.0075717200, ΔPERT=+0.0000068731)\n",
            "[round 8 | client 2] seed LR=0.1475308184 (prev=0.1550616367), seed PERT=0.1400077231 (prev=0.1400154463), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.486473 step=0.02732 g_raw=+0.013 g_sm=+0.006 acc=1 | LR→0.147826 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.482961 step=0.008 g_raw=+0.004 g_sm=+0.008 acc=1 | LR→0.148122 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.478677 step=0.0211 g_raw=+0.009 g_sm=+0.009 acc=1 | LR→0.148419 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.466625 step=0.02985 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.148717 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#025 loss=0.457494 step=0.05165 g_raw=+0.017 g_sm=+0.015 acc=1 | LR→0.149015 PERT→0.140009 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1475308184, PERT_used=0.1400077231 → LR_next=0.1490149186, PERT_next=0.1400090299\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1475308184→0.1490149186 PERT 0.1400077231→0.1400090299\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.80\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.455907 step=0.01572 g_raw=+0.007 g_sm=+0.014 acc=1 | LR→0.149314 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.450306 step=0.007711 g_raw=+0.000 g_sm=+0.014 acc=1 | LR→0.149613 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#040 loss=0.442907 step=0.06127 g_raw=+0.019 g_sm=+0.015 acc=1 | LR→0.149913 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#045 loss=0.438885 step=0.009806 g_raw=+0.005 g_sm=+0.015 acc=1 | LR→0.150214 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#050 loss=0.435339 step=0.03807 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.150515 PERT→0.140011 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1490149186, PERT_used=0.1400090299 → LR_next=0.1505146914, PERT_next=0.1400110280\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1490149186→0.1505146914 PERT 0.1400090299→0.1400110280\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.81\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.427985 step=0.121 g_raw=+0.044 g_sm=+0.015 acc=1 | LR→0.150816 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#060 loss=0.426257 step=0.01686 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.151119 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#065 loss=0.423289 step=0.05843 g_raw=+0.020 g_sm=+0.014 acc=1 | LR→0.151422 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#070 loss=0.416830 step=0.03251 g_raw=+0.012 g_sm=+0.015 acc=1 | LR→0.151725 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#075 loss=0.412512 step=0.004516 g_raw=+0.005 g_sm=+0.014 acc=1 | LR→0.152030 PERT→0.140013 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1505146914, PERT_used=0.1400110280 → LR_next=0.1520295516, PERT_next=0.1400130195\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1505146914→0.1520295516 PERT 0.1400110280→0.1400130195\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.75\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.410191 step=0.009415 g_raw=+0.005 g_sm=+0.014 acc=1 | LR→0.152334 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#085 loss=0.409489 step=0.002036 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.152640 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#090 loss=0.406423 step=0.01404 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.152946 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#095 loss=0.405258 step=0.00836 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.153252 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#100 loss=0.402212 step=0.001834 g_raw=-0.001 g_sm=+0.011 acc=1 | LR→0.153559 PERT→0.140015 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1520295516, PERT_used=0.1400130195 → LR_next=0.1535593350, PERT_next=0.1400147163\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1520295516→0.1535593350 PERT 0.1400130195→0.1400147163\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.398082 step=0.01255 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.153867 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#110 loss=0.396076 step=0.01427 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.154176 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#115 loss=0.393178 step=0.02332 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.154484 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#120 loss=0.390498 step=0.00689 g_raw=+0.000 g_sm=+0.011 acc=1 | LR→0.154794 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#125 loss=0.386469 step=0.02672 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.155104 PERT→0.140016 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1535593350, PERT_used=0.1400147163 → LR_next=0.1551043543, PERT_next=0.1400162711\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1535593350→0.1551043543 PERT 0.1400147163→0.1400162711\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.73\n",
            "[round 8 | client 2] final LR=0.1551043543, final PERT=0.1400162711  (ΔLR=+0.0075735359, ΔPERT=+0.0000085480)\n",
            "[round 8 | client 3] seed LR=0.1475299434 (prev=0.1550598867), seed PERT=0.1400069671 (prev=0.1400139342), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.452142 step=0.03216 g_raw=+0.010 g_sm=+0.005 acc=1 | LR→0.147825 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.444641 step=0.03888 g_raw=+0.014 g_sm=+0.008 acc=1 | LR→0.148122 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.442129 step=0.03415 g_raw=+0.012 g_sm=+0.009 acc=1 | LR→0.148418 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.435367 step=0.1155 g_raw=+0.040 g_sm=+0.011 acc=1 | LR→0.148716 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.426270 step=0.05207 g_raw=+0.019 g_sm=+0.014 acc=1 | LR→0.149014 PERT→0.140008 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1475299434, PERT_used=0.1400069671 → LR_next=0.1490138937, PERT_next=0.1400081413\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1475299434→0.1490138937 PERT 0.1400069671→0.1400081413\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.65\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.423823 step=0.01867 g_raw=+0.007 g_sm=+0.014 acc=1 | LR→0.149313 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.420001 step=0.06407 g_raw=+0.024 g_sm=+0.014 acc=1 | LR→0.149612 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.418958 step=0.02095 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.149912 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.416632 step=0.02095 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.150212 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.415681 step=0.006031 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.150513 PERT→0.140010 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1490138937, PERT_used=0.1400081413 → LR_next=0.1505134643, PERT_next=0.1400099609\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1490138937→0.1505134643 PERT 0.1400081413→0.1400099609\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.413698 step=0.04805 g_raw=+0.016 g_sm=+0.011 acc=1 | LR→0.150815 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.412119 step=0.04074 g_raw=+0.016 g_sm=+0.011 acc=1 | LR→0.151117 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.410540 step=0.03001 g_raw=+0.011 g_sm=+0.010 acc=1 | LR→0.151420 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#070 loss=0.409947 step=0.02667 g_raw=+0.008 g_sm=+0.009 acc=1 | LR→0.151724 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#075 loss=0.409075 step=0.02668 g_raw=+0.007 g_sm=+0.008 acc=1 | LR→0.152028 PERT→0.140011 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1505134643, PERT_used=0.1400099609 → LR_next=0.1520276458, PERT_next=0.1400113387\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1505134643→0.1520276458 PERT 0.1400099609→0.1400113387\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.63\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.408454 step=0.02767 g_raw=+0.010 g_sm=+0.008 acc=1 | LR→0.152332 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#085 loss=0.407718 step=0.001363 g_raw=+0.003 g_sm=+0.007 acc=1 | LR→0.152637 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#090 loss=0.406929 step=0.01412 g_raw=+0.006 g_sm=+0.007 acc=1 | LR→0.152943 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.402753 step=0.04256 g_raw=+0.015 g_sm=+0.009 acc=1 | LR→0.153250 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.401810 step=0.03586 g_raw=+0.010 g_sm=+0.008 acc=1 | LR→0.153557 PERT→0.140012 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1520276458, PERT_used=0.1400113387 → LR_next=0.1535567659, PERT_next=0.1400124482\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1520276458→0.1535567659 PERT 0.1400113387→0.1400124482\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.62\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.399561 step=0.05944 g_raw=+0.017 g_sm=+0.009 acc=1 | LR→0.153864 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#110 loss=0.398626 step=0.01784 g_raw=+0.008 g_sm=+0.009 acc=1 | LR→0.154173 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.397416 step=0.0036 g_raw=-0.002 g_sm=+0.009 acc=1 | LR→0.154482 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.396582 step=0.008012 g_raw=+0.003 g_sm=+0.008 acc=1 | LR→0.154791 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.394255 step=0.01658 g_raw=+0.004 g_sm=+0.009 acc=1 | LR→0.155101 PERT→0.140014 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1535567659, PERT_used=0.1400124482 → LR_next=0.1551013900, PERT_next=0.1400136695\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1535567659→0.1551013900 PERT 0.1400124482→0.1400136695\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.63\n",
            "[round 8 | client 3] final LR=0.1551013900, final PERT=0.1400136695  (ΔLR=+0.0075714466, ΔPERT=+0.0000067024)\n",
            "[round 8 | client 4] seed LR=0.1475304901 (prev=0.1550609802), seed PERT=0.1400074834 (prev=0.1400149668), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.479220 step=0.04792 g_raw=+0.015 g_sm=+0.003 acc=1 | LR→0.147826 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.475490 step=0.04294 g_raw=+0.017 g_sm=+0.006 acc=1 | LR→0.148122 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.467397 step=0.09975 g_raw=+0.036 g_sm=+0.009 acc=1 | LR→0.148419 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.462640 step=0.05047 g_raw=+0.017 g_sm=+0.011 acc=1 | LR→0.148716 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.455763 step=0.03796 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.149014 PERT→0.140008 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1475304901, PERT_used=0.1400074834 → LR_next=0.1490142774, PERT_next=0.1400084992\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1475304901→0.1490142774 PERT 0.1400074834→0.1400084992\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.452970 step=0.0749 g_raw=+0.026 g_sm=+0.013 acc=1 | LR→0.149313 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.447976 step=0.01242 g_raw=+0.004 g_sm=+0.013 acc=1 | LR→0.149612 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.443229 step=0.09824 g_raw=+0.034 g_sm=+0.013 acc=1 | LR→0.149912 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#045 loss=0.441359 step=0.02265 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.150213 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.440994 step=0.006082 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.150514 PERT→0.140010 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1490142774, PERT_used=0.1400084992 → LR_next=0.1505137984, PERT_next=0.1400102691\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1490142774→0.1505137984 PERT 0.1400084992→0.1400102691\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.439294 step=0.0004753 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.150815 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#060 loss=0.438281 step=0.03568 g_raw=+0.010 g_sm=+0.010 acc=1 | LR→0.151118 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.437413 step=0.005446 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.151420 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#070 loss=0.436823 step=0.01182 g_raw=+0.006 g_sm=+0.008 acc=1 | LR→0.151724 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#075 loss=0.435624 step=0.02099 g_raw=+0.006 g_sm=+0.008 acc=1 | LR→0.152028 PERT→0.140012 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1505137984, PERT_used=0.1400102691 → LR_next=0.1520279105, PERT_next=0.1400115799\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1505137984→0.1520279105 PERT 0.1400102691→0.1400115799\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.433713 step=0.01001 g_raw=+0.004 g_sm=+0.008 acc=1 | LR→0.152333 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#085 loss=0.430499 step=0.01915 g_raw=+0.009 g_sm=+0.010 acc=1 | LR→0.152638 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#090 loss=0.429748 step=0.03921 g_raw=+0.015 g_sm=+0.009 acc=1 | LR→0.152944 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.427485 step=0.06316 g_raw=+0.022 g_sm=+0.009 acc=1 | LR→0.153250 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#100 loss=0.425765 step=0.01813 g_raw=+0.004 g_sm=+0.009 acc=1 | LR→0.153557 PERT→0.140013 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1520279105, PERT_used=0.1400115799 → LR_next=0.1535571735, PERT_next=0.1400128173\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1520279105→0.1535571735 PERT 0.1400115799→0.1400128173\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.74\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.423924 step=0.06655 g_raw=+0.021 g_sm=+0.009 acc=1 | LR→0.153865 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#110 loss=0.422041 step=0.02889 g_raw=+0.009 g_sm=+0.009 acc=1 | LR→0.154173 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.420263 step=0.05347 g_raw=+0.017 g_sm=+0.009 acc=1 | LR→0.154482 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#120 loss=0.419440 step=0.009815 g_raw=+0.006 g_sm=+0.009 acc=1 | LR→0.154792 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#125 loss=0.417530 step=0.01988 g_raw=+0.006 g_sm=+0.009 acc=1 | LR→0.155102 PERT→0.140014 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1535571735, PERT_used=0.1400128173 → LR_next=0.1551018057, PERT_next=0.1400140422\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1535571735→0.1551018057 PERT 0.1400128173→0.1400140422\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.76\n",
            "[round 8 | client 4] final LR=0.1551018057, final PERT=0.1400140422  (ΔLR=+0.0075713156, ΔPERT=+0.0000065588)\n",
            "\n",
            "[Round 8] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           0      0.519544      0.830000      0.155106      0.140017\n",
            "           1      0.531717      0.800000      0.155103      0.140015\n",
            "           3      0.556867      0.630000      0.155101      0.140014\n",
            "           2      0.562305      0.730000      0.155104      0.140016\n",
            "           4      0.580533      0.760000      0.155102      0.140014\n",
            "→ [Round 8] best_client=0, best_val=0.519544, prev_global_val=0.633438, improve=+0.113894, action=adopt+mix τ=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  90%|█████████ | 9/10 [1:22:07<09:07, 547.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   8] acc_g=0.679 (μ=0.750, σ=0.069, FG=0.148) | t=537.259s, val=0.595 | TEL=FALSE\n",
            "[Round 9] Teleportation OFF | Aggregation=best\n",
            "[round 9 | client 0] seed LR=0.1475528646 (prev=0.1551057292), seed PERT=0.1400086870 (prev=0.1400173741), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.498602 step=0.0646 g_raw=+0.023 g_sm=+0.003 acc=1 | LR→0.147848 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#010 loss=0.494707 step=0.03075 g_raw=+0.011 g_sm=+0.006 acc=1 | LR→0.148144 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#015 loss=0.485664 step=0.08388 g_raw=+0.031 g_sm=+0.010 acc=1 | LR→0.148441 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#020 loss=0.481036 step=0.01546 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.148739 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#025 loss=0.477703 step=0.01781 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.149037 PERT→0.140010 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1475528646, PERT_used=0.1400086870 → LR_next=0.1490369281, PERT_next=0.1400097510\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1475528646→0.1490369281 PERT 0.1400086870→0.1400097510\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.473443 step=0.06444 g_raw=+0.023 g_sm=+0.013 acc=1 | LR→0.149336 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#035 loss=0.466183 step=0.02474 g_raw=+0.009 g_sm=+0.015 acc=1 | LR→0.149635 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#040 loss=0.463957 step=0.03147 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.149935 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#045 loss=0.460079 step=0.02914 g_raw=+0.010 g_sm=+0.014 acc=1 | LR→0.150236 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#050 loss=0.452484 step=0.0507 g_raw=+0.019 g_sm=+0.015 acc=1 | LR→0.150537 PERT→0.140012 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1490369281, PERT_used=0.1400097510 → LR_next=0.1505368815, PERT_next=0.1400117110\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1490369281→0.1505368815 PERT 0.1400097510→0.1400117110\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.448553 step=0.01407 g_raw=+0.004 g_sm=+0.015 acc=1 | LR→0.150839 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#060 loss=0.445666 step=0.03774 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.151141 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#065 loss=0.444485 step=0.02575 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.151444 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#070 loss=0.443792 step=0.003297 g_raw=+0.001 g_sm=+0.011 acc=1 | LR→0.151748 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#075 loss=0.437724 step=0.07001 g_raw=+0.022 g_sm=+0.013 acc=1 | LR→0.152052 PERT→0.140014 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1505368815, PERT_used=0.1400117110 → LR_next=0.1520518233, PERT_next=0.1400135720\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1505368815→0.1520518233 PERT 0.1400117110→0.1400135720\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.436596 step=0.04843 g_raw=+0.019 g_sm=+0.011 acc=1 | LR→0.152357 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#085 loss=0.435637 step=0.03551 g_raw=+0.013 g_sm=+0.010 acc=1 | LR→0.152662 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#090 loss=0.434080 step=0.009881 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.152968 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#095 loss=0.429976 step=0.03319 g_raw=+0.013 g_sm=+0.011 acc=1 | LR→0.153274 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#100 loss=0.427851 step=0.04379 g_raw=+0.018 g_sm=+0.011 acc=1 | LR→0.153582 PERT→0.140015 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1520518233, PERT_used=0.1400135720 → LR_next=0.1535816490, PERT_next=0.1400151031\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1520518233→0.1535816490 PERT 0.1400135720→0.1400151031\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.76\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.426718 step=0.01599 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.153889 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#110 loss=0.425544 step=0.006691 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.154198 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#115 loss=0.424489 step=0.01014 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.154507 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#120 loss=0.423484 step=0.008894 g_raw=+0.001 g_sm=+0.009 acc=1 | LR→0.154816 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#125 loss=0.420843 step=0.005271 g_raw=+0.004 g_sm=+0.009 acc=1 | LR→0.155127 PERT→0.140016 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1535816490, PERT_used=0.1400151031 → LR_next=0.1551266931, PERT_next=0.1400164777\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1535816490→0.1551266931 PERT 0.1400151031→0.1400164777\n",
            "Training Accuracy: 0.90\n",
            "Test Accuracy: 0.81\n",
            "[round 9 | client 0] final LR=0.1551266931, final PERT=0.1400164777  (ΔLR=+0.0075738285, ΔPERT=+0.0000077907)\n",
            "[round 9 | client 1] seed LR=0.1475516543 (prev=0.1551033087), seed PERT=0.1400076690 (prev=0.1400153380), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.512159 step=0.05017 g_raw=+0.021 g_sm=+0.002 acc=1 | LR→0.147847 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.508308 step=0.002985 g_raw=+0.001 g_sm=+0.005 acc=1 | LR→0.148143 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.506291 step=0.03524 g_raw=+0.015 g_sm=+0.006 acc=1 | LR→0.148440 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.497349 step=0.02277 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.148737 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.494982 step=0.04042 g_raw=+0.014 g_sm=+0.011 acc=1 | LR→0.149035 PERT→0.140009 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1475516543, PERT_used=0.1400076690 → LR_next=0.1490354764, PERT_next=0.1400085176\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1475516543→0.1490354764 PERT 0.1400076690→0.1400085176\n",
            "Training Accuracy: 0.42\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.492460 step=0.04704 g_raw=+0.018 g_sm=+0.011 acc=1 | LR→0.149334 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.488492 step=0.0471 g_raw=+0.019 g_sm=+0.012 acc=1 | LR→0.149633 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.486297 step=0.03165 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.149933 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.484709 step=0.007129 g_raw=+0.001 g_sm=+0.011 acc=1 | LR→0.150234 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.478167 step=0.08192 g_raw=+0.028 g_sm=+0.013 acc=1 | LR→0.150535 PERT→0.140010 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1490354764, PERT_used=0.1400085176 → LR_next=0.1505350478, PERT_next=0.1400101359\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1490354764→0.1505350478 PERT 0.1400085176→0.1400101359\n",
            "Training Accuracy: 0.44\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.473783 step=0.0399 g_raw=+0.015 g_sm=+0.014 acc=1 | LR→0.150837 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#060 loss=0.471287 step=0.01445 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.151139 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.461467 step=0.07288 g_raw=+0.025 g_sm=+0.016 acc=1 | LR→0.151442 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#070 loss=0.457490 step=0.07582 g_raw=+0.028 g_sm=+0.016 acc=1 | LR→0.151746 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#075 loss=0.455528 step=0.01192 g_raw=+0.008 g_sm=+0.015 acc=1 | LR→0.152050 PERT→0.140012 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1505350478, PERT_used=0.1400101359 → LR_next=0.1520501867, PERT_next=0.1400121954\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1505350478→0.1520501867 PERT 0.1400101359→0.1400121954\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.452000 step=0.0216 g_raw=+0.009 g_sm=+0.015 acc=1 | LR→0.152355 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#085 loss=0.448134 step=0.008318 g_raw=-0.001 g_sm=+0.014 acc=1 | LR→0.152660 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#090 loss=0.441333 step=0.09574 g_raw=+0.036 g_sm=+0.015 acc=1 | LR→0.152967 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#095 loss=0.436494 step=0.01913 g_raw=+0.005 g_sm=+0.015 acc=1 | LR→0.153273 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#100 loss=0.435779 step=0.009024 g_raw=+0.003 g_sm=+0.013 acc=1 | LR→0.153581 PERT→0.140014 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1520501867, PERT_used=0.1400121954 → LR_next=0.1535805193, PERT_next=0.1400142036\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1520501867→0.1535805193 PERT 0.1400121954→0.1400142036\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.431008 step=0.09319 g_raw=+0.035 g_sm=+0.013 acc=1 | LR→0.153888 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#110 loss=0.425498 step=0.08275 g_raw=+0.028 g_sm=+0.014 acc=1 | LR→0.154197 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#115 loss=0.422331 step=0.05951 g_raw=+0.023 g_sm=+0.014 acc=1 | LR→0.154506 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#120 loss=0.418660 step=7.602e-05 g_raw=-0.001 g_sm=+0.013 acc=1 | LR→0.154816 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#125 loss=0.416846 step=0.032 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.155126 PERT→0.140016 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1535805193, PERT_used=0.1400142036 → LR_next=0.1551260645, PERT_next=0.1400160407\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1535805193→0.1551260645 PERT 0.1400142036→0.1400160407\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.70\n",
            "[round 9 | client 1] final LR=0.1551260645, final PERT=0.1400160407  (ΔLR=+0.0075744102, ΔPERT=+0.0000083717)\n",
            "[round 9 | client 2] seed LR=0.1475521771 (prev=0.1551043543), seed PERT=0.1400081356 (prev=0.1400162711), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.567460 step=0.02625 g_raw=+0.011 g_sm=+0.006 acc=1 | LR→0.147848 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.563713 step=0.04387 g_raw=+0.018 g_sm=+0.008 acc=1 | LR→0.148144 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.554237 step=0.0872 g_raw=+0.035 g_sm=+0.011 acc=1 | LR→0.148441 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#020 loss=0.545934 step=0.008479 g_raw=+0.003 g_sm=+0.014 acc=1 | LR→0.148738 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#025 loss=0.536058 step=0.09318 g_raw=+0.036 g_sm=+0.016 acc=1 | LR→0.149036 PERT→0.140009 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1475521771, PERT_used=0.1400081356 → LR_next=0.1490364960, PERT_next=0.1400094459\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.022 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1475521771→0.1490364960 PERT 0.1400081356→0.1400094459\n",
            "Training Accuracy: 0.46\n",
            "Test Accuracy: 0.45\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.530419 step=0.07569 g_raw=+0.028 g_sm=+0.017 acc=1 | LR→0.149335 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#035 loss=0.519757 step=0.05301 g_raw=+0.024 g_sm=+0.019 acc=1 | LR→0.149635 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#040 loss=0.505860 step=0.06848 g_raw=+0.027 g_sm=+0.021 acc=1 | LR→0.149935 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#045 loss=0.504433 step=0.05797 g_raw=+0.019 g_sm=+0.018 acc=1 | LR→0.150236 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#050 loss=0.495246 step=0.1059 g_raw=+0.042 g_sm=+0.019 acc=1 | LR→0.150537 PERT→0.140012 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1490364960, PERT_used=0.1400094459 → LR_next=0.1505370867, PERT_next=0.1400120027\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1490364960→0.1505370867 PERT 0.1400094459→0.1400120027\n",
            "Training Accuracy: 0.56\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.493348 step=0.002061 g_raw=+0.002 g_sm=+0.016 acc=1 | LR→0.150839 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#060 loss=0.486294 step=0.089 g_raw=+0.033 g_sm=+0.018 acc=1 | LR→0.151141 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#065 loss=0.483768 step=0.0327 g_raw=+0.009 g_sm=+0.016 acc=1 | LR→0.151445 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#070 loss=0.480278 step=0.06513 g_raw=+0.025 g_sm=+0.016 acc=1 | LR→0.151748 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#075 loss=0.479074 step=0.04 g_raw=+0.014 g_sm=+0.014 acc=1 | LR→0.152052 PERT→0.140014 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1505370867, PERT_used=0.1400120027 → LR_next=0.1520524810, PERT_next=0.1400142785\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1505370867→0.1520524810 PERT 0.1400120027→0.1400142785\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.476837 step=0.01629 g_raw=+0.005 g_sm=+0.013 acc=1 | LR→0.152357 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#085 loss=0.476495 step=0.009538 g_raw=-0.001 g_sm=+0.011 acc=1 | LR→0.152663 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#090 loss=0.476405 step=0.008726 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.152969 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#095 loss=0.474560 step=0.01693 g_raw=+0.003 g_sm=+0.009 acc=1 | LR→0.153275 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#100 loss=0.473067 step=0.04683 g_raw=+0.018 g_sm=+0.009 acc=1 | LR→0.153582 PERT→0.140016 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1520524810, PERT_used=0.1400142785 → LR_next=0.1535822332, PERT_next=0.1400157365\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1520524810→0.1535822332 PERT 0.1400142785→0.1400157365\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.57\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.471384 step=0.04443 g_raw=+0.017 g_sm=+0.009 acc=1 | LR→0.153890 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#110 loss=0.468848 step=0.0137 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.154198 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#115 loss=0.463675 step=0.08605 g_raw=+0.031 g_sm=+0.012 acc=1 | LR→0.154507 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#120 loss=0.463228 step=0.02368 g_raw=+0.007 g_sm=+0.010 acc=1 | LR→0.154817 PERT→0.140017 (scale=0.04)\n",
            "[meta] cb#125 loss=0.461638 step=0.01211 g_raw=+0.007 g_sm=+0.010 acc=1 | LR→0.155127 PERT→0.140017 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1535822332, PERT_used=0.1400157365 → LR_next=0.1551273136, PERT_next=0.1400171385\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1535822332→0.1551273136 PERT 0.1400157365→0.1400171385\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.57\n",
            "[round 9 | client 2] final LR=0.1551273136, final PERT=0.1400171385  (ΔLR=+0.0075751364, ΔPERT=+0.0000090030)\n",
            "[round 9 | client 3] seed LR=0.1475506950 (prev=0.1551013900), seed PERT=0.1400068348 (prev=0.1400136695), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.527049 step=0.01841 g_raw=+0.012 g_sm=+0.003 acc=1 | LR→0.147846 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.524615 step=0.001185 g_raw=-0.004 g_sm=+0.005 acc=1 | LR→0.148142 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.522537 step=0.05224 g_raw=+0.022 g_sm=+0.006 acc=1 | LR→0.148439 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.517903 step=0.08125 g_raw=+0.032 g_sm=+0.008 acc=1 | LR→0.148736 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.512209 step=0.05064 g_raw=+0.022 g_sm=+0.010 acc=1 | LR→0.149034 PERT→0.140008 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1475506950, PERT_used=0.1400068348 → LR_next=0.1490344673, PERT_next=0.1400076456\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1475506950→0.1490344673 PERT 0.1400068348→0.1400076456\n",
            "Training Accuracy: 0.44\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.505062 step=0.06652 g_raw=+0.027 g_sm=+0.012 acc=1 | LR→0.149333 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.501707 step=0.03881 g_raw=+0.014 g_sm=+0.013 acc=1 | LR→0.149633 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.490714 step=0.0556 g_raw=+0.021 g_sm=+0.015 acc=1 | LR→0.149933 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.480983 step=0.012 g_raw=+0.006 g_sm=+0.017 acc=1 | LR→0.150233 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.469503 step=0.06238 g_raw=+0.024 g_sm=+0.019 acc=1 | LR→0.150535 PERT→0.140010 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1490344673, PERT_used=0.1400076456 → LR_next=0.1505345201, PERT_next=0.1400097211\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1490344673→0.1505345201 PERT 0.1400076456→0.1400097211\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.460048 step=0.02735 g_raw=+0.009 g_sm=+0.019 acc=1 | LR→0.150836 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.456124 step=0.05004 g_raw=+0.015 g_sm=+0.018 acc=1 | LR→0.151139 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.445398 step=0.05653 g_raw=+0.020 g_sm=+0.019 acc=1 | LR→0.151442 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#070 loss=0.441917 step=0.05509 g_raw=+0.023 g_sm=+0.018 acc=1 | LR→0.151746 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#075 loss=0.435411 step=0.06104 g_raw=+0.021 g_sm=+0.018 acc=1 | LR→0.152050 PERT→0.140012 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1505345201, PERT_used=0.1400097211 → LR_next=0.1520502612, PERT_next=0.1400123400\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1505345201→0.1520502612 PERT 0.1400097211→0.1400123400\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.76\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.431651 step=0.01587 g_raw=+0.003 g_sm=+0.017 acc=1 | LR→0.152355 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#085 loss=0.421926 step=0.05644 g_raw=+0.018 g_sm=+0.018 acc=1 | LR→0.152661 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#090 loss=0.419892 step=0.01676 g_raw=+0.009 g_sm=+0.016 acc=1 | LR→0.152967 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#095 loss=0.414482 step=0.02392 g_raw=+0.007 g_sm=+0.017 acc=1 | LR→0.153274 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#100 loss=0.412890 step=0.05291 g_raw=+0.017 g_sm=+0.015 acc=1 | LR→0.153581 PERT→0.140015 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1520502612, PERT_used=0.1400123400 → LR_next=0.1535810308, PERT_next=0.1400147459\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1520502612→0.1535810308 PERT 0.1400123400→0.1400147459\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.80\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.406266 step=0.09014 g_raw=+0.031 g_sm=+0.016 acc=1 | LR→0.153889 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#110 loss=0.404445 step=0.02034 g_raw=+0.007 g_sm=+0.014 acc=1 | LR→0.154198 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#115 loss=0.401938 step=0.0524 g_raw=+0.012 g_sm=+0.013 acc=1 | LR→0.154507 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#120 loss=0.401650 step=0.01234 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.154816 PERT→0.140016 (scale=0.04)\n",
            "[meta] cb#125 loss=0.401209 step=0.003049 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.155127 PERT→0.140017 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1535810308, PERT_used=0.1400147459 → LR_next=0.1551266313, PERT_next=0.1400166283\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1535810308→0.1551266313 PERT 0.1400147459→0.1400166283\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.79\n",
            "[round 9 | client 3] final LR=0.1551266313, final PERT=0.1400166283  (ΔLR=+0.0075759363, ΔPERT=+0.0000097935)\n",
            "[round 9 | client 4] seed LR=0.1475509029 (prev=0.1551018057), seed PERT=0.1400070211 (prev=0.1400140422), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.486218 step=0.08267 g_raw=+0.031 g_sm=+0.004 acc=1 | LR→0.147846 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.480548 step=0.0002369 g_raw=-0.001 g_sm=+0.007 acc=1 | LR→0.148143 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.476817 step=0.05066 g_raw=+0.017 g_sm=+0.009 acc=1 | LR→0.148439 PERT→0.140007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.469194 step=0.04259 g_raw=+0.014 g_sm=+0.012 acc=1 | LR→0.148737 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.466667 step=0.03441 g_raw=+0.011 g_sm=+0.011 acc=1 | LR→0.149035 PERT→0.140008 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1475509029, PERT_used=0.1400070211 → LR_next=0.1490349713, PERT_next=0.1400081083\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1475509029→0.1490349713 PERT 0.1400070211→0.1400081083\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.65\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.466466 step=0.0006571 g_raw=+0.001 g_sm=+0.009 acc=1 | LR→0.149334 PERT→0.140008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.461087 step=0.02576 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.149633 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.459296 step=0.002546 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.149933 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.452523 step=0.0228 g_raw=+0.006 g_sm=+0.013 acc=1 | LR→0.150233 PERT→0.140009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.448804 step=0.08606 g_raw=+0.034 g_sm=+0.013 acc=1 | LR→0.150534 PERT→0.140010 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1490349713, PERT_used=0.1400081083 → LR_next=0.1505344700, PERT_next=0.1400096637\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1490349713→0.1505344700 PERT 0.1400081083→0.1400096637\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.443859 step=0.01616 g_raw=+0.003 g_sm=+0.013 acc=1 | LR→0.150836 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.438541 step=0.08028 g_raw=+0.030 g_sm=+0.014 acc=1 | LR→0.151139 PERT→0.140010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.431120 step=0.08598 g_raw=+0.032 g_sm=+0.016 acc=1 | LR→0.151442 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#070 loss=0.426668 step=0.05964 g_raw=+0.019 g_sm=+0.016 acc=1 | LR→0.151745 PERT→0.140011 (scale=0.04)\n",
            "[meta] cb#075 loss=0.424506 step=0.03006 g_raw=+0.010 g_sm=+0.014 acc=1 | LR→0.152050 PERT→0.140012 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1505344700, PERT_used=0.1400096637 → LR_next=0.1520495310, PERT_next=0.1400116568\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1505344700→0.1520495310 PERT 0.1400096637→0.1400116568\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.422544 step=0.01221 g_raw=+0.003 g_sm=+0.013 acc=1 | LR→0.152354 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#085 loss=0.417857 step=0.006215 g_raw=-0.001 g_sm=+0.013 acc=1 | LR→0.152660 PERT→0.140012 (scale=0.04)\n",
            "[meta] cb#090 loss=0.411388 step=0.0708 g_raw=+0.025 g_sm=+0.015 acc=1 | LR→0.152966 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#095 loss=0.408100 step=0.0489 g_raw=+0.017 g_sm=+0.015 acc=1 | LR→0.153273 PERT→0.140013 (scale=0.04)\n",
            "[meta] cb#100 loss=0.405632 step=0.04532 g_raw=+0.016 g_sm=+0.014 acc=1 | LR→0.153580 PERT→0.140014 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1520495310, PERT_used=0.1400116568 → LR_next=0.1535798043, PERT_next=0.1400136169\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1520495310→0.1535798043 PERT 0.1400116568→0.1400136169\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.402418 step=0.03062 g_raw=+0.014 g_sm=+0.013 acc=1 | LR→0.153888 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#110 loss=0.395507 step=0.04061 g_raw=+0.013 g_sm=+0.015 acc=1 | LR→0.154196 PERT→0.140014 (scale=0.04)\n",
            "[meta] cb#115 loss=0.392420 step=0.03348 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.154505 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#120 loss=0.389437 step=0.04037 g_raw=+0.017 g_sm=+0.014 acc=1 | LR→0.154815 PERT→0.140015 (scale=0.04)\n",
            "[meta] cb#125 loss=0.387743 step=0.03236 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.155125 PERT→0.140016 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1535798043, PERT_used=0.1400136169 → LR_next=0.1551254704, PERT_next=0.1400155696\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1535798043→0.1551254704 PERT 0.1400136169→0.1400155696\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.70\n",
            "[round 9 | client 4] final LR=0.1551254704, final PERT=0.1400155696  (ΔLR=+0.0075745676, ΔPERT=+0.0000085485)\n",
            "\n",
            "[Round 9] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           3      0.553647      0.790000      0.155127      0.140017\n",
            "           4      0.570909      0.705000      0.155125      0.140016\n",
            "           1      0.580722      0.700000      0.155126      0.140016\n",
            "           0      0.587705      0.805000      0.155127      0.140016\n",
            "           2      0.663505      0.575000      0.155127      0.140017\n",
            "→ [Round 9] best_client=3, best_val=0.553647, prev_global_val=0.595223, improve=+0.041576, action=adopt+mix τ=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 10/10 [1:31:15<00:00, 547.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   9] acc_g=0.875 (μ=0.715, σ=0.082, FG=0.174) | t=537.524s, val=0.573 | TEL=FALSE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 650x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 650x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 650x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from training.loop import run_federated_training\n",
        "from configs.base_config import use_teleportation as CFG_TEL, noise_preset, shots_used,aggregation\n",
        "from training.metrics import metrics_init, metrics_log_round, metrics_finalize, compute_auc,metrics_summarize\n",
        "from viz.plots import plot_accuracy_curve, plot_val_loss, plot_time_per_round, plot_fidelity_vs_delta_acc, plot_beta_hist, plot_client_fairness_last_round\n",
        "# Initialize metrics store once\n",
        "metrics_store = metrics_init(\n",
        "    log_path=os.path.join(drive_root, \"teleport_metrics_Perturb_shrink.csv\")\n",
        ")\n",
        "\n",
        "#new\n",
        "from ml import optimizers as mlopt\n",
        "from configs.base_config import drive_root\n",
        "import os\n",
        "\n",
        "mlopt.meta_trace_enable(\n",
        "    path=os.path.join(drive_root, \"meta_trace.csv\"),  # or None to skip CSV\n",
        "    every=5                                           # print every 5 callbacks\n",
        ")\n",
        "\n",
        "###########\n",
        "global_acc, clients_train, clients_test, round_times, val_losses, info_last = run_federated_training(\n",
        "    clients=clients,\n",
        "    num_federated_layers=num_federated_layers,\n",
        "    num_deep_unfolding_iterations=num_deep_unfolding_iterations,\n",
        "    initial_learning_rate=initial_learning_rate,\n",
        "    initial_perturbation=initial_perturbation,\n",
        "    num_features=num_features,\n",
        "    best_client_csv_file=best_client_csv_file,\n",
        "    global_csv_file=global_csv_file,\n",
        "    local_csv_file=local_csv_file,\n",
        "    validation_csv_file=validation_csv_file,\n",
        "    test_sequences=test_sequences,\n",
        "    test_labels=test_labels,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    use_teleportation=CFG_TEL,          # ← important\n",
        "    noise_preset=noise_preset,\n",
        "    shots_used=shots_used,\n",
        "    metrics=metrics_store,   # <-- pass it in\n",
        "    aggregation=aggregation           # <--- switch here\n",
        ")\n",
        "\n",
        "rows_np = metrics_finalize(metrics_store)   # if you need the in-memory array\n",
        "#summary = metrics_summarize(metrics_store)  # prints a concise summary, returns a dict\n",
        "\n",
        "# quick visuals\n",
        "rounds = list(range(len(global_acc)))\n",
        "plot_accuracy_curve(rounds, global_acc, label=\"Global accuracy (DT-DUQFL)\")\n",
        "plot_val_loss(rounds, val_losses, label=\"Central validation loss\")\n",
        "plot_time_per_round(rounds, round_times)\n",
        "\n",
        "if info_last is not None:\n",
        "    # this uses \"last\" round's info; in your logger you kept per-round arrays; adapt if needed\n",
        "    pass\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}