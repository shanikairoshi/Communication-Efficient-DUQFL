{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shanikairoshi/Communication-Efficient-DUQFL/blob/main/main_v2_0.1initials.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bee84f36",
      "metadata": {
        "id": "bee84f36"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bc18ac0f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc18ac0f",
        "outputId": "df4481ea-c2a7-4af6-c4bc-75b584cad286"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: genomic-benchmarks in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: biopython>=1.79 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (1.85)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (2.32.4)\n",
            "Requirement already satisfied: pip>=20.0.1 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (24.1.2)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (4.67.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (6.0.3)\n",
            "Requirement already satisfied: gdown>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (5.2.0)\n",
            "Requirement already satisfied: yarl in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (1.20.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown>=4.2.0->genomic-benchmarks) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown>=4.2.0->genomic-benchmarks) (3.19.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->genomic-benchmarks) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->genomic-benchmarks) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->genomic-benchmarks) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->genomic-benchmarks) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->genomic-benchmarks) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->genomic-benchmarks) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->genomic-benchmarks) (2025.8.3)\n",
            "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.12/dist-packages (from yarl->genomic-benchmarks) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from yarl->genomic-benchmarks) (0.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.4->genomic-benchmarks) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown>=4.2.0->genomic-benchmarks) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown>=4.2.0->genomic-benchmarks) (4.15.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=4.2.0->genomic-benchmarks) (1.7.1)\n",
            "Requirement already satisfied: qiskit in /usr/local/lib/python3.12/dist-packages (1.4.4)\n",
            "Requirement already satisfied: qiskit_machine_learning in /usr/local/lib/python3.12/dist-packages (0.8.4)\n",
            "Requirement already satisfied: qiskit_algorithms in /usr/local/lib/python3.12/dist-packages (0.4.0)\n",
            "Requirement already satisfied: qiskit-aer in /usr/local/lib/python3.12/dist-packages (0.17.2)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.17.1)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.12/dist-packages (from qiskit) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.12/dist-packages (from qiskit) (1.15.3)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.12/dist-packages (from qiskit) (1.13.3)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.3.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from qiskit) (2.9.0.post0)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from qiskit) (5.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qiskit) (4.15.0)\n",
            "Requirement already satisfied: symengine<0.14,>=0.11 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.13.0)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.12/dist-packages (from qiskit_machine_learning) (1.6.1)\n",
            "Requirement already satisfied: setuptools>=40.1 in /usr/local/lib/python3.12/dist-packages (from qiskit_machine_learning) (75.2.0)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.12/dist-packages (from qiskit-aer) (5.9.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->qiskit_machine_learning) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->qiskit_machine_learning) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# %%capture\n",
        "!pip install genomic-benchmarks\n",
        "!pip install qiskit qiskit_machine_learning qiskit_algorithms qiskit-aer\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2d53c335",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d53c335",
        "outputId": "80ff146c-c3c7-4c6a-d638-bfe88cf35d7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5291b3a7",
      "metadata": {
        "id": "5291b3a7"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "PROJ = Path.cwd() / \"tduqfl_Project_AGG\"\n",
        "if str(PROJ) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJ))\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Teleportation/tduqfl_Project_AGG/tDuQFL_Project')\n",
        "# ─── 5. Assemble filenames for each artifact ─────────────────────────────────\n",
        "#drive_root = \"/content/drive/MyDrive/Teleportation/tduqfl_Project_AGG/tDuQFL_Project/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c245a1fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c245a1fd",
        "outputId": "861887cf-4cd2-4834-9060-4d3eeb3ce7d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/genomic_benchmarks/utils/datasets.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Python: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "Qiskit: 1.4.4\n",
            "qiskit_aer available?: True\n"
          ]
        }
      ],
      "source": [
        "from common.imports import *\n",
        "from configs.dataset_genome_iid import *     # swap to other configs as needed\n",
        "from io_utils.naming import stamp_now, flags, build_param_str, make_filenames\n",
        "\n",
        "start_str, date_str = stamp_now()\n",
        "teleport_pl, noise_pl = flags(use_teleportation, use_noise)\n",
        "param_str = build_param_str(num_clients, num_federated_layers, num_deep_unfolding_iterations,\n",
        "                            initial_learning_rate, initial_perturbation)\n",
        "\n",
        "best_client_csv_file, global_csv_file, local_csv_file, validation_csv_file = make_filenames(\n",
        "    drive_root, dataset_name, split_type, date_str, teleport_pl, noise_pl, param_str\n",
        ")\n",
        "from io_utils.csv_logger import init_local_csv, init_best_csv, init_validation_csv\n",
        "\n",
        "# Create folders + write headers\n",
        "init_best_csv(best_client_csv_file)\n",
        "\n",
        "local_headers = [\n",
        "    \"Federated Round\", \"Client Number\", \"Iteration\",\n",
        "    \"Objective Function Value\", \"Training Accuracy\", \"Test Accuracy\",\n",
        "    \"Learning Rate\", \"Perturbation\"\n",
        "]\n",
        "init_local_csv(local_csv_file, local_headers)\n",
        "\n",
        "init_validation_csv(validation_csv_file)\n",
        "\n",
        "# Do NOT pre-init global_csv_file here because your save_accuracies_to_csv()\n",
        "# already writes the header each time it runs (in 'w' mode)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "324178e0",
      "metadata": {
        "id": "324178e0"
      },
      "source": [
        "Load and Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d512e2a5",
      "metadata": {
        "id": "d512e2a5"
      },
      "outputs": [],
      "source": [
        "from data.preprocess_genome import load_and_prepare_dataset\n",
        "from data.splitters import split_dataset_for_epochs\n",
        "from configs.base_config import (\n",
        "    num_clients, num_epochs, samples_per_epoch, split_type,\n",
        "    global_seed\n",
        ")\n",
        "\n",
        "np_train_data, np_test_data = load_and_prepare_dataset(word_size, global_seed)\n",
        "\n",
        "# 2) Compute feasible epoch capacity and cap both epochs and rounds\n",
        "N_train = len(np_train_data)\n",
        "train_capacity = N_train // (num_clients * samples_per_epoch)\n",
        "num_epochs_eff = max(1, min(num_epochs, train_capacity))\n",
        "\n",
        "if train_capacity == 0:\n",
        "    raise ValueError(\n",
        "        f\"Not enough training samples ({N_train}) for \"\n",
        "        f\"{num_clients=} × {samples_per_epoch=} per epoch. \"\n",
        "        \"Reduce samples_per_epoch or num_clients, or enable resampling.\"\n",
        "    )\n",
        "\n",
        "num_federated_layers_eff = min(num_federated_layers, num_epochs_eff)\n",
        "\n",
        "# Build clients\n",
        "if split_type.lower() == \"iid\":\n",
        "    from data.splitters import split_dataset_for_epochs\n",
        "    clients = split_dataset_for_epochs(\n",
        "        num_clients=num_clients,\n",
        "        num_epochs=num_epochs_eff,             # or num_epochs\n",
        "        train_data=np_train_data,\n",
        "        test_data=np_test_data,\n",
        "        samples_per_epoch=samples_per_epoch,\n",
        "    )\n",
        "elif split_type.lower() in {\"noniid\", \"non-iid\", \"non_iid\"}:\n",
        "    from data.noniid import make_non_iid_clients\n",
        "    clients = make_non_iid_clients(\n",
        "        train_data=np_train_data,\n",
        "        test_data=np_test_data,\n",
        "        num_clients=num_clients,\n",
        "        num_epochs=num_epochs_eff,             # or num_epochs\n",
        "        samples_per_epoch=samples_per_epoch,\n",
        "        non_iid_ratio=0.8,                     # tune as needed\n",
        "        quantity_variation=0.5,                # tune as needed\n",
        "        seed=global_seed,\n",
        "        plot=True\n",
        "    )\n",
        "else:\n",
        "    raise ValueError(f\"Unknown split_type: {split_type}\")\n",
        "\n",
        "'''\n",
        "clients = split_dataset_for_epochs(\n",
        "    num_clients=num_clients, num_epochs=num_epochs,\n",
        "    train_data=np_train_data, test_data=np_test_data,\n",
        "    samples_per_epoch=samples_per_epoch\n",
        ")\n",
        "'''\n",
        "# validation/tables\n",
        "test_sequences = np.array([d[\"sequence\"] for d in np_test_data])\n",
        "test_labels    = np.array([d[\"label\"]    for d in np_test_data])\n",
        "X_val, y_val   = test_sequences, test_labels\n",
        "\n",
        "# derive num_features once\n",
        "if clients and clients[0].data and clients[0].data[0]:\n",
        "    num_features = clients[0].data[0][0]['sequence'].shape[0]\n",
        "else:\n",
        "    raise RuntimeError(\"Empty client data – check splitting indices.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cf7dd9c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf7dd9c0",
        "outputId": "c9f2c55c-a481-4dc0-caae-2850f2f048a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] num_features = 5\n"
          ]
        }
      ],
      "source": [
        "# Infer num_features from the first available sample in clients\n",
        "def infer_num_features_from_clients(clients):\n",
        "    for c in clients:\n",
        "        for epoch_data in c.data:              # list of samples for that epoch\n",
        "            if not epoch_data:\n",
        "                continue\n",
        "            sample = epoch_data[0]\n",
        "            if \"sequence\" in sample:           # your Genome pipeline\n",
        "                arr = np.asarray(sample[\"sequence\"])\n",
        "                return int(arr.size)\n",
        "            if \"features\" in sample:           # some other pipelines\n",
        "                arr = np.asarray(sample[\"features\"])\n",
        "                return int(arr.size)\n",
        "            if \"image\" in sample:              # e.g., MNIST before flatten\n",
        "                arr = np.asarray(sample[\"image\"]).reshape(-1)\n",
        "                return int(arr.size)\n",
        "            # add any other key you use\n",
        "    raise RuntimeError(\"Could not infer num_features: no samples found.\")\n",
        "\n",
        "num_features = infer_num_features_from_clients(clients)\n",
        "print(f\"[info] num_features = {num_features}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d847bd00",
      "metadata": {
        "id": "d847bd00"
      },
      "source": [
        "run federated loop and plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bbc26297",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bbc26297",
        "outputId": "06d8f24b-effd-4f9f-ec5e-6fe663dca4ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 0] Teleportation OFF | Aggregation=best\n",
            "[round 0 | client 0] seed LR=0.1000000000 (prev=0.1000000000), seed PERT=0.1000000000 (prev=0.1000000000), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.541585 step=0.008759 g_raw=+0.004 g_sm=+0.002 acc=1 | LR→0.100200 PERT→0.100000 (scale=0.04)\n",
            "[meta] cb#010 loss=0.532662 step=0.03616 g_raw=+0.018 g_sm=+0.007 acc=1 | LR→0.100401 PERT→0.100000 (scale=0.04)\n",
            "[meta] cb#015 loss=0.531436 step=0.02267 g_raw=+0.011 g_sm=+0.007 acc=1 | LR→0.100602 PERT→0.100000 (scale=0.04)\n",
            "[meta] cb#020 loss=0.524800 step=0.08009 g_raw=+0.043 g_sm=+0.011 acc=1 | LR→0.100804 PERT→0.100000 (scale=0.04)\n",
            "[meta] cb#025 loss=0.524237 step=0.02262 g_raw=+0.012 g_sm=+0.010 acc=1 | LR→0.101006 PERT→0.100001 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1000000000, PERT_used=0.1000000000 → LR_next=0.1010056524, PERT_next=0.1000006294\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1000000000→0.1010056524 PERT 0.1000000000→0.1000006294\n",
            "Training Accuracy: 0.36\n",
            "Test Accuracy: 0.38\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.522781 step=0.01612 g_raw=+0.008 g_sm=+0.010 acc=1 | LR→0.101208 PERT→0.100001 (scale=0.04)\n",
            "[meta] cb#035 loss=0.517770 step=0.03704 g_raw=+0.019 g_sm=+0.012 acc=1 | LR→0.101411 PERT→0.100001 (scale=0.04)\n",
            "[meta] cb#040 loss=0.515873 step=0.04978 g_raw=+0.026 g_sm=+0.012 acc=1 | LR→0.101614 PERT→0.100001 (scale=0.04)\n",
            "[meta] cb#045 loss=0.514619 step=0.01619 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.101818 PERT→0.100002 (scale=0.04)\n",
            "[meta] cb#050 loss=0.511597 step=0.04618 g_raw=+0.025 g_sm=+0.012 acc=1 | LR→0.102022 PERT→0.100002 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1010056524, PERT_used=0.1000006294 → LR_next=0.1020219082, PERT_next=0.1000017391\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1010056524→0.1020219082 PERT 0.1000006294→0.1000017391\n",
            "Training Accuracy: 0.36\n",
            "Test Accuracy: 0.38\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.506409 step=0.008762 g_raw=+0.004 g_sm=+0.013 acc=1 | LR→0.102226 PERT→0.100002 (scale=0.04)\n",
            "[meta] cb#060 loss=0.505162 step=0.03837 g_raw=+0.019 g_sm=+0.012 acc=1 | LR→0.102431 PERT→0.100002 (scale=0.04)\n",
            "[meta] cb#065 loss=0.499816 step=0.03906 g_raw=+0.019 g_sm=+0.015 acc=1 | LR→0.102637 PERT→0.100003 (scale=0.04)\n",
            "[meta] cb#070 loss=0.498314 step=0.0009943 g_raw=-0.000 g_sm=+0.013 acc=1 | LR→0.102842 PERT→0.100003 (scale=0.04)\n",
            "[meta] cb#075 loss=0.492665 step=0.03534 g_raw=+0.018 g_sm=+0.015 acc=1 | LR→0.103049 PERT→0.100003 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1020219082, PERT_used=0.1000017391 → LR_next=0.1030486348, PERT_next=0.1000030873\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1020219082→0.1030486348 PERT 0.1000017391→0.1000030873\n",
            "Training Accuracy: 0.46\n",
            "Test Accuracy: 0.45\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.488973 step=0.01645 g_raw=+0.008 g_sm=+0.015 acc=1 | LR→0.103255 PERT→0.100003 (scale=0.04)\n",
            "[meta] cb#085 loss=0.486517 step=0.003062 g_raw=+0.001 g_sm=+0.014 acc=1 | LR→0.103462 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#090 loss=0.482354 step=0.01774 g_raw=+0.010 g_sm=+0.015 acc=1 | LR→0.103670 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#095 loss=0.480546 step=0.01417 g_raw=+0.007 g_sm=+0.014 acc=1 | LR→0.103878 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#100 loss=0.479070 step=0.04003 g_raw=+0.019 g_sm=+0.013 acc=1 | LR→0.104086 PERT→0.100005 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1030486348, PERT_used=0.1000030873 → LR_next=0.1040857886, PERT_next=0.1000045265\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1030486348→0.1040857886 PERT 0.1000030873→0.1000045265\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.475622 step=0.02985 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.104294 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#110 loss=0.473207 step=0.06299 g_raw=+0.036 g_sm=+0.013 acc=1 | LR→0.104503 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#115 loss=0.470762 step=0.0288 g_raw=+0.014 g_sm=+0.013 acc=1 | LR→0.104713 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#120 loss=0.469493 step=0.009137 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.104923 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#125 loss=0.469103 step=0.01575 g_raw=+0.011 g_sm=+0.011 acc=1 | LR→0.105133 PERT→0.100006 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1040857886, PERT_used=0.1000045265 → LR_next=0.1051331663, PERT_next=0.1000057612\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1040857886→0.1051331663 PERT 0.1000045265→0.1000057612\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.59\n",
            "[round 0 | client 0] final LR=0.1051331663, final PERT=0.1000057612  (ΔLR=+0.0051331663, ΔPERT=+0.0000057612)\n",
            "[round 0 | client 1] seed LR=0.1000000000 (prev=0.1000000000), seed PERT=0.1000000000 (prev=0.1000000000), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.498151 step=0.127 g_raw=+0.071 g_sm=+0.007 acc=1 | LR→0.100200 PERT→0.100000 (scale=0.04)\n",
            "[meta] cb#010 loss=0.489205 step=0.01536 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.100401 PERT→0.100000 (scale=0.04)\n",
            "[meta] cb#015 loss=0.478982 step=0.02481 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.100602 PERT→0.100001 (scale=0.04)\n",
            "[meta] cb#020 loss=0.466102 step=0.1171 g_raw=+0.062 g_sm=+0.017 acc=1 | LR→0.100804 PERT→0.100001 (scale=0.04)\n",
            "[meta] cb#025 loss=0.456755 step=0.04737 g_raw=+0.023 g_sm=+0.020 acc=1 | LR→0.101006 PERT→0.100001 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1000000000, PERT_used=0.1000000000 → LR_next=0.1010062551, PERT_next=0.1000012261\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.027 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1000000000→0.1010062551 PERT 0.1000000000→0.1000012261\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.83\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.448865 step=0.01304 g_raw=+0.006 g_sm=+0.021 acc=1 | LR→0.101209 PERT→0.100002 (scale=0.04)\n",
            "[meta] cb#035 loss=0.444561 step=0.03547 g_raw=+0.015 g_sm=+0.020 acc=1 | LR→0.101412 PERT→0.100002 (scale=0.04)\n",
            "[meta] cb#040 loss=0.439807 step=0.04022 g_raw=+0.021 g_sm=+0.021 acc=1 | LR→0.101615 PERT→0.100002 (scale=0.04)\n",
            "[meta] cb#045 loss=0.431914 step=0.07004 g_raw=+0.034 g_sm=+0.022 acc=1 | LR→0.101819 PERT→0.100003 (scale=0.04)\n",
            "[meta] cb#050 loss=0.428009 step=0.003982 g_raw=+0.003 g_sm=+0.020 acc=1 | LR→0.102024 PERT→0.100003 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1010062551, PERT_used=0.1000012261 → LR_next=0.1020235003, PERT_next=0.1000032996\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.021 acc_ratio=1.00 | LR 0.1010062551→0.1020235003 PERT 0.1000012261→0.1000032996\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.424826 step=0.01237 g_raw=+0.006 g_sm=+0.019 acc=1 | LR→0.102228 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#060 loss=0.422404 step=0.01129 g_raw=+0.005 g_sm=+0.017 acc=1 | LR→0.102433 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#065 loss=0.418398 step=0.06749 g_raw=+0.030 g_sm=+0.017 acc=1 | LR→0.102639 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#070 loss=0.413173 step=0.001137 g_raw=-0.000 g_sm=+0.017 acc=1 | LR→0.102844 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#075 loss=0.411401 step=0.002212 g_raw=-0.001 g_sm=+0.015 acc=1 | LR→0.103051 PERT→0.100005 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1020235003, PERT_used=0.1000032996 → LR_next=0.1030506688, PERT_next=0.1000050613\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1020235003→0.1030506688 PERT 0.1000032996→0.1000050613\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.407962 step=0.03028 g_raw=+0.015 g_sm=+0.015 acc=1 | LR→0.103257 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#085 loss=0.406743 step=0.02311 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.103464 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#090 loss=0.404004 step=0.01803 g_raw=+0.009 g_sm=+0.014 acc=1 | LR→0.103672 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#095 loss=0.402370 step=0.01617 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.103880 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#100 loss=0.397973 step=0.01804 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.104088 PERT→0.100007 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1030506688, PERT_used=0.1000050613 → LR_next=0.1040878575, PERT_next=0.1000065142\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1030506688→0.1040878575 PERT 0.1000050613→0.1000065142\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.57\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.397357 step=0.02962 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.104297 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#110 loss=0.393730 step=0.001152 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.104506 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#115 loss=0.391386 step=0.01965 g_raw=+0.009 g_sm=+0.014 acc=1 | LR→0.104715 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#120 loss=0.389764 step=0.0279 g_raw=+0.014 g_sm=+0.013 acc=1 | LR→0.104925 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#125 loss=0.386470 step=0.06388 g_raw=+0.032 g_sm=+0.014 acc=1 | LR→0.105135 PERT→0.100008 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1040878575, PERT_used=0.1000065142 → LR_next=0.1051353559, PERT_next=0.1000078441\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1040878575→0.1051353559 PERT 0.1000065142→0.1000078441\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.56\n",
            "[round 0 | client 1] final LR=0.1051353559, final PERT=0.1000078441  (ΔLR=+0.0051353559, ΔPERT=+0.0000078441)\n",
            "[round 0 | client 2] seed LR=0.1000000000 (prev=0.1000000000), seed PERT=0.1000000000 (prev=0.1000000000), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.501135 step=0.0264 g_raw=+0.015 g_sm=+0.003 acc=1 | LR→0.100200 PERT→0.100000 (scale=0.04)\n",
            "[meta] cb#010 loss=0.500294 step=0.006692 g_raw=+0.006 g_sm=+0.004 acc=1 | LR→0.100401 PERT→0.100000 (scale=0.04)\n",
            "[meta] cb#015 loss=0.497999 step=0.001141 g_raw=+0.001 g_sm=+0.006 acc=1 | LR→0.100602 PERT→0.100000 (scale=0.04)\n",
            "[meta] cb#020 loss=0.497511 step=0.007738 g_raw=+0.004 g_sm=+0.006 acc=1 | LR→0.100804 PERT→0.100000 (scale=0.04)\n",
            "[meta] cb#025 loss=0.493594 step=0.05693 g_raw=+0.030 g_sm=+0.009 acc=1 | LR→0.101006 PERT→0.100001 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1000000000, PERT_used=0.1000000000 → LR_next=0.1010055315, PERT_next=0.1000005097\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1000000000→0.1010055315 PERT 0.1000000000→0.1000005097\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.47\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.489495 step=0.01077 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.101208 PERT→0.100001 (scale=0.04)\n",
            "[meta] cb#035 loss=0.487240 step=0.03573 g_raw=+0.017 g_sm=+0.012 acc=1 | LR→0.101411 PERT→0.100001 (scale=0.04)\n",
            "[meta] cb#040 loss=0.483096 step=0.0284 g_raw=+0.015 g_sm=+0.012 acc=1 | LR→0.101614 PERT→0.100001 (scale=0.04)\n",
            "[meta] cb#045 loss=0.479763 step=0.04481 g_raw=+0.025 g_sm=+0.013 acc=1 | LR→0.101818 PERT→0.100001 (scale=0.04)\n",
            "[meta] cb#050 loss=0.477685 step=0.009679 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.102022 PERT→0.100002 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1010055315, PERT_used=0.1000005097 → LR_next=0.1020218453, PERT_next=0.1000016774\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1010055315→0.1020218453 PERT 0.1000005097→0.1000016774\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.476098 step=0.02319 g_raw=+0.010 g_sm=+0.012 acc=1 | LR→0.102226 PERT→0.100002 (scale=0.04)\n",
            "[meta] cb#060 loss=0.474162 step=0.01618 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.102431 PERT→0.100002 (scale=0.04)\n",
            "[meta] cb#065 loss=0.472545 step=0.02363 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.102637 PERT→0.100002 (scale=0.04)\n",
            "[meta] cb#070 loss=0.469891 step=0.01835 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.102842 PERT→0.100003 (scale=0.04)\n",
            "[meta] cb#075 loss=0.468084 step=0.004129 g_raw=+0.002 g_sm=+0.012 acc=1 | LR→0.103048 PERT→0.100003 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1020218453, PERT_used=0.1000016774 → LR_next=0.1030484185, PERT_next=0.1000028775\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1020218453→0.1030484185 PERT 0.1000016774→0.1000028775\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.467419 step=0.01114 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.103255 PERT→0.100003 (scale=0.04)\n",
            "[meta] cb#085 loss=0.466896 step=0.01626 g_raw=+0.009 g_sm=+0.010 acc=1 | LR→0.103462 PERT→0.100003 (scale=0.04)\n",
            "[meta] cb#090 loss=0.464402 step=0.01397 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.103669 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#095 loss=0.461117 step=0.007518 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.103877 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#100 loss=0.458711 step=0.01006 g_raw=+0.005 g_sm=+0.012 acc=1 | LR→0.104085 PERT→0.100004 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1030484185, PERT_used=0.1000028775 → LR_next=0.1040852186, PERT_next=0.1000039788\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1030484185→0.1040852186 PERT 0.1000028775→0.1000039788\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.456103 step=0.005037 g_raw=+0.000 g_sm=+0.012 acc=1 | LR→0.104294 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#110 loss=0.453352 step=0.004961 g_raw=+0.002 g_sm=+0.012 acc=1 | LR→0.104503 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#115 loss=0.451710 step=0.01022 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.104712 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#120 loss=0.448612 step=0.000492 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.104922 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#125 loss=0.443883 step=0.06491 g_raw=+0.035 g_sm=+0.014 acc=1 | LR→0.105133 PERT→0.100005 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1040852186, PERT_used=0.1000039788 → LR_next=0.1051325923, PERT_next=0.1000052152\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1040852186→0.1051325923 PERT 0.1000039788→0.1000052152\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.73\n",
            "[round 0 | client 2] final LR=0.1051325923, final PERT=0.1000052152  (ΔLR=+0.0051325923, ΔPERT=+0.0000052152)\n",
            "[round 0 | client 3] seed LR=0.1000000000 (prev=0.1000000000), seed PERT=0.1000000000 (prev=0.1000000000), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.477335 step=0.006438 g_raw=+0.002 g_sm=+0.002 acc=1 | LR→0.100200 PERT→0.100000 (scale=0.04)\n",
            "[meta] cb#010 loss=0.476145 step=0.01106 g_raw=+0.004 g_sm=+0.003 acc=1 | LR→0.100401 PERT→0.100000 (scale=0.04)\n",
            "[meta] cb#015 loss=0.474278 step=0.002091 g_raw=+0.001 g_sm=+0.005 acc=1 | LR→0.100602 PERT→0.100000 (scale=0.04)\n",
            "[meta] cb#020 loss=0.471503 step=0.0489 g_raw=+0.025 g_sm=+0.007 acc=1 | LR→0.100804 PERT→0.100000 (scale=0.04)\n",
            "[meta] cb#025 loss=0.470302 step=0.007819 g_raw=+0.005 g_sm=+0.008 acc=1 | LR→0.101005 PERT→0.100000 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1000000000, PERT_used=0.1000000000 → LR_next=0.1010054724, PERT_next=0.1000004511\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1000000000→0.1010054724 PERT 0.1000000000→0.1000004511\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.469230 step=0.01264 g_raw=+0.007 g_sm=+0.008 acc=1 | LR→0.101208 PERT→0.100001 (scale=0.04)\n",
            "[meta] cb#035 loss=0.467932 step=0.01246 g_raw=+0.007 g_sm=+0.009 acc=1 | LR→0.101411 PERT→0.100001 (scale=0.04)\n",
            "[meta] cb#040 loss=0.464502 step=0.04524 g_raw=+0.023 g_sm=+0.011 acc=1 | LR→0.101614 PERT→0.100001 (scale=0.04)\n",
            "[meta] cb#045 loss=0.463260 step=0.01089 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.101818 PERT→0.100001 (scale=0.04)\n",
            "[meta] cb#050 loss=0.460856 step=0.015 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.102022 PERT→0.100001 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1010054724, PERT_used=0.1000004511 → LR_next=0.1020215819, PERT_next=0.1000014192\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1010054724→0.1020215819 PERT 0.1000004511→0.1000014192\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.458622 step=0.03246 g_raw=+0.017 g_sm=+0.012 acc=1 | LR→0.102226 PERT→0.100002 (scale=0.04)\n",
            "[meta] cb#060 loss=0.454805 step=0.06511 g_raw=+0.034 g_sm=+0.013 acc=1 | LR→0.102431 PERT→0.100002 (scale=0.04)\n",
            "[meta] cb#065 loss=0.454064 step=0.006605 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.102636 PERT→0.100002 (scale=0.04)\n",
            "[meta] cb#070 loss=0.453643 step=0.003875 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.102842 PERT→0.100002 (scale=0.04)\n",
            "[meta] cb#075 loss=0.452274 step=0.005587 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.103048 PERT→0.100003 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1020215819, PERT_used=0.1000014192 → LR_next=0.1030480899, PERT_next=0.1000025586\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1020215819→0.1030480899 PERT 0.1000014192→0.1000025586\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.77\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.451494 step=0.004068 g_raw=+0.001 g_sm=+0.009 acc=1 | LR→0.103255 PERT→0.100003 (scale=0.04)\n",
            "[meta] cb#085 loss=0.450236 step=0.02416 g_raw=+0.011 g_sm=+0.009 acc=1 | LR→0.103461 PERT→0.100003 (scale=0.04)\n",
            "[meta] cb#090 loss=0.449530 step=0.009469 g_raw=+0.004 g_sm=+0.009 acc=1 | LR→0.103669 PERT→0.100003 (scale=0.04)\n",
            "[meta] cb#095 loss=0.447963 step=0.03281 g_raw=+0.016 g_sm=+0.009 acc=1 | LR→0.103877 PERT→0.100003 (scale=0.04)\n",
            "[meta] cb#100 loss=0.445753 step=3.277e-05 g_raw=+0.000 g_sm=+0.010 acc=1 | LR→0.104085 PERT→0.100003 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1030480899, PERT_used=0.1000025586 → LR_next=0.1040846880, PERT_next=0.1000034690\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1030480899→0.1040846880 PERT 0.1000025586→0.1000034690\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.78\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.443184 step=0.02899 g_raw=+0.015 g_sm=+0.010 acc=1 | LR→0.104293 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#110 loss=0.441804 step=0.0008778 g_raw=+0.001 g_sm=+0.010 acc=1 | LR→0.104502 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#115 loss=0.441331 step=0.01379 g_raw=+0.007 g_sm=+0.009 acc=1 | LR→0.104712 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#120 loss=0.437493 step=0.02768 g_raw=+0.014 g_sm=+0.010 acc=1 | LR→0.104922 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#125 loss=0.434769 step=0.02465 g_raw=+0.011 g_sm=+0.011 acc=1 | LR→0.105132 PERT→0.100004 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1040846880, PERT_used=0.1000034690 → LR_next=0.1051318311, PERT_next=0.1000044912\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1040846880→0.1051318311 PERT 0.1000034690→0.1000044912\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.81\n",
            "[round 0 | client 3] final LR=0.1051318311, final PERT=0.1000044912  (ΔLR=+0.0051318311, ΔPERT=+0.0000044912)\n",
            "[round 0 | client 4] seed LR=0.1000000000 (prev=0.1000000000), seed PERT=0.1000000000 (prev=0.1000000000), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.478175 step=0.02382 g_raw=+0.012 g_sm=+0.004 acc=1 | LR→0.100200 PERT→0.100000 (scale=0.04)\n",
            "[meta] cb#010 loss=0.469856 step=0.02756 g_raw=+0.013 g_sm=+0.008 acc=1 | LR→0.100401 PERT→0.100000 (scale=0.04)\n",
            "[meta] cb#015 loss=0.457425 step=0.09776 g_raw=+0.050 g_sm=+0.014 acc=1 | LR→0.100602 PERT→0.100000 (scale=0.04)\n",
            "[meta] cb#020 loss=0.450949 step=0.02151 g_raw=+0.012 g_sm=+0.016 acc=1 | LR→0.100804 PERT→0.100001 (scale=0.04)\n",
            "[meta] cb#025 loss=0.447044 step=0.0149 g_raw=+0.007 g_sm=+0.016 acc=1 | LR→0.101006 PERT→0.100001 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1000000000, PERT_used=0.1000000000 → LR_next=0.1010060872, PERT_next=0.1000010598\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.023 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1000000000→0.1010060872 PERT 0.1000000000→0.1000010598\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.443851 step=0.01668 g_raw=+0.007 g_sm=+0.016 acc=1 | LR→0.101209 PERT→0.100001 (scale=0.04)\n",
            "[meta] cb#035 loss=0.441436 step=0.03465 g_raw=+0.018 g_sm=+0.016 acc=1 | LR→0.101412 PERT→0.100002 (scale=0.04)\n",
            "[meta] cb#040 loss=0.436958 step=0.04844 g_raw=+0.024 g_sm=+0.016 acc=1 | LR→0.101615 PERT→0.100002 (scale=0.04)\n",
            "[meta] cb#045 loss=0.432196 step=0.01434 g_raw=+0.008 g_sm=+0.017 acc=1 | LR→0.101819 PERT→0.100002 (scale=0.04)\n",
            "[meta] cb#050 loss=0.428520 step=0.01038 g_raw=+0.006 g_sm=+0.016 acc=1 | LR→0.102023 PERT→0.100003 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1010060872, PERT_used=0.1000010598 → LR_next=0.1020228812, PERT_next=0.1000026928\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1010060872→0.1020228812 PERT 0.1000010598→0.1000026928\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.422375 step=0.001305 g_raw=+0.001 g_sm=+0.017 acc=1 | LR→0.102227 PERT→0.100003 (scale=0.04)\n",
            "[meta] cb#060 loss=0.416772 step=0.05985 g_raw=+0.029 g_sm=+0.017 acc=1 | LR→0.102432 PERT→0.100003 (scale=0.04)\n",
            "[meta] cb#065 loss=0.413588 step=0.005271 g_raw=+0.001 g_sm=+0.017 acc=1 | LR→0.102638 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#070 loss=0.407008 step=0.08897 g_raw=+0.045 g_sm=+0.018 acc=1 | LR→0.102844 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#075 loss=0.404351 step=0.004108 g_raw=+0.002 g_sm=+0.017 acc=1 | LR→0.103050 PERT→0.100004 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1020228812, PERT_used=0.1000026928 → LR_next=0.1030499673, PERT_next=0.1000043805\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1020228812→0.1030499673 PERT 0.1000026928→0.1000043805\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.74\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.402474 step=0.03641 g_raw=+0.018 g_sm=+0.016 acc=1 | LR→0.103257 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#085 loss=0.401281 step=0.02888 g_raw=+0.012 g_sm=+0.015 acc=1 | LR→0.103464 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#090 loss=0.399059 step=0.04343 g_raw=+0.023 g_sm=+0.014 acc=1 | LR→0.103671 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#095 loss=0.397046 step=0.005294 g_raw=+0.001 g_sm=+0.014 acc=1 | LR→0.103879 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#100 loss=0.395736 step=0.004223 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.104087 PERT→0.100006 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1030499673, PERT_used=0.1000043805 → LR_next=0.1040871387, PERT_next=0.1000058236\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1030499673→0.1040871387 PERT 0.1000043805→0.1000058236\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.75\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.391020 step=0.0554 g_raw=+0.026 g_sm=+0.014 acc=1 | LR→0.104296 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#110 loss=0.389132 step=0.001254 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.104505 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#115 loss=0.388302 step=0.03124 g_raw=+0.016 g_sm=+0.012 acc=1 | LR→0.104714 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#120 loss=0.387136 step=0.009835 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.104924 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#125 loss=0.383819 step=0.04492 g_raw=+0.023 g_sm=+0.012 acc=1 | LR→0.105135 PERT→0.100007 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1040871387, PERT_used=0.1000058236 → LR_next=0.1051345422, PERT_next=0.1000070701\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1040871387→0.1051345422 PERT 0.1000058236→0.1000070701\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.76\n",
            "[round 0 | client 4] final LR=0.1051345422, final PERT=0.1000070701  (ΔLR=+0.0051345422, ΔPERT=+0.0000070701)\n",
            "\n",
            "[Round 0] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           4      0.555525      0.760000      0.105135      0.100007\n",
            "           3      0.590165      0.815000      0.105132      0.100004\n",
            "           2      0.614028      0.730000      0.105133      0.100005\n",
            "           1      0.619578      0.555000      0.105135      0.100008\n",
            "           0      0.665253      0.590000      0.105133      0.100006\n",
            "→ [Round 0] action=init_from_best, best_client=4, best_val=0.555525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  10%|█         | 1/10 [09:13<1:23:02, 553.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   0] acc_g=0.717 (μ=0.690, σ=0.100, FG=0.224) | t=544.050s, val=0.556 | TEL=FALSE\n",
            "[Round 1] Teleportation OFF | Aggregation=best\n",
            "[round 1 | client 0] seed LR=0.1025665831 (prev=0.1051331663), seed PERT=0.1000028806 (prev=0.1000057612), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.514080 step=0.02331 g_raw=+0.012 g_sm=+0.004 acc=1 | LR→0.102772 PERT→0.100003 (scale=0.04)\n",
            "[meta] cb#010 loss=0.511641 step=0.04749 g_raw=+0.024 g_sm=+0.006 acc=1 | LR→0.102978 PERT→0.100003 (scale=0.04)\n",
            "[meta] cb#015 loss=0.503346 step=0.06879 g_raw=+0.036 g_sm=+0.010 acc=1 | LR→0.103184 PERT→0.100003 (scale=0.04)\n",
            "[meta] cb#020 loss=0.500769 step=0.006365 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.103391 PERT→0.100003 (scale=0.04)\n",
            "[meta] cb#025 loss=0.499031 step=0.02066 g_raw=+0.010 g_sm=+0.011 acc=1 | LR→0.103598 PERT→0.100004 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1025665831, PERT_used=0.1000028806 → LR_next=0.1035981703, PERT_next=0.1000036296\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1025665831→0.1035981703 PERT 0.1000028806→0.1000036296\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.58\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.497513 step=0.04792 g_raw=+0.025 g_sm=+0.011 acc=1 | LR→0.103806 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#035 loss=0.494664 step=0.0209 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.104014 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#040 loss=0.487774 step=0.06529 g_raw=+0.032 g_sm=+0.015 acc=1 | LR→0.104222 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#045 loss=0.486724 step=0.03441 g_raw=+0.018 g_sm=+0.013 acc=1 | LR→0.104431 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#050 loss=0.483353 step=0.04973 g_raw=+0.024 g_sm=+0.014 acc=1 | LR→0.104641 PERT→0.100005 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1035981703, PERT_used=0.1000036296 → LR_next=0.1046406509, PERT_next=0.1000048736\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1035981703→0.1046406509 PERT 0.1000036296→0.1000048736\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.73\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.481754 step=0.02274 g_raw=+0.012 g_sm=+0.014 acc=1 | LR→0.104850 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#060 loss=0.473152 step=0.04706 g_raw=+0.024 g_sm=+0.017 acc=1 | LR→0.105061 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#065 loss=0.469487 step=0.01447 g_raw=+0.006 g_sm=+0.017 acc=1 | LR→0.105271 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#070 loss=0.464567 step=0.008737 g_raw=+0.005 g_sm=+0.017 acc=1 | LR→0.105482 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#075 loss=0.454918 step=0.01273 g_raw=+0.006 g_sm=+0.017 acc=1 | LR→0.105694 PERT→0.100007 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1046406509, PERT_used=0.1000048736 → LR_next=0.1056940493, PERT_next=0.1000065222\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1046406509→0.1056940493 PERT 0.1000048736→0.1000065222\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.74\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.449557 step=0.05267 g_raw=+0.026 g_sm=+0.018 acc=1 | LR→0.105906 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#085 loss=0.443889 step=0.03095 g_raw=+0.013 g_sm=+0.019 acc=1 | LR→0.106118 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#090 loss=0.433260 step=0.01159 g_raw=+0.006 g_sm=+0.020 acc=1 | LR→0.106331 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#095 loss=0.430311 step=0.05878 g_raw=+0.028 g_sm=+0.019 acc=1 | LR→0.106545 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#100 loss=0.426570 step=0.01307 g_raw=+0.007 g_sm=+0.019 acc=1 | LR→0.106758 PERT→0.100008 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1056940493, PERT_used=0.1000065222 → LR_next=0.1067583139, PERT_next=0.1000084162\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1056940493→0.1067583139 PERT 0.1000065222→0.1000084162\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.74\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.421590 step=0.0486 g_raw=+0.024 g_sm=+0.019 acc=1 | LR→0.106972 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#110 loss=0.414707 step=0.07365 g_raw=+0.037 g_sm=+0.019 acc=1 | LR→0.107187 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#115 loss=0.412824 step=0.03991 g_raw=+0.020 g_sm=+0.018 acc=1 | LR→0.107402 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#120 loss=0.407501 step=0.02752 g_raw=+0.013 g_sm=+0.018 acc=1 | LR→0.107617 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#125 loss=0.405534 step=0.02163 g_raw=+0.011 g_sm=+0.016 acc=1 | LR→0.107833 PERT→0.100010 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1067583139, PERT_used=0.1000084162 → LR_next=0.1078331920, PERT_next=0.1000102146\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1067583139→0.1078331920 PERT 0.1000084162→0.1000102146\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.80\n",
            "[round 1 | client 0] final LR=0.1078331920, final PERT=0.1000102146  (ΔLR=+0.0052666088, ΔPERT=+0.0000073340)\n",
            "[round 1 | client 1] seed LR=0.1025676780 (prev=0.1051353559), seed PERT=0.1000039221 (prev=0.1000078441), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.491890 step=0.06618 g_raw=+0.032 g_sm=+0.006 acc=1 | LR→0.102773 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#010 loss=0.488575 step=0.01271 g_raw=+0.006 g_sm=+0.008 acc=1 | LR→0.102979 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#015 loss=0.488275 step=0.01229 g_raw=+0.006 g_sm=+0.007 acc=1 | LR→0.103185 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#020 loss=0.484103 step=0.045 g_raw=+0.024 g_sm=+0.010 acc=1 | LR→0.103392 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#025 loss=0.474984 step=0.03341 g_raw=+0.017 g_sm=+0.014 acc=1 | LR→0.103599 PERT→0.100005 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1025676780, PERT_used=0.1000039221 → LR_next=0.1035992977, PERT_next=0.1000046919\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1025676780→0.1035992977 PERT 0.1000039221→0.1000046919\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.474435 step=0.01438 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.103807 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#035 loss=0.473211 step=0.02043 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.104015 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#040 loss=0.469181 step=0.03209 g_raw=+0.017 g_sm=+0.013 acc=1 | LR→0.104224 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#045 loss=0.465742 step=0.008611 g_raw=+0.005 g_sm=+0.014 acc=1 | LR→0.104433 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#050 loss=0.463569 step=0.04652 g_raw=+0.023 g_sm=+0.014 acc=1 | LR→0.104642 PERT→0.100006 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1035992977, PERT_used=0.1000046919 → LR_next=0.1046418659, PERT_next=0.1000060087\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1035992977→0.1046418659 PERT 0.1000046919→0.1000060087\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.458069 step=0.07256 g_raw=+0.036 g_sm=+0.016 acc=1 | LR→0.104852 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#060 loss=0.452552 step=0.07312 g_raw=+0.037 g_sm=+0.017 acc=1 | LR→0.105062 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#065 loss=0.445923 step=0.08225 g_raw=+0.040 g_sm=+0.018 acc=1 | LR→0.105273 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#070 loss=0.443992 step=0.00241 g_raw=+0.000 g_sm=+0.016 acc=1 | LR→0.105484 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#075 loss=0.436850 step=0.051 g_raw=+0.024 g_sm=+0.018 acc=1 | LR→0.105695 PERT→0.100008 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1046418659, PERT_used=0.1000060087 → LR_next=0.1056952823, PERT_next=0.1000076628\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1046418659→0.1056952823 PERT 0.1000060087→0.1000076628\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.76\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.433599 step=0.04185 g_raw=+0.022 g_sm=+0.017 acc=1 | LR→0.105907 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#085 loss=0.426097 step=0.08822 g_raw=+0.043 g_sm=+0.019 acc=1 | LR→0.106120 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#090 loss=0.422991 step=0.006703 g_raw=+0.004 g_sm=+0.018 acc=1 | LR→0.106332 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#095 loss=0.419452 step=0.03216 g_raw=+0.015 g_sm=+0.018 acc=1 | LR→0.106546 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#100 loss=0.417092 step=0.04423 g_raw=+0.022 g_sm=+0.017 acc=1 | LR→0.106759 PERT→0.100009 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1056952823, PERT_used=0.1000076628 → LR_next=0.1067594223, PERT_next=0.1000094284\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1056952823→0.1067594223 PERT 0.1000076628→0.1000094284\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.77\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.415314 step=0.03806 g_raw=+0.019 g_sm=+0.016 acc=1 | LR→0.106973 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#110 loss=0.413649 step=0.0286 g_raw=+0.013 g_sm=+0.015 acc=1 | LR→0.107188 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#115 loss=0.412039 step=0.0213 g_raw=+0.010 g_sm=+0.014 acc=1 | LR→0.107403 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#120 loss=0.410495 step=0.01769 g_raw=+0.008 g_sm=+0.013 acc=1 | LR→0.107618 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#125 loss=0.408629 step=0.03614 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.107834 PERT→0.100011 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1067594223, PERT_used=0.1000094284 → LR_next=0.1078338947, PERT_next=0.1000108403\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1067594223→0.1078338947 PERT 0.1000094284→0.1000108403\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.79\n",
            "[round 1 | client 1] final LR=0.1078338947, final PERT=0.1000108403  (ΔLR=+0.0052662167, ΔPERT=+0.0000069182)\n",
            "[round 1 | client 2] seed LR=0.1025662961 (prev=0.1051325923), seed PERT=0.1000026076 (prev=0.1000052152), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.557083 step=0.02415 g_raw=+0.011 g_sm=+0.004 acc=1 | LR→0.102772 PERT→0.100003 (scale=0.04)\n",
            "[meta] cb#010 loss=0.537710 step=0.1049 g_raw=+0.058 g_sm=+0.012 acc=1 | LR→0.102978 PERT→0.100003 (scale=0.04)\n",
            "[meta] cb#015 loss=0.535222 step=0.04893 g_raw=+0.027 g_sm=+0.012 acc=1 | LR→0.103184 PERT→0.100003 (scale=0.04)\n",
            "[meta] cb#020 loss=0.516233 step=0.1051 g_raw=+0.055 g_sm=+0.018 acc=1 | LR→0.103391 PERT→0.100003 (scale=0.04)\n",
            "[meta] cb#025 loss=0.505687 step=0.07416 g_raw=+0.041 g_sm=+0.020 acc=1 | LR→0.103598 PERT→0.100004 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1025662961, PERT_used=0.1000026076 → LR_next=0.1035983313, PERT_next=0.1000037918\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.027 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1025662961→0.1035983313 PERT 0.1000026076→0.1000037918\n",
            "Training Accuracy: 0.54\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.500642 step=0.06979 g_raw=+0.038 g_sm=+0.020 acc=1 | LR→0.103806 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#035 loss=0.486922 step=0.08048 g_raw=+0.044 g_sm=+0.022 acc=1 | LR→0.104014 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#040 loss=0.479717 step=0.007288 g_raw=+0.005 g_sm=+0.022 acc=1 | LR→0.104223 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#045 loss=0.472761 step=0.0717 g_raw=+0.037 g_sm=+0.023 acc=1 | LR→0.104432 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#050 loss=0.469820 step=0.02827 g_raw=+0.015 g_sm=+0.021 acc=1 | LR→0.104642 PERT→0.100006 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1035983313, PERT_used=0.1000037918 → LR_next=0.1046417428, PERT_next=0.1000059240\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.022 g_sm_mean=+0.021 acc_ratio=1.00 | LR 0.1035983313→0.1046417428 PERT 0.1000037918→0.1000059240\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.460480 step=0.05257 g_raw=+0.025 g_sm=+0.022 acc=1 | LR→0.104852 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#060 loss=0.444284 step=0.04384 g_raw=+0.022 g_sm=+0.025 acc=1 | LR→0.105062 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#065 loss=0.439926 step=0.05694 g_raw=+0.026 g_sm=+0.023 acc=1 | LR→0.105273 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#070 loss=0.429575 step=0.07947 g_raw=+0.039 g_sm=+0.025 acc=1 | LR→0.105484 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#075 loss=0.426820 step=0.01006 g_raw=+0.005 g_sm=+0.022 acc=1 | LR→0.105696 PERT→0.100008 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1046417428, PERT_used=0.1000059240 → LR_next=0.1056958948, PERT_next=0.1000082752\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.024 g_sm_mean=+0.024 acc_ratio=1.00 | LR 0.1046417428→0.1056958948 PERT 0.1000059240→0.1000082752\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.55\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.419982 step=0.07199 g_raw=+0.034 g_sm=+0.023 acc=1 | LR→0.105908 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#085 loss=0.404953 step=0.02321 g_raw=+0.012 g_sm=+0.025 acc=1 | LR→0.106121 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#090 loss=0.392781 step=0.01496 g_raw=+0.008 g_sm=+0.026 acc=1 | LR→0.106334 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#095 loss=0.387564 step=0.05396 g_raw=+0.026 g_sm=+0.025 acc=1 | LR→0.106547 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#100 loss=0.383053 step=0.05015 g_raw=+0.024 g_sm=+0.024 acc=1 | LR→0.106761 PERT→0.100011 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1056958948, PERT_used=0.1000082752 → LR_next=0.1067607850, PERT_next=0.1000107378\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.025 g_sm_mean=+0.025 acc_ratio=1.00 | LR 0.1056958948→0.1067607850 PERT 0.1000082752→0.1000107378\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.77\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.376660 step=0.01658 g_raw=+0.006 g_sm=+0.023 acc=1 | LR→0.106975 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#110 loss=0.373913 step=0.02422 g_raw=+0.010 g_sm=+0.021 acc=1 | LR→0.107190 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.371484 step=0.03245 g_raw=+0.017 g_sm=+0.020 acc=1 | LR→0.107405 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.370070 step=0.05222 g_raw=+0.024 g_sm=+0.017 acc=1 | LR→0.107620 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#125 loss=0.368403 step=0.005025 g_raw=+0.001 g_sm=+0.015 acc=1 | LR→0.107836 PERT→0.100013 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1067607850, PERT_used=0.1000107378 → LR_next=0.1078358856, PERT_next=0.1000127196\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.020 acc_ratio=1.00 | LR 0.1067607850→0.1078358856 PERT 0.1000107378→0.1000127196\n",
            "Training Accuracy: 0.96\n",
            "Test Accuracy: 0.79\n",
            "[round 1 | client 2] final LR=0.1078358856, final PERT=0.1000127196  (ΔLR=+0.0052695895, ΔPERT=+0.0000101120)\n",
            "[round 1 | client 3] seed LR=0.1025659155 (prev=0.1051318311), seed PERT=0.1000022456 (prev=0.1000044912), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.501438 step=0.07834 g_raw=+0.039 g_sm=+0.005 acc=1 | LR→0.102771 PERT→0.100002 (scale=0.04)\n",
            "[meta] cb#010 loss=0.500149 step=0.003122 g_raw=+0.003 g_sm=+0.006 acc=1 | LR→0.102977 PERT→0.100002 (scale=0.04)\n",
            "[meta] cb#015 loss=0.497547 step=0.02621 g_raw=+0.016 g_sm=+0.007 acc=1 | LR→0.103183 PERT→0.100003 (scale=0.04)\n",
            "[meta] cb#020 loss=0.495309 step=0.02926 g_raw=+0.017 g_sm=+0.009 acc=1 | LR→0.103390 PERT→0.100003 (scale=0.04)\n",
            "[meta] cb#025 loss=0.489880 step=0.07057 g_raw=+0.034 g_sm=+0.011 acc=1 | LR→0.103597 PERT→0.100003 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1025659155, PERT_used=0.1000022456 → LR_next=0.1035974249, PERT_next=0.1000029259\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1025659155→0.1035974249 PERT 0.1000022456→0.1000029259\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.62\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.485849 step=0.07852 g_raw=+0.038 g_sm=+0.013 acc=1 | LR→0.103805 PERT→0.100003 (scale=0.04)\n",
            "[meta] cb#035 loss=0.483362 step=0.03739 g_raw=+0.019 g_sm=+0.013 acc=1 | LR→0.104013 PERT→0.100003 (scale=0.04)\n",
            "[meta] cb#040 loss=0.468647 step=0.1091 g_raw=+0.056 g_sm=+0.018 acc=1 | LR→0.104222 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#045 loss=0.461707 step=0.07338 g_raw=+0.040 g_sm=+0.019 acc=1 | LR→0.104431 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#050 loss=0.455825 step=0.02388 g_raw=+0.013 g_sm=+0.020 acc=1 | LR→0.104640 PERT→0.100004 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1035974249, PERT_used=0.1000029259 → LR_next=0.1046402231, PERT_next=0.1000044806\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.022 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1035974249→0.1046402231 PERT 0.1000029259→0.1000044806\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.62\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.449821 step=0.009225 g_raw=+0.004 g_sm=+0.020 acc=1 | LR→0.104850 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#060 loss=0.448607 step=0.01307 g_raw=+0.007 g_sm=+0.017 acc=1 | LR→0.105060 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#065 loss=0.447609 step=0.02197 g_raw=+0.011 g_sm=+0.015 acc=1 | LR→0.105271 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#070 loss=0.446860 step=0.0305 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.105482 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#075 loss=0.442892 step=0.01759 g_raw=+0.010 g_sm=+0.014 acc=1 | LR→0.105694 PERT→0.100006 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1046402231, PERT_used=0.1000044806 → LR_next=0.1056936175, PERT_next=0.1000061295\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1046402231→0.1056936175 PERT 0.1000044806→0.1000061295\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.438966 step=0.02479 g_raw=+0.012 g_sm=+0.014 acc=1 | LR→0.105906 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#085 loss=0.438509 step=0.01187 g_raw=+0.005 g_sm=+0.013 acc=1 | LR→0.106118 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#090 loss=0.426554 step=0.01278 g_raw=+0.006 g_sm=+0.017 acc=1 | LR→0.106331 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#095 loss=0.422093 step=0.05561 g_raw=+0.027 g_sm=+0.018 acc=1 | LR→0.106544 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#100 loss=0.419492 step=0.003311 g_raw=+0.001 g_sm=+0.016 acc=1 | LR→0.106758 PERT→0.100008 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1056936175, PERT_used=0.1000061295 → LR_next=0.1067575239, PERT_next=0.1000076919\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1056936175→0.1067575239 PERT 0.1000061295→0.1000076919\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.65\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.418482 step=0.01119 g_raw=+0.005 g_sm=+0.014 acc=1 | LR→0.106972 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#110 loss=0.415559 step=0.01795 g_raw=+0.009 g_sm=+0.014 acc=1 | LR→0.107186 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#115 loss=0.414999 step=0.008075 g_raw=+0.006 g_sm=+0.013 acc=1 | LR→0.107401 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#120 loss=0.414040 step=0.01914 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.107616 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#125 loss=0.412671 step=0.03417 g_raw=+0.017 g_sm=+0.011 acc=1 | LR→0.107832 PERT→0.100009 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1067575239, PERT_used=0.1000076919 → LR_next=0.1078318864, PERT_next=0.1000090197\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1067575239→0.1078318864 PERT 0.1000076919→0.1000090197\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.67\n",
            "[round 1 | client 3] final LR=0.1078318864, final PERT=0.1000090197  (ΔLR=+0.0052659709, ΔPERT=+0.0000067741)\n",
            "[round 1 | client 4] seed LR=0.1025672711 (prev=0.1051345422), seed PERT=0.1000035350 (prev=0.1000070701), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.492202 step=0.06403 g_raw=+0.034 g_sm=+0.005 acc=1 | LR→0.102773 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#010 loss=0.486432 step=0.03487 g_raw=+0.018 g_sm=+0.008 acc=1 | LR→0.102979 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#015 loss=0.484744 step=0.01452 g_raw=+0.008 g_sm=+0.009 acc=1 | LR→0.103185 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#020 loss=0.480580 step=0.04727 g_raw=+0.023 g_sm=+0.011 acc=1 | LR→0.103392 PERT→0.100004 (scale=0.04)\n",
            "[meta] cb#025 loss=0.480022 step=0.01345 g_raw=+0.006 g_sm=+0.010 acc=1 | LR→0.103599 PERT→0.100004 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1025672711, PERT_used=0.1000035350 → LR_next=0.1035989237, PERT_next=0.1000043405\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1025672711→0.1035989237 PERT 0.1000035350→0.1000043405\n",
            "Training Accuracy: 0.54\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.476928 step=0.03648 g_raw=+0.020 g_sm=+0.012 acc=1 | LR→0.103807 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#035 loss=0.471994 step=0.04223 g_raw=+0.021 g_sm=+0.014 acc=1 | LR→0.104015 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#040 loss=0.466607 step=0.03557 g_raw=+0.017 g_sm=+0.015 acc=1 | LR→0.104223 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#045 loss=0.460156 step=0.02516 g_raw=+0.011 g_sm=+0.016 acc=1 | LR→0.104432 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#050 loss=0.438057 step=0.03905 g_raw=+0.019 g_sm=+0.022 acc=1 | LR→0.104642 PERT→0.100006 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1035989237, PERT_used=0.1000043405 → LR_next=0.1046417078, PERT_next=0.1000058673\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.024 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1035989237→0.1046417078 PERT 0.1000043405→0.1000058673\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.82\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.435238 step=0.02478 g_raw=+0.013 g_sm=+0.020 acc=1 | LR→0.104852 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#060 loss=0.416206 step=0.13 g_raw=+0.066 g_sm=+0.025 acc=1 | LR→0.105062 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#065 loss=0.415133 step=0.00768 g_raw=+0.003 g_sm=+0.021 acc=1 | LR→0.105273 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#070 loss=0.412645 step=0.03234 g_raw=+0.016 g_sm=+0.019 acc=1 | LR→0.105484 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#075 loss=0.405401 step=0.08131 g_raw=+0.040 g_sm=+0.021 acc=1 | LR→0.105696 PERT→0.100008 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1046417078, PERT_used=0.1000058673 → LR_next=0.1056955941, PERT_next=0.1000079676\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.021 acc_ratio=1.00 | LR 0.1046417078→0.1056955941 PERT 0.1000058673→0.1000079676\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.400647 step=0.0749 g_raw=+0.038 g_sm=+0.020 acc=1 | LR→0.105908 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#085 loss=0.395477 step=0.04949 g_raw=+0.023 g_sm=+0.020 acc=1 | LR→0.106120 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#090 loss=0.384832 step=0.0352 g_raw=+0.017 g_sm=+0.022 acc=1 | LR→0.106333 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#095 loss=0.381552 step=0.07474 g_raw=+0.034 g_sm=+0.020 acc=1 | LR→0.106546 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#100 loss=0.378316 step=0.01284 g_raw=+0.006 g_sm=+0.018 acc=1 | LR→0.106760 PERT→0.100010 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1056955941, PERT_used=0.1000079676 → LR_next=0.1067600017, PERT_next=0.1000099808\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.020 acc_ratio=1.00 | LR 0.1056955941→0.1067600017 PERT 0.1000079676→0.1000099808\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.376733 step=0.03251 g_raw=+0.014 g_sm=+0.017 acc=1 | LR→0.106974 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#110 loss=0.371329 step=0.06887 g_raw=+0.033 g_sm=+0.017 acc=1 | LR→0.107189 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#115 loss=0.369933 step=0.01488 g_raw=+0.008 g_sm=+0.016 acc=1 | LR→0.107404 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#120 loss=0.367132 step=0.0152 g_raw=+0.005 g_sm=+0.015 acc=1 | LR→0.107619 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#125 loss=0.362133 step=0.01666 g_raw=+0.008 g_sm=+0.016 acc=1 | LR→0.107835 PERT→0.100012 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1067600017, PERT_used=0.1000099808 → LR_next=0.1078347231, PERT_next=0.1000116183\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1067600017→0.1078347231 PERT 0.1000099808→0.1000116183\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.63\n",
            "[round 1 | client 4] final LR=0.1078347231, final PERT=0.1000116183  (ΔLR=+0.0052674520, ΔPERT=+0.0000080833)\n",
            "\n",
            "[Round 1] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           2      0.554993      0.785000      0.107836      0.100013\n",
            "           4      0.565046      0.630000      0.107835      0.100012\n",
            "           1      0.570428      0.785000      0.107834      0.100011\n",
            "           0      0.584474      0.795000      0.107833      0.100010\n",
            "           3      0.613851      0.665000      0.107832      0.100009\n",
            "→ [Round 1] best_client=2, best_val=0.554993, prev_global_val=0.555525, improve=+0.000531, action=hold (τ=0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  20%|██        | 2/10 [18:53<1:15:52, 569.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   1] acc_g=0.743 (μ=0.732, σ=0.070, FG=0.147) | t=569.002s, val=0.551 | TEL=FALSE\n",
            "[Round 2] Teleportation OFF | Aggregation=best\n",
            "[round 2 | client 0] seed LR=0.1039165960 (prev=0.1078331920), seed PERT=0.1000051073 (prev=0.1000102146), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.478453 step=0.005067 g_raw=+0.003 g_sm=+0.002 acc=1 | LR→0.104125 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#010 loss=0.474981 step=0.04933 g_raw=+0.023 g_sm=+0.005 acc=1 | LR→0.104333 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#015 loss=0.471243 step=0.0001681 g_raw=-0.000 g_sm=+0.007 acc=1 | LR→0.104542 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#020 loss=0.470388 step=0.01494 g_raw=+0.007 g_sm=+0.008 acc=1 | LR→0.104752 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#025 loss=0.465623 step=0.0216 g_raw=+0.011 g_sm=+0.010 acc=1 | LR→0.104962 PERT→0.100006 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1039165960, PERT_used=0.1000051073 → LR_next=0.1049615628, PERT_next=0.1000056672\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1039165960→0.1049615628 PERT 0.1000051073→0.1000056672\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.58\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.463477 step=0.02455 g_raw=+0.011 g_sm=+0.011 acc=1 | LR→0.105172 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#035 loss=0.459969 step=0.005114 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.105383 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#040 loss=0.457474 step=0.001169 g_raw=-0.002 g_sm=+0.011 acc=1 | LR→0.105594 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#045 loss=0.454641 step=0.005943 g_raw=+0.003 g_sm=+0.012 acc=1 | LR→0.105806 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#050 loss=0.449399 step=0.06406 g_raw=+0.032 g_sm=+0.014 acc=1 | LR→0.106018 PERT→0.100007 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1049615628, PERT_used=0.1000056672 → LR_next=0.1060176750, PERT_next=0.1000068284\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1049615628→0.1060176750 PERT 0.1000056672→0.1000068284\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.444926 step=0.07145 g_raw=+0.034 g_sm=+0.014 acc=1 | LR→0.106230 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#060 loss=0.444089 step=0.005222 g_raw=+0.003 g_sm=+0.013 acc=1 | LR→0.106443 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#065 loss=0.441789 step=0.005764 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.106657 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#070 loss=0.440491 step=0.01502 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.106870 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#075 loss=0.436700 step=0.01108 g_raw=+0.005 g_sm=+0.013 acc=1 | LR→0.107085 PERT→0.100008 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1060176750, PERT_used=0.1000068284 → LR_next=0.1070845890, PERT_next=0.1000081533\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1060176750→0.1070845890 PERT 0.1000068284→0.1000081533\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.81\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.432575 step=0.01534 g_raw=+0.009 g_sm=+0.014 acc=1 | LR→0.107299 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#085 loss=0.426986 step=0.007261 g_raw=+0.004 g_sm=+0.015 acc=1 | LR→0.107514 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#090 loss=0.425432 step=0.0365 g_raw=+0.018 g_sm=+0.014 acc=1 | LR→0.107730 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#095 loss=0.422608 step=0.0106 g_raw=+0.005 g_sm=+0.014 acc=1 | LR→0.107946 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#100 loss=0.418184 step=0.05703 g_raw=+0.027 g_sm=+0.014 acc=1 | LR→0.108162 PERT→0.100010 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1070845890, PERT_used=0.1000081533 → LR_next=0.1081623585, PERT_next=0.1000095879\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1070845890→0.1081623585 PERT 0.1000081533→0.1000095879\n",
            "Training Accuracy: 0.90\n",
            "Test Accuracy: 0.83\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.417719 step=0.01236 g_raw=+0.005 g_sm=+0.012 acc=1 | LR→0.108379 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#110 loss=0.415028 step=0.0155 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.108596 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#115 loss=0.413378 step=0.01321 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.108814 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#120 loss=0.413046 step=0.002836 g_raw=-0.000 g_sm=+0.010 acc=1 | LR→0.109032 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#125 loss=0.410851 step=0.006928 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.109251 PERT→0.100011 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1081623585, PERT_used=0.1000095879 → LR_next=0.1092507239, PERT_next=0.1000107922\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1081623585→0.1092507239 PERT 0.1000095879→0.1000107922\n",
            "Training Accuracy: 0.94\n",
            "Test Accuracy: 0.85\n",
            "[round 2 | client 0] final LR=0.1092507239, final PERT=0.1000107922  (ΔLR=+0.0053341279, ΔPERT=+0.0000056849)\n",
            "[round 2 | client 1] seed LR=0.1039169473 (prev=0.1078338947), seed PERT=0.1000054202 (prev=0.1000108403), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.503603 step=0.03831 g_raw=+0.018 g_sm=+0.002 acc=1 | LR→0.104125 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#010 loss=0.499977 step=0.005126 g_raw=+0.001 g_sm=+0.005 acc=1 | LR→0.104334 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.497616 step=0.006387 g_raw=+0.003 g_sm=+0.007 acc=1 | LR→0.104543 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.494046 step=0.00979 g_raw=+0.005 g_sm=+0.009 acc=1 | LR→0.104752 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#025 loss=0.490350 step=0.003778 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.104962 PERT→0.100006 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1039169473, PERT_used=0.1000054202 → LR_next=0.1049619482, PERT_next=0.1000060092\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1039169473→0.1049619482 PERT 0.1000054202→0.1000060092\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.487904 step=0.03238 g_raw=+0.016 g_sm=+0.011 acc=1 | LR→0.105172 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#035 loss=0.486146 step=0.03377 g_raw=+0.016 g_sm=+0.011 acc=1 | LR→0.105383 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#040 loss=0.482904 step=0.04955 g_raw=+0.024 g_sm=+0.012 acc=1 | LR→0.105594 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#045 loss=0.475424 step=0.09957 g_raw=+0.052 g_sm=+0.015 acc=1 | LR→0.105806 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#050 loss=0.472672 step=0.01784 g_raw=+0.009 g_sm=+0.014 acc=1 | LR→0.106018 PERT→0.100007 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1049619482, PERT_used=0.1000060092 → LR_next=0.1060181328, PERT_next=0.1000072350\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1049619482→0.1060181328 PERT 0.1000060092→0.1000072350\n",
            "Training Accuracy: 0.54\n",
            "Test Accuracy: 0.55\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.467653 step=0.03312 g_raw=+0.015 g_sm=+0.015 acc=1 | LR→0.106231 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#060 loss=0.466245 step=0.002463 g_raw=+0.002 g_sm=+0.014 acc=1 | LR→0.106444 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#065 loss=0.464082 step=0.03471 g_raw=+0.017 g_sm=+0.014 acc=1 | LR→0.106657 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#070 loss=0.461707 step=0.004481 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.106871 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#075 loss=0.458594 step=0.02433 g_raw=+0.012 g_sm=+0.014 acc=1 | LR→0.107085 PERT→0.100009 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1060181328, PERT_used=0.1000072350 → LR_next=0.1070851799, PERT_next=0.1000086798\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1060181328→0.1070851799 PERT 0.1000072350→0.1000086798\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.57\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.456940 step=0.003755 g_raw=+0.003 g_sm=+0.012 acc=1 | LR→0.107300 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#085 loss=0.456179 step=0.02326 g_raw=+0.012 g_sm=+0.011 acc=1 | LR→0.107515 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#090 loss=0.455196 step=0.02902 g_raw=+0.014 g_sm=+0.011 acc=1 | LR→0.107730 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#095 loss=0.452318 step=0.06785 g_raw=+0.033 g_sm=+0.011 acc=1 | LR→0.107946 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#100 loss=0.450073 step=0.02708 g_raw=+0.014 g_sm=+0.012 acc=1 | LR→0.108163 PERT→0.100010 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1070851799, PERT_used=0.1000086798 → LR_next=0.1081626299, PERT_next=0.1000098135\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1070851799→0.1081626299 PERT 0.1000086798→0.1000098135\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.58\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.448495 step=0.01288 g_raw=+0.005 g_sm=+0.012 acc=1 | LR→0.108379 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#110 loss=0.447611 step=0.02137 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.108597 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#115 loss=0.446341 step=0.01544 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.108814 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#120 loss=0.445516 step=0.001327 g_raw=+0.001 g_sm=+0.010 acc=1 | LR→0.109032 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#125 loss=0.444530 step=0.00379 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.109251 PERT→0.100011 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1081626299, PERT_used=0.1000098135 → LR_next=0.1092508364, PERT_next=0.1000108698\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1081626299→0.1092508364 PERT 0.1000098135→0.1000108698\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.58\n",
            "[round 2 | client 1] final LR=0.1092508364, final PERT=0.1000108698  (ΔLR=+0.0053338890, ΔPERT=+0.0000054497)\n",
            "[round 2 | client 2] seed LR=0.1039179428 (prev=0.1078358856), seed PERT=0.1000063598 (prev=0.1000127196), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.557288 step=0.01033 g_raw=+0.004 g_sm=+0.002 acc=1 | LR→0.104126 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.552061 step=0.03646 g_raw=+0.018 g_sm=+0.007 acc=1 | LR→0.104335 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.549077 step=0.007316 g_raw=+0.005 g_sm=+0.008 acc=1 | LR→0.104544 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.545743 step=0.03855 g_raw=+0.019 g_sm=+0.010 acc=1 | LR→0.104753 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.536596 step=0.09377 g_raw=+0.049 g_sm=+0.014 acc=1 | LR→0.104963 PERT→0.100007 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1039179428, PERT_used=0.1000063598 → LR_next=0.1049630732, PERT_next=0.1000070627\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1039179428→0.1049630732 PERT 0.1000063598→0.1000070627\n",
            "Training Accuracy: 0.32\n",
            "Test Accuracy: 0.40\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.528418 step=0.03842 g_raw=+0.022 g_sm=+0.017 acc=1 | LR→0.105174 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.523445 step=0.04403 g_raw=+0.023 g_sm=+0.017 acc=1 | LR→0.105384 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.520098 step=0.04245 g_raw=+0.020 g_sm=+0.017 acc=1 | LR→0.105596 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.515722 step=0.03282 g_raw=+0.017 g_sm=+0.018 acc=1 | LR→0.105808 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.512196 step=0.02933 g_raw=+0.014 g_sm=+0.017 acc=1 | LR→0.106020 PERT→0.100009 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1049630732, PERT_used=0.1000070627 → LR_next=0.1060197854, PERT_next=0.1000087756\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1049630732→0.1060197854 PERT 0.1000070627→0.1000087756\n",
            "Training Accuracy: 0.42\n",
            "Test Accuracy: 0.41\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.508981 step=0.03056 g_raw=+0.016 g_sm=+0.017 acc=1 | LR→0.106232 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.498256 step=0.05745 g_raw=+0.031 g_sm=+0.019 acc=1 | LR→0.106445 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.494122 step=0.02137 g_raw=+0.009 g_sm=+0.018 acc=1 | LR→0.106659 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.488266 step=0.00231 g_raw=+0.001 g_sm=+0.018 acc=1 | LR→0.106873 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.484420 step=0.07044 g_raw=+0.034 g_sm=+0.018 acc=1 | LR→0.107087 PERT→0.100011 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1060197854, PERT_used=0.1000087756 → LR_next=0.1070872140, PERT_next=0.1000105612\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1060197854→0.1070872140 PERT 0.1000087756→0.1000105612\n",
            "Training Accuracy: 0.52\n",
            "Test Accuracy: 0.43\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.481477 step=0.01558 g_raw=+0.008 g_sm=+0.017 acc=1 | LR→0.107302 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.479840 step=0.0009492 g_raw=+0.002 g_sm=+0.015 acc=1 | LR→0.107517 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.474284 step=0.06129 g_raw=+0.032 g_sm=+0.017 acc=1 | LR→0.107733 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.472271 step=0.03207 g_raw=+0.016 g_sm=+0.016 acc=1 | LR→0.107949 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.465822 step=0.05207 g_raw=+0.025 g_sm=+0.018 acc=1 | LR→0.108165 PERT→0.100012 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1070872140, PERT_used=0.1000105612 → LR_next=0.1081652562, PERT_next=0.1000122235\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1070872140→0.1081652562 PERT 0.1000105612→0.1000122235\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.55\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.462273 step=0.01486 g_raw=+0.006 g_sm=+0.017 acc=1 | LR→0.108382 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#110 loss=0.453576 step=0.06519 g_raw=+0.035 g_sm=+0.019 acc=1 | LR→0.108600 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.452875 step=0.01836 g_raw=+0.010 g_sm=+0.017 acc=1 | LR→0.108817 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.446180 step=0.004123 g_raw=+0.001 g_sm=+0.017 acc=1 | LR→0.109036 PERT→0.100014 (scale=0.04)\n",
            "[meta] cb#125 loss=0.441284 step=0.03536 g_raw=+0.019 g_sm=+0.016 acc=1 | LR→0.109254 PERT→0.100014 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1081652562, PERT_used=0.1000122235 → LR_next=0.1092542317, PERT_next=0.1000139597\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1081652562→0.1092542317 PERT 0.1000122235→0.1000139597\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.56\n",
            "[round 2 | client 2] final LR=0.1092542317, final PERT=0.1000139597  (ΔLR=+0.0053362889, ΔPERT=+0.0000075999)\n",
            "[round 2 | client 3] seed LR=0.1039159432 (prev=0.1078318864), seed PERT=0.1000045098 (prev=0.1000090197), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.549011 step=0.02343 g_raw=+0.014 g_sm=+0.005 acc=1 | LR→0.104124 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#010 loss=0.532862 step=0.1019 g_raw=+0.051 g_sm=+0.013 acc=1 | LR→0.104333 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#015 loss=0.522839 step=0.07233 g_raw=+0.039 g_sm=+0.017 acc=1 | LR→0.104542 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#020 loss=0.518212 step=0.001498 g_raw=+0.002 g_sm=+0.016 acc=1 | LR→0.104752 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#025 loss=0.515395 step=0.03623 g_raw=+0.018 g_sm=+0.016 acc=1 | LR→0.104962 PERT→0.100006 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1039159432, PERT_used=0.1000045098 → LR_next=0.1049615591, PERT_next=0.1000056944\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.024 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1039159432→0.1049615591 PERT 0.1000045098→0.1000056944\n",
            "Training Accuracy: 0.46\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.510446 step=0.04027 g_raw=+0.023 g_sm=+0.017 acc=1 | LR→0.105172 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#035 loss=0.501577 step=0.0755 g_raw=+0.036 g_sm=+0.018 acc=1 | LR→0.105383 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#040 loss=0.488287 step=0.07319 g_raw=+0.037 g_sm=+0.022 acc=1 | LR→0.105594 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#045 loss=0.475205 step=0.02636 g_raw=+0.014 g_sm=+0.022 acc=1 | LR→0.105806 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#050 loss=0.471383 step=0.01983 g_raw=+0.009 g_sm=+0.021 acc=1 | LR→0.106019 PERT→0.100008 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1049615591, PERT_used=0.1000056944 → LR_next=0.1060185628, PERT_next=0.1000076965\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.024 g_sm_mean=+0.020 acc_ratio=1.00 | LR 0.1049615591→0.1060185628 PERT 0.1000056944→0.1000076965\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.467280 step=0.05629 g_raw=+0.030 g_sm=+0.020 acc=1 | LR→0.106231 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#060 loss=0.464770 step=0.01126 g_raw=+0.004 g_sm=+0.019 acc=1 | LR→0.106444 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#065 loss=0.462606 step=0.02329 g_raw=+0.012 g_sm=+0.017 acc=1 | LR→0.106658 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.461982 step=0.01919 g_raw=+0.007 g_sm=+0.015 acc=1 | LR→0.106872 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#075 loss=0.459764 step=0.01082 g_raw=+0.005 g_sm=+0.014 acc=1 | LR→0.107086 PERT→0.100009 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1060185628, PERT_used=0.1000076965 → LR_next=0.1070859596, PERT_next=0.1000094641\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1060185628→0.1070859596 PERT 0.1000076965→0.1000094641\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.458228 step=0.005647 g_raw=+0.003 g_sm=+0.013 acc=1 | LR→0.107301 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.454567 step=0.05472 g_raw=+0.029 g_sm=+0.015 acc=1 | LR→0.107516 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#090 loss=0.450061 step=0.05092 g_raw=+0.025 g_sm=+0.016 acc=1 | LR→0.107731 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#095 loss=0.446314 step=0.01365 g_raw=+0.007 g_sm=+0.015 acc=1 | LR→0.107947 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.444599 step=0.03034 g_raw=+0.017 g_sm=+0.015 acc=1 | LR→0.108164 PERT→0.100011 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1070859596, PERT_used=0.1000094641 → LR_next=0.1081637802, PERT_next=0.1000109331\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1070859596→0.1081637802 PERT 0.1000094641→0.1000109331\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.440783 step=0.0664 g_raw=+0.031 g_sm=+0.015 acc=1 | LR→0.108381 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#110 loss=0.436844 step=0.01844 g_raw=+0.009 g_sm=+0.016 acc=1 | LR→0.108598 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.433252 step=0.06166 g_raw=+0.032 g_sm=+0.016 acc=1 | LR→0.108816 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.428598 step=0.005164 g_raw=+0.004 g_sm=+0.016 acc=1 | LR→0.109034 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#125 loss=0.424488 step=0.02052 g_raw=+0.010 g_sm=+0.016 acc=1 | LR→0.109253 PERT→0.100013 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1081637802, PERT_used=0.1000109331 → LR_next=0.1092525608, PERT_next=0.1000125045\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1081637802→0.1092525608 PERT 0.1000109331→0.1000125045\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.71\n",
            "[round 2 | client 3] final LR=0.1092525608, final PERT=0.1000125045  (ΔLR=+0.0053366176, ΔPERT=+0.0000079947)\n",
            "[round 2 | client 4] seed LR=0.1039173615 (prev=0.1078347231), seed PERT=0.1000058091 (prev=0.1000116183), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.536152 step=0.02448 g_raw=+0.013 g_sm=+0.002 acc=1 | LR→0.104125 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.533089 step=0.05682 g_raw=+0.029 g_sm=+0.005 acc=1 | LR→0.104334 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.531144 step=0.01261 g_raw=+0.007 g_sm=+0.007 acc=1 | LR→0.104543 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.529833 step=0.009352 g_raw=+0.004 g_sm=+0.007 acc=1 | LR→0.104752 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#025 loss=0.528230 step=0.005094 g_raw=+0.003 g_sm=+0.008 acc=1 | LR→0.104962 PERT→0.100006 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1039173615, PERT_used=0.1000058091 → LR_next=0.1049622857, PERT_next=0.1000063211\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1039173615→0.1049622857 PERT 0.1000058091→0.1000063211\n",
            "Training Accuracy: 0.40\n",
            "Test Accuracy: 0.35\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.525095 step=0.0345 g_raw=+0.018 g_sm=+0.010 acc=1 | LR→0.105173 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.520891 step=0.03206 g_raw=+0.018 g_sm=+0.012 acc=1 | LR→0.105383 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#040 loss=0.516783 step=0.06079 g_raw=+0.029 g_sm=+0.013 acc=1 | LR→0.105595 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#045 loss=0.515660 step=0.03051 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.105806 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#050 loss=0.510901 step=0.02643 g_raw=+0.012 g_sm=+0.014 acc=1 | LR→0.106018 PERT→0.100008 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1049622857, PERT_used=0.1000063211 → LR_next=0.1060184368, PERT_next=0.1000075121\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1049622857→0.1060184368 PERT 0.1000063211→0.1000075121\n",
            "Training Accuracy: 0.52\n",
            "Test Accuracy: 0.41\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.508008 step=0.03051 g_raw=+0.015 g_sm=+0.015 acc=1 | LR→0.106231 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#060 loss=0.501742 step=2.094e-05 g_raw=+0.001 g_sm=+0.016 acc=1 | LR→0.106444 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#065 loss=0.488629 step=0.04589 g_raw=+0.024 g_sm=+0.020 acc=1 | LR→0.106658 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.481455 step=0.0684 g_raw=+0.035 g_sm=+0.021 acc=1 | LR→0.106871 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#075 loss=0.478368 step=0.001167 g_raw=-0.001 g_sm=+0.019 acc=1 | LR→0.107086 PERT→0.100009 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1060184368, PERT_used=0.1000075121 → LR_next=0.1070858581, PERT_next=0.1000093036\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1060184368→0.1070858581 PERT 0.1000075121→0.1000093036\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.45\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.476973 step=0.04137 g_raw=+0.021 g_sm=+0.017 acc=1 | LR→0.107301 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.475554 step=0.01358 g_raw=+0.007 g_sm=+0.015 acc=1 | LR→0.107516 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#090 loss=0.470161 step=0.037 g_raw=+0.019 g_sm=+0.016 acc=1 | LR→0.107731 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#095 loss=0.468045 step=0.03327 g_raw=+0.017 g_sm=+0.016 acc=1 | LR→0.107947 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.466550 step=0.04022 g_raw=+0.020 g_sm=+0.015 acc=1 | LR→0.108164 PERT→0.100011 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1070858581, PERT_used=0.1000093036 → LR_next=0.1081638380, PERT_next=0.1000109209\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1070858581→0.1081638380 PERT 0.1000093036→0.1000109209\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.45\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.461570 step=0.04118 g_raw=+0.022 g_sm=+0.016 acc=1 | LR→0.108381 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#110 loss=0.458494 step=0.01895 g_raw=+0.008 g_sm=+0.015 acc=1 | LR→0.108598 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.456025 step=0.04424 g_raw=+0.020 g_sm=+0.015 acc=1 | LR→0.108816 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.453769 step=0.01964 g_raw=+0.011 g_sm=+0.015 acc=1 | LR→0.109034 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#125 loss=0.451794 step=0.0003052 g_raw=-0.000 g_sm=+0.014 acc=1 | LR→0.109253 PERT→0.100012 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1081638380, PERT_used=0.1000109209 → LR_next=0.1092525401, PERT_next=0.1000124199\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1081638380→0.1092525401 PERT 0.1000109209→0.1000124199\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.45\n",
            "[round 2 | client 4] final LR=0.1092525401, final PERT=0.1000124199  (ΔLR=+0.0053351785, ΔPERT=+0.0000066107)\n",
            "\n",
            "[Round 2] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           0      0.565442      0.855000      0.109251      0.100011\n",
            "           3      0.626818      0.710000      0.109253      0.100013\n",
            "           2      0.669393      0.555000      0.109254      0.100014\n",
            "           1      0.670355      0.580000      0.109251      0.100011\n",
            "           4      0.825596      0.450000      0.109253      0.100012\n",
            "→ [Round 2] best_client=0, best_val=0.565442, prev_global_val=0.550882, improve=-0.014559, action=hold (τ=0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  30%|███       | 3/10 [28:22<1:06:22, 568.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   2] acc_g=0.774 (μ=0.630, σ=0.140, FG=0.305) | t=558.763s, val=0.547 | TEL=FALSE\n",
            "[Round 3] Teleportation OFF | Aggregation=best\n",
            "[round 3 | client 0] seed LR=0.1046253620 (prev=0.1092507239), seed PERT=0.1000053961 (prev=0.1000107922), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.491383 step=0.001177 g_raw=-0.000 g_sm=+0.005 acc=1 | LR→0.104835 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#010 loss=0.487049 step=0.004063 g_raw=+0.001 g_sm=+0.007 acc=1 | LR→0.105045 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.482371 step=0.05481 g_raw=+0.025 g_sm=+0.010 acc=1 | LR→0.105255 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.476507 step=0.07772 g_raw=+0.040 g_sm=+0.013 acc=1 | LR→0.105466 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#025 loss=0.472941 step=0.03134 g_raw=+0.016 g_sm=+0.014 acc=1 | LR→0.105678 PERT→0.100006 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1046253620, PERT_used=0.1000053961 → LR_next=0.1056778070, PERT_next=0.1000062881\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1046253620→0.1056778070 PERT 0.1000053961→0.1000062881\n",
            "Training Accuracy: 0.50\n",
            "Test Accuracy: 0.55\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.462561 step=0.01644 g_raw=+0.008 g_sm=+0.017 acc=1 | LR→0.105890 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.461554 step=0.02267 g_raw=+0.011 g_sm=+0.015 acc=1 | LR→0.106102 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#040 loss=0.453389 step=0.08313 g_raw=+0.042 g_sm=+0.018 acc=1 | LR→0.106315 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#045 loss=0.450759 step=0.01477 g_raw=+0.008 g_sm=+0.017 acc=1 | LR→0.106528 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.446116 step=0.02071 g_raw=+0.010 g_sm=+0.016 acc=1 | LR→0.106742 PERT→0.100008 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1056778070, PERT_used=0.1000062881 → LR_next=0.1067416324, PERT_next=0.1000079239\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1056778070→0.1067416324 PERT 0.1000062881→0.1000079239\n",
            "Training Accuracy: 0.48\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.441699 step=0.06911 g_raw=+0.033 g_sm=+0.017 acc=1 | LR→0.106956 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#060 loss=0.440691 step=0.01637 g_raw=+0.008 g_sm=+0.015 acc=1 | LR→0.107170 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.437470 step=0.02535 g_raw=+0.013 g_sm=+0.016 acc=1 | LR→0.107385 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.434070 step=0.03935 g_raw=+0.019 g_sm=+0.015 acc=1 | LR→0.107600 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#075 loss=0.426199 step=0.03488 g_raw=+0.016 g_sm=+0.018 acc=1 | LR→0.107816 PERT→0.100010 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1067416324, PERT_used=0.1000079239 → LR_next=0.1078161482, PERT_next=0.1000095420\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1067416324→0.1078161482 PERT 0.1000079239→0.1000095420\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.65\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.421163 step=0.005896 g_raw=+0.004 g_sm=+0.017 acc=1 | LR→0.108032 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.420318 step=0.01841 g_raw=+0.010 g_sm=+0.015 acc=1 | LR→0.108249 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#090 loss=0.411218 step=0.04536 g_raw=+0.020 g_sm=+0.018 acc=1 | LR→0.108466 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.409229 step=0.01581 g_raw=+0.008 g_sm=+0.017 acc=1 | LR→0.108684 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.400680 step=0.06386 g_raw=+0.031 g_sm=+0.019 acc=1 | LR→0.108902 PERT→0.100011 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1078161482, PERT_used=0.1000095420 → LR_next=0.1089015626, PERT_next=0.1000112356\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1078161482→0.1089015626 PERT 0.1000095420→0.1000112356\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.397439 step=0.01627 g_raw=+0.008 g_sm=+0.018 acc=1 | LR→0.109120 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.394841 step=0.04718 g_raw=+0.024 g_sm=+0.017 acc=1 | LR→0.109339 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.389460 step=0.03143 g_raw=+0.014 g_sm=+0.018 acc=1 | LR→0.109558 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.387802 step=0.01432 g_raw=+0.008 g_sm=+0.016 acc=1 | LR→0.109778 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.384609 step=0.02687 g_raw=+0.012 g_sm=+0.016 acc=1 | LR→0.109998 PERT→0.100013 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1089015626, PERT_used=0.1000112356 → LR_next=0.1099979660, PERT_next=0.1000129854\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1089015626→0.1099979660 PERT 0.1000112356→0.1000129854\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.62\n",
            "[round 3 | client 0] final LR=0.1099979660, final PERT=0.1000129854  (ΔLR=+0.0053726040, ΔPERT=+0.0000075893)\n",
            "[round 3 | client 1] seed LR=0.1046254182 (prev=0.1092508364), seed PERT=0.1000054349 (prev=0.1000108698), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.480486 step=0.03148 g_raw=+0.019 g_sm=+0.004 acc=1 | LR→0.104835 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#010 loss=0.478387 step=0.003375 g_raw=+0.004 g_sm=+0.005 acc=1 | LR→0.105045 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.466874 step=0.08687 g_raw=+0.044 g_sm=+0.011 acc=1 | LR→0.105255 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.465916 step=0.03548 g_raw=+0.017 g_sm=+0.011 acc=1 | LR→0.105466 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#025 loss=0.459857 step=0.03147 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.105678 PERT→0.100006 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1046254182, PERT_used=0.1000054349 → LR_next=0.1056777383, PERT_next=0.1000062083\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1046254182→0.1056777383 PERT 0.1000054349→0.1000062083\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.453691 step=0.007618 g_raw=+0.004 g_sm=+0.015 acc=1 | LR→0.105890 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#035 loss=0.451878 step=0.01796 g_raw=+0.007 g_sm=+0.014 acc=1 | LR→0.106102 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#040 loss=0.449274 step=0.03636 g_raw=+0.017 g_sm=+0.014 acc=1 | LR→0.106315 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#045 loss=0.441582 step=0.07381 g_raw=+0.034 g_sm=+0.017 acc=1 | LR→0.106528 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#050 loss=0.436614 step=0.06856 g_raw=+0.033 g_sm=+0.017 acc=1 | LR→0.106741 PERT→0.100008 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1056777383, PERT_used=0.1000062083 → LR_next=0.1067414327, PERT_next=0.1000077218\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1056777383→0.1067414327 PERT 0.1000062083→0.1000077218\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.75\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.436168 step=0.008209 g_raw=+0.004 g_sm=+0.015 acc=1 | LR→0.106955 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#060 loss=0.432889 step=0.008833 g_raw=+0.004 g_sm=+0.014 acc=1 | LR→0.107170 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#065 loss=0.428145 step=0.05166 g_raw=+0.024 g_sm=+0.015 acc=1 | LR→0.107385 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.425195 step=0.002133 g_raw=+0.002 g_sm=+0.015 acc=1 | LR→0.107600 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#075 loss=0.422278 step=0.0291 g_raw=+0.013 g_sm=+0.015 acc=1 | LR→0.107816 PERT→0.100009 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1067414327, PERT_used=0.1000077218 → LR_next=0.1078158287, PERT_next=0.1000092308\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1067414327→0.1078158287 PERT 0.1000077218→0.1000092308\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.78\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.420986 step=0.01655 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.108032 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.417791 step=0.03346 g_raw=+0.015 g_sm=+0.014 acc=1 | LR→0.108249 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#090 loss=0.415419 step=0.03 g_raw=+0.015 g_sm=+0.014 acc=1 | LR→0.108466 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#095 loss=0.412043 step=0.04862 g_raw=+0.023 g_sm=+0.015 acc=1 | LR→0.108683 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#100 loss=0.411246 step=0.01779 g_raw=+0.008 g_sm=+0.013 acc=1 | LR→0.108901 PERT→0.100011 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1078158287, PERT_used=0.1000092308 → LR_next=0.1089009086, PERT_next=0.1000106201\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1078158287→0.1089009086 PERT 0.1000092308→0.1000106201\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.80\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.411182 step=0.006692 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.109119 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#110 loss=0.410454 step=0.00817 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.109338 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#115 loss=0.407773 step=0.04356 g_raw=+0.023 g_sm=+0.011 acc=1 | LR→0.109557 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#120 loss=0.406557 step=0.003027 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.109777 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#125 loss=0.406064 step=0.01553 g_raw=+0.007 g_sm=+0.010 acc=1 | LR→0.109997 PERT→0.100012 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1089009086, PERT_used=0.1000106201 → LR_next=0.1099965423, PERT_next=0.1000116760\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1089009086→0.1099965423 PERT 0.1000106201→0.1000116760\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.79\n",
            "[round 3 | client 1] final LR=0.1099965423, final PERT=0.1000116760  (ΔLR=+0.0053711241, ΔPERT=+0.0000062411)\n",
            "[round 3 | client 2] seed LR=0.1046271159 (prev=0.1092542317), seed PERT=0.1000069799 (prev=0.1000139597), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.516843 step=0.03117 g_raw=+0.015 g_sm=+0.005 acc=1 | LR→0.104837 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.515836 step=0.01662 g_raw=+0.010 g_sm=+0.006 acc=1 | LR→0.105047 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.513303 step=0.02228 g_raw=+0.012 g_sm=+0.008 acc=1 | LR→0.105257 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.509043 step=0.02578 g_raw=+0.013 g_sm=+0.010 acc=1 | LR→0.105468 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.504501 step=0.08633 g_raw=+0.044 g_sm=+0.012 acc=1 | LR→0.105679 PERT→0.100008 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1046271159, PERT_used=0.1000069799 → LR_next=0.1056793754, PERT_next=0.1000076797\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1046271159→0.1056793754 PERT 0.1000069799→0.1000076797\n",
            "Training Accuracy: 0.38\n",
            "Test Accuracy: 0.40\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.501089 step=0.0005658 g_raw=+0.002 g_sm=+0.012 acc=1 | LR→0.105891 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.493562 step=0.02734 g_raw=+0.013 g_sm=+0.015 acc=1 | LR→0.106104 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.489881 step=0.011 g_raw=+0.004 g_sm=+0.015 acc=1 | LR→0.106316 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.485722 step=0.03386 g_raw=+0.016 g_sm=+0.015 acc=1 | LR→0.106529 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.483528 step=0.02894 g_raw=+0.015 g_sm=+0.015 acc=1 | LR→0.106743 PERT→0.100009 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1056793754, PERT_used=0.1000076797 → LR_next=0.1067430217, PERT_next=0.1000091328\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1056793754→0.1067430217 PERT 0.1000076797→0.1000091328\n",
            "Training Accuracy: 0.54\n",
            "Test Accuracy: 0.46\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.481087 step=0.0246 g_raw=+0.013 g_sm=+0.015 acc=1 | LR→0.106957 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.477328 step=0.01603 g_raw=+0.008 g_sm=+0.015 acc=1 | LR→0.107171 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.474842 step=0.05599 g_raw=+0.027 g_sm=+0.014 acc=1 | LR→0.107386 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.472213 step=0.007456 g_raw=+0.004 g_sm=+0.014 acc=1 | LR→0.107602 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.465397 step=0.003055 g_raw=+0.004 g_sm=+0.015 acc=1 | LR→0.107817 PERT→0.100011 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1067430217, PERT_used=0.1000091328 → LR_next=0.1078173702, PERT_next=0.1000105829\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1067430217→0.1078173702 PERT 0.1000091328→0.1000105829\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.461361 step=0.05358 g_raw=+0.026 g_sm=+0.016 acc=1 | LR→0.108034 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.460958 step=0.001968 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.108250 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.460218 step=0.008979 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.108467 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.454806 step=0.08013 g_raw=+0.039 g_sm=+0.014 acc=1 | LR→0.108685 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.451784 step=0.008996 g_raw=+0.004 g_sm=+0.014 acc=1 | LR→0.108902 PERT→0.100012 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1078173702, PERT_used=0.1000105829 → LR_next=0.1089024538, PERT_next=0.1000119614\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1078173702→0.1089024538 PERT 0.1000105829→0.1000119614\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.449396 step=0.0168 g_raw=+0.011 g_sm=+0.013 acc=1 | LR→0.109121 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.448659 step=0.004945 g_raw=+0.002 g_sm=+0.012 acc=1 | LR→0.109340 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.448510 step=0.007567 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.109559 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.447635 step=0.003464 g_raw=+0.001 g_sm=+0.009 acc=1 | LR→0.109778 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.446678 step=0.03061 g_raw=+0.013 g_sm=+0.009 acc=1 | LR→0.109998 PERT→0.100013 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1089024538, PERT_used=0.1000119614 → LR_next=0.1099981587, PERT_next=0.1000130679\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1089024538→0.1099981587 PERT 0.1000119614→0.1000130679\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.51\n",
            "[round 3 | client 2] final LR=0.1099981587, final PERT=0.1000130679  (ΔLR=+0.0053710428, ΔPERT=+0.0000060880)\n",
            "[round 3 | client 3] seed LR=0.1046262804 (prev=0.1092525608), seed PERT=0.1000062523 (prev=0.1000125045), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.486795 step=0.01423 g_raw=+0.006 g_sm=+0.002 acc=1 | LR→0.104836 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.483547 step=0.02272 g_raw=+0.011 g_sm=+0.004 acc=1 | LR→0.105046 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.482396 step=0.04423 g_raw=+0.023 g_sm=+0.005 acc=1 | LR→0.105256 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.481024 step=0.03145 g_raw=+0.015 g_sm=+0.006 acc=1 | LR→0.105467 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.478238 step=0.007061 g_raw=+0.004 g_sm=+0.008 acc=1 | LR→0.105678 PERT→0.100007 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1046262804, PERT_used=0.1000062523 → LR_next=0.1056782539, PERT_next=0.1000066893\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.004 acc_ratio=1.00 | LR 0.1046262804→0.1056782539 PERT 0.1000062523→0.1000066893\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.468021 step=0.1116 g_raw=+0.053 g_sm=+0.012 acc=1 | LR→0.105890 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.463467 step=0.02167 g_raw=+0.010 g_sm=+0.014 acc=1 | LR→0.106102 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#040 loss=0.460303 step=0.02189 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.106315 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#045 loss=0.456688 step=0.04415 g_raw=+0.022 g_sm=+0.014 acc=1 | LR→0.106528 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.454422 step=0.005632 g_raw=+0.004 g_sm=+0.014 acc=1 | LR→0.106742 PERT→0.100008 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1056782539, PERT_used=0.1000066893 → LR_next=0.1067417101, PERT_next=0.1000079749\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1056782539→0.1067417101 PERT 0.1000066893→0.1000079749\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.60\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.453872 step=0.003198 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.106956 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#060 loss=0.450061 step=0.02303 g_raw=+0.011 g_sm=+0.013 acc=1 | LR→0.107170 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#065 loss=0.448838 step=0.01203 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.107385 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.447445 step=0.009909 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.107600 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#075 loss=0.446010 step=0.02068 g_raw=+0.011 g_sm=+0.011 acc=1 | LR→0.107816 PERT→0.100009 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1067417101, PERT_used=0.1000079749 → LR_next=0.1078157841, PERT_next=0.1000091826\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1067417101→0.1078157841 PERT 0.1000079749→0.1000091826\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.63\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.443507 step=0.04892 g_raw=+0.024 g_sm=+0.012 acc=1 | LR→0.108032 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#085 loss=0.442763 step=0.004731 g_raw=-0.001 g_sm=+0.010 acc=1 | LR→0.108248 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#090 loss=0.442304 step=0.02084 g_raw=+0.010 g_sm=+0.009 acc=1 | LR→0.108465 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#095 loss=0.441889 step=0.005827 g_raw=+0.001 g_sm=+0.008 acc=1 | LR→0.108683 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#100 loss=0.440630 step=0.01378 g_raw=+0.007 g_sm=+0.008 acc=1 | LR→0.108900 PERT→0.100010 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1078157841, PERT_used=0.1000091826 → LR_next=0.1089004088, PERT_next=0.1000101542\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1078157841→0.1089004088 PERT 0.1000091826→0.1000101542\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.438677 step=0.03353 g_raw=+0.015 g_sm=+0.009 acc=1 | LR→0.109119 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#110 loss=0.437411 step=0.02658 g_raw=+0.011 g_sm=+0.009 acc=1 | LR→0.109337 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#115 loss=0.437064 step=0.0008433 g_raw=+0.000 g_sm=+0.008 acc=1 | LR→0.109556 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#120 loss=0.435886 step=0.01524 g_raw=+0.008 g_sm=+0.008 acc=1 | LR→0.109776 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#125 loss=0.433820 step=0.03716 g_raw=+0.018 g_sm=+0.009 acc=1 | LR→0.109996 PERT→0.100011 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1089004088, PERT_used=0.1000101542 → LR_next=0.1099958393, PERT_next=0.1000110300\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1089004088→0.1099958393 PERT 0.1000101542→0.1000110300\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.64\n",
            "[round 3 | client 3] final LR=0.1099958393, final PERT=0.1000110300  (ΔLR=+0.0053695589, ΔPERT=+0.0000047778)\n",
            "[round 3 | client 4] seed LR=0.1046262700 (prev=0.1092525401), seed PERT=0.1000062099 (prev=0.1000124199), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.464494 step=0.0314 g_raw=+0.014 g_sm=+0.005 acc=1 | LR→0.104836 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.463709 step=0.009873 g_raw=+0.007 g_sm=+0.005 acc=1 | LR→0.105046 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.451961 step=0.003709 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.105256 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.445276 step=0.05868 g_raw=+0.029 g_sm=+0.014 acc=1 | LR→0.105467 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.444144 step=0.0228 g_raw=+0.011 g_sm=+0.013 acc=1 | LR→0.105679 PERT→0.100007 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1046262700, PERT_used=0.1000062099 → LR_next=0.1056787025, PERT_next=0.1000070815\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1046262700→0.1056787025 PERT 0.1000062099→0.1000070815\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.82\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.440904 step=0.05465 g_raw=+0.026 g_sm=+0.014 acc=1 | LR→0.105891 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.438191 step=0.01558 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.106103 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.431111 step=0.0148 g_raw=+0.007 g_sm=+0.015 acc=1 | LR→0.106316 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.425832 step=0.02449 g_raw=+0.012 g_sm=+0.016 acc=1 | LR→0.106529 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.424287 step=0.01704 g_raw=+0.006 g_sm=+0.015 acc=1 | LR→0.106742 PERT→0.100009 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1056787025, PERT_used=0.1000070815 → LR_next=0.1067423389, PERT_next=0.1000085316\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1056787025→0.1067423389 PERT 0.1000070815→0.1000085316\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.82\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.419181 step=0.03253 g_raw=+0.015 g_sm=+0.016 acc=1 | LR→0.106956 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.415251 step=0.04223 g_raw=+0.020 g_sm=+0.016 acc=1 | LR→0.107171 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.412460 step=0.04311 g_raw=+0.021 g_sm=+0.016 acc=1 | LR→0.107386 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.412207 step=0.00928 g_raw=+0.004 g_sm=+0.014 acc=1 | LR→0.107601 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.410436 step=0.04388 g_raw=+0.020 g_sm=+0.013 acc=1 | LR→0.107817 PERT→0.100010 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1067423389, PERT_used=0.1000085316 → LR_next=0.1078167329, PERT_next=0.1000100303\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1067423389→0.1078167329 PERT 0.1000085316→0.1000100303\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.83\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.409938 step=0.02592 g_raw=+0.012 g_sm=+0.011 acc=1 | LR→0.108033 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.404972 step=0.01867 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.108249 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.404569 step=0.006006 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.108466 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.401184 step=0.02893 g_raw=+0.016 g_sm=+0.012 acc=1 | LR→0.108684 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.399581 step=0.01634 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.108902 PERT→0.100011 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1078167329, PERT_used=0.1000100303 → LR_next=0.1089016001, PERT_next=0.1000112159\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1078167329→0.1089016001 PERT 0.1000100303→0.1000112159\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.82\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.393896 step=0.03374 g_raw=+0.016 g_sm=+0.014 acc=1 | LR→0.109120 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#110 loss=0.390912 step=0.0231 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.109339 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.388348 step=0.0197 g_raw=+0.009 g_sm=+0.014 acc=1 | LR→0.109558 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.383657 step=0.0479 g_raw=+0.021 g_sm=+0.015 acc=1 | LR→0.109778 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#125 loss=0.382756 step=0.02343 g_raw=+0.011 g_sm=+0.013 acc=1 | LR→0.109998 PERT→0.100013 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1089016001, PERT_used=0.1000112159 → LR_next=0.1099976301, PERT_next=0.1000126259\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1089016001→0.1099976301 PERT 0.1000112159→0.1000126259\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.69\n",
            "[round 3 | client 4] final LR=0.1099976301, final PERT=0.1000126259  (ΔLR=+0.0053713600, ΔPERT=+0.0000064159)\n",
            "\n",
            "[Round 3] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           4      0.544495      0.690000      0.109998      0.100013\n",
            "           1      0.565045      0.785000      0.109997      0.100012\n",
            "           0      0.565448      0.620000      0.109998      0.100013\n",
            "           3      0.630253      0.635000      0.109996      0.100011\n",
            "           2      0.700708      0.510000      0.109998      0.100013\n",
            "→ [Round 3] best_client=4, best_val=0.544495, prev_global_val=0.546809, improve=+0.002314, action=adopt+mix τ=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  40%|████      | 4/10 [37:32<56:10, 561.75s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   3] acc_g=0.819 (μ=0.648, σ=0.090, FG=0.193) | t=541.150s, val=0.549 | TEL=FALSE\n",
            "[Round 4] Teleportation OFF | Aggregation=best\n",
            "[round 4 | client 0] seed LR=0.1049989830 (prev=0.1099979660), seed PERT=0.1000064927 (prev=0.1000129854), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.536954 step=0.039 g_raw=+0.018 g_sm=+0.003 acc=1 | LR→0.105209 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.533220 step=0.004378 g_raw=+0.002 g_sm=+0.006 acc=1 | LR→0.105420 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.530338 step=0.02845 g_raw=+0.014 g_sm=+0.008 acc=1 | LR→0.105631 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.528310 step=0.03421 g_raw=+0.017 g_sm=+0.009 acc=1 | LR→0.105843 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.526332 step=0.002452 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.106055 PERT→0.100007 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1049989830, PERT_used=0.1000064927 → LR_next=0.1060549070, PERT_next=0.1000071213\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1049989830→0.1060549070 PERT 0.1000064927→0.1000071213\n",
            "Training Accuracy: 0.24\n",
            "Test Accuracy: 0.24\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.522788 step=0.004927 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.106267 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.518648 step=0.01999 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.106480 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.514217 step=0.06081 g_raw=+0.029 g_sm=+0.013 acc=1 | LR→0.106694 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.506237 step=0.01976 g_raw=+0.010 g_sm=+0.016 acc=1 | LR→0.106908 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.504834 step=0.03026 g_raw=+0.014 g_sm=+0.015 acc=1 | LR→0.107122 PERT→0.100008 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1060549070, PERT_used=0.1000071213 → LR_next=0.1071221445, PERT_next=0.1000083985\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1060549070→0.1071221445 PERT 0.1000071213→0.1000083985\n",
            "Training Accuracy: 0.48\n",
            "Test Accuracy: 0.47\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.499144 step=0.02398 g_raw=+0.012 g_sm=+0.017 acc=1 | LR→0.107337 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.494935 step=0.006399 g_raw=+0.003 g_sm=+0.016 acc=1 | LR→0.107552 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.490169 step=0.06436 g_raw=+0.034 g_sm=+0.016 acc=1 | LR→0.107768 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.485677 step=0.02515 g_raw=+0.011 g_sm=+0.017 acc=1 | LR→0.107984 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.479761 step=0.03254 g_raw=+0.016 g_sm=+0.018 acc=1 | LR→0.108201 PERT→0.100010 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1071221445, PERT_used=0.1000083985 → LR_next=0.1082005530, PERT_next=0.1000100743\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1071221445→0.1082005530 PERT 0.1000083985→0.1000100743\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.55\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.471434 step=0.02743 g_raw=+0.014 g_sm=+0.020 acc=1 | LR→0.108418 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.468180 step=0.01141 g_raw=+0.005 g_sm=+0.019 acc=1 | LR→0.108635 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.462109 step=0.04208 g_raw=+0.022 g_sm=+0.019 acc=1 | LR→0.108853 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.455347 step=0.02483 g_raw=+0.012 g_sm=+0.020 acc=1 | LR→0.109071 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.451733 step=0.06586 g_raw=+0.033 g_sm=+0.019 acc=1 | LR→0.109290 PERT→0.100012 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1082005530, PERT_used=0.1000100743 → LR_next=0.1092901206, PERT_next=0.1000120271\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.020 acc_ratio=1.00 | LR 0.1082005530→0.1092901206 PERT 0.1000100743→0.1000120271\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.62\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.447961 step=0.05279 g_raw=+0.025 g_sm=+0.019 acc=1 | LR→0.109509 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.442624 step=0.04543 g_raw=+0.022 g_sm=+0.020 acc=1 | LR→0.109729 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.436695 step=0.01018 g_raw=+0.007 g_sm=+0.020 acc=1 | LR→0.109949 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.433124 step=0.02548 g_raw=+0.012 g_sm=+0.019 acc=1 | LR→0.110170 PERT→0.100014 (scale=0.04)\n",
            "[meta] cb#125 loss=0.429990 step=0.03833 g_raw=+0.020 g_sm=+0.018 acc=1 | LR→0.110391 PERT→0.100014 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1092901206, PERT_used=0.1000120271 → LR_next=0.1103906587, PERT_next=0.1000139787\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.020 acc_ratio=1.00 | LR 0.1092901206→0.1103906587 PERT 0.1000120271→0.1000139787\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.68\n",
            "[round 4 | client 0] final LR=0.1103906587, final PERT=0.1000139787  (ΔLR=+0.0053916757, ΔPERT=+0.0000074860)\n",
            "[round 4 | client 1] seed LR=0.1049982711 (prev=0.1099965423), seed PERT=0.1000058380 (prev=0.1000116760), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.552391 step=0.02237 g_raw=+0.012 g_sm=+0.004 acc=1 | LR→0.105209 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.547859 step=0.06785 g_raw=+0.034 g_sm=+0.007 acc=1 | LR→0.105419 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.542885 step=0.03373 g_raw=+0.017 g_sm=+0.010 acc=1 | LR→0.105631 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.534261 step=0.004988 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.105842 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#025 loss=0.525431 step=0.1025 g_raw=+0.051 g_sm=+0.015 acc=1 | LR→0.106054 PERT→0.100007 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1049982711, PERT_used=0.1000058380 → LR_next=0.1060544266, PERT_next=0.1000066917\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1049982711→0.1060544266 PERT 0.1000058380→0.1000066917\n",
            "Training Accuracy: 0.24\n",
            "Test Accuracy: 0.33\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.522312 step=0.01653 g_raw=+0.010 g_sm=+0.015 acc=1 | LR→0.106267 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.519024 step=0.01173 g_raw=+0.006 g_sm=+0.016 acc=1 | LR→0.106480 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#040 loss=0.510847 step=0.03257 g_raw=+0.017 g_sm=+0.018 acc=1 | LR→0.106694 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.498713 step=0.04936 g_raw=+0.026 g_sm=+0.021 acc=1 | LR→0.106908 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.494831 step=0.06112 g_raw=+0.026 g_sm=+0.020 acc=1 | LR→0.107122 PERT→0.100008 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1060544266, PERT_used=0.1000066917 → LR_next=0.1071221929, PERT_next=0.1000084670\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1060544266→0.1071221929 PERT 0.1000066917→0.1000084670\n",
            "Training Accuracy: 0.54\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.489012 step=0.00725 g_raw=+0.003 g_sm=+0.020 acc=1 | LR→0.107337 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.479683 step=0.07681 g_raw=+0.037 g_sm=+0.021 acc=1 | LR→0.107552 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.476644 step=0.007849 g_raw=+0.005 g_sm=+0.020 acc=1 | LR→0.107768 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.474830 step=0.01316 g_raw=+0.005 g_sm=+0.017 acc=1 | LR→0.107984 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.470010 step=0.04057 g_raw=+0.020 g_sm=+0.018 acc=1 | LR→0.108201 PERT→0.100010 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1071221929, PERT_used=0.1000084670 → LR_next=0.1082008943, PERT_next=0.1000104131\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1071221929→0.1082008943 PERT 0.1000084670→0.1000104131\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.58\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.464154 step=0.09028 g_raw=+0.041 g_sm=+0.018 acc=1 | LR→0.108418 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.460449 step=0.0006871 g_raw=+0.001 g_sm=+0.017 acc=1 | LR→0.108635 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.456762 step=0.01606 g_raw=+0.010 g_sm=+0.017 acc=1 | LR→0.108853 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.447697 step=0.001577 g_raw=+0.001 g_sm=+0.019 acc=1 | LR→0.109072 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.446855 step=0.009682 g_raw=+0.005 g_sm=+0.016 acc=1 | LR→0.109290 PERT→0.100012 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1082008943, PERT_used=0.1000104131 → LR_next=0.1092902826, PERT_next=0.1000121987\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1082008943→0.1092902826 PERT 0.1000104131→0.1000121987\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.440569 step=0.0155 g_raw=+0.008 g_sm=+0.017 acc=1 | LR→0.109509 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#110 loss=0.438431 step=0.007578 g_raw=+0.003 g_sm=+0.016 acc=1 | LR→0.109729 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.435456 step=0.02973 g_raw=+0.017 g_sm=+0.016 acc=1 | LR→0.109949 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.434088 step=0.01822 g_raw=+0.010 g_sm=+0.014 acc=1 | LR→0.110170 PERT→0.100014 (scale=0.04)\n",
            "[meta] cb#125 loss=0.429940 step=0.05121 g_raw=+0.022 g_sm=+0.015 acc=1 | LR→0.110390 PERT→0.100014 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1092902826, PERT_used=0.1000121987 → LR_next=0.1103904278, PERT_next=0.1000137929\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1092902826→0.1103904278 PERT 0.1000121987→0.1000137929\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.59\n",
            "[round 4 | client 1] final LR=0.1103904278, final PERT=0.1000137929  (ΔLR=+0.0053921567, ΔPERT=+0.0000079549)\n",
            "[round 4 | client 2] seed LR=0.1049990793 (prev=0.1099981587), seed PERT=0.1000065339 (prev=0.1000130679), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.490953 step=0.0478 g_raw=+0.023 g_sm=+0.004 acc=1 | LR→0.105209 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.481046 step=0.06184 g_raw=+0.031 g_sm=+0.010 acc=1 | LR→0.105420 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.468153 step=0.09591 g_raw=+0.048 g_sm=+0.015 acc=1 | LR→0.105631 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.462790 step=0.07037 g_raw=+0.033 g_sm=+0.016 acc=1 | LR→0.105843 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.457120 step=0.05324 g_raw=+0.026 g_sm=+0.016 acc=1 | LR→0.106055 PERT→0.100008 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1049990793, PERT_used=0.1000065339 → LR_next=0.1060554554, PERT_next=0.1000075880\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.023 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1049990793→0.1060554554 PERT 0.1000065339→0.1000075880\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.447164 step=0.06207 g_raw=+0.030 g_sm=+0.019 acc=1 | LR→0.106268 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.444317 step=0.04186 g_raw=+0.018 g_sm=+0.018 acc=1 | LR→0.106481 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.439661 step=0.007145 g_raw=+0.003 g_sm=+0.018 acc=1 | LR→0.106695 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.435831 step=0.01982 g_raw=+0.008 g_sm=+0.017 acc=1 | LR→0.106909 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.433714 step=0.05003 g_raw=+0.021 g_sm=+0.016 acc=1 | LR→0.107123 PERT→0.100009 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1060554554, PERT_used=0.1000075880 → LR_next=0.1071232092, PERT_next=0.1000093419\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1060554554→0.1071232092 PERT 0.1000075880→0.1000093419\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.429854 step=0.08725 g_raw=+0.044 g_sm=+0.015 acc=1 | LR→0.107338 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.426750 step=0.01159 g_raw=+0.004 g_sm=+0.014 acc=1 | LR→0.107553 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.415525 step=0.04638 g_raw=+0.021 g_sm=+0.018 acc=1 | LR→0.107769 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.411429 step=0.02064 g_raw=+0.010 g_sm=+0.018 acc=1 | LR→0.107985 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#075 loss=0.400753 step=0.0172 g_raw=+0.009 g_sm=+0.020 acc=1 | LR→0.108202 PERT→0.100011 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1071232092, PERT_used=0.1000093419 → LR_next=0.1082016230, PERT_next=0.1000110128\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1071232092→0.1082016230 PERT 0.1000093419→0.1000110128\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.394014 step=0.08049 g_raw=+0.039 g_sm=+0.020 acc=1 | LR→0.108419 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.390923 step=0.007665 g_raw=+0.002 g_sm=+0.019 acc=1 | LR→0.108636 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#090 loss=0.386131 step=0.01239 g_raw=+0.007 g_sm=+0.019 acc=1 | LR→0.108854 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.383321 step=0.05446 g_raw=+0.025 g_sm=+0.018 acc=1 | LR→0.109072 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#100 loss=0.379018 step=0.007812 g_raw=+0.003 g_sm=+0.017 acc=1 | LR→0.109291 PERT→0.100013 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1082016230, PERT_used=0.1000110128 → LR_next=0.1092911371, PERT_next=0.1000129068\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1082016230→0.1092911371 PERT 0.1000110128→0.1000129068\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.65\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.376469 step=0.03494 g_raw=+0.015 g_sm=+0.016 acc=1 | LR→0.109510 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#110 loss=0.373758 step=0.03403 g_raw=+0.017 g_sm=+0.016 acc=1 | LR→0.109730 PERT→0.100014 (scale=0.04)\n",
            "[meta] cb#115 loss=0.367652 step=0.001884 g_raw=+0.003 g_sm=+0.017 acc=1 | LR→0.109950 PERT→0.100014 (scale=0.04)\n",
            "[meta] cb#120 loss=0.361653 step=0.03476 g_raw=+0.018 g_sm=+0.017 acc=1 | LR→0.110170 PERT→0.100014 (scale=0.04)\n",
            "[meta] cb#125 loss=0.357485 step=0.06616 g_raw=+0.030 g_sm=+0.017 acc=1 | LR→0.110391 PERT→0.100015 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1092911371, PERT_used=0.1000129068 → LR_next=0.1103913659, PERT_next=0.1000145689\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1092911371→0.1103913659 PERT 0.1000129068→0.1000145689\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.65\n",
            "[round 4 | client 2] final LR=0.1103913659, final PERT=0.1000145689  (ΔLR=+0.0053922865, ΔPERT=+0.0000080350)\n",
            "[round 4 | client 3] seed LR=0.1049979197 (prev=0.1099958393), seed PERT=0.1000055150 (prev=0.1000110300), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.492447 step=0.01138 g_raw=+0.006 g_sm=+0.002 acc=1 | LR→0.105208 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.491136 step=0.03861 g_raw=+0.021 g_sm=+0.004 acc=1 | LR→0.105419 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.488135 step=0.01277 g_raw=+0.007 g_sm=+0.006 acc=1 | LR→0.105630 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.485449 step=0.04376 g_raw=+0.022 g_sm=+0.008 acc=1 | LR→0.105842 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#025 loss=0.483847 step=0.01844 g_raw=+0.008 g_sm=+0.009 acc=1 | LR→0.106054 PERT→0.100006 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1049979197, PERT_used=0.1000055150 → LR_next=0.1060537134, PERT_next=0.1000060309\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1049979197→0.1060537134 PERT 0.1000055150→0.1000060309\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.480296 step=0.01195 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.106266 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#035 loss=0.477080 step=0.006066 g_raw=+0.003 g_sm=+0.012 acc=1 | LR→0.106479 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#040 loss=0.474491 step=0.0278 g_raw=+0.014 g_sm=+0.012 acc=1 | LR→0.106693 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#045 loss=0.473658 step=0.01217 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.106907 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#050 loss=0.471948 step=0.01569 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.107121 PERT→0.100007 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1060537134, PERT_used=0.1000060309 → LR_next=0.1071207845, PERT_next=0.1000071639\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1060537134→0.1071207845 PERT 0.1000060309→0.1000071639\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.467269 step=0.01483 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.107336 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#060 loss=0.465446 step=0.029 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.107551 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#065 loss=0.463893 step=0.04194 g_raw=+0.021 g_sm=+0.012 acc=1 | LR→0.107766 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#070 loss=0.460620 step=0.0003202 g_raw=+0.000 g_sm=+0.012 acc=1 | LR→0.107982 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#075 loss=0.459503 step=0.00418 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.108199 PERT→0.100008 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1071207845, PERT_used=0.1000071639 → LR_next=0.1081987034, PERT_next=0.1000083998\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1071207845→0.1081987034 PERT 0.1000071639→0.1000083998\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.62\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.452629 step=0.08163 g_raw=+0.038 g_sm=+0.014 acc=1 | LR→0.108416 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#085 loss=0.447594 step=0.04861 g_raw=+0.022 g_sm=+0.015 acc=1 | LR→0.108633 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#090 loss=0.444148 step=0.03924 g_raw=+0.020 g_sm=+0.015 acc=1 | LR→0.108851 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#095 loss=0.442287 step=0.03016 g_raw=+0.015 g_sm=+0.014 acc=1 | LR→0.109069 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#100 loss=0.441256 step=0.004305 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.109288 PERT→0.100010 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1081987034, PERT_used=0.1000083998 → LR_next=0.1092876558, PERT_next=0.1000098067\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1081987034→0.1092876558 PERT 0.1000083998→0.1000098067\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.439321 step=0.01463 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.109507 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#110 loss=0.437637 step=0.008083 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.109726 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#115 loss=0.436354 step=0.04318 g_raw=+0.021 g_sm=+0.011 acc=1 | LR→0.109946 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#120 loss=0.433439 step=0.01335 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.110167 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#125 loss=0.431729 step=0.01938 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.110387 PERT→0.100011 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1092876558, PERT_used=0.1000098067 → LR_next=0.1103873325, PERT_next=0.1000110003\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1092876558→0.1103873325 PERT 0.1000098067→0.1000110003\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.74\n",
            "[round 4 | client 3] final LR=0.1103873325, final PERT=0.1000110003  (ΔLR=+0.0053894129, ΔPERT=+0.0000054853)\n",
            "[round 4 | client 4] seed LR=0.1049988150 (prev=0.1099976301), seed PERT=0.1000063129 (prev=0.1000126259), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.471275 step=0.07906 g_raw=+0.040 g_sm=+0.004 acc=1 | LR→0.105209 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.469461 step=0.03279 g_raw=+0.019 g_sm=+0.006 acc=1 | LR→0.105420 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.460670 step=0.03131 g_raw=+0.016 g_sm=+0.011 acc=1 | LR→0.105631 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.451555 step=0.03308 g_raw=+0.017 g_sm=+0.014 acc=1 | LR→0.105843 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.444844 step=0.05925 g_raw=+0.029 g_sm=+0.016 acc=1 | LR→0.106055 PERT→0.100007 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1049988150, PERT_used=0.1000063129 → LR_next=0.1060550093, PERT_next=0.1000071980\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1049988150→0.1060550093 PERT 0.1000063129→0.1000071980\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.438233 step=0.02768 g_raw=+0.015 g_sm=+0.018 acc=1 | LR→0.106268 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.434138 step=0.0197 g_raw=+0.011 g_sm=+0.018 acc=1 | LR→0.106481 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.428371 step=0.04077 g_raw=+0.021 g_sm=+0.019 acc=1 | LR→0.106694 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.426770 step=0.01163 g_raw=+0.006 g_sm=+0.017 acc=1 | LR→0.106908 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.425398 step=0.02681 g_raw=+0.013 g_sm=+0.016 acc=1 | LR→0.107123 PERT→0.100009 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1060550093, PERT_used=0.1000071980 → LR_next=0.1071227694, PERT_next=0.1000089621\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1060550093→0.1071227694 PERT 0.1000071980→0.1000089621\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.419200 step=0.07862 g_raw=+0.037 g_sm=+0.017 acc=1 | LR→0.107338 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.415229 step=0.05557 g_raw=+0.028 g_sm=+0.017 acc=1 | LR→0.107553 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.411330 step=0.04909 g_raw=+0.026 g_sm=+0.017 acc=1 | LR→0.107769 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.409441 step=0.02741 g_raw=+0.013 g_sm=+0.016 acc=1 | LR→0.107985 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.404676 step=0.003447 g_raw=+0.003 g_sm=+0.015 acc=1 | LR→0.108201 PERT→0.100011 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1071227694, PERT_used=0.1000089621 → LR_next=0.1082011365, PERT_next=0.1000105938\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1071227694→0.1082011365 PERT 0.1000089621→0.1000105938\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.60\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.398828 step=0.05456 g_raw=+0.024 g_sm=+0.016 acc=1 | LR→0.108418 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.395785 step=0.03526 g_raw=+0.015 g_sm=+0.016 acc=1 | LR→0.108636 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.390543 step=0.02861 g_raw=+0.013 g_sm=+0.016 acc=1 | LR→0.108853 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.388358 step=0.02035 g_raw=+0.009 g_sm=+0.014 acc=1 | LR→0.109072 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.385379 step=0.04749 g_raw=+0.023 g_sm=+0.015 acc=1 | LR→0.109290 PERT→0.100012 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1082011365, PERT_used=0.1000105938 → LR_next=0.1092902926, PERT_next=0.1000121647\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1082011365→0.1092902926 PERT 0.1000105938→0.1000121647\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.384079 step=0.03772 g_raw=+0.018 g_sm=+0.014 acc=1 | LR→0.109509 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.382116 step=0.01146 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.109729 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.380467 step=0.007708 g_raw=+0.003 g_sm=+0.012 acc=1 | LR→0.109949 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.378461 step=0.03209 g_raw=+0.016 g_sm=+0.012 acc=1 | LR→0.110169 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.376334 step=0.02312 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.110390 PERT→0.100013 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1092902926, PERT_used=0.1000121647 → LR_next=0.1103901028, PERT_next=0.1000134553\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1092902926→0.1103901028 PERT 0.1000121647→0.1000134553\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.68\n",
            "[round 4 | client 4] final LR=0.1103901028, final PERT=0.1000134553  (ΔLR=+0.0053912877, ΔPERT=+0.0000071423)\n",
            "\n",
            "[Round 4] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           4      0.561434      0.675000      0.110390      0.100013\n",
            "           2      0.575574      0.645000      0.110391      0.100015\n",
            "           0      0.583214      0.675000      0.110391      0.100014\n",
            "           3      0.621280      0.740000      0.110387      0.100011\n",
            "           1      0.625572      0.590000      0.110390      0.100014\n",
            "→ [Round 4] best_client=4, best_val=0.561434, prev_global_val=0.548769, improve=-0.012665, action=hold (τ=0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  50%|█████     | 5/10 [46:42<46:26, 557.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   4] acc_g=0.809 (μ=0.665, σ=0.049, FG=0.102) | t=539.650s, val=0.558 | TEL=FALSE\n",
            "[Round 5] Teleportation OFF | Aggregation=best\n",
            "[round 5 | client 0] seed LR=0.1051953293 (prev=0.1103906587), seed PERT=0.1000069894 (prev=0.1000139787), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.493577 step=0.0166 g_raw=+0.009 g_sm=+0.002 acc=1 | LR→0.105406 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.492989 step=0.0267 g_raw=+0.013 g_sm=+0.003 acc=1 | LR→0.105617 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.491504 step=0.02635 g_raw=+0.014 g_sm=+0.005 acc=1 | LR→0.105829 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.488376 step=0.03658 g_raw=+0.019 g_sm=+0.007 acc=1 | LR→0.106041 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.486941 step=0.03591 g_raw=+0.018 g_sm=+0.008 acc=1 | LR→0.106253 PERT→0.100007 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1051953293, PERT_used=0.1000069894 → LR_next=0.1062529692, PERT_next=0.1000073745\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.004 acc_ratio=1.00 | LR 0.1051953293→0.1062529692 PERT 0.1000069894→0.1000073745\n",
            "Training Accuracy: 0.50\n",
            "Test Accuracy: 0.37\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.484237 step=0.02638 g_raw=+0.014 g_sm=+0.009 acc=1 | LR→0.106466 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.482177 step=0.000364 g_raw=-0.000 g_sm=+0.009 acc=1 | LR→0.106679 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.479810 step=0.01897 g_raw=+0.008 g_sm=+0.010 acc=1 | LR→0.106893 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.477844 step=0.03457 g_raw=+0.017 g_sm=+0.011 acc=1 | LR→0.107107 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.477284 step=0.01843 g_raw=+0.008 g_sm=+0.010 acc=1 | LR→0.107322 PERT→0.100008 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1062529692, PERT_used=0.1000073745 → LR_next=0.1073218785, PERT_next=0.1000083522\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1062529692→0.1073218785 PERT 0.1000073745→0.1000083522\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.476308 step=0.003377 g_raw=-0.001 g_sm=+0.009 acc=1 | LR→0.107537 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.475907 step=0.01265 g_raw=+0.006 g_sm=+0.008 acc=1 | LR→0.107752 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.472283 step=0.01036 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.107968 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.471542 step=0.01244 g_raw=+0.007 g_sm=+0.009 acc=1 | LR→0.108185 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#075 loss=0.470072 step=0.002933 g_raw=+0.001 g_sm=+0.009 acc=1 | LR→0.108401 PERT→0.100009 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1073218785, PERT_used=0.1000083522 → LR_next=0.1084014893, PERT_next=0.1000092822\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1073218785→0.1084014893 PERT 0.1000083522→0.1000092822\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.58\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.468793 step=0.03753 g_raw=+0.019 g_sm=+0.009 acc=1 | LR→0.108619 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#085 loss=0.467950 step=0.009811 g_raw=+0.007 g_sm=+0.009 acc=1 | LR→0.108836 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#090 loss=0.464581 step=0.02601 g_raw=+0.013 g_sm=+0.011 acc=1 | LR→0.109054 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#095 loss=0.462447 step=0.007255 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.109273 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#100 loss=0.459796 step=0.006904 g_raw=+0.005 g_sm=+0.012 acc=1 | LR→0.109492 PERT→0.100010 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1084014893, PERT_used=0.1000092822 → LR_next=0.1094920312, PERT_next=0.1000102767\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1084014893→0.1094920312 PERT 0.1000092822→0.1000102767\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.457342 step=0.02436 g_raw=+0.013 g_sm=+0.012 acc=1 | LR→0.109711 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#110 loss=0.454904 step=0.0474 g_raw=+0.023 g_sm=+0.012 acc=1 | LR→0.109931 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#115 loss=0.453116 step=0.01081 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.110152 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#120 loss=0.450222 step=0.04227 g_raw=+0.022 g_sm=+0.012 acc=1 | LR→0.110373 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#125 loss=0.449456 step=0.001214 g_raw=+0.001 g_sm=+0.011 acc=1 | LR→0.110594 PERT→0.100011 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1094920312, PERT_used=0.1000102767 → LR_next=0.1105937561, PERT_next=0.1000114629\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1094920312→0.1105937561 PERT 0.1000102767→0.1000114629\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.79\n",
            "[round 5 | client 0] final LR=0.1105937561, final PERT=0.1000114629  (ΔLR=+0.0053984267, ΔPERT=+0.0000044735)\n",
            "[round 5 | client 1] seed LR=0.1051952139 (prev=0.1103904278), seed PERT=0.1000068964 (prev=0.1000137929), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.452477 step=0.04661 g_raw=+0.022 g_sm=+0.003 acc=1 | LR→0.105406 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.449931 step=0.03977 g_raw=+0.021 g_sm=+0.005 acc=1 | LR→0.105617 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.448114 step=0.004202 g_raw=+0.002 g_sm=+0.006 acc=1 | LR→0.105829 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.447553 step=0.006248 g_raw=+0.003 g_sm=+0.006 acc=1 | LR→0.106041 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.444801 step=0.0312 g_raw=+0.016 g_sm=+0.008 acc=1 | LR→0.106253 PERT→0.100007 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1051952139, PERT_used=0.1000068964 → LR_next=0.1062529800, PERT_next=0.1000074015\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1051952139→0.1062529800 PERT 0.1000068964→0.1000074015\n",
            "Training Accuracy: 0.56\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.442969 step=0.00769 g_raw=+0.002 g_sm=+0.008 acc=1 | LR→0.106466 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.441876 step=0.009766 g_raw=+0.006 g_sm=+0.008 acc=1 | LR→0.106679 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.440652 step=0.007104 g_raw=+0.003 g_sm=+0.008 acc=1 | LR→0.106893 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.436674 step=0.03159 g_raw=+0.015 g_sm=+0.011 acc=1 | LR→0.107107 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.436432 step=0.01853 g_raw=+0.009 g_sm=+0.009 acc=1 | LR→0.107322 PERT→0.100008 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1062529800, PERT_used=0.1000074015 → LR_next=0.1073217753, PERT_next=0.1000082728\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1062529800→0.1073217753 PERT 0.1000074015→0.1000082728\n",
            "Training Accuracy: 0.56\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.434856 step=0.002978 g_raw=+0.001 g_sm=+0.009 acc=1 | LR→0.107537 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#060 loss=0.432687 step=0.0383 g_raw=+0.018 g_sm=+0.010 acc=1 | LR→0.107752 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.431247 step=0.04149 g_raw=+0.021 g_sm=+0.010 acc=1 | LR→0.107968 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.429035 step=0.008609 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.108185 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#075 loss=0.428269 step=0.03901 g_raw=+0.017 g_sm=+0.009 acc=1 | LR→0.108401 PERT→0.100009 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1073217753, PERT_used=0.1000082728 → LR_next=0.1084014452, PERT_next=0.1000092584\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1073217753→0.1084014452 PERT 0.1000082728→0.1000092584\n",
            "Training Accuracy: 0.56\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.427822 step=0.001839 g_raw=+0.002 g_sm=+0.008 acc=1 | LR→0.108619 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#085 loss=0.427154 step=0.0149 g_raw=+0.007 g_sm=+0.008 acc=1 | LR→0.108836 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#090 loss=0.426808 step=0.01576 g_raw=+0.007 g_sm=+0.007 acc=1 | LR→0.109054 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#095 loss=0.425076 step=0.02459 g_raw=+0.011 g_sm=+0.008 acc=1 | LR→0.109273 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#100 loss=0.423818 step=0.008753 g_raw=+0.003 g_sm=+0.009 acc=1 | LR→0.109492 PERT→0.100010 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1084014452, PERT_used=0.1000092584 → LR_next=0.1094917993, PERT_next=0.1000100817\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1084014452→0.1094917993 PERT 0.1000092584→0.1000100817\n",
            "Training Accuracy: 0.56\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.421804 step=0.01623 g_raw=+0.007 g_sm=+0.009 acc=1 | LR→0.109711 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#110 loss=0.421165 step=0.02778 g_raw=+0.012 g_sm=+0.009 acc=1 | LR→0.109931 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#115 loss=0.420366 step=0.01903 g_raw=+0.008 g_sm=+0.008 acc=1 | LR→0.110151 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#120 loss=0.419922 step=0.003038 g_raw=+0.001 g_sm=+0.008 acc=1 | LR→0.110372 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#125 loss=0.418524 step=0.02147 g_raw=+0.009 g_sm=+0.008 acc=1 | LR→0.110593 PERT→0.100011 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1094917993, PERT_used=0.1000100817 → LR_next=0.1105931544, PERT_next=0.1000109356\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1094917993→0.1105931544 PERT 0.1000100817→0.1000109356\n",
            "Training Accuracy: 0.56\n",
            "Test Accuracy: 0.54\n",
            "[round 5 | client 1] final LR=0.1105931544, final PERT=0.1000109356  (ΔLR=+0.0053979405, ΔPERT=+0.0000040392)\n",
            "[round 5 | client 2] seed LR=0.1051956829 (prev=0.1103913659), seed PERT=0.1000072845 (prev=0.1000145689), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.496102 step=0.02513 g_raw=+0.013 g_sm=+0.002 acc=1 | LR→0.105406 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.494388 step=0.02657 g_raw=+0.012 g_sm=+0.004 acc=1 | LR→0.105617 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.491998 step=0.0351 g_raw=+0.017 g_sm=+0.006 acc=1 | LR→0.105829 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.489193 step=0.03027 g_raw=+0.014 g_sm=+0.008 acc=1 | LR→0.106041 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.487864 step=0.03275 g_raw=+0.015 g_sm=+0.008 acc=1 | LR→0.106253 PERT→0.100008 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1051956829, PERT_used=0.1000072845 → LR_next=0.1062534285, PERT_next=0.1000077658\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1051956829→0.1062534285 PERT 0.1000072845→0.1000077658\n",
            "Training Accuracy: 0.50\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.486878 step=0.003883 g_raw=+0.003 g_sm=+0.008 acc=1 | LR→0.106466 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.482967 step=0.07537 g_raw=+0.038 g_sm=+0.010 acc=1 | LR→0.106680 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.478899 step=0.0253 g_raw=+0.013 g_sm=+0.011 acc=1 | LR→0.106893 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.477692 step=4.877e-05 g_raw=-0.001 g_sm=+0.010 acc=1 | LR→0.107108 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.472949 step=0.02167 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.107322 PERT→0.100009 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1062534285, PERT_used=0.1000077658 → LR_next=0.1073223572, PERT_next=0.1000087572\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1062534285→0.1073223572 PERT 0.1000077658→0.1000087572\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.471833 step=0.01486 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.107537 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.470454 step=0.03644 g_raw=+0.019 g_sm=+0.011 acc=1 | LR→0.107753 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.467822 step=0.01728 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.107969 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.463151 step=0.03895 g_raw=+0.019 g_sm=+0.013 acc=1 | LR→0.108185 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.461893 step=0.001344 g_raw=+0.001 g_sm=+0.011 acc=1 | LR→0.108402 PERT→0.100010 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1073223572, PERT_used=0.1000087572 → LR_next=0.1084022411, PERT_next=0.1000099347\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1073223572→0.1084022411 PERT 0.1000087572→0.1000099347\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.60\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.459627 step=0.04282 g_raw=+0.020 g_sm=+0.012 acc=1 | LR→0.108620 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.458263 step=0.02224 g_raw=+0.010 g_sm=+0.011 acc=1 | LR→0.108837 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#090 loss=0.457958 step=0.009928 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.109055 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.456474 step=0.008079 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.109274 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.455827 step=0.01946 g_raw=+0.010 g_sm=+0.009 acc=1 | LR→0.109493 PERT→0.100011 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1084022411, PERT_used=0.1000099347 → LR_next=0.1094928625, PERT_next=0.1000109950\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1084022411→0.1094928625 PERT 0.1000099347→0.1000109950\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.452770 step=0.03928 g_raw=+0.020 g_sm=+0.010 acc=1 | LR→0.109712 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#110 loss=0.449873 step=0.04846 g_raw=+0.025 g_sm=+0.011 acc=1 | LR→0.109932 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#115 loss=0.446972 step=0.01525 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.110153 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.445243 step=0.003523 g_raw=+0.002 g_sm=+0.012 acc=1 | LR→0.110373 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#125 loss=0.440644 step=0.04262 g_raw=+0.021 g_sm=+0.013 acc=1 | LR→0.110595 PERT→0.100012 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1094928625, PERT_used=0.1000109950 → LR_next=0.1105945458, PERT_next=0.1000121360\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1094928625→0.1105945458 PERT 0.1000109950→0.1000121360\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.67\n",
            "[round 5 | client 2] final LR=0.1105945458, final PERT=0.1000121360  (ΔLR=+0.0053988629, ΔPERT=+0.0000048515)\n",
            "[round 5 | client 3] seed LR=0.1051936663 (prev=0.1103873325), seed PERT=0.1000055002 (prev=0.1000110003), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.522774 step=0.01615 g_raw=+0.008 g_sm=+0.003 acc=1 | LR→0.105404 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.516419 step=0.05723 g_raw=+0.029 g_sm=+0.008 acc=1 | LR→0.105615 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.509176 step=0.00953 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.105827 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.504603 step=0.02393 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.106039 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#025 loss=0.487742 step=0.1379 g_raw=+0.068 g_sm=+0.017 acc=1 | LR→0.106252 PERT→0.100006 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1051936663, PERT_used=0.1000055002 → LR_next=0.1062518270, PERT_next=0.1000063913\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.022 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1051936663→0.1062518270 PERT 0.1000055002→0.1000063913\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.58\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.477737 step=0.02451 g_raw=+0.010 g_sm=+0.019 acc=1 | LR→0.106465 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.473152 step=0.03514 g_raw=+0.019 g_sm=+0.019 acc=1 | LR→0.106678 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#040 loss=0.464101 step=0.02796 g_raw=+0.016 g_sm=+0.020 acc=1 | LR→0.106892 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.462282 step=0.04797 g_raw=+0.022 g_sm=+0.017 acc=1 | LR→0.107107 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.460895 step=0.02827 g_raw=+0.013 g_sm=+0.016 acc=1 | LR→0.107322 PERT→0.100008 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1062518270, PERT_used=0.1000063913 → LR_next=0.1073216400, PERT_next=0.1000082219\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1062518270→0.1073216400 PERT 0.1000063913→0.1000082219\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.454089 step=0.03709 g_raw=+0.018 g_sm=+0.018 acc=1 | LR→0.107537 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.452957 step=0.01941 g_raw=+0.010 g_sm=+0.016 acc=1 | LR→0.107753 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.446998 step=0.0008786 g_raw=-0.000 g_sm=+0.017 acc=1 | LR→0.107969 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.445344 step=0.01394 g_raw=+0.007 g_sm=+0.016 acc=1 | LR→0.108185 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.443741 step=0.01295 g_raw=+0.005 g_sm=+0.015 acc=1 | LR→0.108402 PERT→0.100010 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1073216400, PERT_used=0.1000082219 → LR_next=0.1084020267, PERT_next=0.1000098698\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1073216400→0.1084020267 PERT 0.1000082219→0.1000098698\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.79\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.441547 step=0.01789 g_raw=+0.009 g_sm=+0.014 acc=1 | LR→0.108619 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.437867 step=0.007199 g_raw=+0.003 g_sm=+0.014 acc=1 | LR→0.108837 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#090 loss=0.435518 step=0.02757 g_raw=+0.014 g_sm=+0.014 acc=1 | LR→0.109055 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.433610 step=0.03778 g_raw=+0.019 g_sm=+0.013 acc=1 | LR→0.109274 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.432442 step=0.02618 g_raw=+0.013 g_sm=+0.012 acc=1 | LR→0.109493 PERT→0.100011 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1084020267, PERT_used=0.1000098698 → LR_next=0.1094929851, PERT_next=0.1000112399\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1084020267→0.1094929851 PERT 0.1000098698→0.1000112399\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.76\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.431460 step=0.007249 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.109712 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#110 loss=0.430173 step=0.03622 g_raw=+0.020 g_sm=+0.011 acc=1 | LR→0.109932 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.428360 step=0.02701 g_raw=+0.013 g_sm=+0.011 acc=1 | LR→0.110153 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.426489 step=0.0575 g_raw=+0.028 g_sm=+0.011 acc=1 | LR→0.110373 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#125 loss=0.425687 step=0.0228 g_raw=+0.012 g_sm=+0.010 acc=1 | LR→0.110595 PERT→0.100012 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1094929851, PERT_used=0.1000112399 → LR_next=0.1105945980, PERT_next=0.1000123161\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1094929851→0.1105945980 PERT 0.1000112399→0.1000123161\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.77\n",
            "[round 5 | client 3] final LR=0.1105945980, final PERT=0.1000123161  (ΔLR=+0.0054009317, ΔPERT=+0.0000068159)\n",
            "[round 5 | client 4] seed LR=0.1051950514 (prev=0.1103901028), seed PERT=0.1000067276 (prev=0.1000134553), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.492501 step=0.003924 g_raw=+0.003 g_sm=+0.001 acc=1 | LR→0.105406 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.486322 step=0.009714 g_raw=+0.004 g_sm=+0.005 acc=1 | LR→0.105617 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.476637 step=0.09988 g_raw=+0.050 g_sm=+0.010 acc=1 | LR→0.105828 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.475693 step=0.009956 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.106040 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.471530 step=0.03544 g_raw=+0.016 g_sm=+0.011 acc=1 | LR→0.106253 PERT→0.100007 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1051950514, PERT_used=0.1000067276 → LR_next=0.1062529948, PERT_next=0.1000074011\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1051950514→0.1062529948 PERT 0.1000067276→0.1000074011\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.465008 step=0.03255 g_raw=+0.016 g_sm=+0.014 acc=1 | LR→0.106466 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.460899 step=0.005276 g_raw=+0.003 g_sm=+0.014 acc=1 | LR→0.106679 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.458726 step=0.03339 g_raw=+0.015 g_sm=+0.014 acc=1 | LR→0.106893 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.455835 step=0.0265 g_raw=+0.014 g_sm=+0.014 acc=1 | LR→0.107108 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.453322 step=0.01629 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.107322 PERT→0.100009 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1062529948, PERT_used=0.1000074011 → LR_next=0.1073223572, PERT_next=0.1000088008\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1062529948→0.1073223572 PERT 0.1000074011→0.1000088008\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.60\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.451743 step=0.04057 g_raw=+0.019 g_sm=+0.013 acc=1 | LR→0.107538 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.450844 step=0.0386 g_raw=+0.018 g_sm=+0.012 acc=1 | LR→0.107753 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.447704 step=0.03813 g_raw=+0.018 g_sm=+0.013 acc=1 | LR→0.107969 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.443718 step=0.01303 g_raw=+0.006 g_sm=+0.014 acc=1 | LR→0.108186 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.440196 step=0.03401 g_raw=+0.016 g_sm=+0.014 acc=1 | LR→0.108402 PERT→0.100010 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1073223572, PERT_used=0.1000088008 → LR_next=0.1084023991, PERT_next=0.1000101240\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1073223572→0.1084023991 PERT 0.1000088008→0.1000101240\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.62\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.438439 step=0.02113 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.108620 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.433598 step=0.07451 g_raw=+0.037 g_sm=+0.015 acc=1 | LR→0.108837 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.429006 step=0.002205 g_raw=+0.001 g_sm=+0.015 acc=1 | LR→0.109056 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.423981 step=0.05198 g_raw=+0.024 g_sm=+0.016 acc=1 | LR→0.109274 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.422043 step=0.02622 g_raw=+0.012 g_sm=+0.016 acc=1 | LR→0.109493 PERT→0.100012 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1084023991, PERT_used=0.1000101240 → LR_next=0.1094934985, PERT_next=0.1000116195\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1084023991→0.1094934985 PERT 0.1000101240→0.1000116195\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.420071 step=0.001331 g_raw=+0.001 g_sm=+0.014 acc=1 | LR→0.109713 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.419507 step=0.02794 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.109933 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.418631 step=0.01537 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.110153 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.416271 step=0.03922 g_raw=+0.018 g_sm=+0.012 acc=1 | LR→0.110374 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.414592 step=0.02595 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.110595 PERT→0.100013 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1094934985, PERT_used=0.1000116195 → LR_next=0.1105952975, PERT_next=0.1000128594\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1094934985→0.1105952975 PERT 0.1000116195→0.1000128594\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.63\n",
            "[round 5 | client 4] final LR=0.1105952975, final PERT=0.1000128594  (ΔLR=+0.0054002461, ΔPERT=+0.0000061317)\n",
            "\n",
            "[Round 5] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           3      0.579891      0.770000      0.110595      0.100012\n",
            "           2      0.591090      0.665000      0.110595      0.100012\n",
            "           4      0.600759      0.630000      0.110595      0.100013\n",
            "           0      0.628915      0.790000      0.110594      0.100011\n",
            "           1      0.652072      0.540000      0.110593      0.100011\n",
            "→ [Round 5] best_client=3, best_val=0.579891, prev_global_val=0.557861, improve=-0.022029, action=hold (τ=0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  60%|██████    | 6/10 [55:50<36:56, 554.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   5] acc_g=0.800 (μ=0.679, σ=0.092, FG=0.206) | t=537.309s, val=0.573 | TEL=FALSE\n",
            "[Round 6] Teleportation OFF | Aggregation=best\n",
            "[round 6 | client 0] seed LR=0.1052968780 (prev=0.1105937561), seed PERT=0.1000057314 (prev=0.1000114629), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.484233 step=0.003564 g_raw=+0.001 g_sm=+0.001 acc=1 | LR→0.105508 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.481438 step=0.04439 g_raw=+0.023 g_sm=+0.004 acc=1 | LR→0.105719 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.478950 step=0.01619 g_raw=+0.008 g_sm=+0.006 acc=1 | LR→0.105931 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.472795 step=0.06262 g_raw=+0.032 g_sm=+0.009 acc=1 | LR→0.106143 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#025 loss=0.471825 step=0.01285 g_raw=+0.006 g_sm=+0.009 acc=1 | LR→0.106356 PERT→0.100006 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1052968780, PERT_used=0.1000057314 → LR_next=0.1063556925, PERT_next=0.1000062610\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1052968780→0.1063556925 PERT 0.1000057314→0.1000062610\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.467180 step=0.03076 g_raw=+0.016 g_sm=+0.011 acc=1 | LR→0.106569 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#035 loss=0.464732 step=0.0177 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.106782 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#040 loss=0.461011 step=0.03459 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.106996 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#045 loss=0.456560 step=0.07889 g_raw=+0.039 g_sm=+0.014 acc=1 | LR→0.107211 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#050 loss=0.453489 step=0.06079 g_raw=+0.029 g_sm=+0.014 acc=1 | LR→0.107426 PERT→0.100007 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1063556925, PERT_used=0.1000062610 → LR_next=0.1074258655, PERT_next=0.1000074531\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1063556925→0.1074258655 PERT 0.1000062610→0.1000074531\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.78\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.450039 step=0.03746 g_raw=+0.019 g_sm=+0.014 acc=1 | LR→0.107641 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#060 loss=0.442961 step=0.08413 g_raw=+0.042 g_sm=+0.016 acc=1 | LR→0.107857 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#065 loss=0.441712 step=0.007364 g_raw=+0.003 g_sm=+0.015 acc=1 | LR→0.108073 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#070 loss=0.436824 step=0.002326 g_raw=+0.002 g_sm=+0.015 acc=1 | LR→0.108290 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#075 loss=0.433566 step=0.07397 g_raw=+0.034 g_sm=+0.015 acc=1 | LR→0.108507 PERT→0.100009 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1074258655, PERT_used=0.1000074531 → LR_next=0.1085071143, PERT_next=0.1000089287\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1074258655→0.1085071143 PERT 0.1000074531→0.1000089287\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.83\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.431692 step=0.005841 g_raw=+0.002 g_sm=+0.014 acc=1 | LR→0.108725 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#085 loss=0.429002 step=0.0507 g_raw=+0.023 g_sm=+0.014 acc=1 | LR→0.108943 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#090 loss=0.424363 step=0.02992 g_raw=+0.014 g_sm=+0.015 acc=1 | LR→0.109161 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#095 loss=0.423453 step=0.004745 g_raw=+0.002 g_sm=+0.014 acc=1 | LR→0.109380 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#100 loss=0.422290 step=0.0172 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.109599 PERT→0.100010 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1085071143, PERT_used=0.1000089287 → LR_next=0.1095991945, PERT_next=0.1000103573\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1085071143→0.1095991945 PERT 0.1000089287→0.1000103573\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.80\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.422017 step=0.01399 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.109819 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#110 loss=0.421211 step=0.01553 g_raw=+0.009 g_sm=+0.010 acc=1 | LR→0.110039 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#115 loss=0.419258 step=0.05393 g_raw=+0.026 g_sm=+0.010 acc=1 | LR→0.110259 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#120 loss=0.417319 step=0.04856 g_raw=+0.021 g_sm=+0.010 acc=1 | LR→0.110480 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#125 loss=0.416223 step=0.007355 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.110702 PERT→0.100011 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1095991945, PERT_used=0.1000103573 → LR_next=0.1107018300, PERT_next=0.1000113919\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1095991945→0.1107018300 PERT 0.1000103573→0.1000113919\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.79\n",
            "[round 6 | client 0] final LR=0.1107018300, final PERT=0.1000113919  (ΔLR=+0.0054049519, ΔPERT=+0.0000056605)\n",
            "[round 6 | client 1] seed LR=0.1052965772 (prev=0.1105931544), seed PERT=0.1000054678 (prev=0.1000109356), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.510026 step=0.02864 g_raw=+0.015 g_sm=+0.005 acc=1 | LR→0.105507 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.504672 step=0.08275 g_raw=+0.040 g_sm=+0.009 acc=1 | LR→0.105719 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.501795 step=0.05456 g_raw=+0.025 g_sm=+0.010 acc=1 | LR→0.105931 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.494939 step=0.006541 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.106143 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#025 loss=0.493107 step=0.01752 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.106356 PERT→0.100006 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1052965772, PERT_used=0.1000054678 → LR_next=0.1063557589, PERT_next=0.1000063456\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1052965772→0.1063557589 PERT 0.1000054678→0.1000063456\n",
            "Training Accuracy: 0.48\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.491236 step=0.05102 g_raw=+0.025 g_sm=+0.012 acc=1 | LR→0.106569 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.489318 step=0.004884 g_raw=+0.001 g_sm=+0.011 acc=1 | LR→0.106783 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#040 loss=0.486581 step=0.01187 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.106997 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#045 loss=0.484709 step=0.02057 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.107211 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#050 loss=0.481626 step=0.01551 g_raw=+0.008 g_sm=+0.013 acc=1 | LR→0.107426 PERT→0.100008 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1063557589, PERT_used=0.1000063456 → LR_next=0.1074259578, PERT_next=0.1000075612\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1063557589→0.1074259578 PERT 0.1000063456→0.1000075612\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.60\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.480368 step=0.01821 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.107641 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#060 loss=0.477376 step=0.0155 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.107857 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#065 loss=0.474451 step=0.004102 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.108073 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#070 loss=0.468921 step=0.04679 g_raw=+0.023 g_sm=+0.015 acc=1 | LR→0.108290 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#075 loss=0.466003 step=0.008381 g_raw=+0.004 g_sm=+0.015 acc=1 | LR→0.108507 PERT→0.100009 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1074259578, PERT_used=0.1000075612 → LR_next=0.1085070973, PERT_next=0.1000089351\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1074259578→0.1085070973 PERT 0.1000075612→0.1000089351\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.464136 step=0.003187 g_raw=-0.000 g_sm=+0.013 acc=1 | LR→0.108725 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#085 loss=0.463216 step=0.02817 g_raw=+0.013 g_sm=+0.012 acc=1 | LR→0.108943 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#090 loss=0.458493 step=0.04186 g_raw=+0.018 g_sm=+0.014 acc=1 | LR→0.109161 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#095 loss=0.457625 step=0.00261 g_raw=-0.000 g_sm=+0.013 acc=1 | LR→0.109380 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#100 loss=0.455480 step=0.0002531 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.109599 PERT→0.100010 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1085070973, PERT_used=0.1000089351 → LR_next=0.1095990766, PERT_next=0.1000102718\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1085070973→0.1095990766 PERT 0.1000089351→0.1000102718\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.74\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.452137 step=0.03218 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.109819 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#110 loss=0.446841 step=0.05381 g_raw=+0.028 g_sm=+0.015 acc=1 | LR→0.110039 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#115 loss=0.444828 step=0.01045 g_raw=+0.006 g_sm=+0.015 acc=1 | LR→0.110260 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#120 loss=0.440628 step=0.04941 g_raw=+0.023 g_sm=+0.016 acc=1 | LR→0.110481 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#125 loss=0.437145 step=0.04147 g_raw=+0.022 g_sm=+0.016 acc=1 | LR→0.110702 PERT→0.100012 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1095990766, PERT_used=0.1000102718 → LR_next=0.1107021797, PERT_next=0.1000117300\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1095990766→0.1107021797 PERT 0.1000102718→0.1000117300\n",
            "Training Accuracy: 0.92\n",
            "Test Accuracy: 0.88\n",
            "[round 6 | client 1] final LR=0.1107021797, final PERT=0.1000117300  (ΔLR=+0.0054056025, ΔPERT=+0.0000062621)\n",
            "[round 6 | client 2] seed LR=0.1052972729 (prev=0.1105945458), seed PERT=0.1000060680 (prev=0.1000121360), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.511612 step=0.08283 g_raw=+0.041 g_sm=+0.006 acc=1 | LR→0.105508 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.496092 step=0.07161 g_raw=+0.037 g_sm=+0.011 acc=1 | LR→0.105720 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.483789 step=0.001124 g_raw=-0.001 g_sm=+0.014 acc=1 | LR→0.105931 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.475388 step=0.08597 g_raw=+0.042 g_sm=+0.017 acc=1 | LR→0.106144 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.467663 step=0.02915 g_raw=+0.016 g_sm=+0.018 acc=1 | LR→0.106357 PERT→0.100007 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1052972729, PERT_used=0.1000060680 → LR_next=0.1063567756, PERT_next=0.1000072410\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.026 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1052972729→0.1063567756 PERT 0.1000060680→0.1000072410\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.58\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.462742 step=0.06669 g_raw=+0.032 g_sm=+0.018 acc=1 | LR→0.106570 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.456214 step=0.00249 g_raw=+0.000 g_sm=+0.018 acc=1 | LR→0.106784 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.454544 step=0.01923 g_raw=+0.009 g_sm=+0.016 acc=1 | LR→0.106998 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.442163 step=0.1274 g_raw=+0.062 g_sm=+0.019 acc=1 | LR→0.107213 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.430931 step=0.1373 g_raw=+0.069 g_sm=+0.020 acc=1 | LR→0.107428 PERT→0.100009 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1063567756, PERT_used=0.1000072410 → LR_next=0.1074276243, PERT_next=0.1000090520\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1063567756→0.1074276243 PERT 0.1000072410→0.1000090520\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.60\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.416980 step=0.01769 g_raw=+0.008 g_sm=+0.023 acc=1 | LR→0.107643 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.414723 step=0.04429 g_raw=+0.021 g_sm=+0.021 acc=1 | LR→0.107859 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.406932 step=0.04661 g_raw=+0.021 g_sm=+0.022 acc=1 | LR→0.108076 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.399118 step=0.05641 g_raw=+0.030 g_sm=+0.022 acc=1 | LR→0.108292 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#075 loss=0.393321 step=0.01962 g_raw=+0.009 g_sm=+0.021 acc=1 | LR→0.108510 PERT→0.100011 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1074276243, PERT_used=0.1000090520 → LR_next=0.1085096314, PERT_next=0.1000112102\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.022 g_sm_mean=+0.022 acc_ratio=1.00 | LR 0.1074276243→0.1085096314 PERT 0.1000090520→0.1000112102\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.391826 step=0.00146 g_raw=+0.000 g_sm=+0.018 acc=1 | LR→0.108727 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#085 loss=0.388495 step=0.0008112 g_raw=+0.002 g_sm=+0.017 acc=1 | LR→0.108945 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#090 loss=0.386002 step=0.03166 g_raw=+0.014 g_sm=+0.017 acc=1 | LR→0.109164 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.383956 step=0.03352 g_raw=+0.016 g_sm=+0.016 acc=1 | LR→0.109383 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#100 loss=0.382661 step=0.0435 g_raw=+0.022 g_sm=+0.014 acc=1 | LR→0.109602 PERT→0.100013 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1085096314, PERT_used=0.1000112102 → LR_next=0.1096020607, PERT_next=0.1000129343\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1085096314→0.1096020607 PERT 0.1000112102→0.1000129343\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.58\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.380623 step=0.05096 g_raw=+0.024 g_sm=+0.014 acc=1 | LR→0.109822 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#110 loss=0.379393 step=0.0183 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.110042 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.375136 step=0.05169 g_raw=+0.025 g_sm=+0.014 acc=1 | LR→0.110263 PERT→0.100014 (scale=0.04)\n",
            "[meta] cb#120 loss=0.374150 step=0.01501 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.110484 PERT→0.100014 (scale=0.04)\n",
            "[meta] cb#125 loss=0.370826 step=0.005412 g_raw=+0.003 g_sm=+0.013 acc=1 | LR→0.110705 PERT→0.100014 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1096020607, PERT_used=0.1000129343 → LR_next=0.1107050556, PERT_next=0.1000142676\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1096020607→0.1107050556 PERT 0.1000129343→0.1000142676\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.63\n",
            "[round 6 | client 2] final LR=0.1107050556, final PERT=0.1000142676  (ΔLR=+0.0054077827, ΔPERT=+0.0000081996)\n",
            "[round 6 | client 3] seed LR=0.1052972990 (prev=0.1105945980), seed PERT=0.1000061580 (prev=0.1000123161), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.539289 step=0.06937 g_raw=+0.036 g_sm=+0.005 acc=1 | LR→0.105508 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.538674 step=0.02127 g_raw=+0.011 g_sm=+0.005 acc=1 | LR→0.105719 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.534356 step=0.08285 g_raw=+0.042 g_sm=+0.008 acc=1 | LR→0.105931 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.532791 step=0.001324 g_raw=+0.001 g_sm=+0.008 acc=1 | LR→0.106144 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.530243 step=0.04024 g_raw=+0.023 g_sm=+0.009 acc=1 | LR→0.106356 PERT→0.100007 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1052972990, PERT_used=0.1000061580 → LR_next=0.1063561945, PERT_next=0.1000067599\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1052972990→0.1063561945 PERT 0.1000061580→0.1000067599\n",
            "Training Accuracy: 0.32\n",
            "Test Accuracy: 0.46\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.523543 step=0.04024 g_raw=+0.020 g_sm=+0.013 acc=1 | LR→0.106569 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.515084 step=0.08143 g_raw=+0.040 g_sm=+0.016 acc=1 | LR→0.106783 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#040 loss=0.507012 step=0.03735 g_raw=+0.019 g_sm=+0.018 acc=1 | LR→0.106997 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.504224 step=0.01051 g_raw=+0.006 g_sm=+0.016 acc=1 | LR→0.107212 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.500777 step=0.00465 g_raw=+0.003 g_sm=+0.016 acc=1 | LR→0.107427 PERT→0.100008 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1063561945, PERT_used=0.1000067599 → LR_next=0.1074267566, PERT_next=0.1000083095\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1063561945→0.1074267566 PERT 0.1000067599→0.1000083095\n",
            "Training Accuracy: 0.50\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.497426 step=0.01372 g_raw=+0.006 g_sm=+0.016 acc=1 | LR→0.107642 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.493737 step=0.04932 g_raw=+0.024 g_sm=+0.016 acc=1 | LR→0.107858 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.488785 step=0.03711 g_raw=+0.018 g_sm=+0.016 acc=1 | LR→0.108074 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.487290 step=0.01878 g_raw=+0.010 g_sm=+0.015 acc=1 | LR→0.108291 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.485044 step=0.02491 g_raw=+0.012 g_sm=+0.015 acc=1 | LR→0.108508 PERT→0.100010 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1074267566, PERT_used=0.1000083095 → LR_next=0.1085080952, PERT_next=0.1000098596\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1074267566→0.1085080952 PERT 0.1000083095→0.1000098596\n",
            "Training Accuracy: 0.56\n",
            "Test Accuracy: 0.65\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.483155 step=0.01258 g_raw=+0.006 g_sm=+0.014 acc=1 | LR→0.108726 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.479884 step=0.02793 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.108944 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#090 loss=0.474219 step=0.0379 g_raw=+0.020 g_sm=+0.016 acc=1 | LR→0.109162 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.468438 step=0.09143 g_raw=+0.046 g_sm=+0.017 acc=1 | LR→0.109381 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.467319 step=0.02312 g_raw=+0.011 g_sm=+0.015 acc=1 | LR→0.109600 PERT→0.100011 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1085080952, PERT_used=0.1000098596 → LR_next=0.1096002723, PERT_next=0.1000113675\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1085080952→0.1096002723 PERT 0.1000098596→0.1000113675\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.459857 step=0.05216 g_raw=+0.027 g_sm=+0.018 acc=1 | LR→0.109820 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.454926 step=0.08564 g_raw=+0.043 g_sm=+0.018 acc=1 | LR→0.110040 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.452151 step=0.00857 g_raw=+0.004 g_sm=+0.016 acc=1 | LR→0.110261 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.439677 step=0.08789 g_raw=+0.043 g_sm=+0.019 acc=1 | LR→0.110482 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.431024 step=0.008352 g_raw=+0.005 g_sm=+0.021 acc=1 | LR→0.110704 PERT→0.100013 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1096002723, PERT_used=0.1000113675 → LR_next=0.1107037435, PERT_next=0.1000131475\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.022 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1096002723→0.1107037435 PERT 0.1000113675→0.1000131475\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.77\n",
            "[round 6 | client 3] final LR=0.1107037435, final PERT=0.1000131475  (ΔLR=+0.0054064446, ΔPERT=+0.0000069895)\n",
            "[round 6 | client 4] seed LR=0.1052976488 (prev=0.1105952975), seed PERT=0.1000064297 (prev=0.1000128594), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.517317 step=0.0272 g_raw=+0.014 g_sm=+0.003 acc=1 | LR→0.105508 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.511861 step=0.04743 g_raw=+0.024 g_sm=+0.008 acc=1 | LR→0.105720 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.499525 step=0.1152 g_raw=+0.061 g_sm=+0.013 acc=1 | LR→0.105932 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.495986 step=0.04139 g_raw=+0.020 g_sm=+0.014 acc=1 | LR→0.106144 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.492859 step=0.03573 g_raw=+0.019 g_sm=+0.014 acc=1 | LR→0.106357 PERT→0.100007 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1052976488, PERT_used=0.1000064297 → LR_next=0.1063568652, PERT_next=0.1000073299\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1052976488→0.1063568652 PERT 0.1000064297→0.1000073299\n",
            "Training Accuracy: 0.52\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.483953 step=0.06671 g_raw=+0.034 g_sm=+0.017 acc=1 | LR→0.106570 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.479209 step=0.05496 g_raw=+0.028 g_sm=+0.018 acc=1 | LR→0.106784 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.477621 step=0.04692 g_raw=+0.024 g_sm=+0.016 acc=1 | LR→0.106998 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.471706 step=0.04741 g_raw=+0.021 g_sm=+0.017 acc=1 | LR→0.107213 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.468553 step=0.01287 g_raw=+0.007 g_sm=+0.016 acc=1 | LR→0.107428 PERT→0.100009 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1063568652, PERT_used=0.1000073299 → LR_next=0.1074275571, PERT_next=0.1000089942\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1063568652→0.1074275571 PERT 0.1000073299→0.1000089942\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.463368 step=0.0106 g_raw=+0.003 g_sm=+0.016 acc=1 | LR→0.107643 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.459919 step=0.0478 g_raw=+0.022 g_sm=+0.017 acc=1 | LR→0.107859 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.456496 step=0.01813 g_raw=+0.008 g_sm=+0.016 acc=1 | LR→0.108075 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.455591 step=0.01351 g_raw=+0.007 g_sm=+0.014 acc=1 | LR→0.108292 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.448816 step=0.08486 g_raw=+0.040 g_sm=+0.016 acc=1 | LR→0.108509 PERT→0.100011 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1074275571, PERT_used=0.1000089942 → LR_next=0.1085089280, PERT_next=0.1000105666\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1074275571→0.1085089280 PERT 0.1000089942→0.1000105666\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.82\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.447802 step=0.01676 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.108726 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.446614 step=0.003613 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.108944 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.444154 step=0.0296 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.109163 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.437020 step=0.0251 g_raw=+0.012 g_sm=+0.015 acc=1 | LR→0.109382 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.436211 step=0.03501 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.109601 PERT→0.100012 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1085089280, PERT_used=0.1000105666 → LR_next=0.1096009853, PERT_next=0.1000119576\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1085089280→0.1096009853 PERT 0.1000105666→0.1000119576\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.84\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.427940 step=0.08048 g_raw=+0.037 g_sm=+0.016 acc=1 | LR→0.109821 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.424288 step=0.01586 g_raw=+0.007 g_sm=+0.016 acc=1 | LR→0.110041 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.420532 step=0.07937 g_raw=+0.037 g_sm=+0.015 acc=1 | LR→0.110262 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.418371 step=0.01463 g_raw=+0.009 g_sm=+0.015 acc=1 | LR→0.110483 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.416528 step=0.03142 g_raw=+0.016 g_sm=+0.014 acc=1 | LR→0.110704 PERT→0.100013 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1096009853, PERT_used=0.1000119576 → LR_next=0.1107041520, PERT_next=0.1000134560\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1096009853→0.1107041520 PERT 0.1000119576→0.1000134560\n",
            "Training Accuracy: 0.96\n",
            "Test Accuracy: 0.90\n",
            "[round 6 | client 4] final LR=0.1107041520, final PERT=0.1000134560  (ΔLR=+0.0054065033, ΔPERT=+0.0000070263)\n",
            "\n",
            "[Round 6] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           0      0.537573      0.785000      0.110702      0.100011\n",
            "           4      0.579545      0.895000      0.110704      0.100013\n",
            "           1      0.583991      0.880000      0.110702      0.100012\n",
            "           3      0.600029      0.770000      0.110704      0.100013\n",
            "           2      0.637328      0.630000      0.110705      0.100014\n",
            "→ [Round 6] best_client=0, best_val=0.537573, prev_global_val=0.572550, improve=+0.034977, action=adopt+mix τ=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  70%|███████   | 7/10 [1:04:53<27:32, 550.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   6] acc_g=0.785 (μ=0.792, σ=0.095, FG=0.203) | t=533.867s, val=0.548 | TEL=FALSE\n",
            "[Round 7] Teleportation OFF | Aggregation=best\n",
            "[round 7 | client 0] seed LR=0.1053509150 (prev=0.1107018300), seed PERT=0.1000056960 (prev=0.1000113919), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.503514 step=0.002125 g_raw=+0.002 g_sm=+0.001 acc=1 | LR→0.105562 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.497800 step=0.03312 g_raw=+0.016 g_sm=+0.005 acc=1 | LR→0.105773 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.492640 step=0.02153 g_raw=+0.011 g_sm=+0.007 acc=1 | LR→0.105985 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.489517 step=0.0153 g_raw=+0.008 g_sm=+0.009 acc=1 | LR→0.106198 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#025 loss=0.483789 step=0.0765 g_raw=+0.039 g_sm=+0.012 acc=1 | LR→0.106410 PERT→0.100006 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1053509150, PERT_used=0.1000056960 → LR_next=0.1064103370, PERT_next=0.1000062859\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1053509150→0.1064103370 PERT 0.1000056960→0.1000062859\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.475228 step=0.06267 g_raw=+0.032 g_sm=+0.015 acc=1 | LR→0.106624 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.471909 step=0.04544 g_raw=+0.023 g_sm=+0.015 acc=1 | LR→0.106837 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#040 loss=0.466390 step=0.0114 g_raw=+0.005 g_sm=+0.016 acc=1 | LR→0.107052 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#045 loss=0.459556 step=0.09261 g_raw=+0.047 g_sm=+0.018 acc=1 | LR→0.107266 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.449280 step=0.1157 g_raw=+0.058 g_sm=+0.020 acc=1 | LR→0.107481 PERT→0.100008 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1064103370, PERT_used=0.1000062859 → LR_next=0.1074814836, PERT_next=0.1000078722\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.022 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1064103370→0.1074814836 PERT 0.1000062859→0.1000078722\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.447196 step=0.0397 g_raw=+0.018 g_sm=+0.018 acc=1 | LR→0.107697 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#060 loss=0.441883 step=0.01281 g_raw=+0.006 g_sm=+0.018 acc=1 | LR→0.107913 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.436496 step=0.0008747 g_raw=-0.002 g_sm=+0.018 acc=1 | LR→0.108130 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.430408 step=0.04271 g_raw=+0.019 g_sm=+0.018 acc=1 | LR→0.108346 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#075 loss=0.424046 step=0.05957 g_raw=+0.028 g_sm=+0.020 acc=1 | LR→0.108564 PERT→0.100010 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1074814836, PERT_used=0.1000078722 → LR_next=0.1085637020, PERT_next=0.1000097254\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1074814836→0.1085637020 PERT 0.1000078722→0.1000097254\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.417263 step=0.007812 g_raw=+0.003 g_sm=+0.020 acc=1 | LR→0.108781 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.412699 step=0.02027 g_raw=+0.009 g_sm=+0.020 acc=1 | LR→0.109000 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.400733 step=0.04333 g_raw=+0.020 g_sm=+0.022 acc=1 | LR→0.109218 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.390729 step=0.009275 g_raw=+0.004 g_sm=+0.023 acc=1 | LR→0.109438 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.385172 step=0.006535 g_raw=+0.003 g_sm=+0.021 acc=1 | LR→0.109657 PERT→0.100012 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1085637020, PERT_used=0.1000097254 → LR_next=0.1096571416, PERT_next=0.1000118743\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.022 g_sm_mean=+0.021 acc_ratio=1.00 | LR 0.1085637020→0.1096571416 PERT 0.1000097254→0.1000118743\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.377757 step=0.03021 g_raw=+0.013 g_sm=+0.021 acc=1 | LR→0.109877 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.373760 step=0.03207 g_raw=+0.016 g_sm=+0.020 acc=1 | LR→0.110098 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.370272 step=0.002167 g_raw=+0.000 g_sm=+0.018 acc=1 | LR→0.110318 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.365680 step=0.03991 g_raw=+0.019 g_sm=+0.018 acc=1 | LR→0.110540 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.362578 step=0.03802 g_raw=+0.017 g_sm=+0.018 acc=1 | LR→0.110761 PERT→0.100014 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1096571416, PERT_used=0.1000118743 → LR_next=0.1107613556, PERT_next=0.1000138080\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1096571416→0.1107613556 PERT 0.1000118743→0.1000138080\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.69\n",
            "[round 7 | client 0] final LR=0.1107613556, final PERT=0.1000138080  (ΔLR=+0.0054104406, ΔPERT=+0.0000081120)\n",
            "[round 7 | client 1] seed LR=0.1053510898 (prev=0.1107021797), seed PERT=0.1000058650 (prev=0.1000117300), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.504512 step=0.009307 g_raw=+0.002 g_sm=+0.002 acc=1 | LR→0.105562 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.502151 step=0.001945 g_raw=+0.001 g_sm=+0.004 acc=1 | LR→0.105773 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.500725 step=0.008025 g_raw=+0.003 g_sm=+0.005 acc=1 | LR→0.105985 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.500227 step=0.002944 g_raw=+0.001 g_sm=+0.005 acc=1 | LR→0.106198 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#025 loss=0.499329 step=0.01587 g_raw=+0.007 g_sm=+0.006 acc=1 | LR→0.106410 PERT→0.100006 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1053510898, PERT_used=0.1000058650 → LR_next=0.1064103040, PERT_next=0.1000062579\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.004 acc_ratio=1.00 | LR 0.1053510898→0.1064103040 PERT 0.1000058650→0.1000062579\n",
            "Training Accuracy: 0.48\n",
            "Test Accuracy: 0.63\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.496959 step=0.03522 g_raw=+0.017 g_sm=+0.008 acc=1 | LR→0.106623 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#035 loss=0.494473 step=0.01339 g_raw=+0.007 g_sm=+0.008 acc=1 | LR→0.106837 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#040 loss=0.493588 step=0.008076 g_raw=+0.004 g_sm=+0.008 acc=1 | LR→0.107051 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#045 loss=0.492048 step=0.0338 g_raw=+0.016 g_sm=+0.009 acc=1 | LR→0.107266 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#050 loss=0.490853 step=0.01998 g_raw=+0.010 g_sm=+0.009 acc=1 | LR→0.107481 PERT→0.100007 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1064103040, PERT_used=0.1000062579 → LR_next=0.1074806268, PERT_next=0.1000070781\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1064103040→0.1074806268 PERT 0.1000062579→0.1000070781\n",
            "Training Accuracy: 0.52\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.489835 step=0.005209 g_raw=+0.001 g_sm=+0.009 acc=1 | LR→0.107696 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#060 loss=0.488753 step=0.008452 g_raw=+0.003 g_sm=+0.009 acc=1 | LR→0.107912 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#065 loss=0.487678 step=0.02631 g_raw=+0.015 g_sm=+0.009 acc=1 | LR→0.108128 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#070 loss=0.485159 step=0.01491 g_raw=+0.008 g_sm=+0.010 acc=1 | LR→0.108345 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#075 loss=0.482646 step=0.04764 g_raw=+0.023 g_sm=+0.011 acc=1 | LR→0.108562 PERT→0.100008 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1074806268, PERT_used=0.1000070781 → LR_next=0.1085618579, PERT_next=0.1000080295\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1074806268→0.1085618579 PERT 0.1000070781→0.1000080295\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.479434 step=0.02476 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.108779 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#085 loss=0.478280 step=0.0195 g_raw=+0.010 g_sm=+0.011 acc=1 | LR→0.108997 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#090 loss=0.474011 step=0.03919 g_raw=+0.020 g_sm=+0.013 acc=1 | LR→0.109216 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#095 loss=0.467866 step=0.03367 g_raw=+0.018 g_sm=+0.015 acc=1 | LR→0.109435 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#100 loss=0.464976 step=0.0314 g_raw=+0.017 g_sm=+0.015 acc=1 | LR→0.109654 PERT→0.100009 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1085618579, PERT_used=0.1000080295 → LR_next=0.1096543570, PERT_next=0.1000093377\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1085618579→0.1096543570 PERT 0.1000080295→0.1000093377\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.75\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.463426 step=0.01674 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.109874 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#110 loss=0.460826 step=0.02737 g_raw=+0.014 g_sm=+0.014 acc=1 | LR→0.110094 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#115 loss=0.458867 step=0.05338 g_raw=+0.026 g_sm=+0.014 acc=1 | LR→0.110315 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#120 loss=0.456016 step=0.01346 g_raw=+0.007 g_sm=+0.014 acc=1 | LR→0.110536 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#125 loss=0.449403 step=0.08817 g_raw=+0.043 g_sm=+0.016 acc=1 | LR→0.110758 PERT→0.100011 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1096543570, PERT_used=0.1000093377 → LR_next=0.1107579826, PERT_next=0.1000107653\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1096543570→0.1107579826 PERT 0.1000093377→0.1000107653\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.74\n",
            "[round 7 | client 1] final LR=0.1107579826, final PERT=0.1000107653  (ΔLR=+0.0054068928, ΔPERT=+0.0000049003)\n",
            "[round 7 | client 2] seed LR=0.1053525278 (prev=0.1107050556), seed PERT=0.1000071338 (prev=0.1000142676), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.455774 step=0.003598 g_raw=+0.003 g_sm=+0.003 acc=1 | LR→0.105563 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.453440 step=0.01517 g_raw=+0.005 g_sm=+0.005 acc=1 | LR→0.105775 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.451010 step=0.01962 g_raw=+0.009 g_sm=+0.007 acc=1 | LR→0.105987 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.446125 step=0.01816 g_raw=+0.008 g_sm=+0.009 acc=1 | LR→0.106199 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.445595 step=0.002924 g_raw=+0.002 g_sm=+0.008 acc=1 | LR→0.106412 PERT→0.100008 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1053525278, PERT_used=0.1000071338 → LR_next=0.1064120014, PERT_next=0.1000077570\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1053525278→0.1064120014 PERT 0.1000071338→0.1000077570\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.444956 step=0.008531 g_raw=+0.005 g_sm=+0.008 acc=1 | LR→0.106625 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.443821 step=0.001289 g_raw=+0.002 g_sm=+0.008 acc=1 | LR→0.106839 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.439289 step=0.02298 g_raw=+0.011 g_sm=+0.010 acc=1 | LR→0.107053 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.433999 step=0.02288 g_raw=+0.010 g_sm=+0.012 acc=1 | LR→0.107268 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.430913 step=0.05471 g_raw=+0.024 g_sm=+0.012 acc=1 | LR→0.107483 PERT→0.100009 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1064120014, PERT_used=0.1000077570 → LR_next=0.1074825231, PERT_next=0.1000087464\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1064120014→0.1074825231 PERT 0.1000077570→0.1000087464\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.424857 step=0.0139 g_raw=+0.006 g_sm=+0.014 acc=1 | LR→0.107698 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.423580 step=0.01748 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.107914 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.420545 step=0.04877 g_raw=+0.025 g_sm=+0.014 acc=1 | LR→0.108130 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.419107 step=0.04381 g_raw=+0.020 g_sm=+0.013 acc=1 | LR→0.108347 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.416786 step=0.02661 g_raw=+0.012 g_sm=+0.013 acc=1 | LR→0.108564 PERT→0.100010 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1074825231, PERT_used=0.1000087464 → LR_next=0.1085642115, PERT_next=0.1000101015\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1074825231→0.1085642115 PERT 0.1000087464→0.1000101015\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.415090 step=0.03291 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.108782 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.409929 step=0.07488 g_raw=+0.033 g_sm=+0.015 acc=1 | LR→0.109000 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.402541 step=0.09674 g_raw=+0.044 g_sm=+0.017 acc=1 | LR→0.109218 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.399795 step=0.03031 g_raw=+0.015 g_sm=+0.016 acc=1 | LR→0.109437 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.395027 step=0.04275 g_raw=+0.021 g_sm=+0.017 acc=1 | LR→0.109657 PERT→0.100012 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1085642115, PERT_used=0.1000101015 → LR_next=0.1096569580, PERT_next=0.1000116137\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1085642115→0.1096569580 PERT 0.1000101015→0.1000116137\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.388571 step=0.02703 g_raw=+0.014 g_sm=+0.018 acc=1 | LR→0.109877 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.385354 step=0.00948 g_raw=+0.006 g_sm=+0.017 acc=1 | LR→0.110097 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.384718 step=0.0005889 g_raw=-0.001 g_sm=+0.014 acc=1 | LR→0.110318 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.383116 step=0.002812 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.110539 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.381847 step=0.00618 g_raw=+0.005 g_sm=+0.012 acc=1 | LR→0.110761 PERT→0.100013 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1096569580, PERT_used=0.1000116137 → LR_next=0.1107607471, PERT_next=0.1000131653\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1096569580→0.1107607471 PERT 0.1000116137→0.1000131653\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.51\n",
            "[round 7 | client 2] final LR=0.1107607471, final PERT=0.1000131653  (ΔLR=+0.0054082193, ΔPERT=+0.0000060315)\n",
            "[round 7 | client 3] seed LR=0.1053518718 (prev=0.1107037435), seed PERT=0.1000065738 (prev=0.1000131475), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.536226 step=0.004439 g_raw=+0.003 g_sm=+0.004 acc=1 | LR→0.105563 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.534056 step=0.01545 g_raw=+0.007 g_sm=+0.006 acc=1 | LR→0.105774 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.532306 step=0.05073 g_raw=+0.026 g_sm=+0.007 acc=1 | LR→0.105986 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.527888 step=0.01836 g_raw=+0.010 g_sm=+0.010 acc=1 | LR→0.106199 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.523875 step=0.06598 g_raw=+0.033 g_sm=+0.011 acc=1 | LR→0.106411 PERT→0.100007 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1053518718, PERT_used=0.1000065738 → LR_next=0.1064113709, PERT_next=0.1000072271\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1053518718→0.1064113709 PERT 0.1000065738→0.1000072271\n",
            "Training Accuracy: 0.50\n",
            "Test Accuracy: 0.47\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.520506 step=0.0685 g_raw=+0.036 g_sm=+0.012 acc=1 | LR→0.106625 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.517553 step=0.01905 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.106838 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.511385 step=0.03451 g_raw=+0.017 g_sm=+0.014 acc=1 | LR→0.107053 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.502439 step=0.05903 g_raw=+0.030 g_sm=+0.017 acc=1 | LR→0.107267 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.499853 step=0.002085 g_raw=+0.000 g_sm=+0.016 acc=1 | LR→0.107482 PERT→0.100009 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1064113709, PERT_used=0.1000072271 → LR_next=0.1074823213, PERT_next=0.1000086213\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1064113709→0.1074823213 PERT 0.1000072271→0.1000086213\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.494486 step=0.008103 g_raw=+0.003 g_sm=+0.016 acc=1 | LR→0.107698 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.492208 step=0.04677 g_raw=+0.024 g_sm=+0.015 acc=1 | LR→0.107914 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.490316 step=0.02409 g_raw=+0.011 g_sm=+0.015 acc=1 | LR→0.108130 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.481973 step=0.05962 g_raw=+0.030 g_sm=+0.017 acc=1 | LR→0.108347 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.477180 step=0.02079 g_raw=+0.009 g_sm=+0.018 acc=1 | LR→0.108564 PERT→0.100010 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1074823213, PERT_used=0.1000086213 → LR_next=0.1085642645, PERT_next=0.1000102131\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1074823213→0.1085642645 PERT 0.1000086213→0.1000102131\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.471852 step=0.05325 g_raw=+0.027 g_sm=+0.018 acc=1 | LR→0.108782 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.467719 step=0.06683 g_raw=+0.032 g_sm=+0.018 acc=1 | LR→0.109000 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.463591 step=0.06732 g_raw=+0.033 g_sm=+0.018 acc=1 | LR→0.109219 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.460874 step=0.009203 g_raw=+0.006 g_sm=+0.017 acc=1 | LR→0.109438 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.459639 step=0.03699 g_raw=+0.019 g_sm=+0.015 acc=1 | LR→0.109657 PERT→0.100012 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1085642645, PERT_used=0.1000102131 → LR_next=0.1096572895, PERT_next=0.1000119788\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1085642645→0.1096572895 PERT 0.1000102131→0.1000119788\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.458648 step=0.02092 g_raw=+0.010 g_sm=+0.014 acc=1 | LR→0.109877 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.458067 step=0.009082 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.110097 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.456502 step=0.001106 g_raw=+0.000 g_sm=+0.011 acc=1 | LR→0.110318 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.456302 step=0.00425 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.110539 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.453834 step=0.02577 g_raw=+0.011 g_sm=+0.011 acc=1 | LR→0.110761 PERT→0.100013 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1096572895, PERT_used=0.1000119788 → LR_next=0.1107606788, PERT_next=0.1000131664\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1096572895→0.1107606788 PERT 0.1000119788→0.1000131664\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.51\n",
            "[round 7 | client 3] final LR=0.1107606788, final PERT=0.1000131664  (ΔLR=+0.0054088070, ΔPERT=+0.0000065926)\n",
            "[round 7 | client 4] seed LR=0.1053520760 (prev=0.1107041520), seed PERT=0.1000067280 (prev=0.1000134560), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.503305 step=0.04116 g_raw=+0.021 g_sm=+0.003 acc=1 | LR→0.105563 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.501306 step=0.02573 g_raw=+0.016 g_sm=+0.005 acc=1 | LR→0.105774 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.494742 step=0.0552 g_raw=+0.028 g_sm=+0.009 acc=1 | LR→0.105986 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.491617 step=0.05298 g_raw=+0.029 g_sm=+0.010 acc=1 | LR→0.106199 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.482966 step=0.05412 g_raw=+0.028 g_sm=+0.014 acc=1 | LR→0.106412 PERT→0.100007 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1053520760, PERT_used=0.1000067280 → LR_next=0.1064116341, PERT_next=0.1000074348\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1053520760→0.1064116341 PERT 0.1000067280→0.1000074348\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.477592 step=0.08011 g_raw=+0.038 g_sm=+0.015 acc=1 | LR→0.106625 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.474308 step=0.03752 g_raw=+0.019 g_sm=+0.015 acc=1 | LR→0.106839 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.470301 step=0.06982 g_raw=+0.037 g_sm=+0.015 acc=1 | LR→0.107053 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.464192 step=0.06009 g_raw=+0.029 g_sm=+0.017 acc=1 | LR→0.107268 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.462084 step=0.02496 g_raw=+0.013 g_sm=+0.016 acc=1 | LR→0.107483 PERT→0.100009 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1064116341, PERT_used=0.1000074348 → LR_next=0.1074827419, PERT_next=0.1000089730\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1064116341→0.1074827419 PERT 0.1000074348→0.1000089730\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.461242 step=0.03675 g_raw=+0.018 g_sm=+0.014 acc=1 | LR→0.107698 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.458470 step=0.03441 g_raw=+0.019 g_sm=+0.014 acc=1 | LR→0.107914 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.456959 step=0.01907 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.108130 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.455211 step=0.04556 g_raw=+0.022 g_sm=+0.013 acc=1 | LR→0.108347 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.451432 step=0.039 g_raw=+0.020 g_sm=+0.014 acc=1 | LR→0.108564 PERT→0.100010 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1074827419, PERT_used=0.1000089730 → LR_next=0.1085644564, PERT_next=0.1000103502\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1074827419→0.1085644564 PERT 0.1000089730→0.1000103502\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.448146 step=0.06668 g_raw=+0.031 g_sm=+0.014 acc=1 | LR→0.108782 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.445513 step=0.007525 g_raw=+0.003 g_sm=+0.014 acc=1 | LR→0.109000 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.444223 step=0.02325 g_raw=+0.012 g_sm=+0.013 acc=1 | LR→0.109219 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.441410 step=0.06154 g_raw=+0.031 g_sm=+0.013 acc=1 | LR→0.109438 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.441131 step=0.005519 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.109657 PERT→0.100012 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1085644564, PERT_used=0.1000103502 → LR_next=0.1096569930, PERT_next=0.1000116687\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1085644564→0.1096569930 PERT 0.1000103502→0.1000116687\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.439216 step=0.008768 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.109877 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.438303 step=0.01673 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.110097 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.436405 step=0.005164 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.110318 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.433865 step=0.05674 g_raw=+0.028 g_sm=+0.012 acc=1 | LR→0.110539 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.431445 step=0.04941 g_raw=+0.024 g_sm=+0.012 acc=1 | LR→0.110760 PERT→0.100013 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1096569930, PERT_used=0.1000116687 → LR_next=0.1107603199, PERT_next=0.1000128026\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1096569930→0.1107603199 PERT 0.1000116687→0.1000128026\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.73\n",
            "[round 7 | client 4] final LR=0.1107603199, final PERT=0.1000128026  (ΔLR=+0.0054082439, ΔPERT=+0.0000060746)\n",
            "\n",
            "[Round 7] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           0      0.564617      0.695000      0.110761      0.100014\n",
            "           1      0.608535      0.740000      0.110758      0.100011\n",
            "           4      0.615384      0.730000      0.110760      0.100013\n",
            "           3      0.642382      0.505000      0.110761      0.100013\n",
            "           2      0.778533      0.510000      0.110761      0.100013\n",
            "→ [Round 7] best_client=0, best_val=0.564617, prev_global_val=0.547797, improve=-0.016819, action=hold (τ=0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  80%|████████  | 8/10 [1:13:59<18:17, 548.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   7] acc_g=0.796 (μ=0.636, σ=0.106, FG=0.229) | t=535.149s, val=0.548 | TEL=FALSE\n",
            "[Round 8] Teleportation OFF | Aggregation=best\n",
            "[round 8 | client 0] seed LR=0.1053806778 (prev=0.1107613556), seed PERT=0.1000069040 (prev=0.1000138080), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.508758 step=0.08692 g_raw=+0.042 g_sm=+0.004 acc=1 | LR→0.105592 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.505588 step=0.04365 g_raw=+0.022 g_sm=+0.007 acc=1 | LR→0.105803 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.498045 step=0.01133 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.106015 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.495271 step=0.03099 g_raw=+0.017 g_sm=+0.012 acc=1 | LR→0.106228 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.488668 step=0.04826 g_raw=+0.023 g_sm=+0.014 acc=1 | LR→0.106441 PERT→0.100008 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1053806778, PERT_used=0.1000069040 → LR_next=0.1064406240, PERT_next=0.1000077052\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1053806778→0.1064406240 PERT 0.1000069040→0.1000077052\n",
            "Training Accuracy: 0.52\n",
            "Test Accuracy: 0.60\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.484977 step=0.004572 g_raw=+0.002 g_sm=+0.014 acc=1 | LR→0.106654 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.479940 step=0.08453 g_raw=+0.041 g_sm=+0.015 acc=1 | LR→0.106868 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.475349 step=0.07043 g_raw=+0.035 g_sm=+0.016 acc=1 | LR→0.107082 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.473398 step=0.02118 g_raw=+0.009 g_sm=+0.015 acc=1 | LR→0.107297 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.470158 step=0.02762 g_raw=+0.013 g_sm=+0.015 acc=1 | LR→0.107512 PERT→0.100009 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1064406240, PERT_used=0.1000077052 → LR_next=0.1075119452, PERT_next=0.1000091704\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1064406240→0.1075119452 PERT 0.1000077052→0.1000091704\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.60\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.465536 step=0.01691 g_raw=+0.010 g_sm=+0.015 acc=1 | LR→0.107728 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.463376 step=0.02456 g_raw=+0.012 g_sm=+0.015 acc=1 | LR→0.107944 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.462581 step=0.01954 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.108160 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.460705 step=0.01176 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.108377 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.459383 step=0.01609 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.108594 PERT→0.100011 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1075119452, PERT_used=0.1000091704 → LR_next=0.1085939963, PERT_next=0.1000105869\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1075119452→0.1085939963 PERT 0.1000091704→0.1000105869\n",
            "Training Accuracy: 0.54\n",
            "Test Accuracy: 0.58\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.457419 step=0.008627 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.108812 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.454798 step=0.01514 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.109030 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.453232 step=0.008231 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.109248 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.451496 step=0.005682 g_raw=+0.003 g_sm=+0.012 acc=1 | LR→0.109467 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.450205 step=0.01629 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.109687 PERT→0.100012 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1085939963, PERT_used=0.1000105869 → LR_next=0.1096866776, PERT_next=0.1000117663\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1085939963→0.1096866776 PERT 0.1000105869→0.1000117663\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.448392 step=0.02918 g_raw=+0.013 g_sm=+0.011 acc=1 | LR→0.109907 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.447593 step=0.03343 g_raw=+0.015 g_sm=+0.010 acc=1 | LR→0.110127 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.444214 step=0.0412 g_raw=+0.018 g_sm=+0.011 acc=1 | LR→0.110347 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.441023 step=0.0521 g_raw=+0.024 g_sm=+0.013 acc=1 | LR→0.110569 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.439138 step=0.0247 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.110790 PERT→0.100013 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1096866776, PERT_used=0.1000117663 → LR_next=0.1107902892, PERT_next=0.1000128877\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1096866776→0.1107902892 PERT 0.1000117663→0.1000128877\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.65\n",
            "[round 8 | client 0] final LR=0.1107902892, final PERT=0.1000128877  (ΔLR=+0.0054096114, ΔPERT=+0.0000059837)\n",
            "[round 8 | client 1] seed LR=0.1053789913 (prev=0.1107579826), seed PERT=0.1000053826 (prev=0.1000107653), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.487677 step=0.06496 g_raw=+0.034 g_sm=+0.004 acc=1 | LR→0.105590 PERT→0.100005 (scale=0.04)\n",
            "[meta] cb#010 loss=0.483781 step=0.0131 g_raw=+0.007 g_sm=+0.007 acc=1 | LR→0.105802 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.479033 step=0.06061 g_raw=+0.032 g_sm=+0.010 acc=1 | LR→0.106014 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.475746 step=0.03816 g_raw=+0.018 g_sm=+0.011 acc=1 | LR→0.106226 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#025 loss=0.474780 step=0.01484 g_raw=+0.010 g_sm=+0.011 acc=1 | LR→0.106439 PERT→0.100006 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1053789913, PERT_used=0.1000053826 → LR_next=0.1064388760, PERT_next=0.1000061420\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1053789913→0.1064388760 PERT 0.1000053826→0.1000061420\n",
            "Training Accuracy: 0.50\n",
            "Test Accuracy: 0.45\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.473016 step=0.02059 g_raw=+0.010 g_sm=+0.011 acc=1 | LR→0.106652 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#035 loss=0.469743 step=0.003167 g_raw=-0.000 g_sm=+0.012 acc=1 | LR→0.106866 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#040 loss=0.464195 step=0.002948 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.107080 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#045 loss=0.461942 step=0.01068 g_raw=+0.006 g_sm=+0.013 acc=1 | LR→0.107295 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#050 loss=0.459083 step=0.04571 g_raw=+0.023 g_sm=+0.014 acc=1 | LR→0.107510 PERT→0.100007 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1064388760, PERT_used=0.1000061420 → LR_next=0.1075099543, PERT_next=0.1000073976\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1064388760→0.1075099543 PERT 0.1000061420→0.1000073976\n",
            "Training Accuracy: 0.56\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.453242 step=0.0656 g_raw=+0.032 g_sm=+0.015 acc=1 | LR→0.107725 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#060 loss=0.451002 step=0.003191 g_raw=+0.001 g_sm=+0.014 acc=1 | LR→0.107941 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#065 loss=0.449080 step=0.05041 g_raw=+0.023 g_sm=+0.013 acc=1 | LR→0.108158 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#070 loss=0.448137 step=0.004381 g_raw=+0.003 g_sm=+0.012 acc=1 | LR→0.108375 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#075 loss=0.444233 step=0.02663 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.108592 PERT→0.100009 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1075099543, PERT_used=0.1000073976 → LR_next=0.1085919155, PERT_next=0.1000087498\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1075099543→0.1085919155 PERT 0.1000073976→0.1000087498\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.441516 step=0.01123 g_raw=+0.004 g_sm=+0.013 acc=1 | LR→0.108810 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#085 loss=0.439460 step=0.03443 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.109028 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#090 loss=0.439011 step=0.01154 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.109246 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#095 loss=0.434099 step=0.007033 g_raw=+0.004 g_sm=+0.013 acc=1 | LR→0.109465 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#100 loss=0.433494 step=0.008504 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.109685 PERT→0.100010 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1085919155, PERT_used=0.1000087498 → LR_next=0.1096846710, PERT_next=0.1000100159\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1085919155→0.1096846710 PERT 0.1000087498→0.1000100159\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.431822 step=0.0116 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.109905 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#110 loss=0.428918 step=0.03161 g_raw=+0.017 g_sm=+0.012 acc=1 | LR→0.110125 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#115 loss=0.427883 step=0.02483 g_raw=+0.014 g_sm=+0.011 acc=1 | LR→0.110346 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#120 loss=0.427426 step=0.0053 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.110567 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#125 loss=0.426600 step=0.008149 g_raw=+0.003 g_sm=+0.009 acc=1 | LR→0.110788 PERT→0.100011 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1096846710, PERT_used=0.1000100159 → LR_next=0.1107882273, PERT_next=0.1000111055\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1096846710→0.1107882273 PERT 0.1000100159→0.1000111055\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.67\n",
            "[round 8 | client 1] final LR=0.1107882273, final PERT=0.1000111055  (ΔLR=+0.0054092360, ΔPERT=+0.0000057229)\n",
            "[round 8 | client 2] seed LR=0.1053803736 (prev=0.1107607471), seed PERT=0.1000065827 (prev=0.1000131653), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.488906 step=0.004389 g_raw=+0.004 g_sm=+0.002 acc=1 | LR→0.105591 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.485580 step=0.007721 g_raw=+0.004 g_sm=+0.004 acc=1 | LR→0.105803 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.482217 step=0.03873 g_raw=+0.020 g_sm=+0.007 acc=1 | LR→0.106015 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.475122 step=0.04535 g_raw=+0.022 g_sm=+0.010 acc=1 | LR→0.106227 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.474478 step=0.005797 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.106440 PERT→0.100007 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1053803736, PERT_used=0.1000065827 → LR_next=0.1064400928, PERT_next=0.1000071735\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1053803736→0.1064400928 PERT 0.1000065827→0.1000071735\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.470398 step=0.0541 g_raw=+0.026 g_sm=+0.012 acc=1 | LR→0.106653 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.468869 step=0.03933 g_raw=+0.018 g_sm=+0.011 acc=1 | LR→0.106867 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.461976 step=0.06651 g_raw=+0.035 g_sm=+0.014 acc=1 | LR→0.107081 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.456194 step=0.02129 g_raw=+0.012 g_sm=+0.016 acc=1 | LR→0.107296 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.454538 step=0.001536 g_raw=+0.000 g_sm=+0.015 acc=1 | LR→0.107511 PERT→0.100008 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1064400928, PERT_used=0.1000071735 → LR_next=0.1075112375, PERT_next=0.1000084796\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1064400928→0.1075112375 PERT 0.1000071735→0.1000084796\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.47\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.450584 step=0.01802 g_raw=+0.008 g_sm=+0.015 acc=1 | LR→0.107727 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.443877 step=0.09243 g_raw=+0.045 g_sm=+0.016 acc=1 | LR→0.107943 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.435527 step=0.05959 g_raw=+0.027 g_sm=+0.019 acc=1 | LR→0.108159 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.431764 step=0.006504 g_raw=+0.003 g_sm=+0.018 acc=1 | LR→0.108376 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.429593 step=0.0331 g_raw=+0.014 g_sm=+0.017 acc=1 | LR→0.108594 PERT→0.100010 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1075112375, PERT_used=0.1000084796 → LR_next=0.1085935789, PERT_next=0.1000101700\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1075112375→0.1085935789 PERT 0.1000084796→0.1000101700\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.427634 step=0.03314 g_raw=+0.016 g_sm=+0.015 acc=1 | LR→0.108811 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.426302 step=0.005747 g_raw=+0.003 g_sm=+0.014 acc=1 | LR→0.109029 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.424340 step=0.00159 g_raw=+0.000 g_sm=+0.012 acc=1 | LR→0.109248 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.422202 step=0.01343 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.109467 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.418427 step=0.04267 g_raw=+0.021 g_sm=+0.013 acc=1 | LR→0.109686 PERT→0.100012 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1085935789, PERT_used=0.1000101700 → LR_next=0.1096864920, PERT_next=0.1000115646\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1085935789→0.1096864920 PERT 0.1000101700→0.1000115646\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.416297 step=0.03652 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.109906 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.411242 step=0.007251 g_raw=+0.003 g_sm=+0.014 acc=1 | LR→0.110127 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.404920 step=0.05216 g_raw=+0.022 g_sm=+0.016 acc=1 | LR→0.110348 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.402659 step=0.03557 g_raw=+0.016 g_sm=+0.015 acc=1 | LR→0.110569 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.400052 step=0.03539 g_raw=+0.015 g_sm=+0.015 acc=1 | LR→0.110791 PERT→0.100013 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1096864920, PERT_used=0.1000115646 → LR_next=0.1107905001, PERT_next=0.1000130455\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1096864920→0.1107905001 PERT 0.1000115646→0.1000130455\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.57\n",
            "[round 8 | client 2] final LR=0.1107905001, final PERT=0.1000130455  (ΔLR=+0.0054101265, ΔPERT=+0.0000064628)\n",
            "[round 8 | client 3] seed LR=0.1053803394 (prev=0.1107606788), seed PERT=0.1000065832 (prev=0.1000131664), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.516065 step=0.005402 g_raw=+0.002 g_sm=+0.004 acc=1 | LR→0.105591 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.503257 step=0.09603 g_raw=+0.049 g_sm=+0.009 acc=1 | LR→0.105803 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.495165 step=0.1059 g_raw=+0.053 g_sm=+0.013 acc=1 | LR→0.106015 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.484332 step=0.1052 g_raw=+0.052 g_sm=+0.016 acc=1 | LR→0.106227 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.474118 step=0.08105 g_raw=+0.040 g_sm=+0.019 acc=1 | LR→0.106441 PERT→0.100008 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1053803394, PERT_used=0.1000065832 → LR_next=0.1064405188, PERT_next=0.1000076067\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.024 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1053803394→0.1064405188 PERT 0.1000065832→0.1000076067\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.467368 step=0.0723 g_raw=+0.034 g_sm=+0.019 acc=1 | LR→0.106654 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.453563 step=0.1377 g_raw=+0.067 g_sm=+0.022 acc=1 | LR→0.106868 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.447382 step=0.01989 g_raw=+0.012 g_sm=+0.022 acc=1 | LR→0.107082 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.443388 step=0.004926 g_raw=+0.001 g_sm=+0.020 acc=1 | LR→0.107297 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.428516 step=0.06618 g_raw=+0.032 g_sm=+0.022 acc=1 | LR→0.107512 PERT→0.100010 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1064405188, PERT_used=0.1000076067 → LR_next=0.1075124506, PERT_next=0.1000096410\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.023 g_sm_mean=+0.020 acc_ratio=1.00 | LR 0.1064405188→0.1075124506 PERT 0.1000076067→0.1000096410\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.423270 step=0.02497 g_raw=+0.013 g_sm=+0.022 acc=1 | LR→0.107728 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.418315 step=0.01466 g_raw=+0.005 g_sm=+0.020 acc=1 | LR→0.107944 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.414219 step=0.0437 g_raw=+0.022 g_sm=+0.020 acc=1 | LR→0.108161 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#070 loss=0.412045 step=0.0294 g_raw=+0.014 g_sm=+0.018 acc=1 | LR→0.108378 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#075 loss=0.409997 step=0.04078 g_raw=+0.020 g_sm=+0.016 acc=1 | LR→0.108595 PERT→0.100012 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1075124506, PERT_used=0.1000096410 → LR_next=0.1085951017, PERT_next=0.1000116054\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.020 acc_ratio=1.00 | LR 0.1075124506→0.1085951017 PERT 0.1000096410→0.1000116054\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.407505 step=0.02315 g_raw=+0.011 g_sm=+0.016 acc=1 | LR→0.108813 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#085 loss=0.406558 step=0.02465 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.109031 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#090 loss=0.403892 step=0.03906 g_raw=+0.018 g_sm=+0.014 acc=1 | LR→0.109250 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.403178 step=0.02257 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.109469 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#100 loss=0.399924 step=0.002535 g_raw=+0.002 g_sm=+0.012 acc=1 | LR→0.109688 PERT→0.100013 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1085951017, PERT_used=0.1000116054 → LR_next=0.1096880240, PERT_next=0.1000129943\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1085951017→0.1096880240 PERT 0.1000116054→0.1000129943\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.399437 step=0.02174 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.109908 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#110 loss=0.398116 step=0.0172 g_raw=+0.007 g_sm=+0.010 acc=1 | LR→0.110128 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.396867 step=0.03167 g_raw=+0.015 g_sm=+0.011 acc=1 | LR→0.110349 PERT→0.100014 (scale=0.04)\n",
            "[meta] cb#120 loss=0.395001 step=0.02485 g_raw=+0.012 g_sm=+0.011 acc=1 | LR→0.110570 PERT→0.100014 (scale=0.04)\n",
            "[meta] cb#125 loss=0.394460 step=0.02275 g_raw=+0.011 g_sm=+0.010 acc=1 | LR→0.110792 PERT→0.100014 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1096880240, PERT_used=0.1000129943 → LR_next=0.1107915658, PERT_next=0.1000140405\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1096880240→0.1107915658 PERT 0.1000129943→0.1000140405\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.77\n",
            "[round 8 | client 3] final LR=0.1107915658, final PERT=0.1000140405  (ΔLR=+0.0054112264, ΔPERT=+0.0000074573)\n",
            "[round 8 | client 4] seed LR=0.1053801599 (prev=0.1107603199), seed PERT=0.1000064013 (prev=0.1000128026), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.518167 step=0.007738 g_raw=+0.003 g_sm=+0.004 acc=1 | LR→0.105591 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.516950 step=0.03479 g_raw=+0.018 g_sm=+0.005 acc=1 | LR→0.105803 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.512429 step=0.05063 g_raw=+0.024 g_sm=+0.008 acc=1 | LR→0.106015 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.509935 step=0.01278 g_raw=+0.006 g_sm=+0.010 acc=1 | LR→0.106227 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.508014 step=0.03421 g_raw=+0.017 g_sm=+0.010 acc=1 | LR→0.106440 PERT→0.100007 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1053801599, PERT_used=0.1000064013 → LR_next=0.1064399682, PERT_next=0.1000070779\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1053801599→0.1064399682 PERT 0.1000064013→0.1000070779\n",
            "Training Accuracy: 0.54\n",
            "Test Accuracy: 0.45\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.503969 step=0.05433 g_raw=+0.026 g_sm=+0.012 acc=1 | LR→0.106653 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.499975 step=0.04675 g_raw=+0.024 g_sm=+0.013 acc=1 | LR→0.106867 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.499120 step=0.03608 g_raw=+0.016 g_sm=+0.012 acc=1 | LR→0.107081 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.498678 step=0.0121 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.107296 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.492597 step=0.07793 g_raw=+0.041 g_sm=+0.013 acc=1 | LR→0.107511 PERT→0.100008 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1064399682, PERT_used=0.1000070779 → LR_next=0.1075109558, PERT_next=0.1000082388\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1064399682→0.1075109558 PERT 0.1000070779→0.1000082388\n",
            "Training Accuracy: 0.54\n",
            "Test Accuracy: 0.45\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.491561 step=0.02948 g_raw=+0.015 g_sm=+0.012 acc=1 | LR→0.107726 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#060 loss=0.490508 step=0.01215 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.107942 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.488797 step=0.03536 g_raw=+0.018 g_sm=+0.012 acc=1 | LR→0.108159 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.485743 step=0.009561 g_raw=+0.005 g_sm=+0.012 acc=1 | LR→0.108376 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#075 loss=0.484869 step=0.01392 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.108593 PERT→0.100009 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1075109558, PERT_used=0.1000082388 → LR_next=0.1085927494, PERT_next=0.1000094274\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1075109558→0.1085927494 PERT 0.1000082388→0.1000094274\n",
            "Training Accuracy: 0.54\n",
            "Test Accuracy: 0.45\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.480665 step=0.05462 g_raw=+0.028 g_sm=+0.012 acc=1 | LR→0.108810 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.476600 step=0.0023 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.109029 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#090 loss=0.475117 step=0.02919 g_raw=+0.014 g_sm=+0.013 acc=1 | LR→0.109247 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#095 loss=0.472555 step=0.03133 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.109466 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#100 loss=0.470097 step=0.05135 g_raw=+0.026 g_sm=+0.013 acc=1 | LR→0.109686 PERT→0.100011 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1085927494, PERT_used=0.1000094274 → LR_next=0.1096855260, PERT_next=0.1000107051\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1085927494→0.1096855260 PERT 0.1000094274→0.1000107051\n",
            "Training Accuracy: 0.54\n",
            "Test Accuracy: 0.45\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.466205 step=0.0612 g_raw=+0.030 g_sm=+0.015 acc=1 | LR→0.109905 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#110 loss=0.461800 step=0.07144 g_raw=+0.037 g_sm=+0.015 acc=1 | LR→0.110126 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#115 loss=0.458010 step=0.07075 g_raw=+0.032 g_sm=+0.016 acc=1 | LR→0.110347 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.454347 step=0.02638 g_raw=+0.013 g_sm=+0.016 acc=1 | LR→0.110568 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#125 loss=0.451645 step=0.03717 g_raw=+0.020 g_sm=+0.016 acc=1 | LR→0.110790 PERT→0.100012 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1096855260, PERT_used=0.1000107051 → LR_next=0.1107895412, PERT_next=0.1000122013\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1096855260→0.1107895412 PERT 0.1000107051→0.1000122013\n",
            "Training Accuracy: 0.54\n",
            "Test Accuracy: 0.45\n",
            "[round 8 | client 4] final LR=0.1107895412, final PERT=0.1000122013  (ΔLR=+0.0054093813, ΔPERT=+0.0000058000)\n",
            "\n",
            "[Round 8] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           3      0.576747      0.770000      0.110792      0.100014\n",
            "           2      0.607081      0.570000      0.110791      0.100013\n",
            "           0      0.625870      0.650000      0.110790      0.100013\n",
            "           1      0.631999      0.665000      0.110788      0.100011\n",
            "           4      0.733826      0.445000      0.110790      0.100012\n",
            "→ [Round 8] best_client=3, best_val=0.576747, prev_global_val=0.547705, improve=-0.029042, action=hold (τ=0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  90%|█████████ | 9/10 [1:23:06<09:08, 548.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   8] acc_g=0.778 (μ=0.620, σ=0.108, FG=0.233) | t=537.953s, val=0.546 | TEL=FALSE\n",
            "[Round 9] Teleportation OFF | Aggregation=best\n",
            "[round 9 | client 0] seed LR=0.1053951446 (prev=0.1107902892), seed PERT=0.1000064438 (prev=0.1000128877), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.504918 step=0.01328 g_raw=+0.008 g_sm=+0.002 acc=1 | LR→0.105606 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.501790 step=0.001527 g_raw=+0.001 g_sm=+0.005 acc=1 | LR→0.105818 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.494828 step=0.06168 g_raw=+0.033 g_sm=+0.009 acc=1 | LR→0.106030 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.493387 step=0.03562 g_raw=+0.018 g_sm=+0.010 acc=1 | LR→0.106242 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.490688 step=0.04066 g_raw=+0.020 g_sm=+0.011 acc=1 | LR→0.106455 PERT→0.100007 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1053951446, PERT_used=0.1000064438 → LR_next=0.1064550836, PERT_next=0.1000071016\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1053951446→0.1064550836 PERT 0.1000064438→0.1000071016\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.484860 step=0.02993 g_raw=+0.015 g_sm=+0.014 acc=1 | LR→0.106668 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.481332 step=0.01568 g_raw=+0.007 g_sm=+0.014 acc=1 | LR→0.106882 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.477909 step=0.003147 g_raw=+0.001 g_sm=+0.014 acc=1 | LR→0.107097 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.475442 step=0.01112 g_raw=+0.006 g_sm=+0.014 acc=1 | LR→0.107311 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.471867 step=0.02621 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.107526 PERT→0.100009 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1064550836, PERT_used=0.1000071016 → LR_next=0.1075264793, PERT_next=0.1000085008\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1064550836→0.1075264793 PERT 0.1000071016→0.1000085008\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.466965 step=0.03892 g_raw=+0.021 g_sm=+0.015 acc=1 | LR→0.107742 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.460073 step=0.06769 g_raw=+0.032 g_sm=+0.017 acc=1 | LR→0.107958 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.457169 step=0.03979 g_raw=+0.018 g_sm=+0.017 acc=1 | LR→0.108175 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.454769 step=0.02543 g_raw=+0.014 g_sm=+0.016 acc=1 | LR→0.108392 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.454511 step=0.001881 g_raw=+0.000 g_sm=+0.013 acc=1 | LR→0.108609 PERT→0.100010 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1075264793, PERT_used=0.1000085008 → LR_next=0.1086088125, PERT_next=0.1000100424\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1075264793→0.1086088125 PERT 0.1000085008→0.1000100424\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.73\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.449228 step=0.0123 g_raw=+0.005 g_sm=+0.015 acc=1 | LR→0.108827 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.446715 step=0.006397 g_raw=+0.004 g_sm=+0.014 acc=1 | LR→0.109045 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.445463 step=0.0307 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.109263 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.442160 step=0.05711 g_raw=+0.027 g_sm=+0.013 acc=1 | LR→0.109482 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.439681 step=0.02104 g_raw=+0.011 g_sm=+0.013 acc=1 | LR→0.109702 PERT→0.100011 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1086088125, PERT_used=0.1000100424 → LR_next=0.1097018285, PERT_next=0.1000113910\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1086088125→0.1097018285 PERT 0.1000100424→0.1000113910\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.82\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.436936 step=0.05585 g_raw=+0.027 g_sm=+0.014 acc=1 | LR→0.109922 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.432321 step=0.006534 g_raw=+0.001 g_sm=+0.014 acc=1 | LR→0.110142 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.431049 step=0.0008846 g_raw=+0.000 g_sm=+0.012 acc=1 | LR→0.110363 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.426598 step=0.0269 g_raw=+0.012 g_sm=+0.013 acc=1 | LR→0.110584 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#125 loss=0.424671 step=0.03346 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.110806 PERT→0.100013 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1097018285, PERT_used=0.1000113910 → LR_next=0.1108058270, PERT_next=0.1000127239\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1097018285→0.1108058270 PERT 0.1000113910→0.1000127239\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.86\n",
            "[round 9 | client 0] final LR=0.1108058270, final PERT=0.1000127239  (ΔLR=+0.0054106824, ΔPERT=+0.0000062800)\n",
            "[round 9 | client 1] seed LR=0.1053941136 (prev=0.1107882273), seed PERT=0.1000055528 (prev=0.1000111055), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.518238 step=0.0084 g_raw=+0.004 g_sm=+0.003 acc=1 | LR→0.105605 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.515825 step=0.06276 g_raw=+0.031 g_sm=+0.005 acc=1 | LR→0.105817 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.511615 step=0.04832 g_raw=+0.024 g_sm=+0.008 acc=1 | LR→0.106029 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.507988 step=0.04515 g_raw=+0.021 g_sm=+0.010 acc=1 | LR→0.106241 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#025 loss=0.504310 step=0.01047 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.106454 PERT→0.100006 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1053941136, PERT_used=0.1000055528 → LR_next=0.1064540021, PERT_next=0.1000061728\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1053941136→0.1064540021 PERT 0.1000055528→0.1000061728\n",
            "Training Accuracy: 0.48\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.498597 step=0.05718 g_raw=+0.028 g_sm=+0.014 acc=1 | LR→0.106667 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#035 loss=0.492132 step=0.06806 g_raw=+0.034 g_sm=+0.016 acc=1 | LR→0.106881 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#040 loss=0.488658 step=0.03199 g_raw=+0.015 g_sm=+0.016 acc=1 | LR→0.107096 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#045 loss=0.486474 step=0.02291 g_raw=+0.010 g_sm=+0.015 acc=1 | LR→0.107310 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#050 loss=0.482108 step=0.01565 g_raw=+0.007 g_sm=+0.016 acc=1 | LR→0.107525 PERT→0.100008 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1064540021, PERT_used=0.1000061728 → LR_next=0.1075254920, PERT_next=0.1000076697\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1064540021→0.1075254920 PERT 0.1000061728→0.1000076697\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.477146 step=0.07022 g_raw=+0.033 g_sm=+0.017 acc=1 | LR→0.107741 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#060 loss=0.472973 step=0.006204 g_raw=+0.002 g_sm=+0.016 acc=1 | LR→0.107957 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#065 loss=0.461885 step=0.0534 g_raw=+0.025 g_sm=+0.019 acc=1 | LR→0.108174 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.457986 step=0.05372 g_raw=+0.026 g_sm=+0.019 acc=1 | LR→0.108391 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#075 loss=0.456663 step=0.01068 g_raw=+0.005 g_sm=+0.017 acc=1 | LR→0.108608 PERT→0.100009 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1075254920, PERT_used=0.1000076697 → LR_next=0.1086080555, PERT_next=0.1000094325\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1075254920→0.1086080555 PERT 0.1000076697→0.1000094325\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.453689 step=0.005704 g_raw=+0.004 g_sm=+0.016 acc=1 | LR→0.108826 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.440389 step=0.06035 g_raw=+0.031 g_sm=+0.020 acc=1 | LR→0.109044 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#090 loss=0.430769 step=0.05607 g_raw=+0.028 g_sm=+0.022 acc=1 | LR→0.109263 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.425576 step=0.05423 g_raw=+0.025 g_sm=+0.022 acc=1 | LR→0.109482 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.421305 step=0.02872 g_raw=+0.014 g_sm=+0.021 acc=1 | LR→0.109702 PERT→0.100011 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1086080555, PERT_used=0.1000094325 → LR_next=0.1097017610, PERT_next=0.1000114166\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.023 g_sm_mean=+0.020 acc_ratio=1.00 | LR 0.1086080555→0.1097017610 PERT 0.1000094325→0.1000114166\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.410787 step=0.09926 g_raw=+0.049 g_sm=+0.021 acc=1 | LR→0.109922 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.394871 step=0.1221 g_raw=+0.058 g_sm=+0.025 acc=1 | LR→0.110142 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.393674 step=0.03567 g_raw=+0.017 g_sm=+0.021 acc=1 | LR→0.110363 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.390881 step=0.04582 g_raw=+0.019 g_sm=+0.020 acc=1 | LR→0.110585 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.383961 step=0.101 g_raw=+0.048 g_sm=+0.020 acc=1 | LR→0.110807 PERT→0.100014 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1097017610, PERT_used=0.1000114166 → LR_next=0.1108065990, PERT_next=0.1000135079\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.021 acc_ratio=1.00 | LR 0.1097017610→0.1108065990 PERT 0.1000114166→0.1000135079\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.77\n",
            "[round 9 | client 1] final LR=0.1108065990, final PERT=0.1000135079  (ΔLR=+0.0054124853, ΔPERT=+0.0000079551)\n",
            "[round 9 | client 2] seed LR=0.1053952500 (prev=0.1107905001), seed PERT=0.1000065227 (prev=0.1000130455), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.466603 step=0.01656 g_raw=+0.007 g_sm=+0.002 acc=1 | LR→0.105606 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.461510 step=0.03845 g_raw=+0.020 g_sm=+0.006 acc=1 | LR→0.105818 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.459395 step=0.04723 g_raw=+0.023 g_sm=+0.008 acc=1 | LR→0.106030 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.455846 step=0.01887 g_raw=+0.010 g_sm=+0.010 acc=1 | LR→0.106242 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.454277 step=0.03568 g_raw=+0.017 g_sm=+0.010 acc=1 | LR→0.106455 PERT→0.100007 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1053952500, PERT_used=0.1000065227 → LR_next=0.1064551689, PERT_next=0.1000071606\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1053952500→0.1064551689 PERT 0.1000065227→0.1000071606\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.60\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.450591 step=0.02481 g_raw=+0.012 g_sm=+0.011 acc=1 | LR→0.106669 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.448598 step=0.005443 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.106882 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.444375 step=0.04575 g_raw=+0.024 g_sm=+0.013 acc=1 | LR→0.107097 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.443160 step=0.02642 g_raw=+0.014 g_sm=+0.012 acc=1 | LR→0.107311 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.442381 step=0.002308 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.107526 PERT→0.100008 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1064551689, PERT_used=0.1000071606 → LR_next=0.1075262841, PERT_next=0.1000082981\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1064551689→0.1075262841 PERT 0.1000071606→0.1000082981\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.440768 step=0.03225 g_raw=+0.016 g_sm=+0.011 acc=1 | LR→0.107742 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.438171 step=0.02413 g_raw=+0.011 g_sm=+0.011 acc=1 | LR→0.107958 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.434074 step=0.04269 g_raw=+0.021 g_sm=+0.013 acc=1 | LR→0.108174 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.432184 step=0.004173 g_raw=+0.002 g_sm=+0.012 acc=1 | LR→0.108391 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#075 loss=0.429893 step=0.003206 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.108608 PERT→0.100009 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1075262841, PERT_used=0.1000082981 → LR_next=0.1086082182, PERT_next=0.1000094739\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1075262841→0.1086082182 PERT 0.1000082981→0.1000094739\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.427042 step=0.001232 g_raw=-0.000 g_sm=+0.012 acc=1 | LR→0.108826 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.426480 step=0.02067 g_raw=+0.010 g_sm=+0.011 acc=1 | LR→0.109044 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#090 loss=0.424350 step=0.05361 g_raw=+0.027 g_sm=+0.011 acc=1 | LR→0.109263 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#095 loss=0.423748 step=0.008835 g_raw=+0.006 g_sm=+0.010 acc=1 | LR→0.109482 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#100 loss=0.423345 step=0.02813 g_raw=+0.013 g_sm=+0.009 acc=1 | LR→0.109701 PERT→0.100011 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1086082182, PERT_used=0.1000094739 → LR_next=0.1097009448, PERT_next=0.1000105642\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1086082182→0.1097009448 PERT 0.1000094739→0.1000105642\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.420446 step=0.01475 g_raw=+0.007 g_sm=+0.010 acc=1 | LR→0.109921 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#110 loss=0.419705 step=0.02588 g_raw=+0.012 g_sm=+0.009 acc=1 | LR→0.110141 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#115 loss=0.417696 step=0.04318 g_raw=+0.021 g_sm=+0.010 acc=1 | LR→0.110362 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#120 loss=0.415022 step=0.02662 g_raw=+0.011 g_sm=+0.011 acc=1 | LR→0.110583 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#125 loss=0.414158 step=0.01904 g_raw=+0.011 g_sm=+0.010 acc=1 | LR→0.110805 PERT→0.100012 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1097009448, PERT_used=0.1000105642 → LR_next=0.1108045472, PERT_next=0.1000115476\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1097009448→0.1108045472 PERT 0.1000105642→0.1000115476\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.61\n",
            "[round 9 | client 2] final LR=0.1108045472, final PERT=0.1000115476  (ΔLR=+0.0054092972, ΔPERT=+0.0000050249)\n",
            "[round 9 | client 3] seed LR=0.1053957829 (prev=0.1107915658), seed PERT=0.1000070202 (prev=0.1000140405), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.542407 step=0.07734 g_raw=+0.042 g_sm=+0.006 acc=1 | LR→0.105607 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.537457 step=0.04883 g_raw=+0.028 g_sm=+0.008 acc=1 | LR→0.105818 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.530297 step=0.02942 g_raw=+0.016 g_sm=+0.011 acc=1 | LR→0.106030 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.527815 step=0.05042 g_raw=+0.025 g_sm=+0.012 acc=1 | LR→0.106243 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.525470 step=0.02331 g_raw=+0.010 g_sm=+0.012 acc=1 | LR→0.106456 PERT→0.100008 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1053957829, PERT_used=0.1000070202 → LR_next=0.1064559637, PERT_next=0.1000078992\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1053957829→0.1064559637 PERT 0.1000070202→0.1000078992\n",
            "Training Accuracy: 0.46\n",
            "Test Accuracy: 0.35\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.523168 step=0.05344 g_raw=+0.028 g_sm=+0.012 acc=1 | LR→0.106669 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.517530 step=0.05017 g_raw=+0.026 g_sm=+0.015 acc=1 | LR→0.106883 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.516332 step=0.003835 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.107097 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.507984 step=0.01535 g_raw=+0.007 g_sm=+0.016 acc=1 | LR→0.107312 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.506283 step=0.02021 g_raw=+0.008 g_sm=+0.014 acc=1 | LR→0.107527 PERT→0.100009 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1064559637, PERT_used=0.1000078992 → LR_next=0.1075273711, PERT_next=0.1000093009\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1064559637→0.1075273711 PERT 0.1000078992→0.1000093009\n",
            "Training Accuracy: 0.44\n",
            "Test Accuracy: 0.34\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.503928 step=0.002437 g_raw=+0.001 g_sm=+0.014 acc=1 | LR→0.107743 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.499477 step=0.01194 g_raw=+0.005 g_sm=+0.015 acc=1 | LR→0.107959 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.498331 step=0.001735 g_raw=-0.001 g_sm=+0.013 acc=1 | LR→0.108175 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.496377 step=0.0375 g_raw=+0.020 g_sm=+0.013 acc=1 | LR→0.108392 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.493169 step=0.05025 g_raw=+0.024 g_sm=+0.013 acc=1 | LR→0.108610 PERT→0.100011 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1075273711, PERT_used=0.1000093009 → LR_next=0.1086095384, PERT_next=0.1000106815\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1075273711→0.1086095384 PERT 0.1000093009→0.1000106815\n",
            "Training Accuracy: 0.52\n",
            "Test Accuracy: 0.41\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.492821 step=0.0223 g_raw=+0.011 g_sm=+0.011 acc=1 | LR→0.108827 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.491300 step=0.03648 g_raw=+0.018 g_sm=+0.011 acc=1 | LR→0.109045 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.489604 step=0.01918 g_raw=+0.010 g_sm=+0.011 acc=1 | LR→0.109264 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.488489 step=0.01953 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.109483 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.483999 step=0.05025 g_raw=+0.027 g_sm=+0.013 acc=1 | LR→0.109702 PERT→0.100012 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1086095384, PERT_used=0.1000106815 → LR_next=0.1097023167, PERT_next=0.1000118067\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1086095384→0.1097023167 PERT 0.1000106815→0.1000118067\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.55\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.479978 step=0.04457 g_raw=+0.023 g_sm=+0.014 acc=1 | LR→0.109922 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.478501 step=0.006949 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.110143 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.475714 step=0.05546 g_raw=+0.027 g_sm=+0.014 acc=1 | LR→0.110363 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.474354 step=0.043 g_raw=+0.021 g_sm=+0.013 acc=1 | LR→0.110585 PERT→0.100013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.471369 step=0.01073 g_raw=+0.006 g_sm=+0.013 acc=1 | LR→0.110806 PERT→0.100013 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1097023167, PERT_used=0.1000118067 → LR_next=0.1108062969, PERT_next=0.1000131187\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1097023167→0.1108062969 PERT 0.1000118067→0.1000131187\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.65\n",
            "[round 9 | client 3] final LR=0.1108062969, final PERT=0.1000131187  (ΔLR=+0.0054105140, ΔPERT=+0.0000060985)\n",
            "[round 9 | client 4] seed LR=0.1053947706 (prev=0.1107895412), seed PERT=0.1000061006 (prev=0.1000122013), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.523096 step=0.05566 g_raw=+0.028 g_sm=+0.004 acc=1 | LR→0.105606 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.519025 step=0.0813 g_raw=+0.043 g_sm=+0.007 acc=1 | LR→0.105817 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.515748 step=0.0495 g_raw=+0.026 g_sm=+0.009 acc=1 | LR→0.106029 PERT→0.100006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.507637 step=0.004456 g_raw=+0.003 g_sm=+0.012 acc=1 | LR→0.106242 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.505075 step=0.03133 g_raw=+0.017 g_sm=+0.012 acc=1 | LR→0.106455 PERT→0.100007 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1053947706, PERT_used=0.1000061006 → LR_next=0.1064548178, PERT_next=0.1000068636\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1053947706→0.1064548178 PERT 0.1000061006→0.1000068636\n",
            "Training Accuracy: 0.46\n",
            "Test Accuracy: 0.48\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.504274 step=0.009485 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.106668 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.502272 step=0.0425 g_raw=+0.022 g_sm=+0.012 acc=1 | LR→0.106882 PERT→0.100007 (scale=0.04)\n",
            "[meta] cb#040 loss=0.495329 step=0.08181 g_raw=+0.042 g_sm=+0.014 acc=1 | LR→0.107096 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.492537 step=0.0148 g_raw=+0.009 g_sm=+0.015 acc=1 | LR→0.107311 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.490547 step=0.012 g_raw=+0.006 g_sm=+0.014 acc=1 | LR→0.107526 PERT→0.100008 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1064548178, PERT_used=0.1000068636 → LR_next=0.1075260895, PERT_next=0.1000081499\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1064548178→0.1075260895 PERT 0.1000068636→0.1000081499\n",
            "Training Accuracy: 0.42\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.489303 step=0.01319 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.107742 PERT→0.100008 (scale=0.04)\n",
            "[meta] cb#060 loss=0.486562 step=0.0663 g_raw=+0.034 g_sm=+0.013 acc=1 | LR→0.107958 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.483187 step=0.05884 g_raw=+0.030 g_sm=+0.013 acc=1 | LR→0.108174 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.481136 step=0.04543 g_raw=+0.023 g_sm=+0.013 acc=1 | LR→0.108391 PERT→0.100009 (scale=0.04)\n",
            "[meta] cb#075 loss=0.475279 step=0.04658 g_raw=+0.022 g_sm=+0.015 acc=1 | LR→0.108608 PERT→0.100009 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1075260895, PERT_used=0.1000081499 → LR_next=0.1086081490, PERT_next=0.1000094430\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1075260895→0.1086081490 PERT 0.1000081499→0.1000094430\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.73\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.473611 step=0.003211 g_raw=+0.001 g_sm=+0.014 acc=1 | LR→0.108826 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.468410 step=0.03134 g_raw=+0.016 g_sm=+0.016 acc=1 | LR→0.109044 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#090 loss=0.463367 step=0.005718 g_raw=+0.002 g_sm=+0.016 acc=1 | LR→0.109263 PERT→0.100010 (scale=0.04)\n",
            "[meta] cb#095 loss=0.461483 step=0.03686 g_raw=+0.019 g_sm=+0.015 acc=1 | LR→0.109482 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.457156 step=0.08543 g_raw=+0.043 g_sm=+0.015 acc=1 | LR→0.109701 PERT→0.100011 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1086081490, PERT_used=0.1000094430 → LR_next=0.1097013025, PERT_next=0.1000109231\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1086081490→0.1097013025 PERT 0.1000094430→0.1000109231\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.78\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.454156 step=0.05029 g_raw=+0.024 g_sm=+0.015 acc=1 | LR→0.109921 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#110 loss=0.452507 step=0.03983 g_raw=+0.019 g_sm=+0.014 acc=1 | LR→0.110142 PERT→0.100011 (scale=0.04)\n",
            "[meta] cb#115 loss=0.444834 step=0.02915 g_raw=+0.014 g_sm=+0.016 acc=1 | LR→0.110362 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.437595 step=0.04939 g_raw=+0.024 g_sm=+0.018 acc=1 | LR→0.110584 PERT→0.100012 (scale=0.04)\n",
            "[meta] cb#125 loss=0.429897 step=0.01019 g_raw=+0.005 g_sm=+0.019 acc=1 | LR→0.110806 PERT→0.100013 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1097013025, PERT_used=0.1000109231 → LR_next=0.1108055931, PERT_next=0.1000125244\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1097013025→0.1108055931 PERT 0.1000109231→0.1000125244\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.84\n",
            "[round 9 | client 4] final LR=0.1108055931, final PERT=0.1000125244  (ΔLR=+0.0054108224, ΔPERT=+0.0000064238)\n",
            "\n",
            "[Round 9] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           1      0.562725      0.770000      0.110807      0.100014\n",
            "           0      0.564895      0.865000      0.110806      0.100013\n",
            "           4      0.574890      0.840000      0.110806      0.100013\n",
            "           2      0.616121      0.615000      0.110805      0.100012\n",
            "           3      0.664363      0.645000      0.110806      0.100013\n",
            "→ [Round 9] best_client=1, best_val=0.562725, prev_global_val=0.546064, improve=-0.016661, action=hold (τ=0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 10/10 [1:32:10<00:00, 553.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   9] acc_g=0.792 (μ=0.747, σ=0.101, FG=0.228) | t=533.792s, val=0.550 | TEL=FALSE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 650x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 650x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 650x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from training.loop import run_federated_training\n",
        "from configs.base_config import use_teleportation as CFG_TEL, noise_preset, shots_used,aggregation\n",
        "from training.metrics import metrics_init, metrics_log_round, metrics_finalize, compute_auc,metrics_summarize\n",
        "from viz.plots import plot_accuracy_curve, plot_val_loss, plot_time_per_round, plot_fidelity_vs_delta_acc, plot_beta_hist, plot_client_fairness_last_round\n",
        "# Initialize metrics store once\n",
        "metrics_store = metrics_init(\n",
        "    log_path=os.path.join(drive_root, \"teleport_metrics_Perturb_shrink.csv\")\n",
        ")\n",
        "\n",
        "#new\n",
        "from ml import optimizers as mlopt\n",
        "from configs.base_config import drive_root\n",
        "import os\n",
        "\n",
        "mlopt.meta_trace_enable(\n",
        "    path=os.path.join(drive_root, \"meta_trace.csv\"),  # or None to skip CSV\n",
        "    every=5                                           # print every 5 callbacks\n",
        ")\n",
        "\n",
        "###########\n",
        "global_acc, clients_train, clients_test, round_times, val_losses, info_last = run_federated_training(\n",
        "    clients=clients,\n",
        "    num_federated_layers=num_federated_layers,\n",
        "    num_deep_unfolding_iterations=num_deep_unfolding_iterations,\n",
        "    initial_learning_rate=initial_learning_rate,\n",
        "    initial_perturbation=initial_perturbation,\n",
        "    num_features=num_features,\n",
        "    best_client_csv_file=best_client_csv_file,\n",
        "    global_csv_file=global_csv_file,\n",
        "    local_csv_file=local_csv_file,\n",
        "    validation_csv_file=validation_csv_file,\n",
        "    test_sequences=test_sequences,\n",
        "    test_labels=test_labels,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    use_teleportation=CFG_TEL,          # ← important\n",
        "    noise_preset=noise_preset,\n",
        "    shots_used=shots_used,\n",
        "    metrics=metrics_store,   # <-- pass it in\n",
        "    aggregation=aggregation           # <--- switch here\n",
        ")\n",
        "\n",
        "rows_np = metrics_finalize(metrics_store)   # if you need the in-memory array\n",
        "#summary = metrics_summarize(metrics_store)  # prints a concise summary, returns a dict\n",
        "\n",
        "# quick visuals\n",
        "rounds = list(range(len(global_acc)))\n",
        "plot_accuracy_curve(rounds, global_acc, label=\"Global accuracy (DT-DUQFL)\")\n",
        "plot_val_loss(rounds, val_losses, label=\"Central validation loss\")\n",
        "plot_time_per_round(rounds, round_times)\n",
        "\n",
        "if info_last is not None:\n",
        "    # this uses \"last\" round's info; in your logger you kept per-round arrays; adapt if needed\n",
        "    pass\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}