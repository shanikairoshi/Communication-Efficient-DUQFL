{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shanikairoshi/Communication-Efficient-DUQFL/blob/main/main_v2_1.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bee84f36",
      "metadata": {
        "id": "bee84f36"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bc18ac0f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc18ac0f",
        "outputId": "535f5b7a-d2f0-4d95-a223-5b9f615f8bdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: genomic-benchmarks in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: biopython>=1.79 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (1.85)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (2.32.4)\n",
            "Requirement already satisfied: pip>=20.0.1 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (24.1.2)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (4.67.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (6.0.3)\n",
            "Requirement already satisfied: gdown>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (5.2.0)\n",
            "Requirement already satisfied: yarl in /usr/local/lib/python3.12/dist-packages (from genomic-benchmarks) (1.20.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown>=4.2.0->genomic-benchmarks) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown>=4.2.0->genomic-benchmarks) (3.19.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->genomic-benchmarks) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->genomic-benchmarks) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->genomic-benchmarks) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->genomic-benchmarks) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->genomic-benchmarks) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->genomic-benchmarks) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->genomic-benchmarks) (2025.8.3)\n",
            "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.12/dist-packages (from yarl->genomic-benchmarks) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from yarl->genomic-benchmarks) (0.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.4->genomic-benchmarks) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown>=4.2.0->genomic-benchmarks) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown>=4.2.0->genomic-benchmarks) (4.15.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=4.2.0->genomic-benchmarks) (1.7.1)\n",
            "Requirement already satisfied: qiskit in /usr/local/lib/python3.12/dist-packages (1.4.4)\n",
            "Requirement already satisfied: qiskit_machine_learning in /usr/local/lib/python3.12/dist-packages (0.8.4)\n",
            "Requirement already satisfied: qiskit_algorithms in /usr/local/lib/python3.12/dist-packages (0.4.0)\n",
            "Requirement already satisfied: qiskit-aer in /usr/local/lib/python3.12/dist-packages (0.17.2)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.17.1)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.12/dist-packages (from qiskit) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.12/dist-packages (from qiskit) (1.15.3)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.12/dist-packages (from qiskit) (1.13.3)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.3.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from qiskit) (2.9.0.post0)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from qiskit) (5.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qiskit) (4.15.0)\n",
            "Requirement already satisfied: symengine<0.14,>=0.11 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.13.0)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.12/dist-packages (from qiskit_machine_learning) (1.6.1)\n",
            "Requirement already satisfied: setuptools>=40.1 in /usr/local/lib/python3.12/dist-packages (from qiskit_machine_learning) (75.2.0)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.12/dist-packages (from qiskit-aer) (5.9.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->qiskit_machine_learning) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->qiskit_machine_learning) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# %%capture\n",
        "!pip install genomic-benchmarks\n",
        "!pip install qiskit qiskit_machine_learning qiskit_algorithms qiskit-aer\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2d53c335",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d53c335",
        "outputId": "534e7db6-15bc-48ae-f50d-4f7f84b880b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5291b3a7",
      "metadata": {
        "id": "5291b3a7"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "PROJ = Path.cwd() / \"tduqfl_Project_AGG\"\n",
        "if str(PROJ) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJ))\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Teleportation/tduqfl_Project_AGG/tDuQFL_Project')\n",
        "# ─── 5. Assemble filenames for each artifact ─────────────────────────────────\n",
        "#drive_root = \"/content/drive/MyDrive/Teleportation/tduqfl_Project_AGG/tDuQFL_Project/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c245a1fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c245a1fd",
        "outputId": "5eefac6f-ff8c-437f-a30f-fa76b5ed58b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/genomic_benchmarks/utils/datasets.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Python: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "Qiskit: 1.4.4\n",
            "qiskit_aer available?: True\n"
          ]
        }
      ],
      "source": [
        "from common.imports import *\n",
        "from configs.dataset_genome_iid import *     # swap to other configs as needed\n",
        "from io_utils.naming import stamp_now, flags, build_param_str, make_filenames\n",
        "\n",
        "start_str, date_str = stamp_now()\n",
        "teleport_pl, noise_pl = flags(use_teleportation, use_noise)\n",
        "param_str = build_param_str(num_clients, num_federated_layers, num_deep_unfolding_iterations,\n",
        "                            initial_learning_rate, initial_perturbation)\n",
        "\n",
        "best_client_csv_file, global_csv_file, local_csv_file, validation_csv_file = make_filenames(\n",
        "    drive_root, dataset_name, split_type, date_str, teleport_pl, noise_pl, param_str\n",
        ")\n",
        "from io_utils.csv_logger import init_local_csv, init_best_csv, init_validation_csv\n",
        "\n",
        "# Create folders + write headers\n",
        "init_best_csv(best_client_csv_file)\n",
        "\n",
        "local_headers = [\n",
        "    \"Federated Round\", \"Client Number\", \"Iteration\",\n",
        "    \"Objective Function Value\", \"Training Accuracy\", \"Test Accuracy\",\n",
        "    \"Learning Rate\", \"Perturbation\"\n",
        "]\n",
        "init_local_csv(local_csv_file, local_headers)\n",
        "\n",
        "init_validation_csv(validation_csv_file)\n",
        "\n",
        "# Do NOT pre-init global_csv_file here because your save_accuracies_to_csv()\n",
        "# already writes the header each time it runs (in 'w' mode)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "324178e0",
      "metadata": {
        "id": "324178e0"
      },
      "source": [
        "Load and Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d512e2a5",
      "metadata": {
        "id": "d512e2a5"
      },
      "outputs": [],
      "source": [
        "from data.preprocess_genome import load_and_prepare_dataset\n",
        "from data.splitters import split_dataset_for_epochs\n",
        "from configs.base_config import (\n",
        "    num_clients, num_epochs, samples_per_epoch, split_type,\n",
        "    global_seed\n",
        ")\n",
        "\n",
        "np_train_data, np_test_data = load_and_prepare_dataset(word_size, global_seed)\n",
        "\n",
        "# 2) Compute feasible epoch capacity and cap both epochs and rounds\n",
        "N_train = len(np_train_data)\n",
        "train_capacity = N_train // (num_clients * samples_per_epoch)\n",
        "num_epochs_eff = max(1, min(num_epochs, train_capacity))\n",
        "\n",
        "if train_capacity == 0:\n",
        "    raise ValueError(\n",
        "        f\"Not enough training samples ({N_train}) for \"\n",
        "        f\"{num_clients=} × {samples_per_epoch=} per epoch. \"\n",
        "        \"Reduce samples_per_epoch or num_clients, or enable resampling.\"\n",
        "    )\n",
        "\n",
        "num_federated_layers_eff = min(num_federated_layers, num_epochs_eff)\n",
        "\n",
        "# Build clients\n",
        "if split_type.lower() == \"iid\":\n",
        "    from data.splitters import split_dataset_for_epochs\n",
        "    clients = split_dataset_for_epochs(\n",
        "        num_clients=num_clients,\n",
        "        num_epochs=num_epochs_eff,             # or num_epochs\n",
        "        train_data=np_train_data,\n",
        "        test_data=np_test_data,\n",
        "        samples_per_epoch=samples_per_epoch,\n",
        "    )\n",
        "elif split_type.lower() in {\"noniid\", \"non-iid\", \"non_iid\"}:\n",
        "    from data.noniid import make_non_iid_clients\n",
        "    clients = make_non_iid_clients(\n",
        "        train_data=np_train_data,\n",
        "        test_data=np_test_data,\n",
        "        num_clients=num_clients,\n",
        "        num_epochs=num_epochs_eff,             # or num_epochs\n",
        "        samples_per_epoch=samples_per_epoch,\n",
        "        non_iid_ratio=0.8,                     # tune as needed\n",
        "        quantity_variation=0.5,                # tune as needed\n",
        "        seed=global_seed,\n",
        "        plot=True\n",
        "    )\n",
        "else:\n",
        "    raise ValueError(f\"Unknown split_type: {split_type}\")\n",
        "\n",
        "'''\n",
        "clients = split_dataset_for_epochs(\n",
        "    num_clients=num_clients, num_epochs=num_epochs,\n",
        "    train_data=np_train_data, test_data=np_test_data,\n",
        "    samples_per_epoch=samples_per_epoch\n",
        ")\n",
        "'''\n",
        "# validation/tables\n",
        "test_sequences = np.array([d[\"sequence\"] for d in np_test_data])\n",
        "test_labels    = np.array([d[\"label\"]    for d in np_test_data])\n",
        "X_val, y_val   = test_sequences, test_labels\n",
        "\n",
        "# derive num_features once\n",
        "if clients and clients[0].data and clients[0].data[0]:\n",
        "    num_features = clients[0].data[0][0]['sequence'].shape[0]\n",
        "else:\n",
        "    raise RuntimeError(\"Empty client data – check splitting indices.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cf7dd9c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf7dd9c0",
        "outputId": "5bd1b65b-3fbb-4eab-8ab7-4f4110b07fb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] num_features = 5\n"
          ]
        }
      ],
      "source": [
        "# Infer num_features from the first available sample in clients\n",
        "def infer_num_features_from_clients(clients):\n",
        "    for c in clients:\n",
        "        for epoch_data in c.data:              # list of samples for that epoch\n",
        "            if not epoch_data:\n",
        "                continue\n",
        "            sample = epoch_data[0]\n",
        "            if \"sequence\" in sample:           # your Genome pipeline\n",
        "                arr = np.asarray(sample[\"sequence\"])\n",
        "                return int(arr.size)\n",
        "            if \"features\" in sample:           # some other pipelines\n",
        "                arr = np.asarray(sample[\"features\"])\n",
        "                return int(arr.size)\n",
        "            if \"image\" in sample:              # e.g., MNIST before flatten\n",
        "                arr = np.asarray(sample[\"image\"]).reshape(-1)\n",
        "                return int(arr.size)\n",
        "            # add any other key you use\n",
        "    raise RuntimeError(\"Could not infer num_features: no samples found.\")\n",
        "\n",
        "num_features = infer_num_features_from_clients(clients)\n",
        "print(f\"[info] num_features = {num_features}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d847bd00",
      "metadata": {
        "id": "d847bd00"
      },
      "source": [
        "run federated loop and plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bbc26297",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bbc26297",
        "outputId": "5edb2b63-2825-44b8-90d9-f30a91b647af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 0] Teleportation OFF | Aggregation=best\n",
            "[round 0 | client 0] seed LR=0.1200000000 (prev=0.1200000000), seed PERT=0.1200000000 (prev=0.1200000000), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.479299 step=0.02947 g_raw=+0.014 g_sm=+0.002 acc=1 | LR→0.120240 PERT→0.120000 (scale=0.04)\n",
            "[meta] cb#010 loss=0.472118 step=0.0781 g_raw=+0.038 g_sm=+0.007 acc=1 | LR→0.120481 PERT→0.120000 (scale=0.04)\n",
            "[meta] cb#015 loss=0.468913 step=0.06626 g_raw=+0.029 g_sm=+0.009 acc=1 | LR→0.120722 PERT→0.120000 (scale=0.04)\n",
            "[meta] cb#020 loss=0.461321 step=0.05936 g_raw=+0.026 g_sm=+0.012 acc=1 | LR→0.120964 PERT→0.120001 (scale=0.04)\n",
            "[meta] cb#025 loss=0.457949 step=0.01423 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.121207 PERT→0.120001 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1200000000, PERT_used=0.1200000000 → LR_next=0.1212068865, PERT_next=0.1200008578\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1200000000→0.1212068865 PERT 0.1200000000→0.1200008578\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.455405 step=0.003089 g_raw=+0.001 g_sm=+0.011 acc=1 | LR→0.121450 PERT→0.120001 (scale=0.04)\n",
            "[meta] cb#035 loss=0.450428 step=0.00622 g_raw=+0.003 g_sm=+0.012 acc=1 | LR→0.121693 PERT→0.120001 (scale=0.04)\n",
            "[meta] cb#040 loss=0.444438 step=0.03753 g_raw=+0.017 g_sm=+0.014 acc=1 | LR→0.121937 PERT→0.120002 (scale=0.04)\n",
            "[meta] cb#045 loss=0.440830 step=0.04882 g_raw=+0.020 g_sm=+0.014 acc=1 | LR→0.122182 PERT→0.120002 (scale=0.04)\n",
            "[meta] cb#050 loss=0.437370 step=0.004641 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.122427 PERT→0.120002 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1212068865, PERT_used=0.1200008578 → LR_next=0.1224266405, PERT_next=0.1200024306\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1212068865→0.1224266405 PERT 0.1200008578→0.1200024306\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.432857 step=0.06282 g_raw=+0.028 g_sm=+0.014 acc=1 | LR→0.122672 PERT→0.120003 (scale=0.04)\n",
            "[meta] cb#060 loss=0.428927 step=0.01011 g_raw=+0.002 g_sm=+0.014 acc=1 | LR→0.122918 PERT→0.120003 (scale=0.04)\n",
            "[meta] cb#065 loss=0.425481 step=0.05694 g_raw=+0.023 g_sm=+0.015 acc=1 | LR→0.123164 PERT→0.120003 (scale=0.04)\n",
            "[meta] cb#070 loss=0.423788 step=0.01595 g_raw=+0.009 g_sm=+0.014 acc=1 | LR→0.123411 PERT→0.120004 (scale=0.04)\n",
            "[meta] cb#075 loss=0.421455 step=0.02172 g_raw=+0.010 g_sm=+0.014 acc=1 | LR→0.123659 PERT→0.120004 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1224266405, PERT_used=0.1200024306 → LR_next=0.1236588001, PERT_next=0.1200041302\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1224266405→0.1236588001 PERT 0.1200024306→0.1200041302\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.419711 step=0.05233 g_raw=+0.022 g_sm=+0.013 acc=1 | LR→0.123907 PERT→0.120004 (scale=0.04)\n",
            "[meta] cb#085 loss=0.417493 step=0.009937 g_raw=+0.005 g_sm=+0.012 acc=1 | LR→0.124155 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#090 loss=0.415355 step=0.03234 g_raw=+0.013 g_sm=+0.012 acc=1 | LR→0.124404 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#095 loss=0.411254 step=0.04676 g_raw=+0.019 g_sm=+0.012 acc=1 | LR→0.124653 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#100 loss=0.408092 step=0.02755 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.124903 PERT→0.120006 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1236588001, PERT_used=0.1200041302 → LR_next=0.1249031599, PERT_next=0.1200056370\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1236588001→0.1249031599 PERT 0.1200041302→0.1200056370\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.404894 step=0.04038 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.125154 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#110 loss=0.402536 step=0.02741 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.125404 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#115 loss=0.401775 step=0.03802 g_raw=+0.018 g_sm=+0.012 acc=1 | LR→0.125656 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#120 loss=0.401632 step=0.004495 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.125908 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#125 loss=0.398327 step=0.04717 g_raw=+0.020 g_sm=+0.011 acc=1 | LR→0.126160 PERT→0.120007 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1249031599, PERT_used=0.1200056370 → LR_next=0.1261599358, PERT_next=0.1200070431\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1249031599→0.1261599358 PERT 0.1200056370→0.1200070431\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.64\n",
            "[round 0 | client 0] final LR=0.1261599358, final PERT=0.1200070431  (ΔLR=+0.0061599358, ΔPERT=+0.0000070431)\n",
            "[round 0 | client 1] seed LR=0.1200000000 (prev=0.1200000000), seed PERT=0.1200000000 (prev=0.1200000000), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.464053 step=0.03009 g_raw=+0.014 g_sm=+0.003 acc=1 | LR→0.120240 PERT→0.120000 (scale=0.04)\n",
            "[meta] cb#010 loss=0.461043 step=0.05135 g_raw=+0.023 g_sm=+0.005 acc=1 | LR→0.120481 PERT→0.120000 (scale=0.04)\n",
            "[meta] cb#015 loss=0.459632 step=0.02213 g_raw=+0.010 g_sm=+0.006 acc=1 | LR→0.120722 PERT→0.120000 (scale=0.04)\n",
            "[meta] cb#020 loss=0.456330 step=0.03417 g_raw=+0.016 g_sm=+0.008 acc=1 | LR→0.120964 PERT→0.120000 (scale=0.04)\n",
            "[meta] cb#025 loss=0.452817 step=0.02906 g_raw=+0.013 g_sm=+0.010 acc=1 | LR→0.121207 PERT→0.120001 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1200000000, PERT_used=0.1200000000 → LR_next=0.1212067294, PERT_next=0.1200007023\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1200000000→0.1212067294 PERT 0.1200000000→0.1200007023\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.450778 step=0.009447 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.121450 PERT→0.120001 (scale=0.04)\n",
            "[meta] cb#035 loss=0.449003 step=0.04797 g_raw=+0.020 g_sm=+0.010 acc=1 | LR→0.121693 PERT→0.120001 (scale=0.04)\n",
            "[meta] cb#040 loss=0.447977 step=0.002703 g_raw=+0.001 g_sm=+0.010 acc=1 | LR→0.121937 PERT→0.120001 (scale=0.04)\n",
            "[meta] cb#045 loss=0.444883 step=0.0403 g_raw=+0.019 g_sm=+0.010 acc=1 | LR→0.122181 PERT→0.120002 (scale=0.04)\n",
            "[meta] cb#050 loss=0.443879 step=0.009414 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.122426 PERT→0.120002 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1212067294, PERT_used=0.1200007023 → LR_next=0.1224261033, PERT_next=0.1200019040\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1212067294→0.1224261033 PERT 0.1200007023→0.1200019040\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.441880 step=0.02606 g_raw=+0.010 g_sm=+0.010 acc=1 | LR→0.122671 PERT→0.120002 (scale=0.04)\n",
            "[meta] cb#060 loss=0.440599 step=0.03868 g_raw=+0.015 g_sm=+0.010 acc=1 | LR→0.122917 PERT→0.120002 (scale=0.04)\n",
            "[meta] cb#065 loss=0.436230 step=0.07077 g_raw=+0.029 g_sm=+0.012 acc=1 | LR→0.123164 PERT→0.120003 (scale=0.04)\n",
            "[meta] cb#070 loss=0.432996 step=0.03183 g_raw=+0.015 g_sm=+0.012 acc=1 | LR→0.123411 PERT→0.120003 (scale=0.04)\n",
            "[meta] cb#075 loss=0.431314 step=0.005495 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.123658 PERT→0.120003 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1224261033, PERT_used=0.1200019040 → LR_next=0.1236578739, PERT_next=0.1200032315\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1224261033→0.1236578739 PERT 0.1200019040→0.1200032315\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.74\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.429170 step=0.02211 g_raw=+0.010 g_sm=+0.012 acc=1 | LR→0.123906 PERT→0.120004 (scale=0.04)\n",
            "[meta] cb#085 loss=0.426309 step=0.03439 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.124154 PERT→0.120004 (scale=0.04)\n",
            "[meta] cb#090 loss=0.424767 step=0.02164 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.124403 PERT→0.120004 (scale=0.04)\n",
            "[meta] cb#095 loss=0.423582 step=0.002319 g_raw=-0.000 g_sm=+0.011 acc=1 | LR→0.124652 PERT→0.120004 (scale=0.04)\n",
            "[meta] cb#100 loss=0.419864 step=0.04444 g_raw=+0.018 g_sm=+0.013 acc=1 | LR→0.124902 PERT→0.120005 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1236578739, PERT_used=0.1200032315 → LR_next=0.1249021780, PERT_next=0.1200046935\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1236578739→0.1249021780 PERT 0.1200032315→0.1200046935\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.77\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.419506 step=0.008641 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.125153 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#110 loss=0.419021 step=0.007423 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.125403 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#115 loss=0.417917 step=0.003005 g_raw=+0.001 g_sm=+0.009 acc=1 | LR→0.125655 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#120 loss=0.417486 step=0.02469 g_raw=+0.010 g_sm=+0.008 acc=1 | LR→0.125906 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#125 loss=0.416555 step=0.02961 g_raw=+0.012 g_sm=+0.008 acc=1 | LR→0.126159 PERT→0.120006 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1249021780, PERT_used=0.1200046935 → LR_next=0.1261586651, PERT_next=0.1200058344\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.006 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1249021780→0.1261586651 PERT 0.1200046935→0.1200058344\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.76\n",
            "[round 0 | client 1] final LR=0.1261586651, final PERT=0.1200058344  (ΔLR=+0.0061586651, ΔPERT=+0.0000058344)\n",
            "[round 0 | client 2] seed LR=0.1200000000 (prev=0.1200000000), seed PERT=0.1200000000 (prev=0.1200000000), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.501104 step=0.02958 g_raw=+0.012 g_sm=+0.004 acc=1 | LR→0.120240 PERT→0.120000 (scale=0.04)\n",
            "[meta] cb#010 loss=0.482577 step=0.01171 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.120481 PERT→0.120000 (scale=0.04)\n",
            "[meta] cb#015 loss=0.474630 step=0.08995 g_raw=+0.036 g_sm=+0.013 acc=1 | LR→0.120723 PERT→0.120001 (scale=0.04)\n",
            "[meta] cb#020 loss=0.465550 step=0.04084 g_raw=+0.018 g_sm=+0.016 acc=1 | LR→0.120965 PERT→0.120001 (scale=0.04)\n",
            "[meta] cb#025 loss=0.463937 step=0.01499 g_raw=+0.006 g_sm=+0.014 acc=1 | LR→0.121207 PERT→0.120001 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1200000000, PERT_used=0.1200000000 → LR_next=0.1212072934, PERT_next=0.1200012606\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1200000000→0.1212072934 PERT 0.1200000000→0.1200012606\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.455875 step=0.04944 g_raw=+0.023 g_sm=+0.017 acc=1 | LR→0.121450 PERT→0.120002 (scale=0.04)\n",
            "[meta] cb#035 loss=0.453312 step=0.03402 g_raw=+0.014 g_sm=+0.016 acc=1 | LR→0.121694 PERT→0.120002 (scale=0.04)\n",
            "[meta] cb#040 loss=0.443387 step=0.07682 g_raw=+0.032 g_sm=+0.018 acc=1 | LR→0.121938 PERT→0.120002 (scale=0.04)\n",
            "[meta] cb#045 loss=0.436654 step=0.08159 g_raw=+0.029 g_sm=+0.019 acc=1 | LR→0.122182 PERT→0.120003 (scale=0.04)\n",
            "[meta] cb#050 loss=0.433318 step=0.01921 g_raw=+0.007 g_sm=+0.018 acc=1 | LR→0.122428 PERT→0.120003 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1212072934, PERT_used=0.1200012606 → LR_next=0.1224275242, PERT_next=0.1200032968\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1212072934→0.1224275242 PERT 0.1200012606→0.1200032968\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.428918 step=0.008592 g_raw=+0.002 g_sm=+0.017 acc=1 | LR→0.122673 PERT→0.120004 (scale=0.04)\n",
            "[meta] cb#060 loss=0.423107 step=0.02713 g_raw=+0.013 g_sm=+0.017 acc=1 | LR→0.122919 PERT→0.120004 (scale=0.04)\n",
            "[meta] cb#065 loss=0.420783 step=0.03538 g_raw=+0.012 g_sm=+0.016 acc=1 | LR→0.123166 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#070 loss=0.414605 step=0.0004536 g_raw=+0.001 g_sm=+0.016 acc=1 | LR→0.123413 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#075 loss=0.412902 step=0.03867 g_raw=+0.016 g_sm=+0.014 acc=1 | LR→0.123660 PERT→0.120005 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1224275242, PERT_used=0.1200032968 → LR_next=0.1236599839, PERT_next=0.1200052790\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1224275242→0.1236599839 PERT 0.1200032968→0.1200052790\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.409051 step=0.07424 g_raw=+0.031 g_sm=+0.015 acc=1 | LR→0.123908 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#085 loss=0.406577 step=0.03186 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.124156 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#090 loss=0.402946 step=0.06656 g_raw=+0.029 g_sm=+0.015 acc=1 | LR→0.124405 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#095 loss=0.401833 step=0.04327 g_raw=+0.020 g_sm=+0.013 acc=1 | LR→0.124655 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#100 loss=0.398216 step=0.06463 g_raw=+0.026 g_sm=+0.014 acc=1 | LR→0.124905 PERT→0.120007 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1236599839, PERT_used=0.1200052790 → LR_next=0.1249045101, PERT_next=0.1200069342\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1236599839→0.1249045101 PERT 0.1200052790→0.1200069342\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.397223 step=0.005931 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.125155 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#110 loss=0.395947 step=0.04619 g_raw=+0.016 g_sm=+0.012 acc=1 | LR→0.125406 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#115 loss=0.393651 step=0.06785 g_raw=+0.028 g_sm=+0.011 acc=1 | LR→0.125657 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#120 loss=0.391370 step=0.03369 g_raw=+0.013 g_sm=+0.012 acc=1 | LR→0.125909 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#125 loss=0.389716 step=0.03459 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.126161 PERT→0.120008 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1249045101, PERT_used=0.1200069342 → LR_next=0.1261612901, PERT_next=0.1200083314\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1249045101→0.1261612901 PERT 0.1200069342→0.1200083314\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.70\n",
            "[round 0 | client 2] final LR=0.1261612901, final PERT=0.1200083314  (ΔLR=+0.0061612901, ΔPERT=+0.0000083314)\n",
            "[round 0 | client 3] seed LR=0.1200000000 (prev=0.1200000000), seed PERT=0.1200000000 (prev=0.1200000000), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.535789 step=0.01156 g_raw=+0.005 g_sm=+0.001 acc=1 | LR→0.120240 PERT→0.120000 (scale=0.04)\n",
            "[meta] cb#010 loss=0.529408 step=0.04326 g_raw=+0.019 g_sm=+0.005 acc=1 | LR→0.120481 PERT→0.120000 (scale=0.04)\n",
            "[meta] cb#015 loss=0.523733 step=0.003666 g_raw=+0.002 g_sm=+0.008 acc=1 | LR→0.120722 PERT→0.120000 (scale=0.04)\n",
            "[meta] cb#020 loss=0.519023 step=0.07679 g_raw=+0.033 g_sm=+0.011 acc=1 | LR→0.120964 PERT→0.120000 (scale=0.04)\n",
            "[meta] cb#025 loss=0.513700 step=0.03194 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.121207 PERT→0.120001 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1200000000, PERT_used=0.1200000000 → LR_next=0.1212068106, PERT_next=0.1200007827\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1200000000→0.1212068106 PERT 0.1200000000→0.1200007827\n",
            "Training Accuracy: 0.50\n",
            "Test Accuracy: 0.63\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.512159 step=0.03674 g_raw=+0.015 g_sm=+0.012 acc=1 | LR→0.121450 PERT→0.120001 (scale=0.04)\n",
            "[meta] cb#035 loss=0.505960 step=0.04189 g_raw=+0.017 g_sm=+0.013 acc=1 | LR→0.121693 PERT→0.120001 (scale=0.04)\n",
            "[meta] cb#040 loss=0.500906 step=0.02382 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.121937 PERT→0.120002 (scale=0.04)\n",
            "[meta] cb#045 loss=0.495433 step=0.05885 g_raw=+0.025 g_sm=+0.015 acc=1 | LR→0.122182 PERT→0.120002 (scale=0.04)\n",
            "[meta] cb#050 loss=0.493031 step=0.03139 g_raw=+0.015 g_sm=+0.014 acc=1 | LR→0.122427 PERT→0.120002 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1212068106, PERT_used=0.1200007827 → LR_next=0.1224266203, PERT_next=0.1200024108\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1212068106→0.1224266203 PERT 0.1200007827→0.1200024108\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.65\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.490034 step=0.06714 g_raw=+0.028 g_sm=+0.014 acc=1 | LR→0.122672 PERT→0.120003 (scale=0.04)\n",
            "[meta] cb#060 loss=0.485277 step=0.009599 g_raw=+0.004 g_sm=+0.014 acc=1 | LR→0.122918 PERT→0.120003 (scale=0.04)\n",
            "[meta] cb#065 loss=0.481879 step=0.06306 g_raw=+0.029 g_sm=+0.015 acc=1 | LR→0.123164 PERT→0.120003 (scale=0.04)\n",
            "[meta] cb#070 loss=0.480278 step=0.05575 g_raw=+0.025 g_sm=+0.014 acc=1 | LR→0.123411 PERT→0.120004 (scale=0.04)\n",
            "[meta] cb#075 loss=0.477568 step=0.05123 g_raw=+0.025 g_sm=+0.014 acc=1 | LR→0.123659 PERT→0.120004 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1224266203, PERT_used=0.1200024108 → LR_next=0.1236587441, PERT_next=0.1200040759\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1224266203→0.1236587441 PERT 0.1200024108→0.1200040759\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.475645 step=0.003175 g_raw=+0.004 g_sm=+0.013 acc=1 | LR→0.123907 PERT→0.120004 (scale=0.04)\n",
            "[meta] cb#085 loss=0.473800 step=0.02277 g_raw=+0.008 g_sm=+0.013 acc=1 | LR→0.124155 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#090 loss=0.471128 step=0.02962 g_raw=+0.014 g_sm=+0.013 acc=1 | LR→0.124404 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#095 loss=0.468063 step=0.03539 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.124653 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#100 loss=0.466289 step=0.02015 g_raw=+0.008 g_sm=+0.013 acc=1 | LR→0.124903 PERT→0.120006 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1236587441, PERT_used=0.1200040759 → LR_next=0.1249031844, PERT_next=0.1200056605\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1236587441→0.1249031844 PERT 0.1200040759→0.1200056605\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.464818 step=0.02989 g_raw=+0.013 g_sm=+0.012 acc=1 | LR→0.125154 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#110 loss=0.461279 step=0.06577 g_raw=+0.030 g_sm=+0.013 acc=1 | LR→0.125404 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#115 loss=0.460249 step=0.03476 g_raw=+0.014 g_sm=+0.012 acc=1 | LR→0.125656 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#120 loss=0.458944 step=0.01778 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.125908 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#125 loss=0.457743 step=0.01838 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.126160 PERT→0.120007 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1249031844, PERT_used=0.1200056605 → LR_next=0.1261599617, PERT_next=0.1200070678\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1249031844→0.1261599617 PERT 0.1200056605→0.1200070678\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.75\n",
            "[round 0 | client 3] final LR=0.1261599617, final PERT=0.1200070678  (ΔLR=+0.0061599617, ΔPERT=+0.0000070678)\n",
            "[round 0 | client 4] seed LR=0.1200000000 (prev=0.1200000000), seed PERT=0.1200000000 (prev=0.1200000000), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.503315 step=0.01787 g_raw=+0.010 g_sm=+0.003 acc=1 | LR→0.120240 PERT→0.120000 (scale=0.04)\n",
            "[meta] cb#010 loss=0.500345 step=0.001701 g_raw=-0.000 g_sm=+0.005 acc=1 | LR→0.120481 PERT→0.120000 (scale=0.04)\n",
            "[meta] cb#015 loss=0.499622 step=0.02956 g_raw=+0.013 g_sm=+0.005 acc=1 | LR→0.120722 PERT→0.120000 (scale=0.04)\n",
            "[meta] cb#020 loss=0.493640 step=0.05934 g_raw=+0.027 g_sm=+0.009 acc=1 | LR→0.120964 PERT→0.120000 (scale=0.04)\n",
            "[meta] cb#025 loss=0.485594 step=0.04555 g_raw=+0.021 g_sm=+0.012 acc=1 | LR→0.121207 PERT→0.120001 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1200000000, PERT_used=0.1200000000 → LR_next=0.1212067039, PERT_next=0.1200006770\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1200000000→0.1212067039 PERT 0.1200000000→0.1200006770\n",
            "Training Accuracy: 0.54\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.475730 step=0.03109 g_raw=+0.013 g_sm=+0.016 acc=1 | LR→0.121450 PERT→0.120001 (scale=0.04)\n",
            "[meta] cb#035 loss=0.467867 step=0.07168 g_raw=+0.030 g_sm=+0.018 acc=1 | LR→0.121693 PERT→0.120001 (scale=0.04)\n",
            "[meta] cb#040 loss=0.464402 step=0.01674 g_raw=+0.006 g_sm=+0.017 acc=1 | LR→0.121937 PERT→0.120002 (scale=0.04)\n",
            "[meta] cb#045 loss=0.458521 step=0.01334 g_raw=+0.006 g_sm=+0.017 acc=1 | LR→0.122182 PERT→0.120002 (scale=0.04)\n",
            "[meta] cb#050 loss=0.456572 step=0.03159 g_raw=+0.014 g_sm=+0.015 acc=1 | LR→0.122427 PERT→0.120003 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1212067039, PERT_used=0.1200006770 → LR_next=0.1224268651, PERT_next=0.1200026507\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1212067039→0.1224268651 PERT 0.1200006770→0.1200026507\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.450096 step=0.05048 g_raw=+0.022 g_sm=+0.017 acc=1 | LR→0.122672 PERT→0.120003 (scale=0.04)\n",
            "[meta] cb#060 loss=0.441597 step=0.02946 g_raw=+0.011 g_sm=+0.018 acc=1 | LR→0.122918 PERT→0.120003 (scale=0.04)\n",
            "[meta] cb#065 loss=0.434037 step=0.1013 g_raw=+0.046 g_sm=+0.019 acc=1 | LR→0.123165 PERT→0.120004 (scale=0.04)\n",
            "[meta] cb#070 loss=0.430367 step=0.01103 g_raw=+0.005 g_sm=+0.018 acc=1 | LR→0.123412 PERT→0.120004 (scale=0.04)\n",
            "[meta] cb#075 loss=0.423405 step=0.09322 g_raw=+0.040 g_sm=+0.019 acc=1 | LR→0.123659 PERT→0.120005 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1224268651, PERT_used=0.1200026507 → LR_next=0.1236594994, PERT_next=0.1200048088\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1224268651→0.1236594994 PERT 0.1200026507→0.1200048088\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.419043 step=0.02702 g_raw=+0.012 g_sm=+0.019 acc=1 | LR→0.123908 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#085 loss=0.410725 step=0.05541 g_raw=+0.024 g_sm=+0.020 acc=1 | LR→0.124156 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#090 loss=0.409384 step=0.01304 g_raw=+0.008 g_sm=+0.017 acc=1 | LR→0.124405 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#095 loss=0.399322 step=0.03909 g_raw=+0.017 g_sm=+0.019 acc=1 | LR→0.124655 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#100 loss=0.398071 step=0.03974 g_raw=+0.016 g_sm=+0.017 acc=1 | LR→0.124905 PERT→0.120007 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1236594994, PERT_used=0.1200048088 → LR_next=0.1249046096, PERT_next=0.1200070298\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1236594994→0.1249046096 PERT 0.1200048088→0.1200070298\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.394453 step=0.03182 g_raw=+0.014 g_sm=+0.016 acc=1 | LR→0.125155 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#110 loss=0.390973 step=0.01277 g_raw=+0.005 g_sm=+0.015 acc=1 | LR→0.125406 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#115 loss=0.389054 step=0.01043 g_raw=+0.005 g_sm=+0.014 acc=1 | LR→0.125657 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#120 loss=0.386795 step=0.03392 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.125909 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#125 loss=0.383623 step=0.04874 g_raw=+0.020 g_sm=+0.014 acc=1 | LR→0.126162 PERT→0.120009 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1249046096, PERT_used=0.1200070298 → LR_next=0.1261617699, PERT_next=0.1200087878\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1249046096→0.1261617699 PERT 0.1200070298→0.1200087878\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.69\n",
            "[round 0 | client 4] final LR=0.1261617699, final PERT=0.1200087878  (ΔLR=+0.0061617699, ΔPERT=+0.0000087878)\n",
            "\n",
            "[Round 0] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           1      0.541809      0.760000      0.126159      0.120006\n",
            "           4      0.560145      0.690000      0.126162      0.120009\n",
            "           0      0.568239      0.640000      0.126160      0.120007\n",
            "           2      0.582693      0.700000      0.126161      0.120008\n",
            "           3      0.605432      0.750000      0.126160      0.120007\n",
            "→ [Round 0] action=init_from_best, best_client=1, best_val=0.541809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  10%|█         | 1/10 [09:28<1:25:19, 568.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   0] acc_g=0.723 (μ=0.708, σ=0.044, FG=0.096) | t=558.387s, val=0.542 | TEL=FALSE\n",
            "[Round 1] Teleportation OFF | Aggregation=best\n",
            "[round 1 | client 0] seed LR=0.1230799679 (prev=0.1261599358), seed PERT=0.1200035216 (prev=0.1200070431), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.458804 step=0.05755 g_raw=+0.024 g_sm=+0.004 acc=1 | LR→0.123326 PERT→0.120004 (scale=0.04)\n",
            "[meta] cb#010 loss=0.455930 step=0.009914 g_raw=+0.006 g_sm=+0.006 acc=1 | LR→0.123573 PERT→0.120004 (scale=0.04)\n",
            "[meta] cb#015 loss=0.449429 step=0.07883 g_raw=+0.032 g_sm=+0.009 acc=1 | LR→0.123821 PERT→0.120004 (scale=0.04)\n",
            "[meta] cb#020 loss=0.441075 step=0.05803 g_raw=+0.023 g_sm=+0.012 acc=1 | LR→0.124069 PERT→0.120004 (scale=0.04)\n",
            "[meta] cb#025 loss=0.440189 step=0.03652 g_raw=+0.016 g_sm=+0.011 acc=1 | LR→0.124318 PERT→0.120004 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1230799679, PERT_used=0.1200035216 → LR_next=0.1243178376, PERT_next=0.1200043860\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1230799679→0.1243178376 PERT 0.1200035216→0.1200043860\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.430226 step=0.1085 g_raw=+0.048 g_sm=+0.014 acc=1 | LR→0.124567 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#035 loss=0.428493 step=0.02009 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.124817 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#040 loss=0.426537 step=0.03221 g_raw=+0.014 g_sm=+0.013 acc=1 | LR→0.125067 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#045 loss=0.421430 step=0.02868 g_raw=+0.012 g_sm=+0.014 acc=1 | LR→0.125318 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#050 loss=0.419390 step=0.01929 g_raw=+0.008 g_sm=+0.013 acc=1 | LR→0.125569 PERT→0.120006 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1243178376, PERT_used=0.1200043860 → LR_next=0.1255689040, PERT_next=0.1200059641\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1243178376→0.1255689040 PERT 0.1200043860→0.1200059641\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.416153 step=0.04923 g_raw=+0.021 g_sm=+0.014 acc=1 | LR→0.125821 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#060 loss=0.415008 step=0.02241 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.126073 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#065 loss=0.412537 step=0.01471 g_raw=+0.004 g_sm=+0.013 acc=1 | LR→0.126326 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#070 loss=0.409524 step=0.01629 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.126579 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#075 loss=0.407952 step=0.004211 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.126832 PERT→0.120007 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1255689040, PERT_used=0.1200059641 → LR_next=0.1268324873, PERT_next=0.1200074731\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1255689040→0.1268324873 PERT 0.1200059641→0.1200074731\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.405703 step=0.03649 g_raw=+0.017 g_sm=+0.011 acc=1 | LR→0.127087 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#085 loss=0.404126 step=3.987e-05 g_raw=-0.001 g_sm=+0.011 acc=1 | LR→0.127341 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#090 loss=0.402442 step=0.001328 g_raw=-0.001 g_sm=+0.010 acc=1 | LR→0.127597 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#095 loss=0.396738 step=0.0273 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.127852 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#100 loss=0.394574 step=0.01372 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.128109 PERT→0.120009 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1268324873, PERT_used=0.1200074731 → LR_next=0.1281085841, PERT_next=0.1200087932\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1268324873→0.1281085841 PERT 0.1200074731→0.1200087932\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.393498 step=0.01954 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.128365 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#110 loss=0.391035 step=0.02084 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.128623 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#115 loss=0.388116 step=0.05954 g_raw=+0.025 g_sm=+0.012 acc=1 | LR→0.128880 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#120 loss=0.385350 step=0.03212 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.129139 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#125 loss=0.380349 step=0.001374 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.129398 PERT→0.120010 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1281085841, PERT_used=0.1200087932 → LR_next=0.1293975902, PERT_next=0.1200101783\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1281085841→0.1293975902 PERT 0.1200087932→0.1200101783\n",
            "Training Accuracy: 0.90\n",
            "Test Accuracy: 0.71\n",
            "[round 1 | client 0] final LR=0.1293975902, final PERT=0.1200101783  (ΔLR=+0.0063176223, ΔPERT=+0.0000066567)\n",
            "[round 1 | client 1] seed LR=0.1230793326 (prev=0.1261586651), seed PERT=0.1200029172 (prev=0.1200058344), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.519336 step=0.0491 g_raw=+0.020 g_sm=+0.003 acc=1 | LR→0.123326 PERT→0.120003 (scale=0.04)\n",
            "[meta] cb#010 loss=0.513407 step=0.07191 g_raw=+0.032 g_sm=+0.008 acc=1 | LR→0.123573 PERT→0.120003 (scale=0.04)\n",
            "[meta] cb#015 loss=0.511186 step=0.009361 g_raw=+0.003 g_sm=+0.008 acc=1 | LR→0.123820 PERT→0.120003 (scale=0.04)\n",
            "[meta] cb#020 loss=0.501899 step=0.1071 g_raw=+0.048 g_sm=+0.012 acc=1 | LR→0.124069 PERT→0.120004 (scale=0.04)\n",
            "[meta] cb#025 loss=0.496804 step=0.003284 g_raw=+0.002 g_sm=+0.014 acc=1 | LR→0.124317 PERT→0.120004 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1230793326, PERT_used=0.1200029172 → LR_next=0.1243172669, PERT_next=0.1200038501\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1230793326→0.1243172669 PERT 0.1200029172→0.1200038501\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.486576 step=0.05034 g_raw=+0.023 g_sm=+0.016 acc=1 | LR→0.124567 PERT→0.120004 (scale=0.04)\n",
            "[meta] cb#035 loss=0.485654 step=0.007083 g_raw=+0.002 g_sm=+0.014 acc=1 | LR→0.124816 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#040 loss=0.472217 step=0.1188 g_raw=+0.052 g_sm=+0.018 acc=1 | LR→0.125067 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#045 loss=0.459569 step=0.04782 g_raw=+0.021 g_sm=+0.021 acc=1 | LR→0.125318 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#050 loss=0.452559 step=0.004439 g_raw=+0.002 g_sm=+0.021 acc=1 | LR→0.125569 PERT→0.120006 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1243172669, PERT_used=0.1200038501 → LR_next=0.1255689238, PERT_next=0.1200059982\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.023 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1243172669→0.1255689238 PERT 0.1200038501→0.1200059982\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.445020 step=0.008674 g_raw=+0.001 g_sm=+0.020 acc=1 | LR→0.125821 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#060 loss=0.427766 step=0.07162 g_raw=+0.033 g_sm=+0.023 acc=1 | LR→0.126073 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#065 loss=0.417542 step=0.01794 g_raw=+0.006 g_sm=+0.024 acc=1 | LR→0.126326 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#070 loss=0.415056 step=0.02111 g_raw=+0.010 g_sm=+0.022 acc=1 | LR→0.126580 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#075 loss=0.412624 step=0.02269 g_raw=+0.009 g_sm=+0.019 acc=1 | LR→0.126834 PERT→0.120009 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1255689238, PERT_used=0.1200059982 → LR_next=0.1268336857, PERT_next=0.1200086221\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.022 acc_ratio=1.00 | LR 0.1255689238→0.1268336857 PERT 0.1200059982→0.1200086221\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.405143 step=0.01148 g_raw=+0.005 g_sm=+0.020 acc=1 | LR→0.127088 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#085 loss=0.398527 step=0.02154 g_raw=+0.008 g_sm=+0.019 acc=1 | LR→0.127343 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#090 loss=0.391064 step=0.04021 g_raw=+0.017 g_sm=+0.019 acc=1 | LR→0.127599 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#095 loss=0.387521 step=0.02628 g_raw=+0.014 g_sm=+0.018 acc=1 | LR→0.127854 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.382438 step=0.03945 g_raw=+0.015 g_sm=+0.018 acc=1 | LR→0.128111 PERT→0.120011 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1268336857, PERT_used=0.1200086221 → LR_next=0.1281108631, PERT_next=0.1200109432\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.019 acc_ratio=1.00 | LR 0.1268336857→0.1281108631 PERT 0.1200086221→0.1200109432\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.380428 step=0.006674 g_raw=+0.003 g_sm=+0.016 acc=1 | LR→0.128368 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#110 loss=0.373985 step=0.0665 g_raw=+0.026 g_sm=+0.017 acc=1 | LR→0.128625 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.372482 step=0.03383 g_raw=+0.013 g_sm=+0.015 acc=1 | LR→0.128883 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.367139 step=0.07328 g_raw=+0.031 g_sm=+0.016 acc=1 | LR→0.129142 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#125 loss=0.363080 step=0.0194 g_raw=+0.007 g_sm=+0.016 acc=1 | LR→0.129400 PERT→0.120013 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1281108631, PERT_used=0.1200109432 → LR_next=0.1294004670, PERT_next=0.1200128615\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1281108631→0.1294004670 PERT 0.1200109432→0.1200128615\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.73\n",
            "[round 1 | client 1] final LR=0.1294004670, final PERT=0.1200128615  (ΔLR=+0.0063211345, ΔPERT=+0.0000099443)\n",
            "[round 1 | client 2] seed LR=0.1230806450 (prev=0.1261612901), seed PERT=0.1200041657 (prev=0.1200083314), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.510842 step=0.02886 g_raw=+0.014 g_sm=+0.002 acc=1 | LR→0.123327 PERT→0.120004 (scale=0.04)\n",
            "[meta] cb#010 loss=0.504324 step=0.03434 g_raw=+0.015 g_sm=+0.007 acc=1 | LR→0.123574 PERT→0.120004 (scale=0.04)\n",
            "[meta] cb#015 loss=0.501605 step=0.02209 g_raw=+0.010 g_sm=+0.008 acc=1 | LR→0.123822 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#020 loss=0.496910 step=0.04072 g_raw=+0.017 g_sm=+0.010 acc=1 | LR→0.124070 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#025 loss=0.494651 step=0.01133 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.124318 PERT→0.120005 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1230806450, PERT_used=0.1200041657 → LR_next=0.1243184912, PERT_next=0.1200050007\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1230806450→0.1243184912 PERT 0.1200041657→0.1200050007\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.490762 step=0.02051 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.124568 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#035 loss=0.487607 step=0.01183 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.124817 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#040 loss=0.484773 step=0.02734 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.125068 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#045 loss=0.482693 step=0.0306 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.125318 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#050 loss=0.476827 step=0.01488 g_raw=+0.006 g_sm=+0.013 acc=1 | LR→0.125569 PERT→0.120007 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1243184912, PERT_used=0.1200050007 → LR_next=0.1255694924, PERT_next=0.1200065104\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1243184912→0.1255694924 PERT 0.1200050007→0.1200065104\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.58\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.469926 step=0.06801 g_raw=+0.028 g_sm=+0.015 acc=1 | LR→0.125821 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#060 loss=0.460991 step=0.04452 g_raw=+0.017 g_sm=+0.017 acc=1 | LR→0.126074 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#065 loss=0.453616 step=0.1055 g_raw=+0.045 g_sm=+0.017 acc=1 | LR→0.126326 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#070 loss=0.449556 step=0.07132 g_raw=+0.031 g_sm=+0.017 acc=1 | LR→0.126580 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#075 loss=0.443074 step=0.02383 g_raw=+0.009 g_sm=+0.017 acc=1 | LR→0.126834 PERT→0.120008 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1255694924, PERT_used=0.1200065104 → LR_next=0.1268335517, PERT_next=0.1200084642\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1255694924→0.1268335517 PERT 0.1200065104→0.1200084642\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.62\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.430300 step=0.103 g_raw=+0.046 g_sm=+0.020 acc=1 | LR→0.127088 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#085 loss=0.428423 step=0.01024 g_raw=+0.003 g_sm=+0.018 acc=1 | LR→0.127343 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#090 loss=0.424965 step=0.01337 g_raw=+0.007 g_sm=+0.016 acc=1 | LR→0.127598 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#095 loss=0.418452 step=0.08091 g_raw=+0.034 g_sm=+0.018 acc=1 | LR→0.127854 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#100 loss=0.409785 step=0.02394 g_raw=+0.011 g_sm=+0.019 acc=1 | LR→0.128111 PERT→0.120011 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1268335517, PERT_used=0.1200084642 → LR_next=0.1281105475, PERT_next=0.1200106164\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.018 acc_ratio=1.00 | LR 0.1268335517→0.1281105475 PERT 0.1200084642→0.1200106164\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.406146 step=0.08135 g_raw=+0.033 g_sm=+0.017 acc=1 | LR→0.128367 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#110 loss=0.405188 step=0.01965 g_raw=+0.011 g_sm=+0.015 acc=1 | LR→0.128625 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#115 loss=0.402807 step=0.03099 g_raw=+0.012 g_sm=+0.014 acc=1 | LR→0.128883 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.399183 step=0.01714 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.129141 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#125 loss=0.396984 step=0.05322 g_raw=+0.021 g_sm=+0.014 acc=1 | LR→0.129400 PERT→0.120012 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1281105475, PERT_used=0.1200106164 → LR_next=0.1294000454, PERT_next=0.1200124392\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1281105475→0.1294000454 PERT 0.1200106164→0.1200124392\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.64\n",
            "[round 1 | client 2] final LR=0.1294000454, final PERT=0.1200124392  (ΔLR=+0.0063194003, ΔPERT=+0.0000082735)\n",
            "[round 1 | client 3] seed LR=0.1230799809 (prev=0.1261599617), seed PERT=0.1200035339 (prev=0.1200070678), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.508136 step=0.04197 g_raw=+0.017 g_sm=+0.004 acc=1 | LR→0.123326 PERT→0.120004 (scale=0.04)\n",
            "[meta] cb#010 loss=0.505599 step=0.01198 g_raw=+0.005 g_sm=+0.005 acc=1 | LR→0.123573 PERT→0.120004 (scale=0.04)\n",
            "[meta] cb#015 loss=0.498427 step=0.03176 g_raw=+0.016 g_sm=+0.009 acc=1 | LR→0.123821 PERT→0.120004 (scale=0.04)\n",
            "[meta] cb#020 loss=0.491766 step=0.07653 g_raw=+0.036 g_sm=+0.011 acc=1 | LR→0.124069 PERT→0.120004 (scale=0.04)\n",
            "[meta] cb#025 loss=0.486635 step=0.04984 g_raw=+0.021 g_sm=+0.012 acc=1 | LR→0.124318 PERT→0.120004 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1230799809, PERT_used=0.1200035339 → LR_next=0.1243178364, PERT_next=0.1200043845\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1230799809→0.1243178364 PERT 0.1200035339→0.1200043845\n",
            "Training Accuracy: 0.56\n",
            "Test Accuracy: 0.62\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.479370 step=0.1226 g_raw=+0.053 g_sm=+0.014 acc=1 | LR→0.124567 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#035 loss=0.471635 step=0.08126 g_raw=+0.036 g_sm=+0.015 acc=1 | LR→0.124817 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#040 loss=0.463862 step=0.02965 g_raw=+0.012 g_sm=+0.017 acc=1 | LR→0.125067 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#045 loss=0.461134 step=0.0318 g_raw=+0.013 g_sm=+0.016 acc=1 | LR→0.125318 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#050 loss=0.457034 step=0.04932 g_raw=+0.020 g_sm=+0.015 acc=1 | LR→0.125569 PERT→0.120006 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1243178364, PERT_used=0.1200043845 → LR_next=0.1255691519, PERT_next=0.1200062008\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1243178364→0.1255691519 PERT 0.1200043845→0.1200062008\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.453015 step=0.08516 g_raw=+0.037 g_sm=+0.015 acc=1 | LR→0.125821 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#060 loss=0.450109 step=0.01794 g_raw=+0.010 g_sm=+0.015 acc=1 | LR→0.126073 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#065 loss=0.445569 step=0.04863 g_raw=+0.022 g_sm=+0.015 acc=1 | LR→0.126326 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#070 loss=0.440416 step=0.00286 g_raw=-0.001 g_sm=+0.015 acc=1 | LR→0.126579 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#075 loss=0.437841 step=0.01037 g_raw=+0.006 g_sm=+0.015 acc=1 | LR→0.126833 PERT→0.120008 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1255691519, PERT_used=0.1200062008 → LR_next=0.1268330501, PERT_next=0.1200080054\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1255691519→0.1268330501 PERT 0.1200062008→0.1200080054\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.76\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.436590 step=0.05164 g_raw=+0.019 g_sm=+0.013 acc=1 | LR→0.127087 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#085 loss=0.433832 step=0.01505 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.127342 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#090 loss=0.431243 step=0.008533 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.127597 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#095 loss=0.425663 step=0.05799 g_raw=+0.024 g_sm=+0.014 acc=1 | LR→0.127853 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#100 loss=0.420236 step=0.001068 g_raw=+0.004 g_sm=+0.015 acc=1 | LR→0.128109 PERT→0.120010 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1268330501, PERT_used=0.1200080054 → LR_next=0.1281094812, PERT_next=0.1200096332\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1268330501→0.1281094812 PERT 0.1200080054→0.1200096332\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.79\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.414747 step=0.05898 g_raw=+0.026 g_sm=+0.016 acc=1 | LR→0.128366 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#110 loss=0.411328 step=0.02467 g_raw=+0.011 g_sm=+0.016 acc=1 | LR→0.128624 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#115 loss=0.409276 step=0.02787 g_raw=+0.009 g_sm=+0.015 acc=1 | LR→0.128882 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#120 loss=0.405751 step=0.03427 g_raw=+0.014 g_sm=+0.015 acc=1 | LR→0.129140 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#125 loss=0.402309 step=0.002422 g_raw=-0.002 g_sm=+0.014 acc=1 | LR→0.129399 PERT→0.120011 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1281094812, PERT_used=0.1200096332 → LR_next=0.1293989701, PERT_next=0.1200114577\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1281094812→0.1293989701 PERT 0.1200096332→0.1200114577\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.80\n",
            "[round 1 | client 3] final LR=0.1293989701, final PERT=0.1200114577  (ΔLR=+0.0063189892, ΔPERT=+0.0000079238)\n",
            "[round 1 | client 4] seed LR=0.1230808850 (prev=0.1261617699), seed PERT=0.1200043939 (prev=0.1200087878), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.503893 step=0.09304 g_raw=+0.039 g_sm=+0.006 acc=1 | LR→0.123327 PERT→0.120004 (scale=0.04)\n",
            "[meta] cb#010 loss=0.498670 step=0.07717 g_raw=+0.033 g_sm=+0.009 acc=1 | LR→0.123574 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#015 loss=0.491824 step=0.009468 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.123822 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#020 loss=0.488624 step=0.04497 g_raw=+0.019 g_sm=+0.012 acc=1 | LR→0.124070 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#025 loss=0.483500 step=0.005784 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.124319 PERT→0.120005 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1230808850, PERT_used=0.1200043939 → LR_next=0.1243189770, PERT_next=0.1200054640\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1230808850→0.1243189770 PERT 0.1200043939→0.1200054640\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.46\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.480701 step=0.04119 g_raw=+0.021 g_sm=+0.013 acc=1 | LR→0.124568 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#035 loss=0.479918 step=0.0217 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.124818 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#040 loss=0.472306 step=0.0159 g_raw=+0.007 g_sm=+0.014 acc=1 | LR→0.125068 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#045 loss=0.467190 step=0.05447 g_raw=+0.021 g_sm=+0.015 acc=1 | LR→0.125319 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#050 loss=0.459986 step=0.03054 g_raw=+0.014 g_sm=+0.016 acc=1 | LR→0.125570 PERT→0.120007 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1243189770, PERT_used=0.1200054640 → LR_next=0.1255701109, PERT_next=0.1200070958\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1243189770→0.1255701109 PERT 0.1200054640→0.1200070958\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.456187 step=0.02599 g_raw=+0.008 g_sm=+0.015 acc=1 | LR→0.125822 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#060 loss=0.450165 step=0.0988 g_raw=+0.046 g_sm=+0.016 acc=1 | LR→0.126074 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#065 loss=0.446784 step=0.03641 g_raw=+0.013 g_sm=+0.015 acc=1 | LR→0.126327 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#070 loss=0.441705 step=0.08849 g_raw=+0.037 g_sm=+0.016 acc=1 | LR→0.126580 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#075 loss=0.435563 step=0.1025 g_raw=+0.042 g_sm=+0.017 acc=1 | LR→0.126834 PERT→0.120009 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1255701109, PERT_used=0.1200070958 → LR_next=0.1268340424, PERT_next=0.1200089228\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1255701109→0.1268340424 PERT 0.1200070958→0.1200089228\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.431579 step=0.00567 g_raw=+0.002 g_sm=+0.016 acc=1 | LR→0.127088 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#085 loss=0.424401 step=0.06527 g_raw=+0.024 g_sm=+0.017 acc=1 | LR→0.127343 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#090 loss=0.414357 step=0.09855 g_raw=+0.042 g_sm=+0.019 acc=1 | LR→0.127599 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#095 loss=0.411687 step=0.07302 g_raw=+0.030 g_sm=+0.017 acc=1 | LR→0.127855 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.409486 step=0.03314 g_raw=+0.014 g_sm=+0.016 acc=1 | LR→0.128111 PERT→0.120011 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1268340424, PERT_used=0.1200089228 → LR_next=0.1281109171, PERT_next=0.1200109569\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1268340424→0.1281109171 PERT 0.1200089228→0.1200109569\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.405138 step=0.04372 g_raw=+0.017 g_sm=+0.017 acc=1 | LR→0.128368 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#110 loss=0.400705 step=0.04708 g_raw=+0.019 g_sm=+0.017 acc=1 | LR→0.128625 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.399918 step=0.01322 g_raw=+0.009 g_sm=+0.015 acc=1 | LR→0.128883 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.395293 step=0.003569 g_raw=-0.000 g_sm=+0.014 acc=1 | LR→0.129142 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#125 loss=0.391310 step=0.01895 g_raw=+0.006 g_sm=+0.015 acc=1 | LR→0.129400 PERT→0.120013 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1281109171, PERT_used=0.1200109569 → LR_next=0.1294004665, PERT_next=0.1200128241\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1281109171→0.1294004665 PERT 0.1200109569→0.1200128241\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.67\n",
            "[round 1 | client 4] final LR=0.1294004665, final PERT=0.1200128241  (ΔLR=+0.0063195815, ΔPERT=+0.0000084302)\n",
            "\n",
            "[Round 1] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           3      0.547286      0.800000      0.129399      0.120011\n",
            "           1      0.547785      0.730000      0.129400      0.120013\n",
            "           0      0.554905      0.715000      0.129398      0.120010\n",
            "           4      0.630564      0.670000      0.129400      0.120013\n",
            "           2      0.636549      0.640000      0.129400      0.120012\n",
            "→ [Round 1] best_client=3, best_val=0.547286, prev_global_val=0.541809, improve=-0.005477, action=hold (τ=0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  20%|██        | 2/10 [18:46<1:14:59, 562.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   1] acc_g=0.741 (μ=0.711, σ=0.055, FG=0.120) | t=548.020s, val=0.543 | TEL=FALSE\n",
            "[Round 2] Teleportation OFF | Aggregation=best\n",
            "[round 2 | client 0] seed LR=0.1246987951 (prev=0.1293975902), seed PERT=0.1200050892 (prev=0.1200101783), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.468376 step=0.07808 g_raw=+0.030 g_sm=+0.005 acc=1 | LR→0.124948 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#010 loss=0.467113 step=0.006491 g_raw=+0.003 g_sm=+0.006 acc=1 | LR→0.125199 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#015 loss=0.465768 step=0.0233 g_raw=+0.009 g_sm=+0.006 acc=1 | LR→0.125450 PERT→0.120005 (scale=0.04)\n",
            "[meta] cb#020 loss=0.462996 step=0.03999 g_raw=+0.017 g_sm=+0.008 acc=1 | LR→0.125701 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#025 loss=0.462573 step=0.003387 g_raw=+0.004 g_sm=+0.007 acc=1 | LR→0.125953 PERT→0.120006 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1246987951, PERT_used=0.1200050892 → LR_next=0.1259527422, PERT_next=0.1200057593\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1246987951→0.1259527422 PERT 0.1200050892→0.1200057593\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.460073 step=0.05005 g_raw=+0.018 g_sm=+0.008 acc=1 | LR→0.126205 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#035 loss=0.454642 step=0.07059 g_raw=+0.031 g_sm=+0.011 acc=1 | LR→0.126458 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#040 loss=0.452570 step=0.003665 g_raw=+0.000 g_sm=+0.010 acc=1 | LR→0.126711 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#045 loss=0.447837 step=0.05341 g_raw=+0.022 g_sm=+0.012 acc=1 | LR→0.126965 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#050 loss=0.446164 step=0.001504 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.127220 PERT→0.120007 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1259527422, PERT_used=0.1200057593 → LR_next=0.1272198773, PERT_next=0.1200069752\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1259527422→0.1272198773 PERT 0.1200057593→0.1200069752\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.442437 step=0.04324 g_raw=+0.017 g_sm=+0.012 acc=1 | LR→0.127475 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#060 loss=0.437274 step=0.0139 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.127730 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#065 loss=0.433540 step=0.01975 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.127986 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#070 loss=0.432896 step=0.02206 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.128243 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#075 loss=0.431288 step=0.02419 g_raw=+0.011 g_sm=+0.011 acc=1 | LR→0.128500 PERT→0.120008 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1272198773, PERT_used=0.1200069752 → LR_next=0.1285000056, PERT_next=0.1200084202\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1272198773→0.1285000056 PERT 0.1200069752→0.1200084202\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.428103 step=0.02103 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.128758 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#085 loss=0.427388 step=0.0192 g_raw=+0.007 g_sm=+0.010 acc=1 | LR→0.129016 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#090 loss=0.424817 step=0.06615 g_raw=+0.028 g_sm=+0.011 acc=1 | LR→0.129274 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#095 loss=0.423958 step=0.005077 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.129533 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#100 loss=0.422441 step=0.01515 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.129793 PERT→0.120010 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1285000056, PERT_used=0.1200084202 → LR_next=0.1297928241, PERT_next=0.1200096888\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1285000056→0.1297928241 PERT 0.1200084202→0.1200096888\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.420993 step=0.007282 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.130053 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#110 loss=0.417933 step=0.02875 g_raw=+0.010 g_sm=+0.010 acc=1 | LR→0.130314 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#115 loss=0.416535 step=0.0494 g_raw=+0.020 g_sm=+0.010 acc=1 | LR→0.130575 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#120 loss=0.415616 step=0.005837 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.130836 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#125 loss=0.413890 step=0.04 g_raw=+0.016 g_sm=+0.010 acc=1 | LR→0.131099 PERT→0.120011 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1297928241, PERT_used=0.1200096888 → LR_next=0.1310985628, PERT_next=0.1200108780\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1297928241→0.1310985628 PERT 0.1200096888→0.1200108780\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.66\n",
            "[round 2 | client 0] final LR=0.1310985628, final PERT=0.1200108780  (ΔLR=+0.0063997676, ΔPERT=+0.0000057889)\n",
            "[round 2 | client 1] seed LR=0.1247002335 (prev=0.1294004670), seed PERT=0.1200064307 (prev=0.1200128615), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.496127 step=0.1162 g_raw=+0.049 g_sm=+0.006 acc=1 | LR→0.124950 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.491049 step=0.04194 g_raw=+0.016 g_sm=+0.007 acc=1 | LR→0.125200 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.489207 step=0.0114 g_raw=+0.005 g_sm=+0.008 acc=1 | LR→0.125451 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.479803 step=0.05391 g_raw=+0.023 g_sm=+0.011 acc=1 | LR→0.125703 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.471856 step=0.09885 g_raw=+0.045 g_sm=+0.014 acc=1 | LR→0.125955 PERT→0.120007 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1247002335, PERT_used=0.1200064307 → LR_next=0.1259545056, PERT_next=0.1200073968\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1247002335→0.1259545056 PERT 0.1200064307→0.1200073968\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.43\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.467478 step=0.0387 g_raw=+0.018 g_sm=+0.014 acc=1 | LR→0.126207 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.465887 step=0.006425 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.126460 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.455837 step=0.07554 g_raw=+0.030 g_sm=+0.016 acc=1 | LR→0.126714 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.453837 step=0.005525 g_raw=+0.004 g_sm=+0.015 acc=1 | LR→0.126968 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.444152 step=0.01345 g_raw=+0.007 g_sm=+0.017 acc=1 | LR→0.127222 PERT→0.120009 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1259545056, PERT_used=0.1200073968 → LR_next=0.1272222805, PERT_next=0.1200091995\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1259545056→0.1272222805 PERT 0.1200073968→0.1200091995\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.46\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.441610 step=0.05344 g_raw=+0.023 g_sm=+0.016 acc=1 | LR→0.127477 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.439716 step=0.002099 g_raw=-0.003 g_sm=+0.014 acc=1 | LR→0.127733 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.438747 step=0.0009893 g_raw=+0.005 g_sm=+0.013 acc=1 | LR→0.127989 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.434389 step=0.007786 g_raw=+0.006 g_sm=+0.014 acc=1 | LR→0.128246 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#075 loss=0.427543 step=0.09496 g_raw=+0.040 g_sm=+0.015 acc=1 | LR→0.128503 PERT→0.120011 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1272222805, PERT_used=0.1200091995 → LR_next=0.1285027650, PERT_next=0.1200109546\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1272222805→0.1285027650 PERT 0.1200091995→0.1200109546\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.423138 step=0.0367 g_raw=+0.017 g_sm=+0.015 acc=1 | LR→0.128760 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.419786 step=0.0329 g_raw=+0.013 g_sm=+0.015 acc=1 | LR→0.129019 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#090 loss=0.414377 step=0.07662 g_raw=+0.029 g_sm=+0.016 acc=1 | LR→0.129277 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.411796 step=0.04452 g_raw=+0.020 g_sm=+0.016 acc=1 | LR→0.129536 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.407894 step=0.008608 g_raw=+0.003 g_sm=+0.015 acc=1 | LR→0.129796 PERT→0.120013 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1285027650, PERT_used=0.1200109546 → LR_next=0.1297962340, PERT_next=0.1200127990\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1285027650→0.1297962340 PERT 0.1200109546→0.1200127990\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.58\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.404954 step=0.05147 g_raw=+0.018 g_sm=+0.015 acc=1 | LR→0.130056 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#110 loss=0.401082 step=0.06585 g_raw=+0.026 g_sm=+0.015 acc=1 | LR→0.130317 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.399786 step=0.01307 g_raw=+0.006 g_sm=+0.013 acc=1 | LR→0.130578 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#120 loss=0.394851 step=0.01782 g_raw=+0.005 g_sm=+0.014 acc=1 | LR→0.130840 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#125 loss=0.389979 step=0.06996 g_raw=+0.029 g_sm=+0.015 acc=1 | LR→0.131103 PERT→0.120015 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1297962340, PERT_used=0.1200127990 → LR_next=0.1311025804, PERT_next=0.1200145132\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1297962340→0.1311025804 PERT 0.1200127990→0.1200145132\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.60\n",
            "[round 2 | client 1] final LR=0.1311025804, final PERT=0.1200145132  (ΔLR=+0.0064023469, ΔPERT=+0.0000080825)\n",
            "[round 2 | client 2] seed LR=0.1247000227 (prev=0.1294000454), seed PERT=0.1200062196 (prev=0.1200124392), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.509586 step=0.006368 g_raw=+0.001 g_sm=+0.002 acc=1 | LR→0.124950 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.506981 step=0.02199 g_raw=+0.008 g_sm=+0.005 acc=1 | LR→0.125200 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.504057 step=0.0188 g_raw=+0.010 g_sm=+0.007 acc=1 | LR→0.125451 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.500679 step=0.005258 g_raw=+0.001 g_sm=+0.008 acc=1 | LR→0.125702 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.497242 step=0.03317 g_raw=+0.015 g_sm=+0.009 acc=1 | LR→0.125954 PERT→0.120007 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1247000227, PERT_used=0.1200062196 → LR_next=0.1259539963, PERT_next=0.1200069033\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1247000227→0.1259539963 PERT 0.1200062196→0.1200069033\n",
            "Training Accuracy: 0.56\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.490282 step=0.02438 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.126206 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.487565 step=0.03 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.126459 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#040 loss=0.483208 step=0.01396 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.126713 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.480402 step=0.05239 g_raw=+0.023 g_sm=+0.013 acc=1 | LR→0.126967 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.478954 step=0.04046 g_raw=+0.017 g_sm=+0.013 acc=1 | LR→0.127221 PERT→0.120008 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1259539963, PERT_used=0.1200069033 → LR_next=0.1272214290, PERT_next=0.1200083881\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1259539963→0.1272214290 PERT 0.1200069033→0.1200083881\n",
            "Training Accuracy: 0.56\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.472137 step=0.004124 g_raw=+0.002 g_sm=+0.014 acc=1 | LR→0.127476 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.470821 step=0.01806 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.127732 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.470173 step=0.01362 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.127988 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.464026 step=0.004379 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.128245 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.461580 step=0.02083 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.128502 PERT→0.120010 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1272214290, PERT_used=0.1200083881 → LR_next=0.1285016948, PERT_next=0.1200099469\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1272214290→0.1285016948 PERT 0.1200083881→0.1200099469\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.452948 step=0.00277 g_raw=+0.002 g_sm=+0.015 acc=1 | LR→0.128759 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.451586 step=0.02614 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.129017 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.447127 step=0.04128 g_raw=+0.020 g_sm=+0.014 acc=1 | LR→0.129276 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.442883 step=0.004331 g_raw=+0.002 g_sm=+0.014 acc=1 | LR→0.129535 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.432975 step=0.009187 g_raw=+0.004 g_sm=+0.016 acc=1 | LR→0.129795 PERT→0.120012 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1285016948, PERT_used=0.1200099469 → LR_next=0.1297950420, PERT_next=0.1200116886\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1285016948→0.1297950420 PERT 0.1200099469→0.1200116886\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.430480 step=0.06409 g_raw=+0.025 g_sm=+0.015 acc=1 | LR→0.130055 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.429345 step=0.02691 g_raw=+0.012 g_sm=+0.014 acc=1 | LR→0.130316 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.428084 step=0.001445 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.130577 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.424429 step=0.0413 g_raw=+0.017 g_sm=+0.013 acc=1 | LR→0.130839 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.419813 step=0.06249 g_raw=+0.026 g_sm=+0.014 acc=1 | LR→0.131101 PERT→0.120013 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1297950420, PERT_used=0.1200116886 → LR_next=0.1311013216, PERT_next=0.1200133527\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1297950420→0.1311013216 PERT 0.1200116886→0.1200133527\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.72\n",
            "[round 2 | client 2] final LR=0.1311013216, final PERT=0.1200133527  (ΔLR=+0.0064012990, ΔPERT=+0.0000071331)\n",
            "[round 2 | client 3] seed LR=0.1246994850 (prev=0.1293989701), seed PERT=0.1200057289 (prev=0.1200114577), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.460406 step=0.007181 g_raw=+0.004 g_sm=+0.002 acc=1 | LR→0.124949 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.456187 step=0.003486 g_raw=-0.001 g_sm=+0.005 acc=1 | LR→0.125199 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.454156 step=0.02663 g_raw=+0.011 g_sm=+0.006 acc=1 | LR→0.125450 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.451850 step=0.03974 g_raw=+0.018 g_sm=+0.008 acc=1 | LR→0.125702 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#025 loss=0.446270 step=0.01996 g_raw=+0.009 g_sm=+0.010 acc=1 | LR→0.125953 PERT→0.120006 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1246994850, PERT_used=0.1200057289 → LR_next=0.1259534473, PERT_next=0.1200064069\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1246994850→0.1259534473 PERT 0.1200057289→0.1200064069\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.65\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.445083 step=0.03972 g_raw=+0.017 g_sm=+0.010 acc=1 | LR→0.126206 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.437681 step=0.01891 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.126459 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#040 loss=0.435663 step=0.04089 g_raw=+0.017 g_sm=+0.012 acc=1 | LR→0.126712 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#045 loss=0.434037 step=0.02712 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.126966 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.431494 step=0.05418 g_raw=+0.021 g_sm=+0.012 acc=1 | LR→0.127221 PERT→0.120008 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1259534473, PERT_used=0.1200064069 → LR_next=0.1272207657, PERT_next=0.1200077890\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1259534473→0.1272207657 PERT 0.1200064069→0.1200077890\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.62\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.427891 step=0.03148 g_raw=+0.014 g_sm=+0.012 acc=1 | LR→0.127476 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#060 loss=0.421885 step=0.01592 g_raw=+0.005 g_sm=+0.014 acc=1 | LR→0.127731 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#065 loss=0.419703 step=0.03773 g_raw=+0.018 g_sm=+0.013 acc=1 | LR→0.127987 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.418428 step=0.008099 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.128244 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#075 loss=0.418131 step=0.01417 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.128501 PERT→0.120009 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1272207657, PERT_used=0.1200077890 → LR_next=0.1285009548, PERT_next=0.1200092825\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1272207657→0.1285009548 PERT 0.1200077890→0.1200092825\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.60\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.413183 step=0.05997 g_raw=+0.024 g_sm=+0.012 acc=1 | LR→0.128759 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.402642 step=0.07711 g_raw=+0.035 g_sm=+0.016 acc=1 | LR→0.129017 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#090 loss=0.400240 step=0.06196 g_raw=+0.027 g_sm=+0.015 acc=1 | LR→0.129275 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#095 loss=0.397537 step=0.05567 g_raw=+0.021 g_sm=+0.015 acc=1 | LR→0.129535 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.393508 step=0.04955 g_raw=+0.019 g_sm=+0.015 acc=1 | LR→0.129794 PERT→0.120011 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1285009548, PERT_used=0.1200092825 → LR_next=0.1297942291, PERT_next=0.1200109636\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1285009548→0.1297942291 PERT 0.1200092825→0.1200109636\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.389538 step=0.04741 g_raw=+0.019 g_sm=+0.015 acc=1 | LR→0.130054 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#110 loss=0.386564 step=0.005623 g_raw=+0.002 g_sm=+0.014 acc=1 | LR→0.130315 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.383470 step=0.03865 g_raw=+0.017 g_sm=+0.014 acc=1 | LR→0.130576 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.379517 step=0.01348 g_raw=+0.006 g_sm=+0.014 acc=1 | LR→0.130838 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#125 loss=0.378682 step=0.01519 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.131101 PERT→0.120013 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1297942291, PERT_used=0.1200109636 → LR_next=0.1311005534, PERT_next=0.1200126761\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1297942291→0.1311005534 PERT 0.1200109636→0.1200126761\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.61\n",
            "[round 2 | client 3] final LR=0.1311005534, final PERT=0.1200126761  (ΔLR=+0.0064010684, ΔPERT=+0.0000069472)\n",
            "[round 2 | client 4] seed LR=0.1247002332 (prev=0.1294004665), seed PERT=0.1200064120 (prev=0.1200128241), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.487243 step=0.01616 g_raw=+0.009 g_sm=+0.003 acc=1 | LR→0.124950 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.483052 step=0.05379 g_raw=+0.021 g_sm=+0.007 acc=1 | LR→0.125200 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.477118 step=0.05405 g_raw=+0.024 g_sm=+0.009 acc=1 | LR→0.125451 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.475867 step=0.006955 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.125702 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.473286 step=0.005101 g_raw=-0.001 g_sm=+0.010 acc=1 | LR→0.125954 PERT→0.120007 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1247002332, PERT_used=0.1200064120 → LR_next=0.1259543778, PERT_next=0.1200072565\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1247002332→0.1259543778 PERT 0.1200064120→0.1200072565\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.470188 step=0.04631 g_raw=+0.019 g_sm=+0.011 acc=1 | LR→0.126207 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.465737 step=0.05331 g_raw=+0.019 g_sm=+0.012 acc=1 | LR→0.126460 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.462230 step=0.01884 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.126713 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.452340 step=0.05597 g_raw=+0.023 g_sm=+0.016 acc=1 | LR→0.126967 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.448784 step=0.06012 g_raw=+0.023 g_sm=+0.016 acc=1 | LR→0.127222 PERT→0.120009 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1259543778, PERT_used=0.1200072565 → LR_next=0.1272218876, PERT_next=0.1200088104\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1259543778→0.1272218876 PERT 0.1200072565→0.1200088104\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.441798 step=0.009095 g_raw=+0.001 g_sm=+0.016 acc=1 | LR→0.127477 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.437013 step=0.04698 g_raw=+0.018 g_sm=+0.017 acc=1 | LR→0.127733 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.435378 step=0.01735 g_raw=+0.007 g_sm=+0.015 acc=1 | LR→0.127989 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.434396 step=0.02906 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.128245 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.431913 step=0.03016 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.128502 PERT→0.120011 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1272218876, PERT_used=0.1200088104 → LR_next=0.1285024832, PERT_next=0.1200106730\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1272218876→0.1285024832 PERT 0.1200088104→0.1200106730\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.430635 step=0.01384 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.128760 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.429190 step=0.01077 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.129018 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.428052 step=0.0003106 g_raw=+0.000 g_sm=+0.010 acc=1 | LR→0.129277 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.427010 step=0.01222 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.129536 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.424164 step=0.03092 g_raw=+0.010 g_sm=+0.010 acc=1 | LR→0.129795 PERT→0.120012 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1285024832, PERT_used=0.1200106730 → LR_next=0.1297954050, PERT_next=0.1200120141\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1285024832→0.1297954050 PERT 0.1200106730→0.1200120141\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.422702 step=0.03013 g_raw=+0.013 g_sm=+0.010 acc=1 | LR→0.130056 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.421337 step=0.02716 g_raw=+0.013 g_sm=+0.010 acc=1 | LR→0.130316 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.419938 step=0.004732 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.130577 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.417656 step=0.01551 g_raw=+0.007 g_sm=+0.010 acc=1 | LR→0.130839 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.416496 step=0.04974 g_raw=+0.021 g_sm=+0.010 acc=1 | LR→0.131101 PERT→0.120013 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1297954050, PERT_used=0.1200120141 → LR_next=0.1311011734, PERT_next=0.1200132067\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1297954050→0.1311011734 PERT 0.1200120141→0.1200132067\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.75\n",
            "[round 2 | client 4] final LR=0.1311011734, final PERT=0.1200132067  (ΔLR=+0.0064009401, ΔPERT=+0.0000067947)\n",
            "\n",
            "[Round 2] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           2      0.566186      0.720000      0.131101      0.120013\n",
            "           4      0.577791      0.750000      0.131101      0.120013\n",
            "           0      0.607862      0.660000      0.131099      0.120011\n",
            "           1      0.618696      0.605000      0.131103      0.120015\n",
            "           3      0.628215      0.615000      0.131101      0.120013\n",
            "→ [Round 2] best_client=2, best_val=0.566186, prev_global_val=0.543397, improve=-0.022789, action=hold (τ=0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  30%|███       | 3/10 [27:42<1:04:10, 550.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   2] acc_g=0.753 (μ=0.670, σ=0.057, FG=0.129) | t=525.473s, val=0.542 | TEL=FALSE\n",
            "[Round 3] Teleportation OFF | Aggregation=best\n",
            "[round 3 | client 0] seed LR=0.1255492814 (prev=0.1310985628), seed PERT=0.1200054390 (prev=0.1200108780), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.500844 step=0.0686 g_raw=+0.029 g_sm=+0.005 acc=1 | LR→0.125801 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.498086 step=0.01305 g_raw=+0.004 g_sm=+0.006 acc=1 | LR→0.126053 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.490049 step=0.08861 g_raw=+0.038 g_sm=+0.011 acc=1 | LR→0.126305 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.485146 step=0.05275 g_raw=+0.021 g_sm=+0.012 acc=1 | LR→0.126558 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#025 loss=0.483804 step=0.01172 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.126812 PERT→0.120006 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1255492814, PERT_used=0.1200054390 → LR_next=0.1268120860, PERT_next=0.1200063980\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1255492814→0.1268120860 PERT 0.1200054390→0.1200063980\n",
            "Training Accuracy: 0.50\n",
            "Test Accuracy: 0.47\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.478744 step=0.02275 g_raw=+0.008 g_sm=+0.013 acc=1 | LR→0.127066 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.476711 step=0.01894 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.127321 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#040 loss=0.468740 step=0.1219 g_raw=+0.053 g_sm=+0.014 acc=1 | LR→0.127576 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#045 loss=0.467734 step=0.01688 g_raw=+0.006 g_sm=+0.013 acc=1 | LR→0.127832 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.464451 step=0.003056 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.128088 PERT→0.120008 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1268120860, PERT_used=0.1200063980 → LR_next=0.1280882164, PERT_next=0.1200079418\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1268120860→0.1280882164 PERT 0.1200063980→0.1200079418\n",
            "Training Accuracy: 0.54\n",
            "Test Accuracy: 0.48\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.460724 step=0.06469 g_raw=+0.026 g_sm=+0.014 acc=1 | LR→0.128345 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#060 loss=0.459535 step=0.02402 g_raw=+0.011 g_sm=+0.013 acc=1 | LR→0.128602 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.458747 step=0.01678 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.128860 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.457481 step=0.02254 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.129118 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#075 loss=0.455404 step=0.009841 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.129377 PERT→0.120009 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1280882164, PERT_used=0.1200079418 → LR_next=0.1293770941, PERT_next=0.1200093978\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1280882164→0.1293770941 PERT 0.1200079418→0.1200093978\n",
            "Training Accuracy: 0.54\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.454221 step=0.01797 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.129636 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.452244 step=0.0212 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.129896 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#090 loss=0.447855 step=0.007755 g_raw=+0.002 g_sm=+0.012 acc=1 | LR→0.130157 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#095 loss=0.445193 step=0.02443 g_raw=+0.010 g_sm=+0.012 acc=1 | LR→0.130417 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#100 loss=0.439935 step=0.0681 g_raw=+0.029 g_sm=+0.014 acc=1 | LR→0.130679 PERT→0.120011 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1293770941, PERT_used=0.1200093978 → LR_next=0.1306788752, PERT_next=0.1200107935\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1293770941→0.1306788752 PERT 0.1200093978→0.1200107935\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.437316 step=0.000516 g_raw=-0.000 g_sm=+0.013 acc=1 | LR→0.130941 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#110 loss=0.436233 step=0.01791 g_raw=+0.010 g_sm=+0.012 acc=1 | LR→0.131203 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#115 loss=0.433941 step=0.03135 g_raw=+0.013 g_sm=+0.012 acc=1 | LR→0.131466 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.433366 step=0.004342 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.131730 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#125 loss=0.428796 step=0.05377 g_raw=+0.021 g_sm=+0.012 acc=1 | LR→0.131994 PERT→0.120012 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1306788752, PERT_used=0.1200107935 → LR_next=0.1319938401, PERT_next=0.1200122668\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1306788752→0.1319938401 PERT 0.1200107935→0.1200122668\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.58\n",
            "[round 3 | client 0] final LR=0.1319938401, final PERT=0.1200122668  (ΔLR=+0.0064445587, ΔPERT=+0.0000068278)\n",
            "[round 3 | client 1] seed LR=0.1255512902 (prev=0.1311025804), seed PERT=0.1200072566 (prev=0.1200145132), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.506235 step=0.08404 g_raw=+0.035 g_sm=+0.003 acc=1 | LR→0.125803 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.503126 step=0.0515 g_raw=+0.023 g_sm=+0.006 acc=1 | LR→0.126055 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.484097 step=0.1539 g_raw=+0.067 g_sm=+0.012 acc=1 | LR→0.126307 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.479014 step=0.08206 g_raw=+0.032 g_sm=+0.014 acc=1 | LR→0.126560 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.477031 step=0.03433 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.126814 PERT→0.120008 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1255512902, PERT_used=0.1200072566 → LR_next=0.1268141587, PERT_next=0.1200082569\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1255512902→0.1268141587 PERT 0.1200072566→0.1200082569\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.475493 step=0.03356 g_raw=+0.014 g_sm=+0.013 acc=1 | LR→0.127068 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.462406 step=0.1431 g_raw=+0.061 g_sm=+0.016 acc=1 | LR→0.127323 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.456197 step=0.04247 g_raw=+0.018 g_sm=+0.017 acc=1 | LR→0.127578 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.439538 step=0.05371 g_raw=+0.025 g_sm=+0.021 acc=1 | LR→0.127834 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.434633 step=0.02142 g_raw=+0.009 g_sm=+0.020 acc=1 | LR→0.128091 PERT→0.120010 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1268141587, PERT_used=0.1200082569 → LR_next=0.1280908230, PERT_next=0.1200102814\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.022 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1268141587→0.1280908230 PERT 0.1200082569→0.1200102814\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.434343 step=0.01266 g_raw=+0.005 g_sm=+0.016 acc=1 | LR→0.128348 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#060 loss=0.425133 step=0.1155 g_raw=+0.044 g_sm=+0.018 acc=1 | LR→0.128605 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.423358 step=0.0007612 g_raw=-0.002 g_sm=+0.016 acc=1 | LR→0.128863 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#070 loss=0.421651 step=0.05145 g_raw=+0.023 g_sm=+0.015 acc=1 | LR→0.129121 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#075 loss=0.415087 step=0.0353 g_raw=+0.014 g_sm=+0.015 acc=1 | LR→0.129380 PERT→0.120012 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1280908230, PERT_used=0.1200102814 → LR_next=0.1293802917, PERT_next=0.1200122614\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1280908230→0.1293802917 PERT 0.1200102814→0.1200122614\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.409291 step=0.003349 g_raw=+0.004 g_sm=+0.015 acc=1 | LR→0.129640 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#085 loss=0.408041 step=0.005414 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.129900 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#090 loss=0.406529 step=0.02515 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.130160 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#095 loss=0.404502 step=0.04637 g_raw=+0.022 g_sm=+0.012 acc=1 | LR→0.130421 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#100 loss=0.403887 step=0.009628 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.130682 PERT→0.120014 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1293802917, PERT_used=0.1200122614 → LR_next=0.1306822943, PERT_next=0.1200138309\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1293802917→0.1306822943 PERT 0.1200122614→0.1200138309\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.402507 step=0.01036 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.130944 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#110 loss=0.400322 step=0.04262 g_raw=+0.020 g_sm=+0.011 acc=1 | LR→0.131207 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#115 loss=0.397615 step=0.02417 g_raw=+0.011 g_sm=+0.011 acc=1 | LR→0.131470 PERT→0.120015 (scale=0.04)\n",
            "[meta] cb#120 loss=0.397221 step=0.00857 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.131733 PERT→0.120015 (scale=0.04)\n",
            "[meta] cb#125 loss=0.396890 step=0.01257 g_raw=+0.004 g_sm=+0.009 acc=1 | LR→0.131997 PERT→0.120015 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1306822943, PERT_used=0.1200138309 → LR_next=0.1319970300, PERT_next=0.1200150646\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1306822943→0.1319970300 PERT 0.1200138309→0.1200150646\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.66\n",
            "[round 3 | client 1] final LR=0.1319970300, final PERT=0.1200150646  (ΔLR=+0.0064457398, ΔPERT=+0.0000078080)\n",
            "[round 3 | client 2] seed LR=0.1255506608 (prev=0.1311013216), seed PERT=0.1200066763 (prev=0.1200133527), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.467512 step=0.02937 g_raw=+0.012 g_sm=+0.002 acc=1 | LR→0.125802 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.458842 step=0.02678 g_raw=+0.011 g_sm=+0.007 acc=1 | LR→0.126054 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.446965 step=0.1039 g_raw=+0.045 g_sm=+0.012 acc=1 | LR→0.126307 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.442227 step=0.03455 g_raw=+0.014 g_sm=+0.013 acc=1 | LR→0.126560 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.433630 step=0.01464 g_raw=+0.005 g_sm=+0.016 acc=1 | LR→0.126814 PERT→0.120008 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1255506608, PERT_used=0.1200066763 → LR_next=0.1268135808, PERT_next=0.1200077313\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1255506608→0.1268135808 PERT 0.1200066763→0.1200077313\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.429945 step=0.02941 g_raw=+0.010 g_sm=+0.016 acc=1 | LR→0.127068 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.423337 step=0.09456 g_raw=+0.040 g_sm=+0.017 acc=1 | LR→0.127323 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.420590 step=0.05915 g_raw=+0.027 g_sm=+0.016 acc=1 | LR→0.127578 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.414705 step=0.0166 g_raw=+0.007 g_sm=+0.017 acc=1 | LR→0.127834 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.413451 step=0.0169 g_raw=+0.009 g_sm=+0.015 acc=1 | LR→0.128090 PERT→0.120010 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1268135808, PERT_used=0.1200077313 → LR_next=0.1280901141, PERT_next=0.1200096386\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1268135808→0.1280901141 PERT 0.1200077313→0.1200096386\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.410653 step=0.05262 g_raw=+0.019 g_sm=+0.015 acc=1 | LR→0.128347 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.406631 step=0.005465 g_raw=+0.002 g_sm=+0.015 acc=1 | LR→0.128604 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.405508 step=0.02935 g_raw=+0.011 g_sm=+0.013 acc=1 | LR→0.128862 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#070 loss=0.404265 step=0.02469 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.129120 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#075 loss=0.403181 step=0.02982 g_raw=+0.012 g_sm=+0.011 acc=1 | LR→0.129379 PERT→0.120011 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1280901141, PERT_used=0.1200096386 → LR_next=0.1293792015, PERT_next=0.1200112715\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1280901141→0.1293792015 PERT 0.1200096386→0.1200112715\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.400610 step=0.01309 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.129639 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#085 loss=0.399986 step=0.004397 g_raw=+0.001 g_sm=+0.010 acc=1 | LR→0.129898 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#090 loss=0.398302 step=0.003075 g_raw=-0.002 g_sm=+0.009 acc=1 | LR→0.130159 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.397867 step=0.01577 g_raw=+0.007 g_sm=+0.008 acc=1 | LR→0.130419 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.396826 step=0.03746 g_raw=+0.014 g_sm=+0.008 acc=1 | LR→0.130681 PERT→0.120012 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1293792015, PERT_used=0.1200112715 → LR_next=0.1306807517, PERT_next=0.1200124356\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1293792015→0.1306807517 PERT 0.1200112715→0.1200124356\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.396021 step=0.01584 g_raw=+0.005 g_sm=+0.008 acc=1 | LR→0.130943 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#110 loss=0.395644 step=0.006583 g_raw=+0.003 g_sm=+0.007 acc=1 | LR→0.131205 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.394748 step=0.0002529 g_raw=+0.001 g_sm=+0.007 acc=1 | LR→0.131468 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.393681 step=0.01775 g_raw=+0.007 g_sm=+0.007 acc=1 | LR→0.131731 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.393177 step=0.02679 g_raw=+0.011 g_sm=+0.007 acc=1 | LR→0.131995 PERT→0.120013 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1306807517, PERT_used=0.1200124356 → LR_next=0.1319950959, PERT_next=0.1200133274\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.006 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1306807517→0.1319950959 PERT 0.1200124356→0.1200133274\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.72\n",
            "[round 3 | client 2] final LR=0.1319950959, final PERT=0.1200133274  (ΔLR=+0.0064444351, ΔPERT=+0.0000066511)\n",
            "[round 3 | client 3] seed LR=0.1255502767 (prev=0.1311005534), seed PERT=0.1200063380 (prev=0.1200126761), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.509942 step=0.04212 g_raw=+0.018 g_sm=+0.003 acc=1 | LR→0.125802 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.500761 step=0.02684 g_raw=+0.011 g_sm=+0.008 acc=1 | LR→0.126054 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.496447 step=0.01997 g_raw=+0.008 g_sm=+0.009 acc=1 | LR→0.126306 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.492404 step=0.01387 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.126559 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.490861 step=0.01068 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.126813 PERT→0.120007 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1255502767, PERT_used=0.1200063380 → LR_next=0.1268130607, PERT_next=0.1200072680\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1255502767→0.1268130607 PERT 0.1200063380→0.1200072680\n",
            "Training Accuracy: 0.54\n",
            "Test Accuracy: 0.41\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.485856 step=0.05103 g_raw=+0.027 g_sm=+0.012 acc=1 | LR→0.127067 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.478560 step=0.09119 g_raw=+0.037 g_sm=+0.015 acc=1 | LR→0.127322 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.471974 step=0.04834 g_raw=+0.021 g_sm=+0.017 acc=1 | LR→0.127577 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.465276 step=0.0332 g_raw=+0.014 g_sm=+0.018 acc=1 | LR→0.127833 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.461545 step=0.005472 g_raw=+0.001 g_sm=+0.017 acc=1 | LR→0.128090 PERT→0.120009 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1268130607, PERT_used=0.1200072680 → LR_next=0.1280895030, PERT_next=0.1200090949\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1268130607→0.1280895030 PERT 0.1200072680→0.1200090949\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.62\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.460777 step=0.008058 g_raw=+0.003 g_sm=+0.014 acc=1 | LR→0.128346 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.459149 step=0.02184 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.128604 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.457608 step=0.0294 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.128861 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.453217 step=0.0179 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.129120 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.448964 step=0.08388 g_raw=+0.033 g_sm=+0.013 acc=1 | LR→0.129379 PERT→0.120011 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1280895030, PERT_used=0.1200090949 → LR_next=0.1293785336, PERT_next=0.1200106808\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1280895030→0.1293785336 PERT 0.1200090949→0.1200106808\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.445903 step=0.0188 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.129638 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.445254 step=0.01148 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.129898 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.443187 step=0.04563 g_raw=+0.017 g_sm=+0.011 acc=1 | LR→0.130158 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.438884 step=0.06393 g_raw=+0.026 g_sm=+0.013 acc=1 | LR→0.130419 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.437663 step=0.006704 g_raw=+0.002 g_sm=+0.012 acc=1 | LR→0.130680 PERT→0.120012 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1293785336, PERT_used=0.1200106808 → LR_next=0.1306803954, PERT_next=0.1200121372\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1293785336→0.1306803954 PERT 0.1200106808→0.1200121372\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.435938 step=0.05654 g_raw=+0.025 g_sm=+0.011 acc=1 | LR→0.130942 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.435423 step=0.009709 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.131205 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.434004 step=0.01093 g_raw=+0.003 g_sm=+0.009 acc=1 | LR→0.131468 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.432553 step=0.03285 g_raw=+0.016 g_sm=+0.009 acc=1 | LR→0.131731 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.431258 step=0.008762 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.131995 PERT→0.120013 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1306803954, PERT_used=0.1200121372 → LR_next=0.1319950690, PERT_next=0.1200133317\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1306803954→0.1319950690 PERT 0.1200121372→0.1200133317\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.70\n",
            "[round 3 | client 3] final LR=0.1319950690, final PERT=0.1200133317  (ΔLR=+0.0064447923, ΔPERT=+0.0000069937)\n",
            "[round 3 | client 4] seed LR=0.1255505867 (prev=0.1311011734), seed PERT=0.1200066034 (prev=0.1200132067), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.489000 step=0.04759 g_raw=+0.019 g_sm=+0.004 acc=1 | LR→0.125802 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.488470 step=0.02308 g_raw=+0.008 g_sm=+0.004 acc=1 | LR→0.126054 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.487518 step=0.02583 g_raw=+0.013 g_sm=+0.005 acc=1 | LR→0.126306 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.485402 step=0.003665 g_raw=+0.001 g_sm=+0.007 acc=1 | LR→0.126559 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.481479 step=0.03831 g_raw=+0.019 g_sm=+0.009 acc=1 | LR→0.126813 PERT→0.120007 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1255505867, PERT_used=0.1200066034 → LR_next=0.1268130142, PERT_next=0.1200071931\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1255505867→0.1268130142 PERT 0.1200066034→0.1200071931\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.63\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.477943 step=0.02941 g_raw=+0.012 g_sm=+0.011 acc=1 | LR→0.127067 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.471365 step=0.03662 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.127322 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.470019 step=0.0229 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.127577 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.466657 step=0.01748 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.127833 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.466048 step=0.01274 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.128089 PERT→0.120009 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1268130142, PERT_used=0.1200071931 → LR_next=0.1280890455, PERT_next=0.1200086353\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1268130142→0.1280890455 PERT 0.1200071931→0.1200086353\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.463175 step=0.0589 g_raw=+0.026 g_sm=+0.012 acc=1 | LR→0.128346 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.460453 step=0.04202 g_raw=+0.017 g_sm=+0.012 acc=1 | LR→0.128603 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.458827 step=0.01212 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.128861 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.457352 step=0.005409 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.129119 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.454192 step=0.01428 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.129378 PERT→0.120010 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1280890455, PERT_used=0.1200086353 → LR_next=0.1293778695, PERT_next=0.1200100338\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1280890455→0.1293778695 PERT 0.1200086353→0.1200100338\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.452454 step=0.02789 g_raw=+0.014 g_sm=+0.011 acc=1 | LR→0.129637 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.452042 step=0.01841 g_raw=+0.009 g_sm=+0.010 acc=1 | LR→0.129897 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.450683 step=0.0416 g_raw=+0.017 g_sm=+0.010 acc=1 | LR→0.130157 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.448879 step=0.007882 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.130418 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.445280 step=0.04385 g_raw=+0.019 g_sm=+0.010 acc=1 | LR→0.130679 PERT→0.120011 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1293778695, PERT_used=0.1200100338 → LR_next=0.1306794995, PERT_next=0.1200112835\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1293778695→0.1306794995 PERT 0.1200100338→0.1200112835\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.442162 step=0.00453 g_raw=+0.001 g_sm=+0.010 acc=1 | LR→0.130941 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.440993 step=0.01956 g_raw=+0.008 g_sm=+0.010 acc=1 | LR→0.131204 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.439945 step=0.003888 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.131467 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.438934 step=0.003029 g_raw=-0.001 g_sm=+0.009 acc=1 | LR→0.131730 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#125 loss=0.437518 step=0.00164 g_raw=+0.001 g_sm=+0.009 acc=1 | LR→0.131994 PERT→0.120012 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1306794995, PERT_used=0.1200112835 → LR_next=0.1319941404, PERT_next=0.1200124565\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1306794995→0.1319941404 PERT 0.1200112835→0.1200124565\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.70\n",
            "[round 3 | client 4] final LR=0.1319941404, final PERT=0.1200124565  (ΔLR=+0.0064435537, ΔPERT=+0.0000058531)\n",
            "\n",
            "[Round 3] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           2      0.548633      0.725000      0.131995      0.120013\n",
            "           4      0.600738      0.705000      0.131994      0.120012\n",
            "           0      0.607891      0.585000      0.131994      0.120012\n",
            "           1      0.608150      0.655000      0.131997      0.120015\n",
            "           3      0.614373      0.700000      0.131995      0.120013\n",
            "→ [Round 3] best_client=2, best_val=0.548633, prev_global_val=0.541963, improve=-0.006670, action=hold (τ=0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  40%|████      | 4/10 [36:37<54:25, 544.21s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   3] acc_g=0.760 (μ=0.674, σ=0.050, FG=0.104) | t=525.329s, val=0.538 | TEL=FALSE\n",
            "[Round 4] Teleportation OFF | Aggregation=best\n",
            "[round 4 | client 0] seed LR=0.1259969201 (prev=0.1319938401), seed PERT=0.1200061334 (prev=0.1200122668), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.509543 step=0.00711 g_raw=+0.005 g_sm=+0.002 acc=1 | LR→0.126249 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.503936 step=0.0141 g_raw=+0.006 g_sm=+0.006 acc=1 | LR→0.126502 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.498566 step=0.01058 g_raw=+0.005 g_sm=+0.009 acc=1 | LR→0.126756 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.493394 step=0.0101 g_raw=+0.006 g_sm=+0.010 acc=1 | LR→0.127010 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.489521 step=0.03003 g_raw=+0.014 g_sm=+0.011 acc=1 | LR→0.127264 PERT→0.120007 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1259969201, PERT_used=0.1200061334 → LR_next=0.1272640860, PERT_next=0.1200069593\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1259969201→0.1272640860 PERT 0.1200061334→0.1200069593\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.38\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.483618 step=0.05743 g_raw=+0.026 g_sm=+0.013 acc=1 | LR→0.127519 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.475666 step=0.02562 g_raw=+0.010 g_sm=+0.015 acc=1 | LR→0.127775 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.464381 step=0.09746 g_raw=+0.038 g_sm=+0.018 acc=1 | LR→0.128031 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.458729 step=0.05785 g_raw=+0.023 g_sm=+0.019 acc=1 | LR→0.128288 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.455341 step=0.01754 g_raw=+0.007 g_sm=+0.018 acc=1 | LR→0.128545 PERT→0.120009 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1272640860, PERT_used=0.1200069593 → LR_next=0.1285451897, PERT_next=0.1200088996\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1272640860→0.1285451897 PERT 0.1200069593→0.1200088996\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.439434 step=0.05752 g_raw=+0.024 g_sm=+0.022 acc=1 | LR→0.128803 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.428710 step=0.04653 g_raw=+0.019 g_sm=+0.021 acc=1 | LR→0.129062 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.420507 step=0.07091 g_raw=+0.028 g_sm=+0.021 acc=1 | LR→0.129320 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.418669 step=0.03595 g_raw=+0.014 g_sm=+0.019 acc=1 | LR→0.129580 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#075 loss=0.411652 step=0.02701 g_raw=+0.013 g_sm=+0.019 acc=1 | LR→0.129840 PERT→0.120011 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1285451897, PERT_used=0.1200088996 → LR_next=0.1298397571, PERT_next=0.1200113645\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.022 g_sm_mean=+0.021 acc_ratio=1.00 | LR 0.1285451897→0.1298397571 PERT 0.1200088996→0.1200113645\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.410840 step=0.005027 g_raw=+0.006 g_sm=+0.016 acc=1 | LR→0.130100 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#085 loss=0.405499 step=0.02702 g_raw=+0.011 g_sm=+0.016 acc=1 | LR→0.130361 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#090 loss=0.401173 step=0.01466 g_raw=+0.007 g_sm=+0.016 acc=1 | LR→0.130622 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#095 loss=0.396957 step=0.001984 g_raw=+0.002 g_sm=+0.016 acc=1 | LR→0.130884 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#100 loss=0.394529 step=0.03304 g_raw=+0.014 g_sm=+0.015 acc=1 | LR→0.131147 PERT→0.120013 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1298397571, PERT_used=0.1200113645 → LR_next=0.1311468311, PERT_next=0.1200133437\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1298397571→0.1311468311 PERT 0.1200113645→0.1200133437\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.394348 step=0.01289 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.131410 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#110 loss=0.391056 step=0.01742 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.131673 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#115 loss=0.390461 step=0.01775 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.131937 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#120 loss=0.388101 step=0.02095 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.132202 PERT→0.120015 (scale=0.04)\n",
            "[meta] cb#125 loss=0.387594 step=0.007594 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.132466 PERT→0.120015 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1311468311, PERT_used=0.1200133437 → LR_next=0.1324664954, PERT_next=0.1200148085\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1311468311→0.1324664954 PERT 0.1200133437→0.1200148085\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.58\n",
            "[round 4 | client 0] final LR=0.1324664954, final PERT=0.1200148085  (ΔLR=+0.0064695754, ΔPERT=+0.0000086751)\n",
            "[round 4 | client 1] seed LR=0.1259985150 (prev=0.1319970300), seed PERT=0.1200075323 (prev=0.1200150646), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.506638 step=0.08366 g_raw=+0.035 g_sm=+0.004 acc=1 | LR→0.126251 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.502849 step=0.04317 g_raw=+0.018 g_sm=+0.006 acc=1 | LR→0.126504 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.495634 step=0.04282 g_raw=+0.017 g_sm=+0.010 acc=1 | LR→0.126757 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.488189 step=0.0714 g_raw=+0.029 g_sm=+0.013 acc=1 | LR→0.127011 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.484572 step=0.02432 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.127266 PERT→0.120009 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1259985150, PERT_used=0.1200075323 → LR_next=0.1272658983, PERT_next=0.1200085480\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1259985150→0.1272658983 PERT 0.1200075323→0.1200085480\n",
            "Training Accuracy: 0.56\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.475490 step=0.07667 g_raw=+0.030 g_sm=+0.016 acc=1 | LR→0.127521 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.473364 step=0.01224 g_raw=+0.005 g_sm=+0.015 acc=1 | LR→0.127777 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.470783 step=0.06724 g_raw=+0.025 g_sm=+0.014 acc=1 | LR→0.128033 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#045 loss=0.470477 step=0.003372 g_raw=+0.002 g_sm=+0.012 acc=1 | LR→0.128290 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.463985 step=0.09429 g_raw=+0.039 g_sm=+0.014 acc=1 | LR→0.128547 PERT→0.120010 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1272658983, PERT_used=0.1200085480 → LR_next=0.1285467218, PERT_next=0.1200102098\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1272658983→0.1285467218 PERT 0.1200085480→0.1200102098\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.455883 step=0.04486 g_raw=+0.022 g_sm=+0.016 acc=1 | LR→0.128804 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#060 loss=0.450614 step=0.0164 g_raw=+0.009 g_sm=+0.016 acc=1 | LR→0.129063 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.444723 step=0.0244 g_raw=+0.009 g_sm=+0.016 acc=1 | LR→0.129322 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#070 loss=0.442059 step=0.02065 g_raw=+0.009 g_sm=+0.015 acc=1 | LR→0.129581 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#075 loss=0.436961 step=0.02119 g_raw=+0.008 g_sm=+0.015 acc=1 | LR→0.129841 PERT→0.120012 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1285467218, PERT_used=0.1200102098 → LR_next=0.1298406952, PERT_next=0.1200121114\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1285467218→0.1298406952 PERT 0.1200102098→0.1200121114\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.434842 step=0.03265 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.130101 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#085 loss=0.429057 step=0.0722 g_raw=+0.028 g_sm=+0.015 acc=1 | LR→0.130362 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#090 loss=0.425805 step=0.03646 g_raw=+0.014 g_sm=+0.015 acc=1 | LR→0.130623 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#095 loss=0.422903 step=0.001114 g_raw=-0.001 g_sm=+0.014 acc=1 | LR→0.130885 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#100 loss=0.418570 step=0.02733 g_raw=+0.010 g_sm=+0.014 acc=1 | LR→0.131148 PERT→0.120014 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1298406952, PERT_used=0.1200121114 → LR_next=0.1311475186, PERT_next=0.1200138526\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1298406952→0.1311475186 PERT 0.1200121114→0.1200138526\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.57\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.414477 step=0.02918 g_raw=+0.012 g_sm=+0.015 acc=1 | LR→0.131410 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#110 loss=0.409883 step=0.03042 g_raw=+0.011 g_sm=+0.015 acc=1 | LR→0.131674 PERT→0.120015 (scale=0.04)\n",
            "[meta] cb#115 loss=0.399921 step=0.02487 g_raw=+0.011 g_sm=+0.018 acc=1 | LR→0.131938 PERT→0.120015 (scale=0.04)\n",
            "[meta] cb#120 loss=0.396808 step=0.0595 g_raw=+0.021 g_sm=+0.017 acc=1 | LR→0.132203 PERT→0.120015 (scale=0.04)\n",
            "[meta] cb#125 loss=0.392322 step=0.00184 g_raw=+0.001 g_sm=+0.016 acc=1 | LR→0.132468 PERT→0.120016 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1311475186, PERT_used=0.1200138526 → LR_next=0.1324677106, PERT_next=0.1200157892\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1311475186→0.1324677106 PERT 0.1200138526→0.1200157892\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.58\n",
            "[round 4 | client 1] final LR=0.1324677106, final PERT=0.1200157892  (ΔLR=+0.0064691956, ΔPERT=+0.0000082569)\n",
            "[round 4 | client 2] seed LR=0.1259975480 (prev=0.1319950959), seed PERT=0.1200066637 (prev=0.1200133274), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.499672 step=0.01726 g_raw=+0.005 g_sm=+0.001 acc=1 | LR→0.126250 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.498441 step=0.0463 g_raw=+0.019 g_sm=+0.003 acc=1 | LR→0.126503 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.495996 step=0.04288 g_raw=+0.017 g_sm=+0.005 acc=1 | LR→0.126756 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.491479 step=0.08174 g_raw=+0.034 g_sm=+0.008 acc=1 | LR→0.127010 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.490131 step=0.01254 g_raw=+0.006 g_sm=+0.008 acc=1 | LR→0.127264 PERT→0.120007 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1259975480, PERT_used=0.1200066637 → LR_next=0.1272643532, PERT_next=0.1200071435\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.004 acc_ratio=1.00 | LR 0.1259975480→0.1272643532 PERT 0.1200066637→0.1200071435\n",
            "Training Accuracy: 0.52\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.486287 step=0.02381 g_raw=+0.011 g_sm=+0.010 acc=1 | LR→0.127519 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.482815 step=0.06863 g_raw=+0.029 g_sm=+0.011 acc=1 | LR→0.127775 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.480990 step=0.01437 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.128031 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.478241 step=0.03855 g_raw=+0.016 g_sm=+0.011 acc=1 | LR→0.128288 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.476880 step=0.01953 g_raw=+0.007 g_sm=+0.010 acc=1 | LR→0.128545 PERT→0.120008 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1272643532, PERT_used=0.1200071435 → LR_next=0.1285446983, PERT_next=0.1200083731\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1272643532→0.1285446983 PERT 0.1200071435→0.1200083731\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.475518 step=0.03564 g_raw=+0.015 g_sm=+0.010 acc=1 | LR→0.128802 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.472352 step=0.02374 g_raw=+0.011 g_sm=+0.011 acc=1 | LR→0.129060 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.470964 step=0.0237 g_raw=+0.010 g_sm=+0.010 acc=1 | LR→0.129319 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.470613 step=0.00697 g_raw=+0.004 g_sm=+0.009 acc=1 | LR→0.129578 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#075 loss=0.468059 step=0.02435 g_raw=+0.009 g_sm=+0.010 acc=1 | LR→0.129838 PERT→0.120010 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1285446983, PERT_used=0.1200083731 → LR_next=0.1298379071, PERT_next=0.1200095868\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1285446983→0.1298379071 PERT 0.1200083731→0.1200095868\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.58\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.465960 step=0.01739 g_raw=+0.006 g_sm=+0.010 acc=1 | LR→0.130098 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.464752 step=0.002959 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.130359 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#090 loss=0.463175 step=0.009204 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.130620 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#095 loss=0.462447 step=0.02893 g_raw=+0.010 g_sm=+0.009 acc=1 | LR→0.130882 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.461056 step=0.02169 g_raw=+0.009 g_sm=+0.009 acc=1 | LR→0.131144 PERT→0.120011 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1298379071, PERT_used=0.1200095868 → LR_next=0.1311440523, PERT_next=0.1200107331\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1298379071→0.1311440523 PERT 0.1200095868→0.1200107331\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.459912 step=0.003239 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.131407 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#110 loss=0.454669 step=0.06353 g_raw=+0.028 g_sm=+0.011 acc=1 | LR→0.131670 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#115 loss=0.454175 step=0.009444 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.131934 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#120 loss=0.451772 step=0.03199 g_raw=+0.015 g_sm=+0.011 acc=1 | LR→0.132198 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#125 loss=0.450386 step=0.02185 g_raw=+0.011 g_sm=+0.010 acc=1 | LR→0.132463 PERT→0.120012 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1311440523, PERT_used=0.1200107331 → LR_next=0.1324634166, PERT_next=0.1200119513\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1311440523→0.1324634166 PERT 0.1200107331→0.1200119513\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.65\n",
            "[round 4 | client 2] final LR=0.1324634166, final PERT=0.1200119513  (ΔLR=+0.0064658687, ΔPERT=+0.0000052876)\n",
            "[round 4 | client 3] seed LR=0.1259975345 (prev=0.1319950690), seed PERT=0.1200066659 (prev=0.1200133317), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.443065 step=0.03983 g_raw=+0.016 g_sm=+0.004 acc=1 | LR→0.126250 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.439108 step=0.03679 g_raw=+0.016 g_sm=+0.007 acc=1 | LR→0.126503 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.435680 step=0.04267 g_raw=+0.017 g_sm=+0.009 acc=1 | LR→0.126756 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.427788 step=0.01221 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.127010 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.422221 step=0.03356 g_raw=+0.014 g_sm=+0.013 acc=1 | LR→0.127265 PERT→0.120008 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1259975345, PERT_used=0.1200066659 → LR_next=0.1272648245, PERT_next=0.1200076029\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1259975345→0.1272648245 PERT 0.1200066659→0.1200076029\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.85\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.418015 step=0.07031 g_raw=+0.026 g_sm=+0.013 acc=1 | LR→0.127520 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.411405 step=0.03497 g_raw=+0.014 g_sm=+0.015 acc=1 | LR→0.127776 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.409806 step=0.04987 g_raw=+0.022 g_sm=+0.014 acc=1 | LR→0.128032 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.407671 step=0.02827 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.128288 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.404219 step=0.003567 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.128546 PERT→0.120009 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1272648245, PERT_used=0.1200076029 → LR_next=0.1285456188, PERT_next=0.1200092475\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1272648245→0.1285456188 PERT 0.1200076029→0.1200092475\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.85\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.397150 step=0.05996 g_raw=+0.026 g_sm=+0.015 acc=1 | LR→0.128803 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.396649 step=0.003748 g_raw=+0.003 g_sm=+0.013 acc=1 | LR→0.129062 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.392669 step=0.07361 g_raw=+0.029 g_sm=+0.014 acc=1 | LR→0.129320 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.387810 step=0.0123 g_raw=+0.005 g_sm=+0.014 acc=1 | LR→0.129580 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#075 loss=0.384086 step=0.03582 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.129839 PERT→0.120011 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1285456188, PERT_used=0.1200092475 → LR_next=0.1298393367, PERT_next=0.1200109233\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1285456188→0.1298393367 PERT 0.1200092475→0.1200109233\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.83\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.380333 step=0.04726 g_raw=+0.021 g_sm=+0.015 acc=1 | LR→0.130100 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.379007 step=0.03318 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.130360 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#090 loss=0.377866 step=0.02442 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.130622 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.376543 step=0.02226 g_raw=+0.010 g_sm=+0.012 acc=1 | LR→0.130884 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.375265 step=0.04308 g_raw=+0.019 g_sm=+0.011 acc=1 | LR→0.131146 PERT→0.120012 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1298393367, PERT_used=0.1200109233 → LR_next=0.1311459418, PERT_next=0.1200124771\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1298393367→0.1311459418 PERT 0.1200109233→0.1200124771\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.84\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.373959 step=0.04695 g_raw=+0.019 g_sm=+0.010 acc=1 | LR→0.131409 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#110 loss=0.373328 step=0.004561 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.131672 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.370325 step=0.03894 g_raw=+0.014 g_sm=+0.010 acc=1 | LR→0.131936 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.368752 step=0.004619 g_raw=+0.001 g_sm=+0.010 acc=1 | LR→0.132200 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.366995 step=0.04064 g_raw=+0.015 g_sm=+0.010 acc=1 | LR→0.132465 PERT→0.120014 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1311459418, PERT_used=0.1200124771 → LR_next=0.1324653107, PERT_next=0.1200136824\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1311459418→0.1324653107 PERT 0.1200124771→0.1200136824\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.88\n",
            "[round 4 | client 3] final LR=0.1324653107, final PERT=0.1200136824  (ΔLR=+0.0064677762, ΔPERT=+0.0000070165)\n",
            "[round 4 | client 4] seed LR=0.1259970702 (prev=0.1319941404), seed PERT=0.1200062282 (prev=0.1200124565), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.537015 step=0.009822 g_raw=+0.006 g_sm=+0.002 acc=1 | LR→0.126249 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.535808 step=0.02149 g_raw=+0.007 g_sm=+0.003 acc=1 | LR→0.126502 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.525907 step=0.08459 g_raw=+0.034 g_sm=+0.008 acc=1 | LR→0.126756 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.524743 step=0.02687 g_raw=+0.013 g_sm=+0.009 acc=1 | LR→0.127010 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.522494 step=0.0286 g_raw=+0.012 g_sm=+0.009 acc=1 | LR→0.127264 PERT→0.120007 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1259970702, PERT_used=0.1200062282 → LR_next=0.1272640573, PERT_next=0.1200068841\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1259970702→0.1272640573 PERT 0.1200062282→0.1200068841\n",
            "Training Accuracy: 0.44\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.512836 step=0.05547 g_raw=+0.023 g_sm=+0.013 acc=1 | LR→0.127519 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.507942 step=0.02166 g_raw=+0.011 g_sm=+0.013 acc=1 | LR→0.127775 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#040 loss=0.506808 step=0.0004121 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.128031 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.503154 step=0.04541 g_raw=+0.019 g_sm=+0.013 acc=1 | LR→0.128288 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.500349 step=0.05975 g_raw=+0.024 g_sm=+0.013 acc=1 | LR→0.128545 PERT→0.120008 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1272640573, PERT_used=0.1200068841 → LR_next=0.1285447059, PERT_next=0.1200083998\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1272640573→0.1285447059 PERT 0.1200068841→0.1200083998\n",
            "Training Accuracy: 0.44\n",
            "Test Accuracy: 0.57\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.496169 step=0.0248 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.128802 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.495119 step=0.002868 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.129061 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.491333 step=0.07924 g_raw=+0.035 g_sm=+0.013 acc=1 | LR→0.129319 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.487713 step=0.03425 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.129579 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.483315 step=0.05345 g_raw=+0.025 g_sm=+0.014 acc=1 | LR→0.129838 PERT→0.120010 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1285447059, PERT_used=0.1200083998 → LR_next=0.1298382757, PERT_next=0.1200099471\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1285447059→0.1298382757 PERT 0.1200083998→0.1200099471\n",
            "Training Accuracy: 0.54\n",
            "Test Accuracy: 0.63\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.479030 step=0.02435 g_raw=+0.012 g_sm=+0.015 acc=1 | LR→0.130099 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.476584 step=0.05491 g_raw=+0.024 g_sm=+0.014 acc=1 | LR→0.130359 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.469789 step=0.03167 g_raw=+0.014 g_sm=+0.016 acc=1 | LR→0.130621 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.466871 step=0.01839 g_raw=+0.009 g_sm=+0.015 acc=1 | LR→0.130883 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.462649 step=0.04233 g_raw=+0.017 g_sm=+0.015 acc=1 | LR→0.131145 PERT→0.120012 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1298382757, PERT_used=0.1200099471 → LR_next=0.1311451577, PERT_next=0.1200117642\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1298382757→0.1311451577 PERT 0.1200099471→0.1200117642\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.60\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.456405 step=0.06631 g_raw=+0.027 g_sm=+0.016 acc=1 | LR→0.131408 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.452413 step=0.0554 g_raw=+0.025 g_sm=+0.017 acc=1 | LR→0.131672 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.447678 step=0.03607 g_raw=+0.015 g_sm=+0.017 acc=1 | LR→0.131936 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.442294 step=0.05036 g_raw=+0.019 g_sm=+0.017 acc=1 | LR→0.132200 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.438223 step=0.004291 g_raw=+0.001 g_sm=+0.017 acc=1 | LR→0.132465 PERT→0.120014 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1311451577, PERT_used=0.1200117642 → LR_next=0.1324653798, PERT_next=0.1200137496\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1311451577→0.1324653798 PERT 0.1200117642→0.1200137496\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.61\n",
            "[round 4 | client 4] final LR=0.1324653798, final PERT=0.1200137496  (ΔLR=+0.0064683096, ΔPERT=+0.0000075214)\n",
            "\n",
            "[Round 4] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           3      0.466611      0.875000      0.132465      0.120014\n",
            "           4      0.616275      0.610000      0.132465      0.120014\n",
            "           2      0.630216      0.645000      0.132463      0.120012\n",
            "           1      0.635209      0.580000      0.132468      0.120016\n",
            "           0      0.648475      0.585000      0.132466      0.120015\n",
            "→ [Round 4] best_client=3, best_val=0.466611, prev_global_val=0.538264, improve=+0.071654, action=adopt+mix τ=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  50%|█████     | 5/10 [45:30<45:00, 540.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   4] acc_g=0.826 (μ=0.659, σ=0.110, FG=0.201) | t=522.805s, val=0.569 | TEL=FALSE\n",
            "[Round 5] Teleportation OFF | Aggregation=best\n",
            "[round 5 | client 0] seed LR=0.1262332477 (prev=0.1324664954), seed PERT=0.1200074042 (prev=0.1200148085), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.466995 step=0.02117 g_raw=+0.010 g_sm=+0.001 acc=1 | LR→0.126486 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.464905 step=0.05008 g_raw=+0.022 g_sm=+0.004 acc=1 | LR→0.126739 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.461680 step=0.05716 g_raw=+0.023 g_sm=+0.006 acc=1 | LR→0.126993 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.458975 step=0.00966 g_raw=+0.004 g_sm=+0.008 acc=1 | LR→0.127248 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.456950 step=0.01646 g_raw=+0.007 g_sm=+0.009 acc=1 | LR→0.127503 PERT→0.120008 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1262332477, PERT_used=0.1200074042 → LR_next=0.1275025150, PERT_next=0.1200079709\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1262332477→0.1275025150 PERT 0.1200074042→0.1200079709\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.455351 step=0.02634 g_raw=+0.010 g_sm=+0.009 acc=1 | LR→0.127758 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.453938 step=0.004451 g_raw=+0.002 g_sm=+0.008 acc=1 | LR→0.128014 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.451964 step=0.03204 g_raw=+0.013 g_sm=+0.009 acc=1 | LR→0.128271 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.449647 step=0.009681 g_raw=+0.005 g_sm=+0.009 acc=1 | LR→0.128528 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.446454 step=0.008257 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.128785 PERT→0.120009 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1275025150, PERT_used=0.1200079709 → LR_next=0.1287851347, PERT_next=0.1200090874\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1275025150→0.1287851347 PERT 0.1200079709→0.1200090874\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.445497 step=0.01116 g_raw=+0.006 g_sm=+0.010 acc=1 | LR→0.129043 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.444989 step=0.01165 g_raw=+0.005 g_sm=+0.009 acc=1 | LR→0.129302 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.442390 step=0.03176 g_raw=+0.014 g_sm=+0.010 acc=1 | LR→0.129561 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.441463 step=0.00426 g_raw=-0.001 g_sm=+0.009 acc=1 | LR→0.129821 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.441261 step=0.007352 g_raw=+0.003 g_sm=+0.008 acc=1 | LR→0.130081 PERT→0.120010 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1287851347, PERT_used=0.1200090874 → LR_next=0.1300806606, PERT_next=0.1200102072\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1287851347→0.1300806606 PERT 0.1200090874→0.1200102072\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.440159 step=0.002633 g_raw=-0.000 g_sm=+0.008 acc=1 | LR→0.130341 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.438973 step=0.02675 g_raw=+0.013 g_sm=+0.008 acc=1 | LR→0.130602 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.437839 step=0.0002088 g_raw=+0.000 g_sm=+0.008 acc=1 | LR→0.130864 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.436728 step=0.004851 g_raw=+0.000 g_sm=+0.007 acc=1 | LR→0.131126 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.436243 step=0.006783 g_raw=+0.003 g_sm=+0.007 acc=1 | LR→0.131389 PERT→0.120011 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1300806606, PERT_used=0.1200102072 → LR_next=0.1313889743, PERT_next=0.1200111035\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1300806606→0.1313889743 PERT 0.1200102072→0.1200111035\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.435802 step=0.01686 g_raw=+0.006 g_sm=+0.006 acc=1 | LR→0.131652 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#110 loss=0.434237 step=0.01297 g_raw=+0.005 g_sm=+0.007 acc=1 | LR→0.131916 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#115 loss=0.433189 step=0.001817 g_raw=+0.002 g_sm=+0.007 acc=1 | LR→0.132180 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.431863 step=0.0009135 g_raw=+0.000 g_sm=+0.008 acc=1 | LR→0.132445 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#125 loss=0.430865 step=0.02681 g_raw=+0.011 g_sm=+0.008 acc=1 | LR→0.132710 PERT→0.120012 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1313889743, PERT_used=0.1200111035 → LR_next=0.1327104153, PERT_next=0.1200119715\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1313889743→0.1327104153 PERT 0.1200111035→0.1200119715\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.74\n",
            "[round 5 | client 0] final LR=0.1327104153, final PERT=0.1200119715  (ΔLR=+0.0064771676, ΔPERT=+0.0000045673)\n",
            "[round 5 | client 1] seed LR=0.1262338553 (prev=0.1324677106), seed PERT=0.1200078946 (prev=0.1200157892), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.483655 step=0.05376 g_raw=+0.022 g_sm=+0.005 acc=1 | LR→0.126487 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.480200 step=0.03184 g_raw=+0.014 g_sm=+0.007 acc=1 | LR→0.126740 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.474917 step=0.03341 g_raw=+0.014 g_sm=+0.009 acc=1 | LR→0.126994 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.473507 step=0.03145 g_raw=+0.014 g_sm=+0.010 acc=1 | LR→0.127248 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#025 loss=0.471013 step=0.04867 g_raw=+0.019 g_sm=+0.011 acc=1 | LR→0.127503 PERT→0.120009 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1262338553, PERT_used=0.1200078946 → LR_next=0.1275034652, PERT_next=0.1200087780\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1262338553→0.1275034652 PERT 0.1200078946→0.1200087780\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.466052 step=0.02868 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.127759 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.463329 step=0.06604 g_raw=+0.024 g_sm=+0.012 acc=1 | LR→0.128015 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.458047 step=0.06147 g_raw=+0.025 g_sm=+0.014 acc=1 | LR→0.128272 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#045 loss=0.455200 step=0.03631 g_raw=+0.015 g_sm=+0.014 acc=1 | LR→0.128529 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.450896 step=0.06825 g_raw=+0.028 g_sm=+0.015 acc=1 | LR→0.128787 PERT→0.120010 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1275034652, PERT_used=0.1200087780 → LR_next=0.1287865688, PERT_next=0.1200103365\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1275034652→0.1287865688 PERT 0.1200087780→0.1200103365\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.55\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.443986 step=0.004433 g_raw=+0.003 g_sm=+0.016 acc=1 | LR→0.129045 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#060 loss=0.435007 step=0.06556 g_raw=+0.025 g_sm=+0.017 acc=1 | LR→0.129304 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.432671 step=0.0478 g_raw=+0.019 g_sm=+0.016 acc=1 | LR→0.129563 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#070 loss=0.427159 step=0.0112 g_raw=+0.006 g_sm=+0.016 acc=1 | LR→0.129823 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#075 loss=0.425518 step=0.06148 g_raw=+0.023 g_sm=+0.014 acc=1 | LR→0.130083 PERT→0.120012 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1287865688, PERT_used=0.1200103365 → LR_next=0.1300829611, PERT_next=0.1200122424\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1287865688→0.1300829611 PERT 0.1200103365→0.1200122424\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.60\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.423507 step=0.02448 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.130344 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#085 loss=0.418732 step=0.04079 g_raw=+0.019 g_sm=+0.014 acc=1 | LR→0.130605 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#090 loss=0.414830 step=0.00235 g_raw=+0.002 g_sm=+0.014 acc=1 | LR→0.130867 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#095 loss=0.412786 step=0.05197 g_raw=+0.020 g_sm=+0.014 acc=1 | LR→0.131129 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#100 loss=0.410431 step=0.008915 g_raw=+0.003 g_sm=+0.013 acc=1 | LR→0.131392 PERT→0.120014 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1300829611, PERT_used=0.1200122424 → LR_next=0.1313920868, PERT_next=0.1200138593\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1300829611→0.1313920868 PERT 0.1200122424→0.1200138593\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.402560 step=0.03146 g_raw=+0.011 g_sm=+0.015 acc=1 | LR→0.131656 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#110 loss=0.397515 step=0.08426 g_raw=+0.030 g_sm=+0.015 acc=1 | LR→0.131919 PERT→0.120015 (scale=0.04)\n",
            "[meta] cb#115 loss=0.393512 step=0.07551 g_raw=+0.028 g_sm=+0.015 acc=1 | LR→0.132184 PERT→0.120015 (scale=0.04)\n",
            "[meta] cb#120 loss=0.386527 step=0.02117 g_raw=+0.009 g_sm=+0.016 acc=1 | LR→0.132449 PERT→0.120015 (scale=0.04)\n",
            "[meta] cb#125 loss=0.384768 step=0.008493 g_raw=+0.003 g_sm=+0.015 acc=1 | LR→0.132715 PERT→0.120016 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1313920868, PERT_used=0.1200138593 → LR_next=0.1327145702, PERT_next=0.1200156416\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1313920868→0.1327145702 PERT 0.1200138593→0.1200156416\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.68\n",
            "[round 5 | client 1] final LR=0.1327145702, final PERT=0.1200156416  (ΔLR=+0.0064807149, ΔPERT=+0.0000077470)\n",
            "[round 5 | client 2] seed LR=0.1262317083 (prev=0.1324634166), seed PERT=0.1200059757 (prev=0.1200119513), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.453307 step=0.0634 g_raw=+0.025 g_sm=+0.003 acc=1 | LR→0.126484 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.444672 step=0.04064 g_raw=+0.017 g_sm=+0.007 acc=1 | LR→0.126738 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.438689 step=0.02089 g_raw=+0.009 g_sm=+0.010 acc=1 | LR→0.126992 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.435619 step=0.01521 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.127246 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.427728 step=0.0646 g_raw=+0.026 g_sm=+0.012 acc=1 | LR→0.127501 PERT→0.120007 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1262317083, PERT_used=0.1200059757 → LR_next=0.1275013336, PERT_next=0.1200068938\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1262317083→0.1275013336 PERT 0.1200059757→0.1200068938\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.422494 step=0.006454 g_raw=+0.002 g_sm=+0.014 acc=1 | LR→0.127757 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.415057 step=0.09051 g_raw=+0.037 g_sm=+0.016 acc=1 | LR→0.128013 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.405285 step=0.005032 g_raw=+0.001 g_sm=+0.017 acc=1 | LR→0.128270 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.404245 step=0.009505 g_raw=+0.006 g_sm=+0.015 acc=1 | LR→0.128527 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.400626 step=0.05254 g_raw=+0.021 g_sm=+0.015 acc=1 | LR→0.128785 PERT→0.120009 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1275013336, PERT_used=0.1200068938 → LR_next=0.1287847199, PERT_next=0.1200087357\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1275013336→0.1287847199 PERT 0.1200068938→0.1200087357\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.396267 step=0.02117 g_raw=+0.009 g_sm=+0.016 acc=1 | LR→0.129043 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.393130 step=0.0366 g_raw=+0.018 g_sm=+0.016 acc=1 | LR→0.129302 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.389171 step=0.001204 g_raw=+0.001 g_sm=+0.015 acc=1 | LR→0.129561 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.384369 step=0.02039 g_raw=+0.007 g_sm=+0.015 acc=1 | LR→0.129821 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.381082 step=0.0761 g_raw=+0.030 g_sm=+0.015 acc=1 | LR→0.130081 PERT→0.120011 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1287847199, PERT_used=0.1200087357 → LR_next=0.1300810313, PERT_next=0.1200105841\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1287847199→0.1300810313 PERT 0.1200087357→0.1200105841\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.378448 step=0.07067 g_raw=+0.028 g_sm=+0.014 acc=1 | LR→0.130342 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.375647 step=0.03338 g_raw=+0.014 g_sm=+0.013 acc=1 | LR→0.130603 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.374767 step=0.02424 g_raw=+0.008 g_sm=+0.012 acc=1 | LR→0.130865 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.373895 step=0.002328 g_raw=+0.001 g_sm=+0.011 acc=1 | LR→0.131127 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.370675 step=0.04144 g_raw=+0.015 g_sm=+0.012 acc=1 | LR→0.131390 PERT→0.120012 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1300810313, PERT_used=0.1200105841 → LR_next=0.1313900131, PERT_next=0.1200120873\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1300810313→0.1313900131 PERT 0.1200105841→0.1200120873\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.73\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.369272 step=0.01079 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.131653 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.368225 step=0.01048 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.131917 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.367285 step=0.01229 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.132182 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.366636 step=0.01237 g_raw=+0.006 g_sm=+0.009 acc=1 | LR→0.132446 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.363834 step=0.003886 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.132712 PERT→0.120013 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1313900131, PERT_used=0.1200120873 → LR_next=0.1327118570, PERT_next=0.1200133102\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1313900131→0.1327118570 PERT 0.1200120873→0.1200133102\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.73\n",
            "[round 5 | client 2] final LR=0.1327118570, final PERT=0.1200133102  (ΔLR=+0.0064801487, ΔPERT=+0.0000073346)\n",
            "[round 5 | client 3] seed LR=0.1262326553 (prev=0.1324653107), seed PERT=0.1200068412 (prev=0.1200136824), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.481031 step=0.04963 g_raw=+0.023 g_sm=+0.003 acc=1 | LR→0.126485 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.479594 step=0.006532 g_raw=+0.002 g_sm=+0.004 acc=1 | LR→0.126739 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.474757 step=0.04284 g_raw=+0.016 g_sm=+0.007 acc=1 | LR→0.126993 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.469940 step=0.003074 g_raw=-0.001 g_sm=+0.008 acc=1 | LR→0.127247 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.467522 step=0.05095 g_raw=+0.024 g_sm=+0.009 acc=1 | LR→0.127502 PERT→0.120007 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1262326553, PERT_used=0.1200068412 → LR_next=0.1275020033, PERT_next=0.1200074894\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1262326553→0.1275020033 PERT 0.1200068412→0.1200074894\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.462272 step=0.02206 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.127758 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.461778 step=0.02375 g_raw=+0.013 g_sm=+0.010 acc=1 | LR→0.128014 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.461533 step=0.01689 g_raw=+0.010 g_sm=+0.009 acc=1 | LR→0.128270 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.459888 step=0.01458 g_raw=+0.006 g_sm=+0.009 acc=1 | LR→0.128527 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.457197 step=0.03845 g_raw=+0.013 g_sm=+0.010 acc=1 | LR→0.128785 PERT→0.120009 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1275020033, PERT_used=0.1200074894 → LR_next=0.1287846904, PERT_next=0.1200086735\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1275020033→0.1287846904 PERT 0.1200074894→0.1200086735\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.448468 step=0.08368 g_raw=+0.034 g_sm=+0.014 acc=1 | LR→0.129043 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.445289 step=0.002551 g_raw=+0.002 g_sm=+0.014 acc=1 | LR→0.129302 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.442691 step=0.0266 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.129561 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.440294 step=0.02762 g_raw=+0.011 g_sm=+0.013 acc=1 | LR→0.129821 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.436207 step=0.02674 g_raw=+0.012 g_sm=+0.014 acc=1 | LR→0.130081 PERT→0.120010 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1287846904, PERT_used=0.1200086735 → LR_next=0.1300807552, PERT_next=0.1200102946\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1287846904→0.1300807552 PERT 0.1200086735→0.1200102946\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.57\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.435305 step=0.009791 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.130342 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.425140 step=0.0261 g_raw=+0.011 g_sm=+0.016 acc=1 | LR→0.130603 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.422258 step=0.02559 g_raw=+0.009 g_sm=+0.015 acc=1 | LR→0.130865 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.421475 step=0.01196 g_raw=+0.004 g_sm=+0.013 acc=1 | LR→0.131127 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.417114 step=0.003233 g_raw=-0.000 g_sm=+0.013 acc=1 | LR→0.131390 PERT→0.120012 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1300807552, PERT_used=0.1200102946 → LR_next=0.1313899170, PERT_next=0.1200119647\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1300807552→0.1313899170 PERT 0.1200102946→0.1200119647\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.415249 step=0.05844 g_raw=+0.022 g_sm=+0.013 acc=1 | LR→0.131653 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.412305 step=0.04239 g_raw=+0.018 g_sm=+0.013 acc=1 | LR→0.131917 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.410765 step=0.02069 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.132182 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.410100 step=0.02289 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.132447 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.408093 step=0.01791 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.132712 PERT→0.120013 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1313899170, PERT_used=0.1200119647 → LR_next=0.1327119994, PERT_next=0.1200134042\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1313899170→0.1327119994 PERT 0.1200119647→0.1200134042\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.67\n",
            "[round 5 | client 3] final LR=0.1327119994, final PERT=0.1200134042  (ΔLR=+0.0064793441, ΔPERT=+0.0000065630)\n",
            "[round 5 | client 4] seed LR=0.1262326899 (prev=0.1324653798), seed PERT=0.1200068748 (prev=0.1200137496), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.524676 step=0.008102 g_raw=+0.004 g_sm=+0.002 acc=1 | LR→0.126485 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.520445 step=0.03426 g_raw=+0.015 g_sm=+0.005 acc=1 | LR→0.126739 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.517996 step=0.0005475 g_raw=-0.002 g_sm=+0.006 acc=1 | LR→0.126993 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.508350 step=0.0198 g_raw=+0.008 g_sm=+0.010 acc=1 | LR→0.127247 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.501414 step=0.0003815 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.127502 PERT→0.120008 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1262326899, PERT_used=0.1200068748 → LR_next=0.1275021403, PERT_next=0.1200076191\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1262326899→0.1275021403 PERT 0.1200068748→0.1200076191\n",
            "Training Accuracy: 0.46\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.499873 step=0.008253 g_raw=+0.000 g_sm=+0.011 acc=1 | LR→0.127758 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.497516 step=0.01653 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.128014 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.495074 step=0.01511 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.128270 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.491006 step=0.02073 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.128527 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.488740 step=0.03131 g_raw=+0.013 g_sm=+0.012 acc=1 | LR→0.128785 PERT→0.120009 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1275021403, PERT_used=0.1200076191 → LR_next=0.1287851006, PERT_next=0.1200090565\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1275021403→0.1287851006 PERT 0.1200076191→0.1200090565\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.73\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.485806 step=0.02824 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.129043 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.482648 step=0.07082 g_raw=+0.030 g_sm=+0.013 acc=1 | LR→0.129302 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.480713 step=0.02848 g_raw=+0.011 g_sm=+0.013 acc=1 | LR→0.129561 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.476883 step=0.01985 g_raw=+0.009 g_sm=+0.014 acc=1 | LR→0.129821 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.475204 step=0.03328 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.130081 PERT→0.120011 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1287851006, PERT_used=0.1200090565 → LR_next=0.1300810782, PERT_next=0.1200105933\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1287851006→0.1300810782 PERT 0.1200090565→0.1200105933\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.80\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.470925 step=0.04536 g_raw=+0.018 g_sm=+0.014 acc=1 | LR→0.130342 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.468431 step=0.01548 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.130603 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.466342 step=0.06495 g_raw=+0.028 g_sm=+0.013 acc=1 | LR→0.130865 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.462120 step=0.04926 g_raw=+0.020 g_sm=+0.013 acc=1 | LR→0.131127 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.457606 step=0.001155 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.131390 PERT→0.120012 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1300810782, PERT_used=0.1200105933 → LR_next=0.1313901428, PERT_next=0.1200121717\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1300810782→0.1313901428 PERT 0.1200105933→0.1200121717\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.81\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.454080 step=0.05096 g_raw=+0.020 g_sm=+0.013 acc=1 | LR→0.131654 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.453706 step=0.01418 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.131917 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.450208 step=0.009361 g_raw=+0.005 g_sm=+0.012 acc=1 | LR→0.132182 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.445502 step=0.02967 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.132447 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.443972 step=0.03217 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.132712 PERT→0.120014 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1313901428, PERT_used=0.1200121717 → LR_next=0.1327123166, PERT_next=0.1200136918\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1313901428→0.1327123166 PERT 0.1200121717→0.1200136918\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.82\n",
            "[round 5 | client 4] final LR=0.1327123166, final PERT=0.1200136918  (ΔLR=+0.0064796267, ΔPERT=+0.0000068170)\n",
            "\n",
            "[Round 5] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           2      0.534608      0.735000      0.132712      0.120013\n",
            "           0      0.580125      0.745000      0.132710      0.120012\n",
            "           4      0.580302      0.820000      0.132712      0.120014\n",
            "           3      0.589562      0.665000      0.132712      0.120013\n",
            "           1      0.589589      0.675000      0.132715      0.120016\n",
            "→ [Round 5] best_client=2, best_val=0.534608, prev_global_val=0.569073, improve=+0.034465, action=adopt+mix τ=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  60%|██████    | 6/10 [54:27<35:57, 539.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   5] acc_g=0.733 (μ=0.728, σ=0.056, FG=0.121) | t=527.264s, val=0.550 | TEL=FALSE\n",
            "[Round 6] Teleportation OFF | Aggregation=best\n",
            "[round 6 | client 0] seed LR=0.1263552076 (prev=0.1327104153), seed PERT=0.1200059858 (prev=0.1200119715), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.479000 step=0.01841 g_raw=+0.009 g_sm=+0.001 acc=1 | LR→0.126608 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#010 loss=0.468339 step=0.01222 g_raw=+0.005 g_sm=+0.007 acc=1 | LR→0.126862 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#015 loss=0.462213 step=0.003658 g_raw=-0.001 g_sm=+0.009 acc=1 | LR→0.127116 PERT→0.120006 (scale=0.04)\n",
            "[meta] cb#020 loss=0.449523 step=0.05031 g_raw=+0.021 g_sm=+0.014 acc=1 | LR→0.127371 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.438890 step=0.05526 g_raw=+0.027 g_sm=+0.017 acc=1 | LR→0.127626 PERT→0.120007 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1263552076, PERT_used=0.1200059858 → LR_next=0.1276261588, PERT_next=0.1200069827\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1263552076→0.1276261588 PERT 0.1200059858→0.1200069827\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.434827 step=0.04837 g_raw=+0.020 g_sm=+0.017 acc=1 | LR→0.127882 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#035 loss=0.430468 step=0.02808 g_raw=+0.013 g_sm=+0.017 acc=1 | LR→0.128139 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.425500 step=0.04598 g_raw=+0.020 g_sm=+0.017 acc=1 | LR→0.128396 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.420924 step=0.03091 g_raw=+0.013 g_sm=+0.017 acc=1 | LR→0.128653 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.411587 step=0.0432 g_raw=+0.017 g_sm=+0.019 acc=1 | LR→0.128911 PERT→0.120009 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1276261588, PERT_used=0.1200069827 → LR_next=0.1289110342, PERT_next=0.1200090411\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1276261588→0.1289110342 PERT 0.1200069827→0.1200090411\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.408019 step=0.06691 g_raw=+0.026 g_sm=+0.017 acc=1 | LR→0.129170 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.405044 step=0.01283 g_raw=+0.005 g_sm=+0.016 acc=1 | LR→0.129429 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.400467 step=0.0559 g_raw=+0.024 g_sm=+0.017 acc=1 | LR→0.129688 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.399267 step=0.04326 g_raw=+0.014 g_sm=+0.015 acc=1 | LR→0.129948 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#075 loss=0.397172 step=0.009974 g_raw=+0.005 g_sm=+0.014 acc=1 | LR→0.130209 PERT→0.120011 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1289110342, PERT_used=0.1200090411 → LR_next=0.1302087042, PERT_next=0.1200109699\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1289110342→0.1302087042 PERT 0.1200090411→0.1200109699\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.74\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.392767 step=0.04357 g_raw=+0.019 g_sm=+0.014 acc=1 | LR→0.130470 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.390979 step=0.002343 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.130731 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#090 loss=0.388896 step=0.01682 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.130993 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.387635 step=0.01004 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.131256 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.386477 step=0.01892 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.131519 PERT→0.120012 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1302087042, PERT_used=0.1200109699 → LR_next=0.1315189555, PERT_next=0.1200124591\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1302087042→0.1315189555 PERT 0.1200109699→0.1200124591\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.79\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.384987 step=0.033 g_raw=+0.011 g_sm=+0.010 acc=1 | LR→0.131783 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#110 loss=0.381540 step=0.03653 g_raw=+0.010 g_sm=+0.011 acc=1 | LR→0.132047 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.381101 step=0.02037 g_raw=+0.006 g_sm=+0.010 acc=1 | LR→0.132311 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.380617 step=0.0216 g_raw=+0.008 g_sm=+0.009 acc=1 | LR→0.132576 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.380362 step=0.02198 g_raw=+0.009 g_sm=+0.008 acc=1 | LR→0.132842 PERT→0.120014 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1315189555, PERT_used=0.1200124591 → LR_next=0.1328420628, PERT_next=0.1200136515\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1315189555→0.1328420628 PERT 0.1200124591→0.1200136515\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.81\n",
            "[round 6 | client 0] final LR=0.1328420628, final PERT=0.1200136515  (ΔLR=+0.0064868552, ΔPERT=+0.0000076657)\n",
            "[round 6 | client 1] seed LR=0.1263572851 (prev=0.1327145702), seed PERT=0.1200078208 (prev=0.1200156416), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.503706 step=0.1134 g_raw=+0.049 g_sm=+0.005 acc=1 | LR→0.126610 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.493128 step=0.01857 g_raw=+0.007 g_sm=+0.009 acc=1 | LR→0.126864 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.489740 step=0.03592 g_raw=+0.016 g_sm=+0.010 acc=1 | LR→0.127118 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.488129 step=0.02374 g_raw=+0.010 g_sm=+0.010 acc=1 | LR→0.127373 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#025 loss=0.479153 step=0.0205 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.127628 PERT→0.120009 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1263572851, PERT_used=0.1200078208 → LR_next=0.1276282849, PERT_next=0.1200088439\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1263572851→0.1276282849 PERT 0.1200078208→0.1200088439\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.468231 step=0.08198 g_raw=+0.033 g_sm=+0.016 acc=1 | LR→0.127884 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.464995 step=0.05251 g_raw=+0.020 g_sm=+0.016 acc=1 | LR→0.128141 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#040 loss=0.455681 step=0.06005 g_raw=+0.025 g_sm=+0.018 acc=1 | LR→0.128398 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#045 loss=0.447732 step=0.005313 g_raw=+0.002 g_sm=+0.019 acc=1 | LR→0.128655 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.445028 step=0.001849 g_raw=-0.003 g_sm=+0.017 acc=1 | LR→0.128913 PERT→0.120011 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1276282849, PERT_used=0.1200088439 → LR_next=0.1289131653, PERT_next=0.1200108870\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.020 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1276282849→0.1289131653 PERT 0.1200088439→0.1200108870\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.78\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.440666 step=0.02506 g_raw=+0.013 g_sm=+0.017 acc=1 | LR→0.129172 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#060 loss=0.435988 step=0.008392 g_raw=+0.001 g_sm=+0.016 acc=1 | LR→0.129431 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#065 loss=0.425686 step=0.02363 g_raw=+0.011 g_sm=+0.017 acc=1 | LR→0.129690 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#070 loss=0.423761 step=0.06051 g_raw=+0.024 g_sm=+0.016 acc=1 | LR→0.129950 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#075 loss=0.421584 step=0.004578 g_raw=+0.003 g_sm=+0.015 acc=1 | LR→0.130211 PERT→0.120013 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1289131653, PERT_used=0.1200108870 → LR_next=0.1302108912, PERT_next=0.1200128475\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1289131653→0.1302108912 PERT 0.1200108870→0.1200128475\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.418536 step=0.044 g_raw=+0.018 g_sm=+0.014 acc=1 | LR→0.130472 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#085 loss=0.415498 step=0.01411 g_raw=+0.005 g_sm=+0.014 acc=1 | LR→0.130734 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#090 loss=0.413089 step=0.03931 g_raw=+0.016 g_sm=+0.014 acc=1 | LR→0.130996 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#095 loss=0.410784 step=0.005119 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.131258 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#100 loss=0.409611 step=0.02891 g_raw=+0.010 g_sm=+0.012 acc=1 | LR→0.131521 PERT→0.120014 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1302108912, PERT_used=0.1200128475 → LR_next=0.1315213371, PERT_next=0.1200144943\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1302108912→0.1315213371 PERT 0.1200128475→0.1200144943\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.61\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.406945 step=0.00892 g_raw=+0.002 g_sm=+0.012 acc=1 | LR→0.131785 PERT→0.120015 (scale=0.04)\n",
            "[meta] cb#110 loss=0.406640 step=0.01662 g_raw=+0.007 g_sm=+0.010 acc=1 | LR→0.132049 PERT→0.120015 (scale=0.04)\n",
            "[meta] cb#115 loss=0.404809 step=0.01927 g_raw=+0.006 g_sm=+0.010 acc=1 | LR→0.132314 PERT→0.120015 (scale=0.04)\n",
            "[meta] cb#120 loss=0.404504 step=0.01421 g_raw=+0.006 g_sm=+0.009 acc=1 | LR→0.132579 PERT→0.120016 (scale=0.04)\n",
            "[meta] cb#125 loss=0.402135 step=0.03025 g_raw=+0.012 g_sm=+0.009 acc=1 | LR→0.132845 PERT→0.120016 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1315213371, PERT_used=0.1200144943 → LR_next=0.1328445493, PERT_next=0.1200157598\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1315213371→0.1328445493 PERT 0.1200144943→0.1200157598\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.59\n",
            "[round 6 | client 1] final LR=0.1328445493, final PERT=0.1200157598  (ΔLR=+0.0064872642, ΔPERT=+0.0000079390)\n",
            "[round 6 | client 2] seed LR=0.1263559285 (prev=0.1327118570), seed PERT=0.1200066551 (prev=0.1200133102), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.542564 step=0.07038 g_raw=+0.031 g_sm=+0.003 acc=1 | LR→0.126609 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.538028 step=0.02373 g_raw=+0.012 g_sm=+0.006 acc=1 | LR→0.126863 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.528380 step=0.02351 g_raw=+0.011 g_sm=+0.010 acc=1 | LR→0.127117 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.526270 step=0.01533 g_raw=+0.008 g_sm=+0.011 acc=1 | LR→0.127371 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.523451 step=0.03881 g_raw=+0.015 g_sm=+0.011 acc=1 | LR→0.127627 PERT→0.120008 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1263559285, PERT_used=0.1200066551 → LR_next=0.1276267527, PERT_next=0.1200075258\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1263559285→0.1276267527 PERT 0.1200066551→0.1200075258\n",
            "Training Accuracy: 0.32\n",
            "Test Accuracy: 0.36\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.519847 step=0.02 g_raw=+0.010 g_sm=+0.012 acc=1 | LR→0.127883 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.516642 step=0.007852 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.128139 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.515010 step=0.003808 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.128396 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.511687 step=0.03077 g_raw=+0.016 g_sm=+0.012 acc=1 | LR→0.128653 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.505979 step=0.08944 g_raw=+0.038 g_sm=+0.014 acc=1 | LR→0.128911 PERT→0.120009 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1276267527, PERT_used=0.1200075258 → LR_next=0.1289110076, PERT_next=0.1200090011\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1276267527→0.1289110076 PERT 0.1200075258→0.1200090011\n",
            "Training Accuracy: 0.38\n",
            "Test Accuracy: 0.42\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.504724 step=0.00796 g_raw=+0.004 g_sm=+0.013 acc=1 | LR→0.129169 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.502769 step=0.01642 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.129428 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.500144 step=0.04259 g_raw=+0.020 g_sm=+0.013 acc=1 | LR→0.129688 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.497903 step=0.06581 g_raw=+0.029 g_sm=+0.012 acc=1 | LR→0.129948 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.495352 step=0.05281 g_raw=+0.022 g_sm=+0.012 acc=1 | LR→0.130208 PERT→0.120010 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1289110076, PERT_used=0.1200090011 → LR_next=0.1302081817, PERT_next=0.1200104730\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1289110076→0.1302081817 PERT 0.1200090011→0.1200104730\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.493097 step=0.01919 g_raw=+0.008 g_sm=+0.013 acc=1 | LR→0.130469 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.490706 step=0.03045 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.130731 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.488411 step=0.05006 g_raw=+0.020 g_sm=+0.012 acc=1 | LR→0.130993 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.487740 step=0.01228 g_raw=+0.006 g_sm=+0.011 acc=1 | LR→0.131255 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.483566 step=0.02905 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.131518 PERT→0.120012 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1302081817, PERT_used=0.1200104730 → LR_next=0.1315183811, PERT_next=0.1200119197\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1302081817→0.1315183811 PERT 0.1200104730→0.1200119197\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.479865 step=0.05602 g_raw=+0.024 g_sm=+0.013 acc=1 | LR→0.131782 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.475785 step=9.791e-05 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.132046 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.472100 step=0.02922 g_raw=+0.012 g_sm=+0.013 acc=1 | LR→0.132311 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.469948 step=0.01285 g_raw=+0.005 g_sm=+0.013 acc=1 | LR→0.132576 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.467342 step=0.0429 g_raw=+0.019 g_sm=+0.013 acc=1 | LR→0.132842 PERT→0.120013 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1315183811, PERT_used=0.1200119197 → LR_next=0.1328418851, PERT_next=0.1200134757\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1315183811→0.1328418851 PERT 0.1200119197→0.1200134757\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.73\n",
            "[round 6 | client 2] final LR=0.1328418851, final PERT=0.1200134757  (ΔLR=+0.0064859566, ΔPERT=+0.0000068206)\n",
            "[round 6 | client 3] seed LR=0.1263559997 (prev=0.1327119994), seed PERT=0.1200067021 (prev=0.1200134042), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.501152 step=0.01079 g_raw=+0.004 g_sm=+0.003 acc=1 | LR→0.126609 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.499528 step=0.05693 g_raw=+0.024 g_sm=+0.004 acc=1 | LR→0.126863 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.493773 step=0.08077 g_raw=+0.035 g_sm=+0.007 acc=1 | LR→0.127117 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.490101 step=0.04971 g_raw=+0.026 g_sm=+0.008 acc=1 | LR→0.127371 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.487942 step=0.01817 g_raw=+0.011 g_sm=+0.009 acc=1 | LR→0.127627 PERT→0.120007 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1263559997, PERT_used=0.1200067021 → LR_next=0.1276265620, PERT_next=0.1200073258\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1263559997→0.1276265620 PERT 0.1200067021→0.1200073258\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.483769 step=0.006136 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.127882 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.477434 step=0.03952 g_raw=+0.018 g_sm=+0.013 acc=1 | LR→0.128139 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.473844 step=0.04661 g_raw=+0.020 g_sm=+0.014 acc=1 | LR→0.128396 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.471294 step=0.04218 g_raw=+0.018 g_sm=+0.013 acc=1 | LR→0.128653 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.468013 step=0.002382 g_raw=+0.000 g_sm=+0.013 acc=1 | LR→0.128911 PERT→0.120009 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1276265620, PERT_used=0.1200073258 → LR_next=0.1289108816, PERT_next=0.1200088632\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1276265620→0.1289108816 PERT 0.1200073258→0.1200088632\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.63\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.466226 step=0.006439 g_raw=+0.002 g_sm=+0.012 acc=1 | LR→0.129169 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.463596 step=0.004344 g_raw=+0.002 g_sm=+0.012 acc=1 | LR→0.129428 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.455539 step=0.03083 g_raw=+0.015 g_sm=+0.015 acc=1 | LR→0.129688 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.453015 step=0.04842 g_raw=+0.020 g_sm=+0.014 acc=1 | LR→0.129948 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.446769 step=0.07103 g_raw=+0.030 g_sm=+0.016 acc=1 | LR→0.130208 PERT→0.120010 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1289108816, PERT_used=0.1200088632 → LR_next=0.1302081966, PERT_next=0.1200104660\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1289108816→0.1302081966 PERT 0.1200088632→0.1200104660\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.444717 step=0.02581 g_raw=+0.009 g_sm=+0.015 acc=1 | LR→0.130469 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.441113 step=0.02568 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.130731 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.439264 step=0.03424 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.130993 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.439092 step=0.003582 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.131255 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.435301 step=0.06114 g_raw=+0.023 g_sm=+0.012 acc=1 | LR→0.131519 PERT→0.120012 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1302081966, PERT_used=0.1200104660 → LR_next=0.1315185815, PERT_next=0.1200120819\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1302081966→0.1315185815 PERT 0.1200104660→0.1200120819\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.433215 step=0.02815 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.131782 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.427830 step=0.03695 g_raw=+0.016 g_sm=+0.014 acc=1 | LR→0.132046 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.425822 step=0.002799 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.132311 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.424592 step=0.0442 g_raw=+0.018 g_sm=+0.012 acc=1 | LR→0.132576 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.424014 step=0.01519 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.132842 PERT→0.120014 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1315185815, PERT_used=0.1200120819 → LR_next=0.1328420166, PERT_next=0.1200135739\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1315185815→0.1328420166 PERT 0.1200120819→0.1200135739\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.72\n",
            "[round 6 | client 3] final LR=0.1328420166, final PERT=0.1200135739  (ΔLR=+0.0064860169, ΔPERT=+0.0000068717)\n",
            "[round 6 | client 4] seed LR=0.1263561583 (prev=0.1327123166), seed PERT=0.1200068459 (prev=0.1200136918), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.515195 step=0.02279 g_raw=+0.010 g_sm=+0.002 acc=1 | LR→0.126609 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.512636 step=0.01904 g_raw=+0.008 g_sm=+0.004 acc=1 | LR→0.126863 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.510007 step=0.02721 g_raw=+0.013 g_sm=+0.006 acc=1 | LR→0.127117 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.507595 step=0.04262 g_raw=+0.018 g_sm=+0.007 acc=1 | LR→0.127371 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.506061 step=0.02376 g_raw=+0.013 g_sm=+0.008 acc=1 | LR→0.127627 PERT→0.120007 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1263561583, PERT_used=0.1200068459 → LR_next=0.1276266474, PERT_next=0.1200073993\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1263561583→0.1276266474 PERT 0.1200068459→0.1200073993\n",
            "Training Accuracy: 0.48\n",
            "Test Accuracy: 0.43\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.501346 step=0.06901 g_raw=+0.030 g_sm=+0.010 acc=1 | LR→0.127882 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.493911 step=0.008715 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.128139 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.491583 step=0.007481 g_raw=+0.006 g_sm=+0.012 acc=1 | LR→0.128396 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.487913 step=0.03113 g_raw=+0.014 g_sm=+0.013 acc=1 | LR→0.128653 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.484410 step=0.06017 g_raw=+0.026 g_sm=+0.014 acc=1 | LR→0.128911 PERT→0.120009 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1276266474, PERT_used=0.1200073993 → LR_next=0.1289108166, PERT_next=0.1200087958\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1276266474→0.1289108166 PERT 0.1200073993→0.1200087958\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.46\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.482982 step=0.03989 g_raw=+0.017 g_sm=+0.013 acc=1 | LR→0.129169 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.481064 step=0.04172 g_raw=+0.019 g_sm=+0.012 acc=1 | LR→0.129428 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.475692 step=0.009407 g_raw=+0.007 g_sm=+0.014 acc=1 | LR→0.129688 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.472821 step=0.0001088 g_raw=-0.001 g_sm=+0.013 acc=1 | LR→0.129948 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.469914 step=0.05087 g_raw=+0.020 g_sm=+0.013 acc=1 | LR→0.130208 PERT→0.120010 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1289108166, PERT_used=0.1200087958 → LR_next=0.1302080771, PERT_next=0.1200103491\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1289108166→0.1302080771 PERT 0.1200087958→0.1200103491\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.49\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.467197 step=0.02386 g_raw=+0.012 g_sm=+0.013 acc=1 | LR→0.130469 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.464856 step=0.05697 g_raw=+0.023 g_sm=+0.013 acc=1 | LR→0.130731 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.463240 step=0.05308 g_raw=+0.021 g_sm=+0.012 acc=1 | LR→0.130993 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.459743 step=0.03941 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.131255 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.457853 step=0.02537 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.131518 PERT→0.120012 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1302080771, PERT_used=0.1200103491 → LR_next=0.1315183852, PERT_next=0.1200118959\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1302080771→0.1315183852 PERT 0.1200103491→0.1200118959\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.455630 step=0.03761 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.131782 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.454005 step=0.04368 g_raw=+0.018 g_sm=+0.012 acc=1 | LR→0.132046 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.451728 step=0.05741 g_raw=+0.022 g_sm=+0.012 acc=1 | LR→0.132311 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.450049 step=0.0009116 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.132576 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.447462 step=0.009669 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.132842 PERT→0.120013 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1315183852, PERT_used=0.1200118959 → LR_next=0.1328417405, PERT_next=0.1200133175\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1315183852→0.1328417405 PERT 0.1200118959→0.1200133175\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.54\n",
            "[round 6 | client 4] final LR=0.1328417405, final PERT=0.1200133175  (ΔLR=+0.0064855822, ΔPERT=+0.0000064716)\n",
            "\n",
            "[Round 6] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           0      0.521368      0.815000      0.132842      0.120014\n",
            "           3      0.560701      0.725000      0.132842      0.120014\n",
            "           1      0.617526      0.590000      0.132845      0.120016\n",
            "           2      0.641794      0.730000      0.132842      0.120013\n",
            "           4      0.651852      0.540000      0.132842      0.120013\n",
            "→ [Round 6] best_client=0, best_val=0.521368, prev_global_val=0.550391, improve=+0.029023, action=adopt+mix τ=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  70%|███████   | 7/10 [1:03:24<26:54, 538.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   6] acc_g=0.745 (μ=0.680, σ=0.100, FG=0.221) | t=526.269s, val=0.544 | TEL=FALSE\n",
            "[Round 7] Teleportation OFF | Aggregation=best\n",
            "[round 7 | client 0] seed LR=0.1264210314 (prev=0.1328420628), seed PERT=0.1200068258 (prev=0.1200136515), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.505096 step=0.03094 g_raw=+0.012 g_sm=+0.003 acc=1 | LR→0.126674 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.503989 step=0.002632 g_raw=+0.003 g_sm=+0.004 acc=1 | LR→0.126928 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.500173 step=0.05236 g_raw=+0.023 g_sm=+0.006 acc=1 | LR→0.127182 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.497938 step=0.01056 g_raw=+0.004 g_sm=+0.008 acc=1 | LR→0.127437 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.497032 step=0.0164 g_raw=+0.010 g_sm=+0.008 acc=1 | LR→0.127692 PERT→0.120007 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1264210314, PERT_used=0.1200068258 → LR_next=0.1276922222, PERT_next=0.1200074257\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1264210314→0.1276922222 PERT 0.1200068258→0.1200074257\n",
            "Training Accuracy: 0.54\n",
            "Test Accuracy: 0.53\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.496353 step=0.01121 g_raw=+0.004 g_sm=+0.007 acc=1 | LR→0.127948 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.493464 step=0.03023 g_raw=+0.013 g_sm=+0.009 acc=1 | LR→0.128204 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.491548 step=0.01875 g_raw=+0.009 g_sm=+0.009 acc=1 | LR→0.128461 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.489555 step=0.02851 g_raw=+0.010 g_sm=+0.010 acc=1 | LR→0.128719 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#050 loss=0.487765 step=0.004096 g_raw=+0.003 g_sm=+0.010 acc=1 | LR→0.128977 PERT→0.120009 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1276922222, PERT_used=0.1200074257 → LR_next=0.1289767207, PERT_next=0.1200085146\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1276922222→0.1289767207 PERT 0.1200074257→0.1200085146\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.65\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.485586 step=0.03834 g_raw=+0.017 g_sm=+0.011 acc=1 | LR→0.129235 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.483482 step=0.03687 g_raw=+0.015 g_sm=+0.011 acc=1 | LR→0.129494 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#065 loss=0.480630 step=0.05527 g_raw=+0.026 g_sm=+0.012 acc=1 | LR→0.129754 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#070 loss=0.477195 step=0.02036 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.130014 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.473524 step=0.0353 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.130274 PERT→0.120010 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1289767207, PERT_used=0.1200085146 → LR_next=0.1302744973, PERT_next=0.1200099323\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1289767207→0.1302744973 PERT 0.1200085146→0.1200099323\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.465619 step=0.04021 g_raw=+0.018 g_sm=+0.016 acc=1 | LR→0.130536 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.463565 step=0.008881 g_raw=+0.005 g_sm=+0.014 acc=1 | LR→0.130797 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.458917 step=0.05211 g_raw=+0.022 g_sm=+0.015 acc=1 | LR→0.131060 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.456315 step=0.01255 g_raw=+0.006 g_sm=+0.015 acc=1 | LR→0.131322 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.453988 step=0.04464 g_raw=+0.019 g_sm=+0.014 acc=1 | LR→0.131586 PERT→0.120012 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1302744973, PERT_used=0.1200099323 → LR_next=0.1315857111, PERT_next=0.1200116956\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1302744973→0.1315857111 PERT 0.1200099323→0.1200116956\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.74\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.450623 step=0.04263 g_raw=+0.017 g_sm=+0.014 acc=1 | LR→0.131850 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.448438 step=0.0349 g_raw=+0.017 g_sm=+0.014 acc=1 | LR→0.132114 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.446846 step=0.04782 g_raw=+0.018 g_sm=+0.013 acc=1 | LR→0.132379 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.442509 step=0.05627 g_raw=+0.022 g_sm=+0.014 acc=1 | LR→0.132644 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.438753 step=0.0271 g_raw=+0.010 g_sm=+0.014 acc=1 | LR→0.132910 PERT→0.120013 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1315857111, PERT_used=0.1200116956 → LR_next=0.1329099408, PERT_next=0.1200132951\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1315857111→0.1329099408 PERT 0.1200116956→0.1200132951\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.73\n",
            "[round 7 | client 0] final LR=0.1329099408, final PERT=0.1200132951  (ΔLR=+0.0064889094, ΔPERT=+0.0000064693)\n",
            "[round 7 | client 1] seed LR=0.1264222746 (prev=0.1328445493), seed PERT=0.1200078799 (prev=0.1200157598), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.450976 step=0.1144 g_raw=+0.046 g_sm=+0.006 acc=1 | LR→0.126675 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.441834 step=0.00953 g_raw=+0.004 g_sm=+0.009 acc=1 | LR→0.126929 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.430317 step=0.02183 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.127184 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.425541 step=0.01714 g_raw=+0.006 g_sm=+0.014 acc=1 | LR→0.127439 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#025 loss=0.421085 step=0.01738 g_raw=+0.007 g_sm=+0.014 acc=1 | LR→0.127694 PERT→0.120009 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1264222746, PERT_used=0.1200078799 → LR_next=0.1276941597, PERT_next=0.1200091205\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1264222746→0.1276941597 PERT 0.1200078799→0.1200091205\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.63\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.413062 step=0.1162 g_raw=+0.045 g_sm=+0.016 acc=1 | LR→0.127950 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.406133 step=0.01408 g_raw=+0.003 g_sm=+0.016 acc=1 | LR→0.128207 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#040 loss=0.399205 step=0.06375 g_raw=+0.025 g_sm=+0.017 acc=1 | LR→0.128464 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#045 loss=0.393392 step=0.07624 g_raw=+0.031 g_sm=+0.018 acc=1 | LR→0.128721 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#050 loss=0.389050 step=0.05767 g_raw=+0.019 g_sm=+0.017 acc=1 | LR→0.128980 PERT→0.120011 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1276941597, PERT_used=0.1200091205 → LR_next=0.1289796412, PERT_next=0.1200111060\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1276941597→0.1289796412 PERT 0.1200091205→0.1200111060\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.386086 step=0.03703 g_raw=+0.011 g_sm=+0.016 acc=1 | LR→0.129238 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#060 loss=0.385226 step=0.01712 g_raw=+0.005 g_sm=+0.014 acc=1 | LR→0.129497 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#065 loss=0.379804 step=0.03287 g_raw=+0.014 g_sm=+0.015 acc=1 | LR→0.129757 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#070 loss=0.378112 step=0.0357 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.130017 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#075 loss=0.373419 step=0.06154 g_raw=+0.017 g_sm=+0.015 acc=1 | LR→0.130278 PERT→0.120013 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1289796412, PERT_used=0.1200111060 → LR_next=0.1302778799, PERT_next=0.1200129225\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1289796412→0.1302778799 PERT 0.1200111060→0.1200129225\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.75\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.371601 step=0.04691 g_raw=+0.016 g_sm=+0.014 acc=1 | LR→0.130539 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#085 loss=0.369528 step=0.0004787 g_raw=+0.001 g_sm=+0.013 acc=1 | LR→0.130801 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#090 loss=0.363276 step=0.03615 g_raw=+0.014 g_sm=+0.015 acc=1 | LR→0.131063 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#095 loss=0.361792 step=0.01961 g_raw=+0.009 g_sm=+0.014 acc=1 | LR→0.131326 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#100 loss=0.359248 step=0.03065 g_raw=+0.014 g_sm=+0.013 acc=1 | LR→0.131589 PERT→0.120015 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1302778799, PERT_used=0.1200129225 → LR_next=0.1315890183, PERT_next=0.1200145859\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1302778799→0.1315890183 PERT 0.1200129225→0.1200145859\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.79\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.355098 step=0.02286 g_raw=+0.008 g_sm=+0.013 acc=1 | LR→0.131853 PERT→0.120015 (scale=0.04)\n",
            "[meta] cb#110 loss=0.350549 step=0.02977 g_raw=+0.011 g_sm=+0.013 acc=1 | LR→0.132117 PERT→0.120015 (scale=0.04)\n",
            "[meta] cb#115 loss=0.349145 step=0.0597 g_raw=+0.020 g_sm=+0.012 acc=1 | LR→0.132382 PERT→0.120016 (scale=0.04)\n",
            "[meta] cb#120 loss=0.347545 step=0.01748 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.132647 PERT→0.120016 (scale=0.04)\n",
            "[meta] cb#125 loss=0.347197 step=0.02093 g_raw=+0.008 g_sm=+0.009 acc=1 | LR→0.132913 PERT→0.120016 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1315890183, PERT_used=0.1200145859 → LR_next=0.1329131075, PERT_next=0.1200160285\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1315890183→0.1329131075 PERT 0.1200145859→0.1200160285\n",
            "Training Accuracy: 0.90\n",
            "Test Accuracy: 0.83\n",
            "[round 7 | client 1] final LR=0.1329131075, final PERT=0.1200160285  (ΔLR=+0.0064908329, ΔPERT=+0.0000081486)\n",
            "[round 7 | client 2] seed LR=0.1264209426 (prev=0.1328418851), seed PERT=0.1200067378 (prev=0.1200134757), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.476464 step=0.0442 g_raw=+0.018 g_sm=+0.005 acc=1 | LR→0.126674 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.471499 step=0.00128 g_raw=+0.001 g_sm=+0.007 acc=1 | LR→0.126928 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.467958 step=0.04908 g_raw=+0.018 g_sm=+0.009 acc=1 | LR→0.127182 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.462059 step=0.01805 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.127437 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.460298 step=0.03396 g_raw=+0.013 g_sm=+0.011 acc=1 | LR→0.127693 PERT→0.120008 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1264209426, PERT_used=0.1200067378 → LR_next=0.1276925045, PERT_next=0.1200076874\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1264209426→0.1276925045 PERT 0.1200067378→0.1200076874\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.62\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.458189 step=0.02655 g_raw=+0.014 g_sm=+0.012 acc=1 | LR→0.127948 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.453934 step=0.01065 g_raw=+0.006 g_sm=+0.013 acc=1 | LR→0.128205 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.449793 step=0.00968 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.128462 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.444713 step=0.06623 g_raw=+0.023 g_sm=+0.014 acc=1 | LR→0.128719 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.440710 step=0.05176 g_raw=+0.021 g_sm=+0.014 acc=1 | LR→0.128978 PERT→0.120009 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1276925045, PERT_used=0.1200076874 → LR_next=0.1289775320, PERT_next=0.1200092659\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1276925045→0.1289775320 PERT 0.1200076874→0.1200092659\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.438922 step=0.005347 g_raw=+0.003 g_sm=+0.013 acc=1 | LR→0.129236 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.437132 step=0.02065 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.129495 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.434562 step=0.07011 g_raw=+0.031 g_sm=+0.012 acc=1 | LR→0.129755 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.431336 step=0.06643 g_raw=+0.027 g_sm=+0.013 acc=1 | LR→0.130015 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.427542 step=0.04553 g_raw=+0.017 g_sm=+0.013 acc=1 | LR→0.130275 PERT→0.120011 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1289775320, PERT_used=0.1200092659 → LR_next=0.1302754388, PERT_next=0.1200107961\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1289775320→0.1302754388 PERT 0.1200092659→0.1200107961\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.419627 step=0.08161 g_raw=+0.034 g_sm=+0.015 acc=1 | LR→0.130537 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.415605 step=0.08003 g_raw=+0.029 g_sm=+0.015 acc=1 | LR→0.130798 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#090 loss=0.404828 step=0.1038 g_raw=+0.042 g_sm=+0.017 acc=1 | LR→0.131061 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.402681 step=0.04784 g_raw=+0.020 g_sm=+0.016 acc=1 | LR→0.131323 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.401272 step=0.01844 g_raw=+0.005 g_sm=+0.015 acc=1 | LR→0.131587 PERT→0.120013 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1302754388, PERT_used=0.1200107961 → LR_next=0.1315867768, PERT_next=0.1200126640\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1302754388→0.1315867768 PERT 0.1200107961→0.1200126640\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.73\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.395595 step=0.05585 g_raw=+0.024 g_sm=+0.015 acc=1 | LR→0.131851 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#110 loss=0.391582 step=0.03849 g_raw=+0.014 g_sm=+0.015 acc=1 | LR→0.132115 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.388981 step=0.0108 g_raw=+0.001 g_sm=+0.014 acc=1 | LR→0.132380 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#120 loss=0.387864 step=0.02018 g_raw=+0.009 g_sm=+0.013 acc=1 | LR→0.132645 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#125 loss=0.385284 step=0.04677 g_raw=+0.019 g_sm=+0.013 acc=1 | LR→0.132911 PERT→0.120014 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1315867768, PERT_used=0.1200126640 → LR_next=0.1329111837, PERT_next=0.1200144138\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1315867768→0.1329111837 PERT 0.1200126640→0.1200144138\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.75\n",
            "[round 7 | client 2] final LR=0.1329111837, final PERT=0.1200144138  (ΔLR=+0.0064902412, ΔPERT=+0.0000076760)\n",
            "[round 7 | client 3] seed LR=0.1264210083 (prev=0.1328420166), seed PERT=0.1200067869 (prev=0.1200135739), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.510773 step=0.01889 g_raw=+0.008 g_sm=+0.005 acc=1 | LR→0.126674 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.507977 step=0.007044 g_raw=+0.005 g_sm=+0.007 acc=1 | LR→0.126928 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.507176 step=0.02506 g_raw=+0.011 g_sm=+0.006 acc=1 | LR→0.127182 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.502331 step=0.06398 g_raw=+0.026 g_sm=+0.008 acc=1 | LR→0.127437 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.499288 step=0.0521 g_raw=+0.021 g_sm=+0.009 acc=1 | LR→0.127692 PERT→0.120008 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1264210083, PERT_used=0.1200067869 → LR_next=0.1276923764, PERT_next=0.1200075537\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1264210083→0.1276923764 PERT 0.1200067869→0.1200075537\n",
            "Training Accuracy: 0.50\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.491344 step=0.006613 g_raw=+0.001 g_sm=+0.011 acc=1 | LR→0.127948 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.488097 step=0.009765 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.128205 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.484653 step=0.04881 g_raw=+0.020 g_sm=+0.012 acc=1 | LR→0.128462 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.477028 step=0.06124 g_raw=+0.027 g_sm=+0.015 acc=1 | LR→0.128719 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.476782 step=0.0112 g_raw=+0.003 g_sm=+0.012 acc=1 | LR→0.128977 PERT→0.120009 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1276923764, PERT_used=0.1200075537 → LR_next=0.1289772950, PERT_next=0.1200090321\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1276923764→0.1289772950 PERT 0.1200075537→0.1200090321\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.474211 step=0.004644 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.129236 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.472682 step=0.003034 g_raw=+0.001 g_sm=+0.011 acc=1 | LR→0.129495 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.466587 step=0.04061 g_raw=+0.016 g_sm=+0.013 acc=1 | LR→0.129754 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.462355 step=0.03722 g_raw=+0.016 g_sm=+0.014 acc=1 | LR→0.130015 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.461081 step=0.02146 g_raw=+0.008 g_sm=+0.013 acc=1 | LR→0.130275 PERT→0.120011 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1289772950, PERT_used=0.1200090321 → LR_next=0.1302752057, PERT_next=0.1200105680\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1289772950→0.1302752057 PERT 0.1200090321→0.1200105680\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.55\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.455301 step=0.01146 g_raw=+0.006 g_sm=+0.014 acc=1 | LR→0.130536 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.452678 step=0.008966 g_raw=+0.004 g_sm=+0.014 acc=1 | LR→0.130798 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.450271 step=0.0303 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.131060 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.442754 step=0.05715 g_raw=+0.025 g_sm=+0.015 acc=1 | LR→0.131323 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.440088 step=0.05421 g_raw=+0.023 g_sm=+0.015 acc=1 | LR→0.131586 PERT→0.120012 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1302752057, PERT_used=0.1200105680 → LR_next=0.1315863757, PERT_next=0.1200122849\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1302752057→0.1315863757 PERT 0.1200105680→0.1200122849\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.60\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.439659 step=0.004872 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.131850 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#110 loss=0.430851 step=0.06075 g_raw=+0.026 g_sm=+0.016 acc=1 | LR→0.132115 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.425435 step=0.0377 g_raw=+0.014 g_sm=+0.017 acc=1 | LR→0.132379 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.422580 step=0.02652 g_raw=+0.010 g_sm=+0.015 acc=1 | LR→0.132645 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#125 loss=0.420081 step=0.01666 g_raw=+0.008 g_sm=+0.015 acc=1 | LR→0.132911 PERT→0.120014 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1315863757, PERT_used=0.1200122849 → LR_next=0.1329108552, PERT_next=0.1200141038\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1315863757→0.1329108552 PERT 0.1200122849→0.1200141038\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.62\n",
            "[round 7 | client 3] final LR=0.1329108552, final PERT=0.1200141038  (ΔLR=+0.0064898469, ΔPERT=+0.0000073169)\n",
            "[round 7 | client 4] seed LR=0.1264208702 (prev=0.1328417405), seed PERT=0.1200066588 (prev=0.1200133175), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.493820 step=0.04035 g_raw=+0.018 g_sm=+0.003 acc=1 | LR→0.126674 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.490268 step=0.04926 g_raw=+0.021 g_sm=+0.006 acc=1 | LR→0.126928 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.483488 step=0.1106 g_raw=+0.047 g_sm=+0.009 acc=1 | LR→0.127182 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.479488 step=0.02035 g_raw=+0.010 g_sm=+0.010 acc=1 | LR→0.127437 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.474973 step=0.04301 g_raw=+0.017 g_sm=+0.012 acc=1 | LR→0.127692 PERT→0.120007 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1264208702, PERT_used=0.1200066588 → LR_next=0.1276922822, PERT_next=0.1200074680\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1264208702→0.1276922822 PERT 0.1200066588→0.1200074680\n",
            "Training Accuracy: 0.48\n",
            "Test Accuracy: 0.56\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.474140 step=0.009383 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.127948 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.460599 step=0.06099 g_raw=+0.026 g_sm=+0.015 acc=1 | LR→0.128205 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.450780 step=0.1423 g_raw=+0.061 g_sm=+0.016 acc=1 | LR→0.128462 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.446500 step=0.009664 g_raw=+0.004 g_sm=+0.016 acc=1 | LR→0.128719 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.444446 step=0.02774 g_raw=+0.010 g_sm=+0.014 acc=1 | LR→0.128977 PERT→0.120009 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1276922822, PERT_used=0.1200074680 → LR_next=0.1289774369, PERT_next=0.1200091670\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1276922822→0.1289774369 PERT 0.1200074680→0.1200091670\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.62\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.442221 step=0.04567 g_raw=+0.019 g_sm=+0.014 acc=1 | LR→0.129236 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.435102 step=0.0868 g_raw=+0.034 g_sm=+0.015 acc=1 | LR→0.129495 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.430174 step=0.001998 g_raw=+0.001 g_sm=+0.015 acc=1 | LR→0.129755 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.426580 step=0.00647 g_raw=-0.000 g_sm=+0.014 acc=1 | LR→0.130015 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#075 loss=0.419690 step=0.04367 g_raw=+0.017 g_sm=+0.015 acc=1 | LR→0.130276 PERT→0.120011 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1289774369, PERT_used=0.1200091670 → LR_next=0.1302756167, PERT_next=0.1200109496\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1289774369→0.1302756167 PERT 0.1200091670→0.1200109496\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.66\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.415699 step=0.08546 g_raw=+0.033 g_sm=+0.015 acc=1 | LR→0.130537 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.413453 step=0.01562 g_raw=+0.007 g_sm=+0.014 acc=1 | LR→0.130799 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#090 loss=0.412578 step=0.006563 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.131061 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.409711 step=0.05477 g_raw=+0.024 g_sm=+0.013 acc=1 | LR→0.131323 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.407751 step=0.03719 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.131587 PERT→0.120013 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1302756167, PERT_used=0.1200109496 → LR_next=0.1315867126, PERT_next=0.1200125950\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1302756167→0.1315867126 PERT 0.1200109496→0.1200125950\n",
            "Training Accuracy: 0.76\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.406817 step=0.02869 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.131850 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#110 loss=0.402136 step=0.005633 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.132115 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.401005 step=0.0005188 g_raw=+0.000 g_sm=+0.011 acc=1 | LR→0.132380 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.399794 step=0.004879 g_raw=+0.000 g_sm=+0.011 acc=1 | LR→0.132645 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#125 loss=0.398155 step=0.009801 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.132911 PERT→0.120014 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1315867126, PERT_used=0.1200125950 → LR_next=0.1329107348, PERT_next=0.1200139980\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1315867126→0.1329107348 PERT 0.1200125950→0.1200139980\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.76\n",
            "[round 7 | client 4] final LR=0.1329107348, final PERT=0.1200139980  (ΔLR=+0.0064898645, ΔPERT=+0.0000073392)\n",
            "\n",
            "[Round 7] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           1      0.513951      0.835000      0.132913      0.120016\n",
            "           4      0.540544      0.760000      0.132911      0.120014\n",
            "           2      0.580678      0.750000      0.132911      0.120014\n",
            "           0      0.605475      0.735000      0.132910      0.120013\n",
            "           3      0.644909      0.620000      0.132911      0.120014\n",
            "→ [Round 7] best_client=1, best_val=0.513951, prev_global_val=0.544306, improve=+0.030356, action=adopt+mix τ=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  80%|████████  | 8/10 [1:12:23<17:57, 538.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   7] acc_g=0.652 (μ=0.740, σ=0.069, FG=0.139) | t=529.666s, val=0.576 | TEL=FALSE\n",
            "[Round 8] Teleportation OFF | Aggregation=best\n",
            "[round 8 | client 0] seed LR=0.1264549704 (prev=0.1329099408), seed PERT=0.1200066475 (prev=0.1200132951), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.512489 step=0.0691 g_raw=+0.030 g_sm=+0.003 acc=1 | LR→0.126708 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.507179 step=0.0194 g_raw=+0.010 g_sm=+0.006 acc=1 | LR→0.126962 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.493563 step=0.02822 g_raw=+0.013 g_sm=+0.011 acc=1 | LR→0.127216 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.490492 step=0.009421 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.127471 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.487773 step=0.008635 g_raw=+0.003 g_sm=+0.012 acc=1 | LR→0.127727 PERT→0.120008 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1264549704, PERT_used=0.1200066475 → LR_next=0.1277269062, PERT_next=0.1200076267\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1264549704→0.1277269062 PERT 0.1200066475→0.1200076267\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.59\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.483249 step=0.008292 g_raw=+0.004 g_sm=+0.013 acc=1 | LR→0.127983 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.481276 step=0.03069 g_raw=+0.011 g_sm=+0.012 acc=1 | LR→0.128239 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.477729 step=0.02226 g_raw=+0.008 g_sm=+0.013 acc=1 | LR→0.128497 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.474230 step=0.02176 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.128754 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.471090 step=0.005014 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.129012 PERT→0.120009 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1277269062, PERT_used=0.1200076267 → LR_next=0.1290122324, PERT_next=0.1200091611\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1277269062→0.1290122324 PERT 0.1200076267→0.1200091611\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.467801 step=0.02943 g_raw=+0.013 g_sm=+0.014 acc=1 | LR→0.129271 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.464193 step=0.00723 g_raw=+0.004 g_sm=+0.014 acc=1 | LR→0.129530 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.460026 step=0.03438 g_raw=+0.017 g_sm=+0.015 acc=1 | LR→0.129790 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.458113 step=0.03631 g_raw=+0.016 g_sm=+0.014 acc=1 | LR→0.130050 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.455975 step=0.02157 g_raw=+0.008 g_sm=+0.013 acc=1 | LR→0.130311 PERT→0.120011 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1290122324, PERT_used=0.1200091611 → LR_next=0.1303106268, PERT_next=0.1200108187\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1290122324→0.1303106268 PERT 0.1200091611→0.1200108187\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.453037 step=0.03143 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.130572 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.452500 step=0.001591 g_raw=+0.001 g_sm=+0.011 acc=1 | LR→0.130834 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.450697 step=0.0064 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.131096 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.449847 step=0.003295 g_raw=+0.001 g_sm=+0.010 acc=1 | LR→0.131359 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.446754 step=0.005896 g_raw=+0.000 g_sm=+0.011 acc=1 | LR→0.131622 PERT→0.120012 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1303106268, PERT_used=0.1200108187 → LR_next=0.1316217943, PERT_next=0.1200122083\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1303106268→0.1316217943 PERT 0.1200108187→0.1200122083\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.81\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.444274 step=0.02445 g_raw=+0.010 g_sm=+0.011 acc=1 | LR→0.131886 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.442574 step=0.0171 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.132150 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.439136 step=0.01197 g_raw=+0.003 g_sm=+0.012 acc=1 | LR→0.132415 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.434142 step=0.004516 g_raw=+0.002 g_sm=+0.013 acc=1 | LR→0.132680 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.430668 step=0.03735 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.132946 PERT→0.120014 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1316217943, PERT_used=0.1200122083 → LR_next=0.1329461826, PERT_next=0.1200136231\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1316217943→0.1329461826 PERT 0.1200122083→0.1200136231\n",
            "Training Accuracy: 0.90\n",
            "Test Accuracy: 0.86\n",
            "[round 8 | client 0] final LR=0.1329461826, final PERT=0.1200136231  (ΔLR=+0.0064912122, ΔPERT=+0.0000069756)\n",
            "[round 8 | client 1] seed LR=0.1264565537 (prev=0.1329131075), seed PERT=0.1200080142 (prev=0.1200160285), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.487375 step=0.003127 g_raw=+0.004 g_sm=+0.002 acc=1 | LR→0.126710 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.482362 step=0.08164 g_raw=+0.034 g_sm=+0.005 acc=1 | LR→0.126964 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.480868 step=0.01609 g_raw=+0.005 g_sm=+0.006 acc=1 | LR→0.127218 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.477157 step=0.01611 g_raw=+0.004 g_sm=+0.008 acc=1 | LR→0.127473 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.473790 step=0.08027 g_raw=+0.034 g_sm=+0.009 acc=1 | LR→0.127728 PERT→0.120009 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1264565537, PERT_used=0.1200080142 → LR_next=0.1277281405, PERT_next=0.1200086505\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1264565537→0.1277281405 PERT 0.1200080142→0.1200086505\n",
            "Training Accuracy: 0.64\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.471361 step=0.01503 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.127984 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.468744 step=0.04259 g_raw=+0.018 g_sm=+0.010 acc=1 | LR→0.128241 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.465815 step=0.04155 g_raw=+0.018 g_sm=+0.011 acc=1 | LR→0.128498 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.460389 step=0.1013 g_raw=+0.041 g_sm=+0.013 acc=1 | LR→0.128755 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.458738 step=0.04608 g_raw=+0.019 g_sm=+0.012 acc=1 | LR→0.129013 PERT→0.120010 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1277281405, PERT_used=0.1200086505 → LR_next=0.1290132247, PERT_next=0.1200099483\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1277281405→0.1290132247 PERT 0.1200086505→0.1200099483\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.79\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.453826 step=0.02758 g_raw=+0.009 g_sm=+0.014 acc=1 | LR→0.129272 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.451394 step=0.05535 g_raw=+0.022 g_sm=+0.014 acc=1 | LR→0.129531 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.448806 step=0.0424 g_raw=+0.017 g_sm=+0.014 acc=1 | LR→0.129791 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#070 loss=0.445329 step=0.001726 g_raw=-0.000 g_sm=+0.014 acc=1 | LR→0.130051 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#075 loss=0.441869 step=0.02537 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.130312 PERT→0.120012 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1290132247, PERT_used=0.1200099483 → LR_next=0.1303115985, PERT_next=0.1200115777\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1290132247→0.1303115985 PERT 0.1200099483→0.1200115777\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.88\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.439767 step=0.007639 g_raw=+0.004 g_sm=+0.013 acc=1 | LR→0.130573 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#085 loss=0.435375 step=0.02155 g_raw=+0.007 g_sm=+0.014 acc=1 | LR→0.130835 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#090 loss=0.431963 step=0.0321 g_raw=+0.011 g_sm=+0.014 acc=1 | LR→0.131097 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#095 loss=0.427792 step=0.02517 g_raw=+0.010 g_sm=+0.014 acc=1 | LR→0.131360 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#100 loss=0.427247 step=0.01057 g_raw=+0.003 g_sm=+0.012 acc=1 | LR→0.131623 PERT→0.120013 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1303115985, PERT_used=0.1200115777 → LR_next=0.1316230187, PERT_next=0.1200131888\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1303115985→0.1316230187 PERT 0.1200115777→0.1200131888\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.89\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.425952 step=0.009821 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.131887 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#110 loss=0.423988 step=0.03712 g_raw=+0.014 g_sm=+0.012 acc=1 | LR→0.132151 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#115 loss=0.423168 step=0.02358 g_raw=+0.012 g_sm=+0.011 acc=1 | LR→0.132416 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#120 loss=0.420640 step=0.02636 g_raw=+0.013 g_sm=+0.011 acc=1 | LR→0.132681 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#125 loss=0.418554 step=0.02259 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.132947 PERT→0.120015 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1316230187, PERT_used=0.1200131888 → LR_next=0.1329473554, PERT_next=0.1200145459\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1316230187→0.1329473554 PERT 0.1200131888→0.1200145459\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.90\n",
            "[round 8 | client 1] final LR=0.1329473554, final PERT=0.1200145459  (ΔLR=+0.0064908017, ΔPERT=+0.0000065316)\n",
            "[round 8 | client 2] seed LR=0.1264555919 (prev=0.1329111837), seed PERT=0.1200072069 (prev=0.1200144138), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.467150 step=0.1231 g_raw=+0.052 g_sm=+0.006 acc=1 | LR→0.126709 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.462433 step=0.02708 g_raw=+0.013 g_sm=+0.008 acc=1 | LR→0.126963 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.451436 step=0.09055 g_raw=+0.038 g_sm=+0.012 acc=1 | LR→0.127217 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.447386 step=0.04798 g_raw=+0.022 g_sm=+0.013 acc=1 | LR→0.127472 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.441976 step=0.1118 g_raw=+0.042 g_sm=+0.013 acc=1 | LR→0.127728 PERT→0.120008 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1264555919, PERT_used=0.1200072069 → LR_next=0.1277276523, PERT_next=0.1200082973\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1264555919→0.1277276523 PERT 0.1200072069→0.1200082973\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.435232 step=0.07514 g_raw=+0.029 g_sm=+0.015 acc=1 | LR→0.127984 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.429472 step=0.07809 g_raw=+0.029 g_sm=+0.016 acc=1 | LR→0.128240 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.422177 step=0.0107 g_raw=+0.008 g_sm=+0.017 acc=1 | LR→0.128498 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.413044 step=0.002704 g_raw=+0.002 g_sm=+0.018 acc=1 | LR→0.128755 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.410868 step=0.007138 g_raw=+0.004 g_sm=+0.016 acc=1 | LR→0.129013 PERT→0.120010 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1277276523, PERT_used=0.1200082973 → LR_next=0.1290134099, PERT_next=0.1200102260\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1277276523→0.1290134099 PERT 0.1200082973→0.1200102260\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.404161 step=0.03836 g_raw=+0.014 g_sm=+0.017 acc=1 | LR→0.129272 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#060 loss=0.401301 step=0.03799 g_raw=+0.014 g_sm=+0.016 acc=1 | LR→0.129531 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.397720 step=0.07234 g_raw=+0.028 g_sm=+0.016 acc=1 | LR→0.129791 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#070 loss=0.392345 step=0.03782 g_raw=+0.013 g_sm=+0.016 acc=1 | LR→0.130051 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#075 loss=0.391011 step=0.0006037 g_raw=+0.002 g_sm=+0.014 acc=1 | LR→0.130312 PERT→0.120012 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1290134099, PERT_used=0.1200102260 → LR_next=0.1303121059, PERT_next=0.1200121506\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1290134099→0.1303121059 PERT 0.1200102260→0.1200121506\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.70\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.389118 step=0.03159 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.130573 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#085 loss=0.386982 step=0.05055 g_raw=+0.023 g_sm=+0.013 acc=1 | LR→0.130835 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#090 loss=0.385095 step=0.04546 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.131097 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#095 loss=0.382325 step=0.02246 g_raw=+0.009 g_sm=+0.012 acc=1 | LR→0.131360 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#100 loss=0.380345 step=0.02165 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.131623 PERT→0.120014 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1303121059, PERT_used=0.1200121506 → LR_next=0.1316234451, PERT_next=0.1200136831\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1303121059→0.1316234451 PERT 0.1200121506→0.1200136831\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.377346 step=0.003201 g_raw=-0.001 g_sm=+0.011 acc=1 | LR→0.131887 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#110 loss=0.374042 step=0.00913 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.132152 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#115 loss=0.371842 step=0.02635 g_raw=+0.015 g_sm=+0.012 acc=1 | LR→0.132417 PERT→0.120015 (scale=0.04)\n",
            "[meta] cb#120 loss=0.370865 step=0.00862 g_raw=+0.002 g_sm=+0.011 acc=1 | LR→0.132682 PERT→0.120015 (scale=0.04)\n",
            "[meta] cb#125 loss=0.370168 step=0.005327 g_raw=-0.001 g_sm=+0.009 acc=1 | LR→0.132948 PERT→0.120015 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1316234451, PERT_used=0.1200136831 → LR_next=0.1329478070, PERT_next=0.1200150590\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1316234451→0.1329478070 PERT 0.1200136831→0.1200150590\n",
            "Training Accuracy: 0.72\n",
            "Test Accuracy: 0.71\n",
            "[round 8 | client 2] final LR=0.1329478070, final PERT=0.1200150590  (ΔLR=+0.0064922151, ΔPERT=+0.0000078521)\n",
            "[round 8 | client 3] seed LR=0.1264554276 (prev=0.1329108552), seed PERT=0.1200070519 (prev=0.1200141038), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.481654 step=0.03757 g_raw=+0.014 g_sm=+0.003 acc=1 | LR→0.126709 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.472247 step=0.06609 g_raw=+0.027 g_sm=+0.008 acc=1 | LR→0.126962 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.460585 step=0.07782 g_raw=+0.030 g_sm=+0.013 acc=1 | LR→0.127217 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.454383 step=0.1165 g_raw=+0.047 g_sm=+0.013 acc=1 | LR→0.127472 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.452312 step=0.04318 g_raw=+0.018 g_sm=+0.013 acc=1 | LR→0.127727 PERT→0.120008 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1264554276, PERT_used=0.1200070519 → LR_next=0.1277274508, PERT_next=0.1200081089\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.019 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1264554276→0.1277274508 PERT 0.1200070519→0.1200081089\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.82\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.448779 step=0.03778 g_raw=+0.016 g_sm=+0.014 acc=1 | LR→0.127983 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.438779 step=0.109 g_raw=+0.045 g_sm=+0.016 acc=1 | LR→0.128240 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.433523 step=0.02024 g_raw=+0.006 g_sm=+0.017 acc=1 | LR→0.128497 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.428692 step=0.0116 g_raw=+0.006 g_sm=+0.016 acc=1 | LR→0.128755 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.422813 step=0.05154 g_raw=+0.021 g_sm=+0.017 acc=1 | LR→0.129013 PERT→0.120010 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1277274508, PERT_used=0.1200081089 → LR_next=0.1290131187, PERT_next=0.1200099561\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1277274508→0.1290131187 PERT 0.1200081089→0.1200099561\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.84\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.421801 step=0.01152 g_raw=+0.005 g_sm=+0.015 acc=1 | LR→0.129272 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.419031 step=0.0577 g_raw=+0.027 g_sm=+0.014 acc=1 | LR→0.129531 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.416370 step=0.029 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.129791 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#070 loss=0.412956 step=0.005675 g_raw=+0.005 g_sm=+0.013 acc=1 | LR→0.130051 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#075 loss=0.410918 step=0.03244 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.130312 PERT→0.120012 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1290131187, PERT_used=0.1200099561 → LR_next=0.1303115396, PERT_next=0.1200116299\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1290131187→0.1303115396 PERT 0.1200099561→0.1200116299\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.85\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.408719 step=0.0002506 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.130573 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#085 loss=0.407012 step=0.01055 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.130834 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#090 loss=0.405216 step=0.01487 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.131097 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.401775 step=0.04077 g_raw=+0.017 g_sm=+0.012 acc=1 | LR→0.131359 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#100 loss=0.401007 step=0.002532 g_raw=+0.001 g_sm=+0.010 acc=1 | LR→0.131623 PERT→0.120013 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1303115396, PERT_used=0.1200116299 → LR_next=0.1316227092, PERT_next=0.1200130129\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1303115396→0.1316227092 PERT 0.1200116299→0.1200130129\n",
            "Training Accuracy: 0.84\n",
            "Test Accuracy: 0.85\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.399096 step=0.05279 g_raw=+0.022 g_sm=+0.010 acc=1 | LR→0.131886 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#110 loss=0.397315 step=0.03214 g_raw=+0.011 g_sm=+0.010 acc=1 | LR→0.132151 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.395905 step=0.002983 g_raw=+0.001 g_sm=+0.010 acc=1 | LR→0.132416 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#120 loss=0.395271 step=0.001783 g_raw=+0.000 g_sm=+0.009 acc=1 | LR→0.132681 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#125 loss=0.394078 step=0.0006563 g_raw=+0.000 g_sm=+0.008 acc=1 | LR→0.132947 PERT→0.120014 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1316227092, PERT_used=0.1200130129 → LR_next=0.1329468136, PERT_next=0.1200141632\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1316227092→0.1329468136 PERT 0.1200130129→0.1200141632\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.86\n",
            "[round 8 | client 3] final LR=0.1329468136, final PERT=0.1200141632  (ΔLR=+0.0064913861, ΔPERT=+0.0000071113)\n",
            "[round 8 | client 4] seed LR=0.1264553674 (prev=0.1329107348), seed PERT=0.1200069990 (prev=0.1200139980), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.468165 step=0.008173 g_raw=+0.002 g_sm=+0.003 acc=1 | LR→0.126709 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.463387 step=0.0839 g_raw=+0.037 g_sm=+0.006 acc=1 | LR→0.126962 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.452805 step=0.08704 g_raw=+0.036 g_sm=+0.010 acc=1 | LR→0.127217 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.440890 step=0.03597 g_raw=+0.014 g_sm=+0.014 acc=1 | LR→0.127472 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.430675 step=0.1325 g_raw=+0.056 g_sm=+0.017 acc=1 | LR→0.127727 PERT→0.120008 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1264553674, PERT_used=0.1200069990 → LR_next=0.1277273554, PERT_next=0.1200080235\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1264553674→0.1277273554 PERT 0.1200069990→0.1200080235\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.429907 step=0.005058 g_raw=+0.002 g_sm=+0.014 acc=1 | LR→0.127983 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.420378 step=0.07238 g_raw=+0.032 g_sm=+0.016 acc=1 | LR→0.128240 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.407051 step=0.02006 g_raw=+0.007 g_sm=+0.018 acc=1 | LR→0.128497 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.405757 step=0.0001991 g_raw=+0.003 g_sm=+0.016 acc=1 | LR→0.128755 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.394193 step=0.0944 g_raw=+0.037 g_sm=+0.019 acc=1 | LR→0.129013 PERT→0.120010 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1277273554, PERT_used=0.1200080235 → LR_next=0.1290131854, PERT_next=0.1200100223\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.017 acc_ratio=1.00 | LR 0.1277273554→0.1290131854 PERT 0.1200080235→0.1200100223\n",
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.64\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.390420 step=0.02762 g_raw=+0.007 g_sm=+0.018 acc=1 | LR→0.129272 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.389751 step=0.005653 g_raw=+0.003 g_sm=+0.015 acc=1 | LR→0.129531 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.386991 step=0.01432 g_raw=+0.005 g_sm=+0.015 acc=1 | LR→0.129791 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#070 loss=0.384200 step=0.006921 g_raw=+0.004 g_sm=+0.015 acc=1 | LR→0.130051 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#075 loss=0.381557 step=0.02051 g_raw=+0.007 g_sm=+0.014 acc=1 | LR→0.130312 PERT→0.120012 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1290131854, PERT_used=0.1200100223 → LR_next=0.1303118468, PERT_next=0.1200119171\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1290131854→0.1303118468 PERT 0.1200100223→0.1200119171\n",
            "Training Accuracy: 0.74\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.379904 step=0.01729 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.130573 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#085 loss=0.377044 step=0.007121 g_raw=+0.003 g_sm=+0.013 acc=1 | LR→0.130835 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#090 loss=0.374836 step=0.02803 g_raw=+0.010 g_sm=+0.013 acc=1 | LR→0.131097 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#095 loss=0.372869 step=0.005666 g_raw=+0.002 g_sm=+0.012 acc=1 | LR→0.131360 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#100 loss=0.369507 step=0.05474 g_raw=+0.019 g_sm=+0.012 acc=1 | LR→0.131623 PERT→0.120013 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1303118468, PERT_used=0.1200119171 → LR_next=0.1316232093, PERT_next=0.1200134732\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.013 acc_ratio=1.00 | LR 0.1303118468→0.1316232093 PERT 0.1200119171→0.1200134732\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.67\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.367312 step=0.03104 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.131887 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#110 loss=0.366486 step=0.02919 g_raw=+0.010 g_sm=+0.010 acc=1 | LR→0.132151 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#115 loss=0.363825 step=0.08097 g_raw=+0.030 g_sm=+0.010 acc=1 | LR→0.132416 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#120 loss=0.361456 step=0.06511 g_raw=+0.023 g_sm=+0.010 acc=1 | LR→0.132682 PERT→0.120015 (scale=0.04)\n",
            "[meta] cb#125 loss=0.360046 step=0.0004549 g_raw=-0.001 g_sm=+0.010 acc=1 | LR→0.132947 PERT→0.120015 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1316232093, PERT_used=0.1200134732 → LR_next=0.1329474554, PERT_next=0.1200147468\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.009 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1316232093→0.1329474554 PERT 0.1200134732→0.1200147468\n",
            "Training Accuracy: 0.68\n",
            "Test Accuracy: 0.61\n",
            "[round 8 | client 4] final LR=0.1329474554, final PERT=0.1200147468  (ΔLR=+0.0064920880, ΔPERT=+0.0000077478)\n",
            "\n",
            "[Round 8] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           3      0.532492      0.860000      0.132947      0.120014\n",
            "           2      0.536868      0.710000      0.132948      0.120015\n",
            "           1      0.560240      0.895000      0.132947      0.120015\n",
            "           0      0.576601      0.860000      0.132946      0.120014\n",
            "           4      0.576782      0.615000      0.132947      0.120015\n",
            "→ [Round 8] best_client=3, best_val=0.532492, prev_global_val=0.575939, improve=+0.043447, action=adopt+mix τ=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:  90%|█████████ | 9/10 [1:21:23<08:59, 539.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   8] acc_g=0.704 (μ=0.788, σ=0.108, FG=0.228) | t=530.355s, val=0.616 | TEL=FALSE\n",
            "[Round 9] Teleportation OFF | Aggregation=best\n",
            "[round 9 | client 0] seed LR=0.1264730913 (prev=0.1329461826), seed PERT=0.1200068116 (prev=0.1200136231), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.483410 step=0.03733 g_raw=+0.015 g_sm=+0.003 acc=1 | LR→0.126726 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.478747 step=0.05635 g_raw=+0.026 g_sm=+0.007 acc=1 | LR→0.126980 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.475430 step=0.0122 g_raw=+0.004 g_sm=+0.008 acc=1 | LR→0.127235 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.468619 step=0.03452 g_raw=+0.013 g_sm=+0.011 acc=1 | LR→0.127490 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.467495 step=0.002824 g_raw=+0.002 g_sm=+0.010 acc=1 | LR→0.127745 PERT→0.120008 (scale=0.04)\n",
            "[client 0 | unfold 1] LR_used=0.1264730913, PERT_used=0.1200068116 → LR_next=0.1277450677, PERT_next=0.1200076577\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.015 g_sm_mean=+0.007 acc_ratio=1.00 | LR 0.1264730913→0.1277450677 PERT 0.1200068116→0.1200076577\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.52\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.464292 step=0.05925 g_raw=+0.023 g_sm=+0.011 acc=1 | LR→0.128001 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.458852 step=0.05688 g_raw=+0.024 g_sm=+0.013 acc=1 | LR→0.128258 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.458123 step=0.003379 g_raw=-0.001 g_sm=+0.011 acc=1 | LR→0.128515 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.451668 step=0.07021 g_raw=+0.029 g_sm=+0.013 acc=1 | LR→0.128772 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.450476 step=0.02399 g_raw=+0.012 g_sm=+0.012 acc=1 | LR→0.129030 PERT→0.120009 (scale=0.04)\n",
            "[client 0 | unfold 2] LR_used=0.1277450677, PERT_used=0.1200076577 → LR_next=0.1290304678, PERT_next=0.1200090908\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1277450677→0.1290304678 PERT 0.1200076577→0.1200090908\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.51\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.447225 step=0.01396 g_raw=+0.007 g_sm=+0.012 acc=1 | LR→0.129289 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.446268 step=0.03568 g_raw=+0.015 g_sm=+0.011 acc=1 | LR→0.129548 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.442551 step=0.03665 g_raw=+0.018 g_sm=+0.012 acc=1 | LR→0.129808 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.441722 step=0.009056 g_raw=+0.005 g_sm=+0.011 acc=1 | LR→0.130068 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.438330 step=0.02674 g_raw=+0.011 g_sm=+0.011 acc=1 | LR→0.130329 PERT→0.120010 (scale=0.04)\n",
            "[client 0 | unfold 3] LR_used=0.1290304678, PERT_used=0.1200090908 → LR_next=0.1303287075, PERT_next=0.1200104369\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1290304678→0.1303287075 PERT 0.1200090908→0.1200104369\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.435194 step=0.06794 g_raw=+0.029 g_sm=+0.011 acc=1 | LR→0.130590 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.433729 step=0.05346 g_raw=+0.023 g_sm=+0.011 acc=1 | LR→0.130852 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.432751 step=0.006241 g_raw=+0.001 g_sm=+0.009 acc=1 | LR→0.131114 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.429257 step=0.03357 g_raw=+0.014 g_sm=+0.010 acc=1 | LR→0.131377 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.424977 step=0.03193 g_raw=+0.015 g_sm=+0.011 acc=1 | LR→0.131640 PERT→0.120012 (scale=0.04)\n",
            "[client 0 | unfold 4] LR_used=0.1303287075, PERT_used=0.1200104369 → LR_next=0.1316399116, PERT_next=0.1200116940\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1303287075→0.1316399116 PERT 0.1200104369→0.1200116940\n",
            "Training Accuracy: 0.58\n",
            "Test Accuracy: 0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.423287 step=0.008856 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.131904 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#110 loss=0.420246 step=0.04773 g_raw=+0.019 g_sm=+0.012 acc=1 | LR→0.132168 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.417872 step=0.04859 g_raw=+0.022 g_sm=+0.012 acc=1 | LR→0.132433 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.415235 step=0.009664 g_raw=+0.005 g_sm=+0.012 acc=1 | LR→0.132699 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.413535 step=0.0414 g_raw=+0.018 g_sm=+0.012 acc=1 | LR→0.132964 PERT→0.120013 (scale=0.04)\n",
            "[client 0 | unfold 5] LR_used=0.1316399116, PERT_used=0.1200116940 → LR_next=0.1329644803, PERT_next=0.1200131071\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1316399116→0.1329644803 PERT 0.1200116940→0.1200131071\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.51\n",
            "[round 9 | client 0] final LR=0.1329644803, final PERT=0.1200131071  (ΔLR=+0.0064913890, ΔPERT=+0.0000062956)\n",
            "[round 9 | client 1] seed LR=0.1264736777 (prev=0.1329473554), seed PERT=0.1200072729 (prev=0.1200145459), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.431185 step=0.05535 g_raw=+0.023 g_sm=+0.003 acc=1 | LR→0.126727 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.428642 step=0.03769 g_raw=+0.014 g_sm=+0.005 acc=1 | LR→0.126981 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.423134 step=0.03438 g_raw=+0.014 g_sm=+0.008 acc=1 | LR→0.127235 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.418622 step=0.001167 g_raw=-0.001 g_sm=+0.009 acc=1 | LR→0.127490 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.415908 step=0.04003 g_raw=+0.018 g_sm=+0.011 acc=1 | LR→0.127746 PERT→0.120008 (scale=0.04)\n",
            "[client 1 | unfold 1] LR_used=0.1264736777, PERT_used=0.1200072729 → LR_next=0.1277455863, PERT_next=0.1200080499\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1264736777→0.1277455863 PERT 0.1200072729→0.1200080499\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.54\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.411913 step=0.01355 g_raw=+0.005 g_sm=+0.012 acc=1 | LR→0.128002 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.407692 step=0.08783 g_raw=+0.035 g_sm=+0.012 acc=1 | LR→0.128258 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.405272 step=0.03598 g_raw=+0.015 g_sm=+0.013 acc=1 | LR→0.128515 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.404852 step=0.0166 g_raw=+0.007 g_sm=+0.011 acc=1 | LR→0.128773 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.401184 step=0.05258 g_raw=+0.023 g_sm=+0.011 acc=1 | LR→0.129031 PERT→0.120009 (scale=0.04)\n",
            "[client 1 | unfold 2] LR_used=0.1277455863, PERT_used=0.1200080499 → LR_next=0.1290309386, PERT_next=0.1200094336\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.012 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1277455863→0.1290309386 PERT 0.1200080499→0.1200094336\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.398657 step=0.006642 g_raw=+0.004 g_sm=+0.011 acc=1 | LR→0.129290 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.397204 step=0.03169 g_raw=+0.013 g_sm=+0.011 acc=1 | LR→0.129549 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.393218 step=0.05243 g_raw=+0.020 g_sm=+0.012 acc=1 | LR→0.129808 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.387866 step=0.03677 g_raw=+0.016 g_sm=+0.014 acc=1 | LR→0.130069 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#075 loss=0.385348 step=0.01266 g_raw=+0.005 g_sm=+0.013 acc=1 | LR→0.130329 PERT→0.120011 (scale=0.04)\n",
            "[client 1 | unfold 3] LR_used=0.1290309386, PERT_used=0.1200094336 → LR_next=0.1303293221, PERT_next=0.1200109079\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1290309386→0.1303293221 PERT 0.1200094336→0.1200109079\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.384815 step=0.002708 g_raw=+0.001 g_sm=+0.011 acc=1 | LR→0.130591 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.381403 step=0.02177 g_raw=+0.010 g_sm=+0.012 acc=1 | LR→0.130852 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.377129 step=0.03631 g_raw=+0.013 g_sm=+0.013 acc=1 | LR→0.131115 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.375419 step=0.03355 g_raw=+0.014 g_sm=+0.013 acc=1 | LR→0.131377 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.373627 step=0.009914 g_raw=+0.004 g_sm=+0.012 acc=1 | LR→0.131641 PERT→0.120012 (scale=0.04)\n",
            "[client 1 | unfold 4] LR_used=0.1303293221, PERT_used=0.1200109079 → LR_next=0.1316407853, PERT_next=0.1200123955\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.011 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1303293221→0.1316407853 PERT 0.1200109079→0.1200123955\n",
            "Training Accuracy: 0.78\n",
            "Test Accuracy: 0.71\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.373290 step=0.01682 g_raw=+0.009 g_sm=+0.010 acc=1 | LR→0.131905 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#110 loss=0.370431 step=0.01419 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.132169 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.368059 step=0.001018 g_raw=+0.001 g_sm=+0.010 acc=1 | LR→0.132434 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.367034 step=0.03147 g_raw=+0.009 g_sm=+0.009 acc=1 | LR→0.132699 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.365179 step=0.05364 g_raw=+0.021 g_sm=+0.010 acc=1 | LR→0.132965 PERT→0.120014 (scale=0.04)\n",
            "[client 1 | unfold 5] LR_used=0.1316407853, PERT_used=0.1200123955 → LR_next=0.1329650946, PERT_next=0.1200135666\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1316407853→0.1329650946 PERT 0.1200123955→0.1200135666\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.72\n",
            "[round 9 | client 1] final LR=0.1329650946, final PERT=0.1200135666  (ΔLR=+0.0064914169, ΔPERT=+0.0000062936)\n",
            "[round 9 | client 2] seed LR=0.1264739035 (prev=0.1329478070), seed PERT=0.1200075295 (prev=0.1200150590), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.538981 step=0.04546 g_raw=+0.021 g_sm=+0.003 acc=1 | LR→0.126727 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#010 loss=0.527740 step=0.05804 g_raw=+0.022 g_sm=+0.009 acc=1 | LR→0.126981 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#015 loss=0.522789 step=0.04389 g_raw=+0.021 g_sm=+0.011 acc=1 | LR→0.127235 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.515749 step=0.02539 g_raw=+0.009 g_sm=+0.014 acc=1 | LR→0.127491 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.507914 step=0.037 g_raw=+0.017 g_sm=+0.016 acc=1 | LR→0.127746 PERT→0.120009 (scale=0.04)\n",
            "[client 2 | unfold 1] LR_used=0.1264739035, PERT_used=0.1200075295 → LR_next=0.1277461578, PERT_next=0.1200086291\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.021 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1264739035→0.1277461578 PERT 0.1200075295→0.1200086291\n",
            "Training Accuracy: 0.54\n",
            "Test Accuracy: 0.60\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.503738 step=0.06206 g_raw=+0.027 g_sm=+0.016 acc=1 | LR→0.128002 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#035 loss=0.501123 step=0.01071 g_raw=+0.005 g_sm=+0.015 acc=1 | LR→0.128259 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.497709 step=0.06785 g_raw=+0.031 g_sm=+0.015 acc=1 | LR→0.128516 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#045 loss=0.485707 step=0.004555 g_raw=+0.002 g_sm=+0.017 acc=1 | LR→0.128774 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#050 loss=0.479424 step=0.1103 g_raw=+0.050 g_sm=+0.017 acc=1 | LR→0.129032 PERT→0.120011 (scale=0.04)\n",
            "[client 2 | unfold 2] LR_used=0.1277461578, PERT_used=0.1200086291 → LR_next=0.1290320739, PERT_next=0.1200105319\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.017 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1277461578→0.1290320739 PERT 0.1200086291→0.1200105319\n",
            "Training Accuracy: 0.56\n",
            "Test Accuracy: 0.65\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.477688 step=0.007916 g_raw=+0.004 g_sm=+0.016 acc=1 | LR→0.129291 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#060 loss=0.471499 step=0.1049 g_raw=+0.045 g_sm=+0.016 acc=1 | LR→0.129550 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#065 loss=0.471120 step=0.01305 g_raw=+0.006 g_sm=+0.014 acc=1 | LR→0.129810 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#070 loss=0.458585 step=0.01629 g_raw=+0.009 g_sm=+0.016 acc=1 | LR→0.130070 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#075 loss=0.454227 step=0.03171 g_raw=+0.014 g_sm=+0.016 acc=1 | LR→0.130331 PERT→0.120012 (scale=0.04)\n",
            "[client 2 | unfold 3] LR_used=0.1290320739, PERT_used=0.1200105319 → LR_next=0.1303308790, PERT_next=0.1200123838\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.014 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1290320739→0.1303308790 PERT 0.1200105319→0.1200123838\n",
            "Training Accuracy: 0.62\n",
            "Test Accuracy: 0.73\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.451317 step=0.06104 g_raw=+0.025 g_sm=+0.015 acc=1 | LR→0.130592 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#085 loss=0.449046 step=0.006095 g_raw=+0.003 g_sm=+0.014 acc=1 | LR→0.130854 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#090 loss=0.435105 step=0.06917 g_raw=+0.028 g_sm=+0.018 acc=1 | LR→0.131116 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#095 loss=0.430550 step=0.04453 g_raw=+0.014 g_sm=+0.017 acc=1 | LR→0.131379 PERT→0.120014 (scale=0.04)\n",
            "[meta] cb#100 loss=0.426076 step=0.1086 g_raw=+0.039 g_sm=+0.016 acc=1 | LR→0.131643 PERT→0.120014 (scale=0.04)\n",
            "[client 2 | unfold 4] LR_used=0.1303308790, PERT_used=0.1200123838 → LR_next=0.1316428197, PERT_next=0.1200142925\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.016 g_sm_mean=+0.016 acc_ratio=1.00 | LR 0.1303308790→0.1316428197 PERT 0.1200123838→0.1200142925\n",
            "Training Accuracy: 0.88\n",
            "Test Accuracy: 0.84\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.421903 step=0.01467 g_raw=+0.006 g_sm=+0.016 acc=1 | LR→0.131907 PERT→0.120015 (scale=0.04)\n",
            "[meta] cb#110 loss=0.418550 step=0.003697 g_raw=+0.001 g_sm=+0.015 acc=1 | LR→0.132171 PERT→0.120015 (scale=0.04)\n",
            "[meta] cb#115 loss=0.415928 step=0.03571 g_raw=+0.015 g_sm=+0.015 acc=1 | LR→0.132436 PERT→0.120015 (scale=0.04)\n",
            "[meta] cb#120 loss=0.413461 step=0.04171 g_raw=+0.018 g_sm=+0.014 acc=1 | LR→0.132702 PERT→0.120016 (scale=0.04)\n",
            "[meta] cb#125 loss=0.411896 step=0.01502 g_raw=+0.006 g_sm=+0.013 acc=1 | LR→0.132968 PERT→0.120016 (scale=0.04)\n",
            "[client 2 | unfold 5] LR_used=0.1316428197, PERT_used=0.1200142925 → LR_next=0.1329678047, PERT_next=0.1200160550\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.015 acc_ratio=1.00 | LR 0.1316428197→0.1329678047 PERT 0.1200142925→0.1200160550\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.81\n",
            "[round 9 | client 2] final LR=0.1329678047, final PERT=0.1200160550  (ΔLR=+0.0064939012, ΔPERT=+0.0000085254)\n",
            "[round 9 | client 3] seed LR=0.1264734068 (prev=0.1329468136), seed PERT=0.1200070816 (prev=0.1200141632), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.452133 step=0.03303 g_raw=+0.015 g_sm=+0.003 acc=1 | LR→0.126727 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.449989 step=0.01422 g_raw=+0.006 g_sm=+0.004 acc=1 | LR→0.126980 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.447553 step=0.03862 g_raw=+0.017 g_sm=+0.006 acc=1 | LR→0.127235 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#020 loss=0.445466 step=0.02552 g_raw=+0.008 g_sm=+0.007 acc=1 | LR→0.127490 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#025 loss=0.439485 step=0.003441 g_raw=+0.004 g_sm=+0.010 acc=1 | LR→0.127745 PERT→0.120008 (scale=0.04)\n",
            "[client 3 | unfold 1] LR_used=0.1264734068, PERT_used=0.1200070816 → LR_next=0.1277451703, PERT_next=0.1200077248\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.005 acc_ratio=1.00 | LR 0.1264734068→0.1277451703 PERT 0.1200070816→0.1200077248\n",
            "Training Accuracy: 0.70\n",
            "Test Accuracy: 0.60\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.437555 step=0.0507 g_raw=+0.020 g_sm=+0.010 acc=1 | LR→0.128001 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.436733 step=0.007167 g_raw=+0.002 g_sm=+0.009 acc=1 | LR→0.128258 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#040 loss=0.433286 step=0.01022 g_raw=+0.005 g_sm=+0.010 acc=1 | LR→0.128515 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#045 loss=0.427777 step=0.005736 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.128772 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.422942 step=0.07452 g_raw=+0.030 g_sm=+0.013 acc=1 | LR→0.129030 PERT→0.120009 (scale=0.04)\n",
            "[client 3 | unfold 2] LR_used=0.1277451703, PERT_used=0.1200077248 → LR_next=0.1290303982, PERT_next=0.1200089967\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1277451703→0.1290303982 PERT 0.1200077248→0.1200089967\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.69\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.421717 step=0.01076 g_raw=+0.005 g_sm=+0.012 acc=1 | LR→0.129289 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#060 loss=0.420482 step=0.02513 g_raw=+0.011 g_sm=+0.011 acc=1 | LR→0.129548 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.419156 step=0.02464 g_raw=+0.011 g_sm=+0.011 acc=1 | LR→0.129808 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#070 loss=0.418750 step=0.01289 g_raw=+0.004 g_sm=+0.009 acc=1 | LR→0.130068 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#075 loss=0.417993 step=0.03405 g_raw=+0.012 g_sm=+0.009 acc=1 | LR→0.130329 PERT→0.120010 (scale=0.04)\n",
            "[client 3 | unfold 3] LR_used=0.1290303982, PERT_used=0.1200089967 → LR_next=0.1303285516, PERT_next=0.1200102641\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.011 acc_ratio=1.00 | LR 0.1290303982→0.1303285516 PERT 0.1200089967→0.1200102641\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.68\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.416347 step=0.02323 g_raw=+0.010 g_sm=+0.009 acc=1 | LR→0.130590 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#085 loss=0.416104 step=0.01508 g_raw=+0.007 g_sm=+0.008 acc=1 | LR→0.130851 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#090 loss=0.414399 step=0.0313 g_raw=+0.016 g_sm=+0.009 acc=1 | LR→0.131114 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#095 loss=0.413931 step=0.0004567 g_raw=+0.002 g_sm=+0.008 acc=1 | LR→0.131376 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#100 loss=0.413156 step=0.0148 g_raw=+0.004 g_sm=+0.007 acc=1 | LR→0.131639 PERT→0.120011 (scale=0.04)\n",
            "[client 3 | unfold 4] LR_used=0.1303285516, PERT_used=0.1200102641 → LR_next=0.1316394558, PERT_next=0.1200112492\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1303285516→0.1316394558 PERT 0.1200102641→0.1200112492\n",
            "Training Accuracy: 0.80\n",
            "Test Accuracy: 0.72\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.411258 step=0.005486 g_raw=+0.002 g_sm=+0.008 acc=1 | LR→0.131903 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#110 loss=0.409942 step=0.05279 g_raw=+0.019 g_sm=+0.008 acc=1 | LR→0.132167 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#115 loss=0.408679 step=0.0003062 g_raw=-0.001 g_sm=+0.008 acc=1 | LR→0.132432 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#120 loss=0.407791 step=0.01012 g_raw=+0.003 g_sm=+0.007 acc=1 | LR→0.132698 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#125 loss=0.405684 step=0.0001753 g_raw=-0.000 g_sm=+0.008 acc=1 | LR→0.132963 PERT→0.120012 (scale=0.04)\n",
            "[client 3 | unfold 5] LR_used=0.1316394558, PERT_used=0.1200112492 → LR_next=0.1329634751, PERT_next=0.1200121705\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.008 g_sm_mean=+0.008 acc_ratio=1.00 | LR 0.1316394558→0.1329634751 PERT 0.1200112492→0.1200121705\n",
            "Training Accuracy: 0.82\n",
            "Test Accuracy: 0.69\n",
            "[round 9 | client 3] final LR=0.1329634751, final PERT=0.1200121705  (ΔLR=+0.0064900682, ΔPERT=+0.0000050888)\n",
            "[round 9 | client 4] seed LR=0.1264737277 (prev=0.1329474554), seed PERT=0.1200073734 (prev=0.1200147468), gamma=0.50\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 1/5\n",
            "[meta] cb#005 loss=0.455149 step=0.02836 g_raw=+0.012 g_sm=+0.003 acc=1 | LR→0.126727 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#010 loss=0.453628 step=0.003972 g_raw=+0.002 g_sm=+0.004 acc=1 | LR→0.126981 PERT→0.120007 (scale=0.04)\n",
            "[meta] cb#015 loss=0.449258 step=0.03338 g_raw=+0.014 g_sm=+0.006 acc=1 | LR→0.127235 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#020 loss=0.439163 step=0.03997 g_raw=+0.018 g_sm=+0.010 acc=1 | LR→0.127490 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#025 loss=0.421405 step=0.04396 g_raw=+0.021 g_sm=+0.015 acc=1 | LR→0.127746 PERT→0.120008 (scale=0.04)\n",
            "[client 4 | unfold 1] LR_used=0.1264737277, PERT_used=0.1200073734 → LR_next=0.1277456371, PERT_next=0.1200081506\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.018 g_sm_mean=+0.006 acc_ratio=1.00 | LR 0.1264737277→0.1277456371 PERT 0.1200073734→0.1200081506\n",
            "Training Accuracy: 0.86\n",
            "Test Accuracy: 0.80\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 2/5\n",
            "[meta] cb#030 loss=0.416445 step=0.1104 g_raw=+0.043 g_sm=+0.014 acc=1 | LR→0.128002 PERT→0.120008 (scale=0.04)\n",
            "[meta] cb#035 loss=0.414451 step=0.02251 g_raw=+0.007 g_sm=+0.013 acc=1 | LR→0.128258 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#040 loss=0.411278 step=0.06126 g_raw=+0.022 g_sm=+0.013 acc=1 | LR→0.128515 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#045 loss=0.406438 step=0.01549 g_raw=+0.007 g_sm=+0.014 acc=1 | LR→0.128773 PERT→0.120009 (scale=0.04)\n",
            "[meta] cb#050 loss=0.403792 step=0.05443 g_raw=+0.023 g_sm=+0.014 acc=1 | LR→0.129031 PERT→0.120010 (scale=0.04)\n",
            "[client 4 | unfold 2] LR_used=0.1277456371, PERT_used=0.1200081506 → LR_next=0.1290312508, PERT_next=0.1200097770\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.013 g_sm_mean=+0.014 acc_ratio=1.00 | LR 0.1277456371→0.1290312508 PERT 0.1200081506→0.1200097770\n",
            "Training Accuracy: 0.90\n",
            "Test Accuracy: 0.81\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 3/5\n",
            "[meta] cb#055 loss=0.402786 step=0.03767 g_raw=+0.014 g_sm=+0.012 acc=1 | LR→0.129290 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#060 loss=0.399283 step=0.04914 g_raw=+0.021 g_sm=+0.013 acc=1 | LR→0.129549 PERT→0.120010 (scale=0.04)\n",
            "[meta] cb#065 loss=0.395995 step=0.07001 g_raw=+0.029 g_sm=+0.013 acc=1 | LR→0.129809 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#070 loss=0.394902 step=0.00102 g_raw=+0.001 g_sm=+0.012 acc=1 | LR→0.130069 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#075 loss=0.394174 step=0.02943 g_raw=+0.013 g_sm=+0.011 acc=1 | LR→0.130330 PERT→0.120011 (scale=0.04)\n",
            "[client 4 | unfold 3] LR_used=0.1290312508, PERT_used=0.1200097770 → LR_next=0.1303296412, PERT_next=0.1200112548\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.012 acc_ratio=1.00 | LR 0.1290312508→0.1303296412 PERT 0.1200097770→0.1200112548\n",
            "Training Accuracy: 0.90\n",
            "Test Accuracy: 0.82\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 4/5\n",
            "[meta] cb#080 loss=0.392835 step=0.004446 g_raw=+0.001 g_sm=+0.010 acc=1 | LR→0.130591 PERT→0.120011 (scale=0.04)\n",
            "[meta] cb#085 loss=0.389050 step=0.0232 g_raw=+0.009 g_sm=+0.011 acc=1 | LR→0.130853 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#090 loss=0.386290 step=0.01456 g_raw=+0.003 g_sm=+0.011 acc=1 | LR→0.131115 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#095 loss=0.385016 step=0.0456 g_raw=+0.018 g_sm=+0.011 acc=1 | LR→0.131378 PERT→0.120012 (scale=0.04)\n",
            "[meta] cb#100 loss=0.383741 step=0.04583 g_raw=+0.019 g_sm=+0.010 acc=1 | LR→0.131641 PERT→0.120013 (scale=0.04)\n",
            "[client 4 | unfold 4] LR_used=0.1303296412, PERT_used=0.1200112548 → LR_next=0.1316408549, PERT_next=0.1200125119\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.010 g_sm_mean=+0.010 acc_ratio=1.00 | LR 0.1303296412→0.1316408549 PERT 0.1200112548→0.1200125119\n",
            "Training Accuracy: 0.90\n",
            "Test Accuracy: 0.82\n",
            "\n",
            "\n",
            "Deep Unfolding Iteration 5/5\n",
            "[meta] cb#105 loss=0.382991 step=0.01091 g_raw=+0.004 g_sm=+0.009 acc=1 | LR→0.131905 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#110 loss=0.381933 step=0.003341 g_raw=-0.000 g_sm=+0.009 acc=1 | LR→0.132169 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#115 loss=0.379855 step=0.0001268 g_raw=-0.002 g_sm=+0.009 acc=1 | LR→0.132434 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#120 loss=0.379336 step=0.001311 g_raw=+0.002 g_sm=+0.008 acc=1 | LR→0.132699 PERT→0.120013 (scale=0.04)\n",
            "[meta] cb#125 loss=0.378970 step=0.005744 g_raw=+0.002 g_sm=+0.007 acc=1 | LR→0.132965 PERT→0.120014 (scale=0.04)\n",
            "[client 4 | unfold 5] LR_used=0.1316408549, PERT_used=0.1200125119 → LR_next=0.1329650299, PERT_next=0.1200135611\n",
            "[meta-summary] callbacks=25 g_raw_mean=+0.007 g_sm_mean=+0.009 acc_ratio=1.00 | LR 0.1316408549→0.1329650299 PERT 0.1200125119→0.1200135611\n",
            "Training Accuracy: 0.90\n",
            "Test Accuracy: 0.81\n",
            "[round 9 | client 4] final LR=0.1329650299, final PERT=0.1200135611  (ΔLR=+0.0064913022, ΔPERT=+0.0000061878)\n",
            "\n",
            "[Round 9] Validation per client\n",
            "      client      val_loss      test_acc      lr_final    pert_final\n",
            "           4      0.532036      0.815000      0.132965      0.120014\n",
            "           1      0.540702      0.725000      0.132965      0.120014\n",
            "           2      0.574436      0.810000      0.132968      0.120016\n",
            "           0      0.617258      0.510000      0.132964      0.120013\n",
            "           3      0.621072      0.690000      0.132963      0.120012\n",
            "→ [Round 9] best_client=4, best_val=0.532036, prev_global_val=0.615660, improve=+0.083624, action=adopt+mix τ=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 10/10 [1:30:18<00:00, 541.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round   9] acc_g=0.761 (μ=0.710, σ=0.111, FG=0.231) | t=524.950s, val=0.563 | TEL=FALSE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 650x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 650x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAGGCAYAAADrfDCjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAbZBJREFUeJzt3XdcU/f6B/DPSSAJW2QjyHAgaAEFRdBqW3HVVq0ddmrtrW2t3trSSe+vWvWqnda2WrXeUu2229WqlWqHoyi4B4oMF1MgDGWYc35/RCKRISDhEPJ5v168NCdnPMkXwsNzvkOQJEkCEREREVkMhdwBEBEREVHbYgJIREREZGGYABIRERFZGCaARERERBaGCSARERGRhWECSERERGRhmAASERERWRgmgEREREQWhgkgERERkYVhAkhEFuHRRx+Fv79/m1/3lltuwS233GJ4nJmZCUEQsGrVqusea4qYV61aBUEQkJmZ2arnbQp/f388+uijbX5dIqqLCSARGTl16hSefPJJBAYGQqPRwNHREYMGDcL777+PS5cumey658+fx+uvv479+/eb7BqWZMGCBfj555/lDoOI2ikruQMgovZj48aNuPfee6FWqzFp0iT06dMHVVVV+Pvvv/Hiiy/iyJEj+Pjjj01y7fPnz2POnDnw9/dHeHi4Sa7RHvj5+eHSpUuwtrY26XUWLFiAe+65B+PHjzfa/sgjj+D++++HWq026fWJqH1jAkhEAICMjAzcf//98PPzw++//w4vLy/Dc9OnT0daWho2btwoY4TGLl68CFtbW7nDaDZBEKDRaGS7vlKphFKplO36RNQ+8BYwEQEA3nrrLZSVleGTTz4xSv5qdO/eHTNnzjTa9sUXXyAiIgI2Njbo3Lkz7r//fpw5c8Zon1tuuQV9+vTB0aNHceutt8LW1hZdunTBW2+9Zdhn+/bt6N+/PwBgypQpEATBqJ9czTmSk5MxZMgQ2Nra4tVXXwUArF27FmPGjIG3tzfUajW6deuGefPmQafTNfs9uOOOOxAYGFjvc9HR0YiMjDQ8/vTTT3HbbbfB3d0darUaISEhWLZs2XWv0VAfwJ9//hl9+vSBRqNBnz598NNPP9V7/DvvvIOYmBi4uLjAxsYGERER+P777432EQQB5eXlWL16teG9rOl711AfwI8++gi9e/eGWq2Gt7c3pk+fjuLiYqN9mtKWzZWeno57770XnTt3hq2tLQYOHFjvHxoffvghevfuDVtbWzg7OyMyMhJfffWV4fnS0lI8++yz8Pf3h1qthru7O4YPH46UlJQWx0bUkTEBJCIAwPr16xEYGIiYmJgm7T9//nxMmjQJPXr0wKJFi/Dss88iMTERQ4YMqZM4FBUVYdSoUQgLC8O7776LXr164eWXX8avv/4KAAgODsbcuXMBAE888QQ+//xzfP755xgyZIjhHBcuXMDo0aMRHh6OxYsX49ZbbwWgT2js7e0RFxeH999/HxEREZg1axZeeeWVZr8HEydOREZGBvbs2WO0PSsrC7t378b9999v2LZs2TL4+fnh1VdfxbvvvgtfX188/fTTWLp0abOvu2XLFtx9990QBAELFy7E+PHjMWXKFOzdu7fOvu+//z769u2LuXPnYsGCBbCyssK9995rlDR9/vnnUKvVuPnmmw3v5ZNPPtng9V9//XVMnz4d3t7eePfdd3H33XdjxYoVGDFiBKqrq432vV5bNkdubi5iYmKwefNmPP3005g/fz4qKiowduxYowR45cqVeOaZZxASEoLFixdjzpw5CA8Pxz///GPY56mnnsKyZctw991346OPPsILL7wAGxsbHDt2rNlxEVkEiYgsnlarlQBI48aNa9L+mZmZklKplObPn2+0/dChQ5KVlZXR9qFDh0oApM8++8ywrbKyUvL09JTuvvtuw7Y9e/ZIAKRPP/20zvVqzrF8+fI6z128eLHOtieffFKytbWVKioqDNsmT54s+fn5Nfq6tFqtpFarpeeff95o+1tvvSUJgiBlZWU1et2RI0dKgYGBdWIfOnSo4XFGRkad1xkeHi55eXlJxcXFhm1btmyRANSJ+drrVlVVSX369JFuu+02o+12dnbS5MmT68T46aefSgCkjIwMSZIkKS8vT1KpVNKIESMknU5n2G/JkiUSACkhIcHotTSlLRvi5+dnFNOzzz4rAZD++usvw7bS0lIpICBA8vf3N8Qzbtw4qXfv3o2e28nJSZo+ffp1YyAiPVYAiQglJSUAAAcHhybt/+OPP0IURdx3330oKCgwfHl6eqJHjx7Ytm2b0f729vZ4+OGHDY9VKhUGDBiA9PT0JseoVqsxZcqUOtttbGwM/y8tLUVBQQFuvvlmXLx4EcePH2/y+QHA0dERo0ePxrfffgtJkgzb16xZg4EDB6Jr1671Xler1aKgoABDhw5Feno6tFptk6+ZnZ2N/fv3Y/LkyXBycjJsHz58OEJCQursX/u6RUVF0Gq1uPnmm1t8q3Pr1q2oqqrCs88+C4Xi6q+EqVOnwtHRsc7t2NZoyxq//PILBgwYgMGDBxud/4knnkBmZiaOHj0KAOjUqRPOnj1bpzJbW6dOnfDPP//g/PnzzY6DyBIxASQiODo6AtAnUE1x8uRJSJKEHj16wM3Nzejr2LFjyMvLM9rfx8cHgiAYbXN2dkZRUVGTY+zSpQtUKlWd7UeOHMFdd90FJycnODo6ws3NzZCgNCcRqzFx4kScOXMGu3btAqCfFic5ORkTJ0402m/Hjh2IjY2FnZ0dOnXqBDc3N0O/xOZcNysrCwDQo0ePOs8FBQXV2bZhwwYMHDgQGo0GnTt3hpubG5YtW9ai11r7+tdeS6VSITAw0PB8jdZoy9rXru81BgcHG8X28ssvw97eHgMGDECPHj0wffp07Nixw+iYt956C4cPH4avry8GDBiA119/vUVJKZGl4ChgIoKjoyO8vb1x+PDhJu0viiIEQcCvv/5a74hSe3t7o8cNjTqtXWW7ntqVrxrFxcUYOnQoHB0dMXfuXHTr1g0ajQYpKSl4+eWXIYpik89f484774StrS2+/fZbxMTE4Ntvv4VCocC9995r2OfUqVMYNmwYevXqhUWLFsHX1xcqlQq//PIL3nvvvRZdtyn++usvjB07FkOGDMFHH30ELy8vWFtb49NPPzUaEGFKrdGWzRUcHIzU1FRs2LABmzZtwg8//ICPPvoIs2bNwpw5cwAA9913H26++Wb89NNP2LJlC95++228+eab+PHHHzF69GiTxUZkrpgAEhEA/QjYjz/+GLt27UJ0dHSj+3br1g2SJCEgIAA9e/ZsletfW1Vqiu3bt+PChQv48ccfjQaMZGRktDgOOzs73HHHHfjuu++waNEirFmzBjfffDO8vb0N+6xfvx6VlZVYt26d0W3ha299N4Wfnx8AfVX1WqmpqUaPf/jhB2g0GmzevNloHr9PP/20zrFNfT9rrp+ammo0ArqqqgoZGRmIjY1t0nlaws/Pr85rBGC4dV8TG6Bvl4kTJ2LixImoqqrChAkTMH/+fMTHxxum1fHy8sLTTz+Np59+Gnl5eejXrx/mz5/PBJCoHrwFTEQAgJdeegl2dnZ4/PHHkZubW+f5U6dO4f333wcATJgwAUqlEnPmzKlT+ZEkCRcuXGj29e3s7ACgzgjixtRUo2rHUFVVhY8++qjZ169t4sSJOH/+PP73v//hwIEDdW7/1nddrVZbbyJ2PV5eXggPD8fq1auNbuP+9ttvhj5wta8rCILRFDeZmZn1rvhhZ2fXpPcyNjYWKpUKH3zwgdHr+eSTT6DVajFmzJhmv6amuv3225GUlGS43Q4A5eXl+Pjjj+Hv72/oA3nt95NKpUJISAgkSUJ1dTV0Ol2dW+Du7u7w9vZGZWWlyeInMmesABIRAH1V76uvvsLEiRMRHBxstBLIzp078d133xnmkuvWrRv++9//Ij4+HpmZmRg/fjwcHByQkZGBn376CU888QReeOGFZl+/U6dOWL58ORwcHGBnZ4eoqCgEBAQ0eExMTAycnZ0xefJkPPPMMxAEAZ9//vkN3468/fbb4eDggBdeeAFKpRJ333230fMjRoyASqXCnXfeiSeffBJlZWVYuXIl3N3dkZ2d3ezrLVy4EGPGjMHgwYPx2GOPobCw0DDvXVlZmWG/MWPGYNGiRRg1ahQefPBB5OXlYenSpejevTsOHjxodM6IiAhs3boVixYtgre3NwICAhAVFVXn2m5uboiPj8ecOXMwatQojB07Fqmpqfjoo4/Qv39/owEfre2VV17B119/jdGjR+OZZ55B586dsXr1amRkZOCHH34wDEoZMWIEPD09MWjQIHh4eODYsWNYsmQJxowZAwcHBxQXF8PHxwf33HMPwsLCYG9vj61bt2LPnj149913TRY/kVmTZ/AxEbVXJ06ckKZOnSr5+/tLKpVKcnBwkAYNGiR9+OGHRtOqSJIk/fDDD9LgwYMlOzs7yc7OTurVq5c0ffp0KTU11bDP0KFD653Co75pWdauXSuFhIRIVlZWRlOlNHQOSZKkHTt2SAMHDpRsbGwkb29v6aWXXpI2b94sAZC2bdvW6PUa89BDD0kApNjY2HqfX7dunRQaGippNBrJ399fevPNN6WEhASjKVZqYr/eNDCSpH8vg4ODJbVaLYWEhEg//vhjvTF/8sknUo8ePSS1Wi316tVL+vTTT6XZs2dL136cHz9+XBoyZIhkY2MjATBMv3LtNDA1lixZIvXq1UuytraWPDw8pGnTpklFRUVG+zSnLetz7TQwkiRJp06dku655x6pU6dOkkajkQYMGCBt2LDBaJ8VK1ZIQ4YMkVxcXCS1Wi1169ZNevHFFyWtVitJkn4qmhdffFEKCwuTHBwcJDs7OyksLEz66KOPrhsTkaUSJMmEPXeJiIiIqN1hH0AiIiIiC8MEkIiIiMjCMAEkIiIisjBMAImIiIgsDBNAIiIiIgvDBJCIiIjIwnAi6HqIoojz58/DwcGhRctTEREREbU1SZJQWloKb29vw0TqDWECWI/z58/D19dX7jCIiIiImu3MmTPw8fFpdB8mgPVwcHAAoH8DHR0dTXYdURSRn58PNze362bq1D6xDc0f29D8sQ3NH9uwdZSUlMDX19eQxzSGCWA9am77Ojo6mjwBrKiogKOjI7/hzRTb0PyxDc0f29D8sQ1bV1O6r/FdJiIiIrIwTACJiIiILAwTQCIiIiILwwSQiIiIyMIwASQiIiKyMEwAiYiIiCwME0AiIiKSjU6UsDv9ArYcL8Tu9AvQiZLcIVkEzgNIREREsth0OBtz1h9FtrbiypYMeDlpMPvOEIzq4yVrbB0dK4BERETU5jYdzsa0L1JqJX96OdoKTPsiBZsOZ8sUmWVgAkhERERtSidKmLP+KOq72Vuzbc76o7wdbEJMAImIiKhNJWUU1qn81SYByNZWICmjsO2CsjBMAImIiKhN5ZU2nPy1ZD9qPiaARERE1KbcHTStuh81HxNAIiIialMDAjrDy6nh5E4A4OWkwYCAzm0XlIVhAkhERERtSqkQMOuOkEb3mX1nCJQKoY0isjxMAImIiKjNeTRQAVQpBSx7uB/nATQxJoBERETU5r7+57Th/08NCUBnW/3aFJdFCdGBrnKFZTGYABIREVGbKqmoxvqD5wEADhor/Pu2HhgRpO/vJ0rA9hN5coZnEZgAEhERUZtau+8cKqpFAMCEvl1go1Li5sBOhucTjzEBNDUmgERERNRmJEnCl7Vu/z4Q1RUAEOZtDweN/jbw9tQ8VOtEWeKzFEwAiYiIqM0cOKvF8ZxSAEDfrp3Qy9MRAGClFDC0pxsAoKTiMvZmFskWoyVgAkhERERtpvbgjwcGdDV6blgvd8P/E4/ltllMlogJIBEREbWJ0opqrDtwZfCH2gp3hBpP9TK0p6th7r/E4+wHaEpMAImIiKhNrN1/HpeqdQCA8X27wFZlZfR8J1sVIvycAQAZBeVIzy9r8xgtBRNAIiIiMjlJkvBVrdu/9w/wrXe/2ODat4FZBTQVJoBERERkcofOaXE0uwQAEObjhN7eTvXuNyzYw/D/rewHaDJMAImIiMjkvk5qePBHbYGudvB3sQUA7M0qgvZitcljs0SyJ4BLly6Fv78/NBoNoqKikJSU1Oj+xcXFmD59Ory8vKBWq9GzZ0/88ssvhuf//PNP3HnnnfD29oYgCPj5559N/AqIiIioMWWVl7F2v37wh51KiTvDvBvcVxAEQxVQJ0pcFcREZE0A16xZg7i4OMyePRspKSkICwvDyJEjkZdXf2NXVVVh+PDhyMzMxPfff4/U1FSsXLkSXbp0MexTXl6OsLAwLF26tK1eBhERETVi/YHzuFilH/wxrm8X2KmtGt1/GPsBmlzjLWBiixYtwtSpUzFlyhQAwPLly7Fx40YkJCTglVdeqbN/QkICCgsLsXPnTlhbWwMA/P39jfYZPXo0Ro8ebfLYiYiIqGlq3/59sJHbvzX6+3eGg8YKpRWXDauCWCtlv2nZociWAFZVVSE5ORnx8fGGbQqFArGxsdi1a1e9x6xbtw7R0dGYPn061q5dCzc3Nzz44IN4+eWXoVQqWxxLZWUlKisrDY9LSvSdVEVRhCiabikaURQhSZJJr0GmxTY0f2xD88c2bN8On9Pi4FktAKBPF0eEeDnUaatr21ApAEN7umHDwWyUVFzGnowLGBjo0uaxm5vm/AzIlgAWFBRAp9PBw8PDaLuHhweOHz9e7zHp6en4/fff8dBDD+GXX35BWloann76aVRXV2P27NktjmXhwoWYM2dOne35+fmoqKho8XmvRxRFaLVaSJIEhYJ/2ZgjtqH5YxuaP7Zh+/bpn1mG/9/Rq1O93bzqa8NIbzU2HNQ/vz4lE4H2ujaJ15yVlpY2eV9ZbwE3lyiKcHd3x8cffwylUomIiAicO3cOb7/99g0lgPHx8YiLizM8Likpga+vL9zc3ODo6NgaoddLFEUIggA3Nzd+aJkptqH5YxuaP7Zh+1VeeRm/ndgPALBVKfHg4CDY19P/r742HGvfCfO2ZEEnSth9uhzz3d3rHEfGNBpNk/eVLQF0dXWFUqlEbq7xHD+5ubnw9PSs9xgvLy9YW1sb3e4NDg5GTk4OqqqqoFKpWhSLWq2GWq2us12hUJj8w0QQhDa5DpkO29D8sQ3NH9uwffrlcA7KKq8M/gj3hqNNw7+nr23DzvYaRPg5IymjEBkF5ci8cBGBbvZtEre5as73v2w/KSqVChEREUhMTDRsE0URiYmJiI6OrveYQYMGIS0tzege94kTJ+Dl5dXi5I+IiIhM46ukM4b/Nzb3X0O4KojpyPqnUlxcHFauXInVq1fj2LFjmDZtGsrLyw2jgidNmmQ0SGTatGkoLCzEzJkzceLECWzcuBELFizA9OnTDfuUlZVh//792L9/PwAgIyMD+/fvx+nTp0FERERt48h5LQ6cKQYA9PZ2xE1d6l/5ozFcFcR0ZO0DOHHiROTn52PWrFnIyclBeHg4Nm3aZBgYcvr0aaNypq+vLzZv3oznnnsOoaGh6NKlC2bOnImXX37ZsM/evXtx6623Gh7X9O2bPHkyVq1a1TYvjIiIyMJ9c031TxCEZp+jZlWQzAsXDauCONlat2aYFkv2QSAzZszAjBkz6n1u+/btdbZFR0dj9+7dDZ7vlltugSRJrRUeERERNdPFqsv4ed85AICNtRLjwhte+aMxNauCfPJ3hmFVkHHhXa5/IF0Xe8sSERFRq9pwMBullZcBAGPDvOGgaXnVjquCmAYTQCIiImpVtVf+eCCq+YM/aqtZFQSAYVUQunFMAImIiKjVHMsuwb7TxQCAXp4OCPNp/uCP2qyVCgzt6QYAKKm4jL2ZRTcaIoEJIBEREbWib2qv+xvVssEf14qtNRo4kaOBWwUTQCIiImoVl6p0+PHK4A+NtaLVBmzcEuQGpUKfSP5+nP0AWwMTQCIiImoVGw9lo7RCP/jjjlBvONm0zpQtnWxViPBzBgCkF5QjPb+sVc5ryZgAEhERUauoffu3JSt/NIargrQuJoBERER0w07klmJvln6ARpCHA/p17dSq57+tF1cFaU1MAImIiOiGGU39MsC3VQZ/1NbNTb8qCADDqiDUckwAiYiI6IZUVOvwY4p+8IfaSoG7+vq0+jVqVgUBYFgVhFqOCSARERHdkF8PZ0N7SV+RGxPqZbL1erkqSOthAkhEREQ35Ot/zhj+/2ArD/6ojauCtB4mgERERNRiaXmlSMosBAD0cLc3TNdiClwVpPUwASQiIqIW+zrpavXvgQGts/JHY2qvCvL7cY4GbikmgERERNQiFdU6/JByFgCgslJgQr/WWfmjMbVXBWE/wJZjAkhEREQtsvlIDoqvTMcy5iYvdLJVmfyaXBWkdTABJCIiohb56h/TrfzRGK4KcuOYABIREVGzncovwz8Z+sEf3dzs0N/fdIM/rsVVQW4cE0AiIiJqtmvX/TX14I/auCrIjWMCSERERM1SeVmH75OvDP5QKjChX+uv/NEYrgpy45gAEhERUbNsPpKLoitVt1F9PNHZzvSDP67FVUFuDBNAIiIiapZrb//KgauC3BgmgERERNRkGQXl2HnqAgAgwNUOAwM7yxLHtauCJGdxVZDmYAJIRERETfbNntrVP982HfxxrdqrgiRyNHCzMAEkIiKiJqm6LOL7vfrBH9ZKAXe38eCPa3FVkJZrFwng0qVL4e/vD41Gg6ioKCQlJTW6f3FxMaZPnw4vLy+o1Wr07NkTv/zyyw2dk4iIiBr329FcXCivAgCM7O0JF3u1rPFwVZCWkz0BXLNmDeLi4jB79mykpKQgLCwMI0eORF5e/Zl8VVUVhg8fjszMTHz//fdITU3FypUr0aVLlxafk4iIiK7v61qDPx6UafDHtYb14mjglpA9AVy0aBGmTp2KKVOmICQkBMuXL4etrS0SEhLq3T8hIQGFhYX4+eefMWjQIPj7+2Po0KEICwtr8TmJiIiocVkXyvF3WgEAwN/FFgMDXWSOSG9Y7X6Ax9kPsKms5Lx4VVUVkpOTER8fb9imUCgQGxuLXbt21XvMunXrEB0djenTp2Pt2rVwc3PDgw8+iJdffhlKpbJF56ysrERlZaXhcUlJCQBAFEWIoumGlYuiCEmSTHoNMi22ofljG5o/tmHbqF39m9jfF4AEUZRa5dw30oYBLjbwc7FF1oWL2JNZhKLySjjZWLdKXOamOe+frAlgQUEBdDodPDw8jLZ7eHjg+PHj9R6Tnp6O33//HQ899BB++eUXpKWl4emnn0Z1dTVmz57donMuXLgQc+bMqbM9Pz8fFRUVLXx11yeKIrRaLSRJgkIhezGWWoBtaP7YhuaPbWh61ToRa66M/rVSCBjaVd2q3aputA2ju9oj68JF6EQJ6/ecwohe8kxNI7fS0tIm7ytrAtgSoijC3d0dH3/8MZRKJSIiInDu3Dm8/fbbmD17dovOGR8fj7i4OMPjkpIS+Pr6ws3NDY6Ojq0Veh2iKEIQBLi5ufFDy0yxDc0f29D8sQ1N79fDOSi6eBkAMCLEA738u1zniOa50Ta8s58S3+zTJ6R7zlfg4SHu1zmiY9JoNE3eV9YE0NXVFUqlErm5xvfsc3Nz4enpWe8xXl5esLa2hlKpNGwLDg5GTk4OqqqqWnROtVoNtbruSCaFQmHyDxNBENrkOmQ6bEPzxzY0f2xD0/pmzxnD/x+M8jPJ+3wjbTgg0AUOGiuUVlzGHyfyoZP0E0Vbmua8d7K+OyqVChEREUhMTDRsE0URiYmJiI6OrveYQYMGIS0tzeg+94kTJ+Dl5QWVStWicxIREVH9zhRexF8n9YM/una2RUy39jH4ozauCtJ8sqfHcXFxWLlyJVavXo1jx45h2rRpKC8vx5QpUwAAkyZNMhrQMW3aNBQWFmLmzJk4ceIENm7ciAULFmD69OlNPicRERE1Te2VP+4f4AuFQr6VPxrDVUGaR/Y+gBMnTkR+fj5mzZqFnJwchIeHY9OmTYZBHKdPnzYqafr6+mLz5s147rnnEBoaii5dumDmzJl4+eWXm3xOIiIiur5qnYhvr6z8YaUQcE+EvCt/NOaWIDcoBECU9PMB/mdMiNwhtWuCJEmtM4a7AykpKYGTkxO0Wq3JB4Hk5eXB3d2d/VbMFNvQ/LENzR/b0HQ2Hc7BU18kAwBG9fbE8kciTHKd1mrD+5bvQlJmIQDg9+eHItDNvrVCNAvNyV/4k0JERET1qj333wNR7WPlj8YMC746+vf341wVpDFMAImIiKiOs0UX8efJfABAl042uLm7q8wRXV/tVUG2sh9go5gAEhERUR3f7jmDmk5iD7TjwR+1dXOzg7+LLQBgT2YRtBerZY6o/WICSEREREYu60Ss2auf+0+pEHBvpK/METWNIAiGKqBOlLD9BG8DN4QJIBERERnZlpqP3JJKAMCwXu7wcGz6ChNyG9braj/AxGNMABvCBJCIiIiMmNvgj9r6B3SGg0Y/y9321Dxc1onXOcIyMQEkIiIig3PFl7A9VV8569LJBkN6uMkcUfNcuyrIXq4KUi8mgERERGTw7Z4zEK8M/pjY3xdKMxj8cS2uCnJ9TACJiIgIgH7wx7dXBn8oBOA+Mxn8ca2aVUEA9gNsCBNAIiIiAgD8cSIf2doKAMBtvTzg6WQ+gz9q62SrQqRfZwBAekE50vPLZI6o/WECSERERACMB388GGWe1b8aXBWkcUwAiYiICNnaS4ZEyctJg6E93a9zRPvGVUEaxwSQiIiI8O2es2Y/+KM2rgrSOCaAREREFk4nSlizR3/715wHf9QmCAJu68VVQRrCBJCIiMjC/XkiH+evDP64Ncgd3p1sZI6odcSyH2CDmAASERFZuK9qDf64f4B5rfzRGONVQfK5KkgtTACJiIgsWG5JhaE65uGoxq1B5rXyR2NqrwqivVTNVUFqYQJIRERkwb7bewa6K6M/Jkb6wkrZsVIDrgpSv47VykRERNRkoijh6yT9yh+CANzX3/wHf1xraE+uClIfJoBEREQW6q+0ApwrvgRAnyj5ONvKHFHrc7bjqiD1YQJIRERkob7+5+rgjwc60OCPa3FVkLqYABIREVmgvJIKwwoZ7g5q3NbLvFf+aAxXBamLCSAREZEF+i75LC5fGfxxX6QvrDvY4I/auCpIXR23tYmIiKheoijhmysrfwiCfum3joyrgtTVLhLApUuXwt/fHxqNBlFRUUhKSmpw31WrVkEQBKMvjUZjtE9ubi4effRReHt7w9bWFqNGjcLJkydN/TKIiIjMwo5TBThTqB/8cXMPN/h27niDP67FVUGMyZ4ArlmzBnFxcZg9ezZSUlIQFhaGkSNHIi+v4cZxdHREdna24SsrK8vwnCRJGD9+PNLT07F27Vrs27cPfn5+iI2NRXl5eVu8JCIionbt61orfzw4oGNX/2pwVRBjsieAixYtwtSpUzFlyhSEhIRg+fLlsLW1RUJCQoPHCIIAT09Pw5eHx9XOnSdPnsTu3buxbNky9O/fH0FBQVi2bBkuXbqEr7/+ui1eEhERUbuVX1qJLUf0AyFc7dVGAyQ6Mq4KYkzWBLCqqgrJycmIjY01bFMoFIiNjcWuXbsaPK6srAx+fn7w9fXFuHHjcOTIEcNzlZWVAGB0W1ihUECtVuPvv/82wasgIiIyH98bDf7w6dCDP65VezoYS18VxErOixcUFECn0xlV8ADAw8MDx48fr/eYoKAgJCQkIDQ0FFqtFu+88w5iYmJw5MgR+Pj4oFevXujatSvi4+OxYsUK2NnZ4b333sPZs2eRnZ1d7zkrKysNiSMAlJSUAABEUYQomq5ELIoiJEky6TXItNiG5o9taP7Yhk0nihK+qXX7975In3bxvrVVGw7p4QqFAIiSflWQ+NG9THq9ttac90/WBLAloqOjER0dbXgcExOD4OBgrFixAvPmzYO1tTV+/PFH/Otf/0Lnzp2hVCoRGxuL0aNHQ5Kkes+5cOFCzJkzp872/Px8VFRUmOy1iKIIrVYLSZKgUFjOX2AdCdvQ/LENzR/bsOn2nC5BVuFFAMCArg7QXC5DXp78K2O0ZRuGettj/7kypBeUY2/qaXR11lz/IDNRWlra5H1lTQBdXV2hVCqRm2tchs3NzYWnp2eTzmFtbY2+ffsiLS3NsC0iIgL79++HVqtFVVUV3NzcEBUVhcjIyHrPER8fj7i4OMPjkpIS+Pr6ws3NDY6Oji14ZU0jiiIEQYCbmxs/tMwU29D8sQ3NH9uw6TYlnjP8f9KgbnB3bx+TP7dlG466qQz7z6UCAPbn6xAZ1D7eg9Zw7awojZE1AVSpVIiIiEBiYiLGjx8PQP9NkJiYiBkzZjTpHDqdDocOHcLtt99e5zknJycA+oEhe/fuxbx58+o9h1qthlqtrrNdoVCY/BtREIQ2uQ6ZDtvQ/LENzR/b8PoKyiqx5WjN4A8VRvT2alfvV1u1YWyIJ97YpE8Afz+ehyeGdDPp9dpSc9472W8Bx8XFYfLkyYiMjMSAAQOwePFilJeXY8qUKQCASZMmoUuXLli4cCEAYO7cuRg4cCC6d++O4uJivP3228jKysLjjz9uOOd3330HNzc3dO3aFYcOHcLMmTMxfvx4jBgxQpbXSEREJLcfks+iWqfvCnV3hA9UVu0n+WtL3dzs4Odii6wLFw2rgjjZWssdVpuTPQGcOHEi8vPzMWvWLOTk5CA8PBybNm0yDAw5ffq0UUZbVFSEqVOnIicnB87OzoiIiMDOnTsREhJi2Cc7OxtxcXHIzc2Fl5cXJk2ahNdee63NXxsREVF7IEkSvtlzxvD4/v5dZYxGXoIgYFgvDyTsyIBOlPDHyXyMDfOWO6w2J0gNjYywYCUlJXBycoJWqzV5H8C8vDy4u7u3qzI8NR3b0PyxDc0f2/D6dp26gAdW7gYAxHRzwVdTB8ockbG2bsOdaQV48H//AADGhXvj/fv7mvyabaE5+Qt/UoiIiDq42it/PDDAcqt/NbgqCBNAIiKiDq2wvAqbDucAADrbqTCit2Ws/NEYrgrCBJCIiKhD+zHlLKquVLjuifCB2kopc0Ttg6WvCsIEkIiIqIOSJAlf1br9e39/XxmjaV9u6ekOhaD/f+LxPHmDkQETQCIiog4qKaMQ6fnlAICBgZ0R6GYvc0Tth7OdCpF+nQEA6fnlyCgolzmitsUEkIiIqIPi4I/GWfJtYCaAREREHVBReRV+uTL4w9nWGiN7N22JVUsyLPjqgJitTACJiIjI3P247xyqLusHf9zdzwcaaw7+uFbNqiAA9KuCXKqWOaK2wwSQiIiog5Ekyej27/28/VuvmlVBAOhXBTmRL3NEbYcJIBERUQezN6sIaXllAIABAZ3R3Z2DPxoSa6H9AJkAEhERdTBf/3O1+vcgq3+N6h/QGQ5qy1sVhAkgERFRB1J8sQobDmUDAJxsrDGqDwd/NMZaqcCQIMtbFYQJIBERUQfyEwd/NFvt28C/W8ik0EwAiYiIOghJkvBN0hnD4wcGcOWPpqi9KoilTAfDBJCIiKiDSDldjNTcUgBApJ8zeng4yByRebDEVUGYABIREXUQXPmj5SxtVRAmgERERB2A9lI1Nhw8DwBw1FhhTKiXzBGZl9oJoCXcBmYCSERE1AGs3X8OFdX6wR8TOPij2bq52VvUqiBMAImIiMycJEn46p/aK39w8EdzWdqqIEwAiYiIzNz+M8U4nqMf/NGvayf08nSUOSLzZEmrgjABJCIiMnMc/NE6LGlVECaAREREZqykohrrD+hX/nDQWOGOUG+ZIzJf164KktyBVwVhAkhERGTG1u4/j0vVOgDAXX27wEbFwR83wug2cAdeFYQJIBERkZmqM/ijP2//3ihLWRWECSAREZGZOnhWi2PZJQCAcN9OCPHm4I8bZSmrgrSLBHDp0qXw9/eHRqNBVFQUkpKSGtx31apVEATB6Euj0RjtU1ZWhhkzZsDHxwc2NjYICQnB8uXLTf0yiIiI2lTtwR8PcvBHq7nNAkYDy54ArlmzBnFxcZg9ezZSUlIQFhaGkSNHIi+v4fvujo6OyM7ONnxlZWUZPR8XF4dNmzbhiy++wLFjx/Dss89ixowZWLdunalfDhERUZsorajGugP6lT/s1Va4I4wrf7QW4+lgOmY/QNkTwEWLFmHq1KmYMmWKoVJna2uLhISEBo8RBAGenp6GLw8PD6Pnd+7cicmTJ+OWW26Bv78/nnjiCYSFhTVaWSQiIjIn6w6cx8Uq/eCP8X29YauykjmijsN4VZDCDrkqiKwJYFVVFZKTkxEbG2vYplAoEBsbi127djV4XFlZGfz8/ODr64tx48bhyJEjRs/HxMRg3bp1OHfuHCRJwrZt23DixAmMGDHCZK+FiIioLXHuP9OpvSrI5Q66KkiL/lw4c+YMBEGAj48PACApKQlfffUVQkJC8MQTTzT5PAUFBdDpdHUqeB4eHjh+/Hi9xwQFBSEhIQGhoaHQarV45513EBMTgyNHjhji+fDDD/HEE0/Ax8cHVlZWUCgUWLlyJYYMGVLvOSsrK1FZWWl4XFKi71AriiJE0XSTQIqiCEmSTHoNMi22ofljG5o/S2zDQ+e0OHxO/7sq1McJwZ4OZv3622Mb3tbLDQk7MgAAW4/m4I6bPGWO6Pqa8/61KAF88MEH8cQTT+CRRx5BTk4Ohg8fjt69e+PLL79ETk4OZs2a1ZLTNkl0dDSio6MNj2NiYhAcHIwVK1Zg3rx5APQJ4O7du7Fu3Tr4+fnhzz//xPTp0+Ht7W1UbayxcOFCzJkzp872/Px8VFRUmOy1iKIIrVYLSZKgUMh+N55agG1o/tiG5s8S23DVn1f7vt8e5NRov3lz0B7b0M9WhJ1KgfIqEduP5+F8Ti6sauaHaadKS0ubvG+LEsDDhw9jwIABAIBvv/0Wffr0wY4dO7BlyxY89dRTTU4AXV1doVQqkZtrPMImNzcXnp5Ny7Stra3Rt29fpKWlAQAuXbqEV199FT/99BPGjBkDAAgNDcX+/fvxzjvv1JsAxsfHIy4uzvC4pKQEvr6+cHNzg6Oj6YbUi6IIQRDg5ubWbr7hqXnYhuaPbWj+LK0NyysvY0vqfgCAnUqJBwcHwV5t3v3/2msb3hKUjY2HclBSqcPZS9YYENBZ7pAade2sKI1p0XdMdXU11Go1AGDr1q0YO3YsAKBXr17Izs5u8nlUKhUiIiKQmJiI8ePHA9B/EyQmJmLGjBlNOodOp8OhQ4dw++23G2Krrq6u8w2kVCobLI2q1WrD66lNoVCY/BtREIQ2uQ6ZDtvQ/LENzZ8lteHGQzkovzL4Y2x4FzjaqGSOqHW0xzaMDfHAxkM5AIDfU/MxsJurzBE1rjnvXYve5d69e2P58uX466+/8Ntvv2HUqFEAgPPnz8PFxaVZ54qLi8PKlSuxevVqHDt2DNOmTUN5eTmmTJkCAJg0aRLi4+MN+8+dOxdbtmxBeno6UlJS8PDDDyMrKwuPP/44AP0UMUOHDsWLL76I7du3IyMjA6tWrcJnn32Gu+66qyUvl4iIqN3g3H9tpyOvCtKiCuCbb76Ju+66C2+//TYmT56MsLAwAMC6desMt4abauLEicjPz8esWbOQk5OD8PBwbNq0yTAw5PTp00YZbVFREaZOnYqcnBw4OzsjIiICO3fuREhIiGGfb775BvHx8XjooYdQWFgIPz8/zJ8/H0899VRLXi4REVG7cPicFgfOagEAfbo44iYfJ5kj6thqVgVJyiw0rAoS4Gond1itQpAkSWrJgTqdDiUlJXB2djZsy8zMhK2tLdzd3Rs5sv0rKSmBk5MTtFqtyfsA5uXlwd3dvV2VvKnp2Ibmj21o/iypDf/v50P4Yre+Ajj/rj54KMpP5ohaR3tuw+V/nMIbv+pnJvm/McF4/OZAmSNqWHPylxa9y5cuXUJlZaUh+cvKysLixYuRmppq9skfERFRe3Sx6jJ+3qdf+cNWpcTYMG+ZI7IMHXVVkBYlgOPGjcNnn30GACguLkZUVBTeffddjB8/HsuWLWvVAImIiAjYcCAbZZWXAQBjw7zhoLGWOSLL0FFXBWlRApiSkoKbb74ZAPD999/Dw8MDWVlZ+Oyzz/DBBx+0aoBEREQEfMWVP2TRUVcFaVECePHiRTg4OAAAtmzZggkTJkChUGDgwIHIysq6ztFERETUFDpRwq5TF/DRtjTsP1MMAAjxckQoB3+0qWFGt4E7xmjgFo0C7t69O37++Wfcdddd2Lx5M5577jkAQF5enkkHTRAREVmKTYezMWf9UWRrjVekCvV1giC07xUpOpr+/p3hoLZCaeVlbE/Nx2WdCCtl+xqs0lwtin7WrFl44YUX4O/vjwEDBhiWZtuyZQv69u3bqgESERFZmk2HszHti5Q6yR8ArEk6g02Hm77oAt04lZUCQ4LcAADaS9VIziqSOaIb16IE8J577sHp06exd+9ebN682bB92LBheO+991otOCIiIkujEyXMWX8Ujc3RNmf9UejEFs3iRi1kNBr4uPmPBm5x/dLT0xN9+/bF+fPncfbsWQDAgAED0KtXr1YLjoiIyNIkZRTWW/mrIQHI1lYgKaOw7YKiDrcqSIsSQFEUMXfuXDg5OcHPzw9+fn7o1KkT5s2b1+B6u0RERHR9eaUNJ38t2Y9ah7OdChF++vmPa1YFMWctSgD/85//YMmSJXjjjTewb98+7Nu3DwsWLMCHH36I1157rbVjJCIishjuDppW3Y9az7BgD8P/zX00cIsSwNWrV+N///sfpk2bhtDQUISGhuLpp5/GypUrsWrVqlYOkYiIyHIMCOgML6eGkzsBgJeTBgMCOrddUASgY60K0qIEsLCwsN6+fr169UJhIfskEBERtZRSIWDWHSH1Plcz+cvsO0OgVHAqmLbWkVYFaVECGBYWhiVLltTZvmTJEoSGht5wUERERJbM0ab+Zd48nTRY9nA/jOrj1cYREdCxVgVp0UTQb731FsaMGYOtW7ca5gDctWsXzpw5g19++aVVAyQiIrIkkiRh8dYThsf/vq07urvbw91Bf9uXlT95DQt2R8KODADA78dyMTbMW+aIWqZFFcChQ4fixIkTuOuuu1BcXIzi4mJMmDABR44cweeff97aMRIREVmMnacuYE+mfqLh7u72eDa2J8aFd0F0Nxcmf+1AzaogALDtyqog5qhFFUAA8Pb2xvz58422HThwAJ988gk+/vjjGw6MiIjI0lxb/XtmWA8mfe1MzaogGw9mG1YFiQp0kTusZjPvheyIiIg6kGurf2NuYl+/9qgjrArCBJCIiKgdYPXPfHSEVUGYABIREbUDrP6Zj46wKkiz+gBOmDCh0eeLi4tvJBYiIiKLxOqf+RkW7GFI2BOP5eLxmwNljqh5mlUBdHJyavTLz88PkyZNMlWsREREHRKrf+bH3FcFaVYF8NNPPzVVHERERBaJ1T/zVLMqSNaFi4ZVQZwamMC7PWIfQCIiIhmx+meeBEHAbb30VcDLooQ/zWxVECaAREREMmH1z7zFBnsY/p9oZqOBmQASERHJhNU/82bOq4K0iwRw6dKl8Pf3h0ajQVRUFJKSkhrcd9WqVRAEwehLo9EY7XPt8zVfb7/9tqlfChERUZOw+mf+alYFAWBYFcRcyJ4ArlmzBnFxcZg9ezZSUlIQFhaGkSNHIi+v4RE1jo6OyM7ONnxlZWUZPV/7uezsbCQkJEAQBNx9992mfjlERERNwupfx2Cuq4LIngAuWrQIU6dOxZQpUxASEoLly5fD1tYWCQkJDR4jCAI8PT0NXx4eHkbP137O09MTa9euxa233orAQPOao4eIiDomVv86jtqrgphTP8BmTQPT2qqqqpCcnIz4+HjDNoVCgdjYWOzatavB48rKyuDn5wdRFNGvXz8sWLAAvXv3rnff3NxcbNy4EatXr27wfJWVlaisrDQ8LikpAQCIoghRNN39fFEUIUmSSa9BpsU2NG86UcI/6Rdw6vwFdCtRICrQhb+EzZA5/hzuSCu4Wv1zs8Po3h5mFX9rM8c2rOFkY4V+XZ2xN6sIp/LLkZ5fCn8XO1liac77J2sCWFBQAJ1OV6eC5+HhgePHj9d7TFBQEBISEhAaGgqtVot33nkHMTExOHLkCHx8fOrsv3r1ajg4ODS6isnChQsxZ86cOtvz8/NRUVHRzFfVdKIoQqvVQpIkKBSyF2OpBdiG5mtbWhHe234GeWXVV7Zkwt3eGs/d4otbuzvLGhs1j7n9HEqShHc2Xa3+TY50x4UC85pCpLWZWxteK8rXFnuv9P9buycdD/TzuM4RplFaWtrkfWVNAFsiOjoa0dHRhscxMTEIDg7GihUrMG/evDr7JyQk4KGHHqozUKS2+Ph4xMXFGR6XlJTA19cXbm5ucHR0bN0XUIsoihAEAW5ubmb5DU9sQ3O16XAOXt2QDuma7fll1Xh1QzqWPtgXo/p4yhIbNZ+5/RzuSCvAgfNlAPTVv/sHBVl85dnc2vBa4yJtsfTvcwCApLMXMXOU+3WOMI3Gcp1ryZoAurq6QqlUIjfX+J55bm4uPD2b9uFrbW2Nvn37Ii0trc5zf/31F1JTU7FmzZpGz6FWq6FWq+tsVygUJv9GFAShTa5DpsM2NC86UcK8jcfqJH8AIAEQAMzbeAwj+3hZ/C9lc2IuP4eSJOGD36/+vnomtiesrZQyRtR+mEsb1qeHh0OtVUGKUFqpk2VVkOa8d7K+yyqVChEREUhMTDRsE0URiYmJRlW+xuh0Ohw6dAheXnVHT33yySeIiIhAWFhYq8VMROYtKaMQ2dqGu3ZIALK1FUjKKGy7oMhicORvx2SOq4LInmbHxcVh5cqVWL16NY4dO4Zp06ahvLwcU6ZMAQBMmjTJaJDI3LlzsWXLFqSnpyMlJQUPP/wwsrKy8Pjjjxudt6SkBN99912d7URk2fJKm9avt6n7ETUVR/52bOa2KojsfQAnTpyI/Px8zJo1Czk5OQgPD8emTZsMA0NOnz5tVNIsKirC1KlTkZOTA2dnZ0RERGDnzp0ICQkxOu8333wDSZLwwAMPtOnrIaL2zd2haX1kmrofUVOx+tex1awKUlp52bAqiJVS9jpbgwRJkurrCmPRSkpK4OTkBK1Wa/JBIHl5eXB3dzfLPg/ENjRHOlFC1IKtKCiranAfD0c1dr4yjNUZM2EOP4eSJOG+FbsMCeAHD/TF2DBvmaNqP8yhDZti+lcp2HgwGwCw5omBiAp0adPrNyd/Md93mYioBZQKAd5OjVf3bFVKVJvRmp7U/rH6ZxmG9bo6+vf3dr4qCBNAIrIo+88U4+A5/WTv1xb4ah5nFFzES98fBG+QUGtg3z/LcWvQ1VVBtrbzfoCy9wEkImpL725JNfx/zrje6OZqh7Sz+eju4wY7tTXu/3g3LlXrsO7AeQS62eHZ2J4yRksdAat/lsPZToUIP2fsydSvCpJZUA5/V3lWBbkeVgCJyGIkZRTir5MFAAAfZxtMjOyKgYEuGNGrMwYGuiDMtxM+eKAvhCt/wS/eehJr95+TMWIyd6z+WZ5htUYDt+cqIBNAIrIIkiQZVf9mDusBlVXdj8DhIR54dXSw4fGL3x9EchbnBKSWYfXP8sQGX+0HmHis/fYDZAJIRBZh56kL+OfK5M6Brna4q2+XBvd9/OYAPDDAFwBQdVnEE58l40zhxTaJkzoOVv8sUzc3e3TtbAsA2JNZCO2l6uscIQ8mgETU4dWp/sX2aHR+LkEQMHdcH8R000/hcKG8Co+t2oOSivb5QU7tE6t/lkkQBAwLbv+rgjABJKIOb3tqPlJOFwMAenrY487Q68+/Zq1UYNlDEQh003fgPplXhhlf7cNlTg9DTcDqn2Uzh1VBmAASUYcmSRLe/e1q9e+52J5QNPEXsZOtNRIm90cnW/2i7n+eyMfcDUdNEid1LKz+WbaaVUEAGFYFaW+YABJRh7b5SC4OX5n3r7e3I0b29mzW8f6udljxcASslfqk8bNdWVi1I6PV46SOg9U/UlkpMCTIDQCgvVSN5KwimSOqiwkgEXVYoijhvd+u/iKOG9706l9tUYEuWDgh1PB47oaj2Jbafkf3kbxY/SOg/a8KwgSQiDqsDYeykZpbCgAI9+2E22p9IDfXPRE+ePqWbgAAUQL+/dU+pOaUtkqc1HGw+kc12vuqIEwAiahDuqwTjX4RPz+iJwThxn4RvzAiCLffpL+FXFZ5GY+t2oP80sobOid1LKz+UY2aVUEAGFYFaU+YABJRh7R2/3mk5+s/cAcEdMbg7q43fE6FQsC794Yj1McJAHCu+BKmfrYXFdW6Gz43mT9W/+ha7XlVECaARNThVOtEvJ940vD4+eE3Xv2rYaNS4n+TIuHlpAEA7D9TjBe+OwBJklrl/GS+WP2ja9XuB/jTvnNYu/8cdp26AJ0o/+cFE0Ai6nC+Tz6L01dW7hjc3RVRgS6ten53Rw0+mdwftiolAGDDwWy8t/XkdY6ijozVP6pPd3d7uNqrAABHzpdg5jf78cDK3Rj85u/YdDhb1tiYABJRh1J5WYcPa1X/4kb0NMl1Qrwd8cH9fVFTWPwg8SR+3nfOJNei9o/VP6rP5iM5KCirqrM9R1uBaV+kyJoEMgEkog7lm6QzOK+tAADc1ssd/bo6m+xasSEe+M/twYbHL31/EHszC012PWqfWP2j+uhECXPW1z9xfM0N4Dnrj8p2O5gJIBF1GJeqdFiyLc3wOG64aap/tf1rcAAeGNAVAFClE/HE58k4feGiya9L7Qerf1SfpIxCZF/5Y7Q+EoBsbQWSMuT5o5EJIBF1GF/szjJMyzKqtyf6dHEy+TUFQcDccb0No4wLy6vwr9V7UFJRbfJrk/xY/aOG5JU2nPy1ZL/WxgSQiDqE8srLWPbHKQCAIADPtUH1r4a1UoGlD/VDNzc7AMDJvDJM/zKlXa7/Sa2L1T9qiLuDplX3a21MAImoQ1i1MxOF5frO1neGeiPI06FNr+9kY42ER/vD2dYaAPDXyQK8vv4Ip4fpwFj9o8YMCOgMLycNGvqOEAB4OWkwIKBzW4ZlwASQiMye9lI1Vlyp/ikEYGZsD1ni8HOxw4pHImGt1H/kf7H7NFbtzJQlFjI9Vv+oMUqFgNl3hgBAnSSw5vHsO0Nk+6OBCSARmb1P/s5AScVlAMCEfj7o5mYvWywDAjrjjQmhhsfzNhzF78fb1woAdONY/aOmGNXHC8se7gdPJ+PbvJ5OGix7uB9G9ZHvjwYr2a5MRNQKisqrkPB3BgDASiFg5jB5qn+13R3hg4yCcizZlgZRAv791T58Py0GwV6OcodGrYTVP2qqUX28MDzEE0kZhcgrrYC7g/62r9x/MLSLCuDSpUvh7+8PjUaDqKgoJCUlNbjvqlWrIAiC0ZdGU7cD5bFjxzB27Fg4OTnBzs4O/fv3x+nTp035MohIBiv+TEdZpb76d19/X/h2tpU5Ir244T1x+02eAIDyKh3+tWqPbKP9qHWx+kfNpVQIiO7mgnHhXRDdzaVdfL/IngCuWbMGcXFxmD17NlJSUhAWFoaRI0ciLy+vwWMcHR2RnZ1t+MrKyjJ6/tSpUxg8eDB69eqF7du34+DBg3jttdfqTRSJyHzll1Zi9ZU+diqlAjNu7S5vQLUoFALevTccYT76qWjOaysw9bNkVFTrZI6MbhSrf9QRyJ4ALlq0CFOnTsWUKVMQEhKC5cuXw9bWFgkJCQ0eIwgCPD09DV8eHh5Gz//nP//B7bffjrfeegt9+/ZFt27dMHbsWLi7uzdwRiIyR8v/OIVLVxKqB6O6wruTjcwRGbNRKbFyciS8r/T/OXCmGM9/dwBiO1gInlqG1T/qKGTtA1hVVYXk5GTEx8cbtikUCsTGxmLXrl0NHldWVgY/Pz+Iooh+/fphwYIF6N27NwBAFEVs3LgRL730EkaOHIl9+/YhICAA8fHxGD9+fL3nq6ysRGVlpeFxSUmJ4VyiaLp5vERRhCRJJr0GmRbbUD452gp8vltf/ddYKzBtaGCL2sHUbehqp8LKSRG4b8VulFfpsPFgNgJcbNtklRJL0ZY/hzvSCq5W/9zsMLq3B3/+WwE/S1tHc94/WRPAgoIC6HS6OhU8Dw8PHD9+vN5jgoKCkJCQgNDQUGi1WrzzzjuIiYnBkSNH4OPjg7y8PJSVleGNN97Af//7X7z55pvYtGkTJkyYgG3btmHo0KF1zrlw4ULMmTOnzvb8/HxUVJiuz44oitBqtZAkCQqF7MVYagG2oXze/f00qi7rP+zuDnWDdEmLvEvNP09btKGLEpgzyh8vrT8FUQKWbDsFF5UOo4NdTHI9S9NWP4eSJOGdTVerf5Mj3XGhIN9k17Mk/CxtHaWlpU3e1+xGAUdHRyM6OtrwOCYmBsHBwVixYgXmzZtnyH7HjRuH5557DgAQHh6OnTt3Yvny5fUmgPHx8YiLizM8Likpga+vL9zc3ODoaLpRe6IoQhAEuLm58RveTLEN5XGu6BLWHSkAANiplHh2ZG+42KtbdK62asMJ7u4o1lnjvxv1f9wu3JqFED8P9PeXZxLYjqSt2nBHWgEOnC8DoK/+3T8oiLd/Wwk/S1tHc8Y6yJoAurq6QqlUIjfXeI6s3NxceHp6Nukc1tbW6Nu3L9LS0gzntLKyQkhIiNF+wcHB+Pvvv+s9h1qthlpd95eHQqEw+TeiIAhtch0yHbZh21uy7RSqdfp+dFMGBcDN8cb6/rVVG/5rcCAyCi7iy39Oo0onYdqX+/Dz04PQ1aV9jFw2Z6ZuQ0mS8MHvaYbHz8T2hLWV0iTXslT8LL1xzXnvZH2XVSoVIiIikJiYaNgmiiISExONqnyN0el0OHToELy8vAzn7N+/P1JTU432O3HiBPz8/FoveCKSRWZBOb5POQsAcNBYYerNgTJH1HSCIOD1sb1xcw9XAEBheRWmrEqC9lK1zJHR9XDkL3U0sqfZcXFxWLlyJVavXo1jx45h2rRpKC8vx5QpUwAAkyZNMhokMnfuXGzZsgXp6elISUnBww8/jKysLDz++OOGfV588UWsWbMGK1euRFpaGpYsWYL169fj6aefbvPXR0St6/3Ek9BdGUU79eZAOF1Ze9dcWCsVWPJgP3R3169Wciq/HNO/TEG1jp3f2yuO/KWOSPY+gBMnTkR+fj5mzZqFnJwchIeHY9OmTYaBIadPnzYqaRYVFWHq1KnIycmBs7MzIiIisHPnTqNbvnfddReWL1+OhQsX4plnnkFQUBB++OEHDB48uM1fHxG1npO5pfh5/zkAgLOtNaYM8pc3oBZysrFGwuT+GP/RDhSWV+HvtALMXncE88f3gSAwsWhvWP2jjkiQJIkTUl2jpKQETk5O0Gq1Jh8EkpeXB3d3d/Z5MFNsw7Y1/csUbDyUDQB4ZXQvPDW02w2fU8423JtZiAdX/oOqK9W/1+4Iwb8GB7RpDB2BKdtQkiTct2KXIQH84IG+GBvm3arXIH6Wtpbm5C98l4nILBw9X2JI/lztVZgUbf59eiP9O+PNe24yPP7vxqNIPJbbyBHU1lj9o46KCSARmYVFv13tg/X0Ld1hq5K9B0uruKuvD/59m34JO0kC/v31Phw9XyJzVASw7x91bEwAiajdO3CmGFuvVMY8HTV4MKqrzBG1rudie2JMqL6ydLFKh8dX70FeiekmoaemYfWPOjImgETU7r1bq/o347bu0Fh3rPnXFAoB794bhnDfTgCA89oKTP1sLy5V6eQNzIKx+kcdHRNAImrX9mQW4s8T+uW2fJxtcF+kr8wRmYbGWomPJ0WgSyf9pNYHzmrx/Hf7IYocpycHVv+oo2MCSETt2rtbrk7q/sywHlBZddyPLXcHDf43ORJ2Kn2F85dDOXj3t9TrHEWtjdU/sgQd95OUiMzezrQC7E4vBAAEuNphQt8uMkdkesFejljyYD/U5BtLt53CD8ln5Q3KwrD6R5aACSARtUuSJBn1/Zs5rAeslJbxkXVrL3e8dsfVye1f+fEgkjIKZYzIcrD6R5bCMj5NicjsbD+Rj+QsfRWmh7s97rSwyXcfjfHHIwP1cx1W6yQ8+fleZBaUyxxVx8fqH1kKJoBE1O5IkoRFW65WYZ4b3tPiqjCCIGD2nSG4uYcrAKDoYjUeW70H2ovVMkfWcbH6R5aECSARtTtbjubi0DktACDEyxGjenvKHJE8rJQKLH2oH3q42wMA0vPL8fRXyai+snQctS5W/8iSMAEkonZFFCW8V6vvX9zwnlBYcBXGUWONhEf7w8VOBQDYkXYBs9YeAZdxb12s/pGlYQJIRO3KxkPZOJ5TCgAI8+2EYcHuMkckP9/Otvh4UgRUVwbBfJ10Gp/8nSFzVB0Lq39kaZgAElG7oRONqzDPD+8JQWAVBgAi/DrjrXtCDY/n/3IMvx3NlTGijoPVP7JETACJqN1Yu/8cTuXrR7r293c2DIAgvfF9u+CZYT0AAJIEzPxmH46c18oclflj9Y8sERNAImoXqnUiFm89aXj8/IggVv/q8VxsD8OUOBerdPjXqr3ILamQOSrzxeofWSomgETULvyQfBanCy8CAAZ1d8HAQBeZI2qfBEHA2/eEom/XTgCAnJIKTP1sLy5V6eQNzEyx+keWigkgEcmu8rIOHyRerf7FDQ+SMZr2T2OtxMePRKJLJxsAwMGzWjy3Zj9EkSODm4PVP7JkTACJSHZr9pzBea3+NuatQW6I8HOWOaL2z81BjYRH+8NebQUA2HQkB29vSZU5KvPC6h9ZMiaARCSrimodlvyeZnjM6l/TBXk64MMH+6KmaLVs+yl8t/eMvEGZCVb/yNIxASQiWX2xOwt5pZUAgJG9PXCTj5PMEZmXW4PcMeuOEMPjV386hN3pF2SMyDyw+keWjgkgEcmmvPIylm0/BQAQBP2av9R8jw4KwKRoPwBAtU7CU18kI6OgXOao2i9W/4iYABKRjFbtzMSF8ioAwB2h3ujl6ShzROZr1h0hGNrTDQBQfLEa/1q1B8UXq2SOqn1i9Y+ICSARyaSkohof/5kOAFAIwLOxPWSOyLxZKRX48MG+6OlhDwBILyjHU58n4++T+Vi7/xx2nboAHUcJs/pHdEW7SACXLl0Kf39/aDQaREVFISkpqcF9V61aBUEQjL40Go3RPo8++midfUaNGmXql0FEzfDJXxnQXqoGANzV1wfd3Oxljsj8OWqs8cnk/nCxUwEAdmcU4uFPkjDzm/14YOVuDH7zd2w6nC1zlPJi9Y9IT/YEcM2aNYiLi8Ps2bORkpKCsLAwjBw5Enl5eQ0e4+joiOzsbMNXVlZWnX1GjRpltM/XX39typdBRM1QVF6FhL8zAABWCgEzh7H611p8O9viscEB9T6Xo63AtC9SLDYJZPWP6CrZE8BFixZh6tSpmDJlCkJCQrB8+XLY2toiISGhwWMEQYCnp6fhy8PDo84+arXaaB9nZ84rRtRefPxXOkorLwMA7o30QVcXW5kj6jh0ooQvdtf9oxgAam4Az1l/1CJvB7P6R3SVrAlgVVUVkpOTERsba9imUCgQGxuLXbt2NXhcWVkZ/Pz84Ovri3HjxuHIkSN19tm+fTvc3d0RFBSEadOm4cIFTotA1B4UlFVi1Y5MAIBKqcCM21j9a01JGYXI1ja8NrAEIFtbgb9P5rddUO0Aq39ExqzkvHhBQQF0Ol2dCp6HhweOHz9e7zFBQUFISEhAaGgotFot3nnnHcTExODIkSPw8fEBoL/9O2HCBAQEBODUqVN49dVXMXr0aOzatQtKpbLOOSsrK1FZWWl4XFJSAgAQRRGiKLbWy61DFEVIkmTSa5BpsQ2bb9n2NFyq1q9be39/X3g5qmV9/zpaG+aWXGrSfk98nowJ/brgvggfhPo4QRDMNxlqShvuSCu4Wv1zs8Po3h4dps07go72cyiX5rx/siaALREdHY3o6GjD45iYGAQHB2PFihWYN28eAOD+++83PH/TTTchNDQU3bp1w/bt2zFs2LA651y4cCHmzJlTZ3t+fj4qKhr+S/pGiaIIrVYLSZKgUMh+N55agG3YPPllVfhil/72pFop4L6bnBrt79sWOlobWl9uWgJYeVnE10ln8HXSGXRz0eCO3q4Y1asznG2tTRxh67teG0qShHc2Xa3+TY50x4UCy6qAtncd7edQLqWlpU3eV9YE0NXVFUqlErm5uUbbc3Nz4enp2aRzWFtbo2/fvkhLS2twn8DAQLi6uiItLa3eBDA+Ph5xcXGGxyUlJfD19YWbmxscHU03L5koihAEAW5ubvyGN1Nsw+ZZuvsIKnX6vmePRPsjJKCLzBF1vDYc4eoGz99OI7ekAg318rOxVgKQcKlaXy04daEC7/95Fh/tOIdhvdxxX6Qvbu7haja3SK/XhjvSCnDgfBkAffXv/kFBZvPaLEVH+zmUy7WzojRG1gRQpVIhIiICiYmJGD9+PAD9N0FiYiJmzJjRpHPodDocOnQIt99+e4P7nD17FhcuXICXV/0dftVqNdRqdZ3tCoXC5N+IgiC0yXXIdNiGTXO26CK+2aNfp9ZWpcS0W7q1m/esI7WhQgG8PjYE075IgQAYJYE1Kc97E8MwuIcbNh48j2/3nkVylv7WaLVOwqYjudh0JBeejhrcE+GDeyN94Odi19Yvo9kaakNJkvBBrbWmn4ntCWurul2BSH4d6edQLs1572R/l+Pi4rBy5UqsXr0ax44dw7Rp01BeXo4pU6YAACZNmoT4+HjD/nPnzsWWLVuQnp6OlJQUPPzww8jKysLjjz8OQD9A5MUXX8Tu3buRmZmJxMREjBs3Dt27d8fIkSNleY1EBCz5PQ3VV6p/Uwb5w8W+7h9d1DpG9fHCsof7wdPJuBrg6aTBsof7YVQfL9irrTCxf1f8MC0GW+OG4MkhgXC1Vxn2zSmpwJJtaRj69nbc//Eu/JhyFpeqdG39Um4YR/4S1U/2PoATJ05Efn4+Zs2ahZycHISHh2PTpk2GgSGnT582ymiLioowdepU5OTkwNnZGREREdi5cydCQvSLoSuVShw8eBCrV69GcXExvL29MWLECMybN6/eKh8RmV5mQTm+Sz4LAHBQW2HqzYEyR9TxjerjheEhnkjKKEReaQXcHTQYENC53luf3d0dEH97MF4YGYRtx/Pw7d4z2Jaab5gqZnd6IXanF2L22iO4M9wbEyN9zWLgCEf+EjVMkCTJ8iaDuo6SkhI4OTlBq9WavA9gXl4e3N3dWfI2U2zDpolbsx8/7jsHAHgutidmtqNl39iG9csrqcCP+87h2z1nkF5QXuf5IA8H3NffF3f17YLOdqp6ztB2GmrDHWkFeOh//wDQV/82PzuECWA7xZ/D1tGc/EX2CiARdWxpeaX4eb8++etka43HBvvLGxA1ibujBk8N7YYnhwQiOasIa/acwcZD2bh45TZwam4p5m04ijd+PYbhIR64N9IXQ3q4tZsEi9U/osYxASQik3pv60nULDrx5JBucNCY3zQjlkwQBET6d0akf2fMHtu73oEjvxzKwS+HctrVwBH2/SNqHBNAIjKZY9kl2HhQv+6sq70Kk2P8ZI6IbkTNwJGJ/bsiLa8U3+09ix9SzqKgrArA1YEjS7alYWBgZ9wX6YvRfbxgo2rbUbes/hFdHxNAIjKZRb9d/SU87ZbusFXxI6ejaM8DR1j9I7o+fhoTkUkcPFuM347qJ3n3cFTjoaiuMkdEpmCtVGBEb0+M6O2JvJIK/JByDt/tvTpwpLTyMr765zS++uc0enk64N5I0w4cYfWPqGmYABKRSby75eov4Rm3dofGmpPvdnTujhpMu6UbnhoaiL1ZRfj2moEjx3NMP3CE1T+ipmECSEStLjmrEH+c0K+12qWTDe7r7ytzRNSWBEFAf//O6F9r4MiaPWeQcroYgOkGjrD6R9R0TACJqNXVrv49M6w71Fx6y2I1d+DIxP6+GNW7ZQNHWP0jajomgETUqnaeKsDOUxcAAP4utpjQz0fmiKi9aOrAkVnqIxgb7o37mjFwRJIkvJ9Ya81fVv+IGsUEkIhajSRJWFSr+jcztgeslZzVn4w1ZeDIl/+cxpdNGDiiEyX8k34Bmw+cx94sVv+ImooJIBG1mj9O5Bv9Eh4b1kXmiKi9q2/gyIaD2bhUff2BI5sOZ2PO+qPI1lYYnXNoz/azIglRe8UEkIhahSRJRvP+PRfbk7+EqcmaO3Ckb9dO+PVwTr3nSvg7A/39nTGqD6uARA3hvRkiahW/Hc3FwbNaAEAvTweM7uMpc0RkrmoGjvz49CBsjRuCJ4YEwtX+6u3fnJKKBpO/GnPWHzX0LSSiupgAkknoRAm7Tl3A2v3nsOvUBX4Qd3CiaFz9e35EEBSs/lEr6O7ugFdvD8au+GFY8UgEYoPdcb1vLQlAtrYCSRmFbRIjkTniLWBqdfX1y/Fy0mD2nSG8JdNB/Xo4B8dzSgEAYT5OiA12lzki6mislQqM7O2Jkb098fmuTLy29sh1j8krrbjuPkSWihVAalWbDmdj2hcpdTpl52grMO2LFGw6nC1TZGQqOlHCe7Um340bEdQm672S5eru7tCk/dwdNCaOhMh8sQJILaYTJVwor0ReSSXySiuQra3Awl+Oo76bvTXbXvz+IIovVcPDUQM3ezVc7dVwsVdxqhAztu7AOaTllQEAIv2cMaSHq8wRUUc3IKAzvJw0yNFW1Pt5IwDwdNJgQEDntg6NyGwwAaQ6RFHChfIq5JZUIL+0ErklFci9kuTV/JtXUon8sspm9+0rrbiMV344VGe7s601XK8khK4Oarjaq+DmoH/sZtiugoudGiorJovtRbVOxOKtJw2Pn2f1j9qAUiFg9p0hmPZFCgTAKAms+e6bfWcIR6ETNYIJoExqJi9NO1uI7mVKRAW6mvzDShQlFF7UJ3Z5pZXIu5LYXfu4oKwSl9t40EbRxWoUXazGySuVpMZ0MiSLKrg5aOBqr7qaKDqo4GavaZNkUY42bG9+TDmLrAsXAQAx3VwQ3c1F5ojIUozq44VlD/er09/Yk/2NiZqECaAM6g6SyLihQRKiKKHoYpU+mSutQP6VpC73SqUu90pyl1/aOomdQgBc7NXwcFTDw0EDd0c13B00KK+8jP/9nXHd46cM8oeD2gr5ZVXIL9UnnDVfFdXidY8vvliN4ovVSMu7fqxONtZXKokqQ4XRzeFqsmioOto3L1ls7TY0R5WXdfig1tJbz4/oKWM0ZIlG9fHC8BBP/JNegLSz+eju42aRf4gRtQQTwDZWM0ji2jSsZpDEsof7GRIISZJQdLH6yi3Yhqt2ea2U2AkC4GJ3JbFz1MDDUQ03B41RoufhqIGLnQpW9fTZ04kSNh7Kvm6/nP8bU/+tGUmSUF6lu5oUXvm3vkQxv7RpyaL2UjW0l5qeLBoSxStJYn3JY3JWIZ75en+T2rAj+3bPGZwrvgQAuCXIDRF+7G9FbU+pEDAw0AWB9jq4u7tw+iGiJmIC2IZ0ooQ56482Okji2W/2o5fXKeSXViGvtALVutZK7FRwr0nmHDVwd1DD3VFj+L+Ho/5Wan2JXVPdaL8cQRBgr7aCvdoKAa52jV6rJlksqJUYGiWKhu36bTXLSjWmJlk8lV/etBd8bUzQv845649ieIhnh65CVFTrsGTb1epf3HBW/4iIzAkTwDaUlFFYZ3qUa1VcFrH/jLbJ56zpB2d0O9ZRAw9DgqevXLXVKNu26pdTO1n0v06yCADllZdrVQ+rkG+UJFZeSRyrUFBWiYtV108WG1IzAe38jUdxX39f9HR36JAViS92ZyG3pBIAMCLEA6E+neQNiIiImoUJYBtqzqSkLnb6UbA1t2JrqnfuRhW79jkitqZfTlJGIfJKK+DuoJ+OQc6KmJ3aCnZqK/i5XD9ZvFh1GQWlVcgvq0B+aZXRreeDZ4tx8GzJdc+RsCMTCTsy4aixQoSfMyKvrHEa6uMEjbWyNV6SbMorL2P5H6cMj59j9Y+IyOwwAWxDTZ2U9PPHBuDmnm4mjsa0lArBbEeE2qqs0NXFCl1dbOs8t+vUBTywcneTz1VScRnbUvOxLTUfAKBSKnCTjxMirySFkX7OcLZTXecs7cvqXZkoKKsCANwR6oVgL0eZIyIiouZqF+WjpUuXwt/fHxqNBlFRUUhKSmpw31WrVkEQBKMvjabhxOqpp56CIAhYvHixCSJvnprJSxuqgwnQL5kW050T6bZXTWlDV3sVXr29F0b29oDLNcldlU5EclYRVvyZjqmf7UXfeb8hdtEfiP/xIH5IPovTFy5CktrvusklFdVY8Uc6AP1o8GdjWf0jIjJHslcA16xZg7i4OCxfvhxRUVFYvHgxRo4cidTUVLi717+eqKOjI1JTUw2PG5p49qeffsLu3bvh7e1tktibi5OXmr+mtOF/x/cxGsmdeeEi9mQWYm9mIfZmFiG9wHiQSVpeGdLyyvB10hkAgJuDGv39nRHpp79tHOzlcEODc1pTwt8Z0F6qBgCMD++C7u72MkdEREQtIXsCuGjRIkydOhVTpkwBACxfvhwbN25EQkICXnnllXqPEQQBnp6ejZ733Llz+Pe//43NmzdjzJgxrR53S3HyUvPXnDYUBAEBrnYIcLXDfZG+AICCskrszSzC3sxC7MkqwpFzWqNpfPJLK/HLoRz8cigHAGCrUqJfV2dE+Dmjv39n9O3aCXbqtv/RLb5YhU/+0s/zqFQImBnbo81jICKi1iFrAlhVVYXk5GTEx8cbtikUCsTGxmLXrl0NHldWVgY/Pz+Iooh+/fphwYIF6N27t+F5URTxyCOP4MUXXzTa3l5w8lLzdyNt6Gqvxqg+nhjVR/9HzKUqHfafKTYkhClZRSirvGzY/2KVDn+nFeDvtAIA+uQrxMsRkf76hDDSzxnujqZf9H7lX+kovRLXvRE+TRpQQ0RE7ZOsCWBBQQF0Oh08PDyMtnt4eOD48eP1HhMUFISEhASEhoZCq9XinXfeQUxMDI4cOQIfHx8AwJtvvgkrKys888wzTYqjsrISlZWVhsclJfpRnqIoQhSvP9lwSwgABvg7I8DuMtzcnCFAgtjGy6/RjWmtNlRbCYgKcEZUgDMA/XyRqTml2JtVpP/KLEROydXvT50o4dA5LQ6d0+LTHZkAgK6dbRDp1xmR/s6I9HNGNze7Vl2T90JZpeFaKqWA6bd2M9nPRlsTRRGSJHWY12OJ2Ibmj23YOprz/sl+C7i5oqOjER0dbXgcExOD4OBgrFixAvPmzUNycjLef/99pKSkNPkX4MKFCzFnzpw62/Pz81FR0fSpW5pLFEVotVpIkgSFon308aLmMVUbuloBo7rZYFQ3G0iSF3JKq3DgfBkOnCvDwfNlOHXB+PvydOElnC48hx/3nQMAOGmUuMnbHmFXvnq5297QlEEf/HnWMD/i2D6usK4qRV5eactfYDvCn0PzxzY0f2zD1lFa2vTPZVkTQFdXVyiVSuTm5hptz83NvW4fvxrW1tbo27cv0tL0qxL89ddfyMvLQ9euXQ376HQ6PP/881i8eDEyMzPrnCM+Ph5xcXGGxyUlJfD19YWbmxscHU03xYUoihAEAW5ubvyGN1Nt1YYeHkBY96uPtZeqkXK6SN+XMKsIB85qUXX56l9+2god/k7X4u90/aTiKisFwgzTzzijX1dnONlYN3pNnShhT2YhTuaV4bv9+rX01FYKPD+6T5vccm4r/Dk0f2xD88c2bB2NzYpyLVkTQJVKhYiICCQmJmL8+PEA9N8EiYmJmDFjRpPOodPpcOjQIdx+++0AgEceeQSxsbFG+4wcORKPPPKIYaDJtdRqNdRqdZ3tCoXC5N+IgiC0yXXIdORoQ2c7NYYFe2JYsP4PpcrLOhw+p8WezJqksBDFF6sN+1ddFrEnswh7MouAP/TbgjwcrvYj9HdGl042hqr5psPZdQa5AMDg7q7w6lR3fkRzx59D88c2NH9swxvXnPdO9lvAcXFxmDx5MiIjIzFgwAAsXrwY5eXlhmRt0qRJ6NKlCxYuXAgAmDt3LgYOHIju3bujuLgYb7/9NrKysvD4448DAFxcXODiYjwBsbW1NTw9PREUFNS2L46ojaitlIjw64wIv87AUEAUJaQXlF1J+vTTz5wuvGh0TGpuKVJzS/HlP6cB6OegjPBzhp3KCmv2nqn3OonH87DpcDZHqxMRmTnZE8CJEyciPz8fs2bNQk5ODsLDw7Fp0ybDwJDTp08bZbRFRUWYOnUqcnJy4OzsjIiICOzcuRMhISFyvQSidkehENDd3QHd3R3wwAB9d4i8kgrszbqaEB45r0XtMSvZ2gpsOJjd6HkFAHPWH8XwEE+OWiciMmOC1J6XHZBJSUkJnJycoNVqTd4HMC8vD+7u7ix5mylzbsOyysvYf7pYnxBmFWLf6WLDQI/r+XrqQLNd6u9a5tyGpMc2NH9sw9bRnPxF9gogEcnDXm2FwT1cMbiHfunByzoRy/9IxztbUq9zJJBXarrR8UREZHpMs4kIAGClVCDCz7lJ+7o7dJxRwERElogJIBEZDAjoDC8nDRrq3SdAP1hkQEDntgyLiIhaGRNAIjJQKgTMvlM/oOraJLDm8ew7QzgAhIjIzDEBJCIjo/p4YdnD/eDpZHyb19NJg2UP9+MUMEREHQAHgRBRHaP6eGF4iCeSMgqRV1oBdwf9bV9W/oiIOgYmgERUL6VC6DBTvRARkTHeAiYiIiKyMEwAiYiIiCwME0AiIiIiC8MEkIiIiMjCMAEkIiIisjBMAImIiIgsDKeBqYckSQCAkpISk15HFEWUlpZCo9FAoWAubo7YhuaPbWj+2Ibmj23YOmrylpo8pjFMAOtRWloKAPD19ZU5EiIiIqLmKS0thZOTU6P7CFJT0kQLI4oizp8/DwcHBwiC6VY+KCkpga+vL86cOQNHR0eTXYdMh21o/tiG5o9taP7Yhq1DkiSUlpbC29v7upVUVgDroVAo4OPj02bXc3R05De8mWMbmj+2ofljG5o/tuGNu17lrwZvtBMRERFZGCaARERERBaGCaCM1Go1Zs+eDbVaLXco1EJsQ/PHNjR/bEPzxzZsexwEQkRERGRhWAEkIiIisjBMAImIiIgsDBNAIiIiIgvDBFAmS5cuhb+/PzQaDaKiopCUlCR3SNRECxcuRP/+/eHg4AB3d3eMHz8eqampcodFN+CNN96AIAh49tln5Q6FmuHcuXN4+OGH4eLiAhsbG9x0003Yu3ev3GFRM+h0Orz22msICAiAjY0NunXrhnnz5jVpKTO6MUwAZbBmzRrExcVh9uzZSElJQVhYGEaOHIm8vDy5Q6Mm+OOPPzB9+nTs3r0bv/32G6qrqzFixAiUl5fLHRq1wJ49e7BixQqEhobKHQo1Q1FREQYNGgRra2v8+uuvOHr0KN599104OzvLHRo1w5tvvolly5ZhyZIlOHbsGN5880289dZb+PDDD+UOrcPjKGAZREVFoX///liyZAkA/dJzvr6++Pe//41XXnlF5uioufLz8+Hu7o4//vgDQ4YMkTscaoaysjL069cPH330Ef773/8iPDwcixcvljssaoJXXnkFO3bswF9//SV3KHQD7rjjDnh4eOCTTz4xbLv77rthY2ODL774QsbIOj5WANtYVVUVkpOTERsba9imUCgQGxuLXbt2yRgZtZRWqwUAdO7cWeZIqLmmT5+OMWPGGP08knlYt24dIiMjce+998Ld3R19+/bFypUr5Q6LmikmJgaJiYk4ceIEAODAgQP4+++/MXr0aJkj6/i4FnAbKygogE6ng4eHh9F2Dw8PHD9+XKaoqKVEUcSzzz6LQYMGoU+fPnKHQ83wzTffICUlBXv27JE7FGqB9PR0LFu2DHFxcXj11VexZ88ePPPMM1CpVJg8ebLc4VETvfLKKygpKUGvXr2gVCqh0+kwf/58PPTQQ3KH1uExASS6AdOnT8fhw4fx999/yx0KNcOZM2cwc+ZM/Pbbb9BoNHKHQy0giiIiIyOxYMECAEDfvn1x+PBhLF++nAmgGfn222/x5Zdf4quvvkLv3r2xf/9+PPvss/D29mY7mhgTwDbm6uoKpVKJ3Nxco+25ubnw9PSUKSpqiRkzZmDDhg34888/4ePjI3c41AzJycnIy8tDv379DNt0Oh3+/PNPLFmyBJWVlVAqlTJGSNfj5eWFkJAQo23BwcH44YcfZIqIWuLFF1/EK6+8gvvvvx8AcNNNNyErKwsLFy5kAmhi7APYxlQqFSIiIpCYmGjYJooiEhMTER0dLWNk1FSSJGHGjBn46aef8PvvvyMgIEDukKiZhg0bhkOHDmH//v2Gr8jISDz00EPYv38/kz8zMGjQoDrTL504cQJ+fn4yRUQtcfHiRSgUxqmIUqmEKIoyRWQ5WAGUQVxcHCZPnozIyEgMGDAAixcvRnl5OaZMmSJ3aNQE06dPx1dffYW1a9fCwcEBOTk5AAAnJyfY2NjIHB01hYODQ50+m3Z2dnBxcWFfTjPx3HPPISYmBgsWLMB9992HpKQkfPzxx/j444/lDo2a4c4778T8+fPRtWtX9O7dG/v27cOiRYvw2GOPyR1ah8dpYGSyZMkSvP3228jJyUF4eDg++OADREVFyR0WNYEgCPVu//TTT/Hoo4+2bTDUam655RZOA2NmNmzYgPj4eJw8eRIBAQGIi4vD1KlT5Q6LmqG0tBSvvfYafvrpJ+Tl5cHb2xsPPPAAZs2aBZVKJXd4HRoTQCIiIiILwz6ARERERBaGCSARERGRhWECSERERGRhmAASERERWRgmgEREREQWhgkgERERkYVhAkhERERkYZgAEhEREVkYJoBEZBEEQcDPP/8sdxjNsn37dgiCgOLiYrlDabLXX38d4eHhcodBRNfBBJCI2p1HH30UgiDU+UpLS5M7tOsyx6SNiCyPldwBEBHVZ9SoUfj000+Ntrm5uckUDVBVVWUWa5NWV1fD2tpa7jCIqJ1jBZCI2iW1Wg1PT0+jL6VSCQBYu3Yt+vXrB41Gg8DAQMyZMweXL182HHvy5EkMGTIEGo0GISEh+O233+qc/8yZM7jvvvvQqVMndO7cGePGjUNmZqbh+UcffRTjx4/H/Pnz4e3tjaCgIADA559/jsjISDg4OMDT0xMPPvgg8vLyAACZmZm49dZbAQDOzs4QBAGPPvooAEAURSxcuBABAQGwsbFBWFgYvv/+e6OYfvnlF/Ts2RM2Nja49dZbjeJpiCAIWLZsGcaOHQs7OzvMnz8fALBs2TJ069YNKpUKQUFB+Pzzzw3HZGZmQhAE7N+/37CtuLgYgiBg+/btAK5WMhMTExEZGQlbW1vExMQgNTXV6PpvvPEGPDw84ODggH/961+oqKi4bsxEJD8mgERkVv766y9MmjQJM2fOxNGjR7FixQqsWrXKkPiIoogJEyZApVLhn3/+wfLly/Hyyy8bnaO6uhojR46Eg4MD/vrrL+zYsQP29vYYNWoUqqqqDPslJiYiNTUVv/32GzZs2GA4dt68eThw4AB+/vlnZGZmGpI8X19f/PDDDwCA1NRUZGdn4/333wcALFy4EJ999hmWL1+OI0eO4LnnnsPDDz+MP/74A4A+IZ0wYQLuvPNO7N+/H48//jheeeWVJr0nr7/+Ou666y4cOnQIjz32GH766SfMnDkTzz//PA4fPownn3wSU6ZMwbZt25r9fv/nP//Bu+++i71798LKygqPPfaY4blvv/0Wr7/+OhYsWIC9e/fCy8sLH330UbOvQUQykIiI2pnJkydLSqVSsrOzM3zdc889kiRJ0rBhw6QFCxYY7f/5559LXl5ekiRJ0ubNmyUrKyvp3Llzhud//fVXCYD0008/GfYPCgqSRFE07FNZWSnZ2NhImzdvNsTg4eEhVVZWNhrrnj17JABSaWmpJEmStG3bNgmAVFRUZNinoqJCsrW1lXbu3Gl07L/+9S/pgQcekCRJkuLj46WQkBCj519++eU657oWAOnZZ5812hYTEyNNnTrVaNu9994r3X777ZIkSVJGRoYEQNq3b5/h+aKiIgmAtG3bNqPXsXXrVsM+GzdulABIly5dkiRJkqKjo6Wnn37a6DpRUVFSWFhYg/ESUfvAPoBE1C7deuutWLZsmeGxnZ0dAODAgQPYsWOHoeIHADqdDhUVFbh48SKOHTsGX19feHt7G56Pjo42OveBAweQlpYGBwcHo+0VFRU4deqU4fFNN91Up99fcnIyXn/9dRw4cABFRUUQRREAcPr0aYSEhNT7WtLS0nDx4kUMHz7caHtVVRX69u0LADh27BiioqKMnr827oZERkYaPT527BieeOIJo22DBg0yVCObIzQ01PB/Ly8vAEBeXh66du2KY8eO4amnnqoTc0sqjUTUtpgAElG7ZGdnh+7du9fZXlZWhjlz5mDChAl1ntNoNE06d1lZGSIiIvDll1/Wea72QJOapLNGeXk5Ro4ciZEjR+LLL7+Em5sbTp8+jZEjRxrdOq7vegCwceNGdOnSxeg5tVrdpJgbc22c16NQ6Hv/SJJk2FZdXV3vvrUHlAiCAACGpJeIzBcTQCIyK/369UNqamq9ySEABAcH48yZM8jOzjZUrHbv3l3nHGvWrIG7uzscHR2bfO3jx4/jwoULeOONN+Dr6wsA2Lt3r9E+NRVDnU5n2BYSEgK1Wo3Tp09j6NChDca9bt06o23Xxt1UwcHB2LFjByZPnmzYtmPHDkOFsibJzc7ONlQgaw8Iac51/vnnH0yaNOmGYyaitsUEkIjMyqxZs3DHHXega9euuOeee6BQKHDgwAEcPnwY//3vfxEbG4uePXti8uTJePvtt1FSUoL//Oc/Rud46KGH8Pbbb2PcuHGYO3cufHx8kJWVhR9//BEvvfQSfHx86r12165doVKp8OGHH+Kpp57C4cOHMW/ePKN9/Pz8IAgCNmzYgNtvvx02NjZwcHDACy+8gOeeew6iKGLw4MHQarXYsWMHHB0dMXnyZDz11FN499138eKLL+Lxxx9HcnIyVq1a1aL36MUXX8R9992Hvn37IjY2FuvXr8ePP/6IrVu3AgBsbGwwcOBAvPHGGwgICEBeXh7+7//+r9nXmTlzJh599FFERkZi0KBB+PLLL3HkyBEEBga2KG4iakNyd0IkIrrW5MmTpXHjxjX4/KZNm6SYmBjJxsZGcnR0lAYMGCB9/PHHhudTU1OlwYMHSyqVSurZs6e0adMmo0EgkiRJ2dnZ0qRJkyRXV1dJrVZLgYGB0tSpUyWtVttoDF999ZXk7+8vqdVqKTo6Wlq3bl2dARVz586VPD09JUEQpMmTJ0uSJEmiKEqLFy+WgoKCJGtra8nNzU0aOXKk9McffxiOW79+vdS9e3dJrVZLN998s5SQkNCkQSC1X1eNjz76SAoMDJSsra2lnj17Sp999pnR80ePHpWio6MlGxsbKTw8XNqyZUu9g0BqX3vfvn0SACkjI8Owbf78+ZKrq6tkb28vTZ48WXrppZc4CITIDAiSVKsTCBERERF1eJwHkIiIiMjCMAEkIiIisjBMAImIiIgsDBNAIiIiIgvDBJCIiIjIwjABJCIiIrIwTACJiIiILAwTQCIiIiILwwSQiIiIyMIwASQiIiKyMEwAiYiIiCwME0AiIiIiC/P/zQBPZAhtulYAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 650x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from training.loop import run_federated_training\n",
        "from configs.base_config import use_teleportation as CFG_TEL, noise_preset, shots_used,aggregation\n",
        "from training.metrics import metrics_init, metrics_log_round, metrics_finalize, compute_auc,metrics_summarize\n",
        "from viz.plots import plot_accuracy_curve, plot_val_loss, plot_time_per_round, plot_fidelity_vs_delta_acc, plot_beta_hist, plot_client_fairness_last_round\n",
        "# Initialize metrics store once\n",
        "metrics_store = metrics_init(\n",
        "    log_path=os.path.join(drive_root, \"teleport_metrics_Perturb_shrink.csv\")\n",
        ")\n",
        "\n",
        "#new\n",
        "from ml import optimizers as mlopt\n",
        "from configs.base_config import drive_root\n",
        "import os\n",
        "\n",
        "mlopt.meta_trace_enable(\n",
        "    path=os.path.join(drive_root, \"meta_trace.csv\"),  # or None to skip CSV\n",
        "    every=5                                           # print every 5 callbacks\n",
        ")\n",
        "\n",
        "###########\n",
        "global_acc, clients_train, clients_test, round_times, val_losses, info_last = run_federated_training(\n",
        "    clients=clients,\n",
        "    num_federated_layers=num_federated_layers,\n",
        "    num_deep_unfolding_iterations=num_deep_unfolding_iterations,\n",
        "    initial_learning_rate=initial_learning_rate,\n",
        "    initial_perturbation=initial_perturbation,\n",
        "    num_features=num_features,\n",
        "    best_client_csv_file=best_client_csv_file,\n",
        "    global_csv_file=global_csv_file,\n",
        "    local_csv_file=local_csv_file,\n",
        "    validation_csv_file=validation_csv_file,\n",
        "    test_sequences=test_sequences,\n",
        "    test_labels=test_labels,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    use_teleportation=CFG_TEL,          # ← important\n",
        "    noise_preset=noise_preset,\n",
        "    shots_used=shots_used,\n",
        "    metrics=metrics_store,   # <-- pass it in\n",
        "    aggregation=aggregation           # <--- switch here\n",
        ")\n",
        "\n",
        "rows_np = metrics_finalize(metrics_store)   # if you need the in-memory array\n",
        "#summary = metrics_summarize(metrics_store)  # prints a concise summary, returns a dict\n",
        "\n",
        "# quick visuals\n",
        "rounds = list(range(len(global_acc)))\n",
        "plot_accuracy_curve(rounds, global_acc, label=\"Global accuracy (DT-DUQFL)\")\n",
        "plot_val_loss(rounds, val_losses, label=\"Central validation loss\")\n",
        "plot_time_per_round(rounds, round_times)\n",
        "\n",
        "if info_last is not None:\n",
        "    # this uses \"last\" round's info; in your logger you kept per-round arrays; adapt if needed\n",
        "    pass\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}